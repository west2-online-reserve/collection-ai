{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "import json\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "with open('IMDB.json','r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "train_data = data['train']\n",
    "test_data = data['test']\n",
    "\n",
    "for item in train_data:\n",
    "    X_train.append(item['seq'])\n",
    "    y_train.append(int(item['label']))\n",
    "    \n",
    "for item in test_data:\n",
    "    X_test.append(item['seq'])\n",
    "    y_test.append(int(item['label']))\n",
    "   \n",
    "print(f\"X_train: {len(X_train)}\\ny_train: {len(y_train)}\\nX_test: {len(X_test)}\\ny_test: {len(y_test)}\")\n",
    "print(f\"X_train[0]: {X_train[0][0:100]}\\ny_train[0]: {y_train[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5380eef259049697"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 清洗数据\n",
    "import re\n",
    "\n",
    "def clean_str(string):\n",
    "    string = string.lower()\n",
    "    string = re.sub(r\"[^a-z\\-!?\\ ]\", \"\", string)        \n",
    "    return string\n",
    "\n",
    "X_train = [clean_str(string) for string in X_train]\n",
    "X_test = [clean_str(string) for string in X_test]\n",
    "\n",
    "X_train[0:100]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f419d987e60c1072"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('imdb.vocab') as vocab:\n",
    "    vocab = vocab.readlines()\n",
    "    vocab = [word.strip() for word in vocab]\n",
    "    vocab = ['<PAD>'] + vocab\n",
    "\n",
    "len(vocab), vocab[0:10]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b05a4e000342d5cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 构建词典\n",
    "word2idx = {word:idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx:word for idx, word in enumerate(vocab)}\n",
    "\n",
    "print(list(word2idx.items())[0:10])"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e7172585317d09ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 进行one-hot编码\n",
    "encoded_X_train = [[word2idx.get(word, 0) for word in string.split(' ')] for string in X_train]\n",
    "encoded_X_test = [[word2idx.get(word, 0) for word in string.split(' ')] for string in X_test]\n",
    "\n",
    "print(f\"X_train: {X_train[0:100]}\\n\")\n",
    "print(f\"encoded_X_train:{encoded_X_train[0:100]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "cf909b07cda40176"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据截断\n",
    "max_len = 400\n",
    "\n",
    "encoded_X_train = [string[0:max_len] for string in encoded_X_train]\n",
    "encoded_X_test = [string[0:max_len] for string in encoded_X_test]"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ee748c8611b8f14c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b0be8a59237c8e4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 对数据进行padding\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "X_train = pad_sequence([torch.tensor(string) for string in encoded_X_train], batch_first=True)\n",
    "X_test = pad_sequence([torch.tensor(string) for string in encoded_X_test], batch_first=True)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "37cb80581b5d96c4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "X_train = X_train.to(device)\n",
    "X_test = X_test.to(device)\n",
    "y_train = torch.tensor(y_train).to(device)\n",
    "y_test = torch.tensor(y_test).to(device)\n",
    "\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4835733b3c81a2dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 构建数据集\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "train_data = TensorDataset(X_train, torch.tensor(y_train))\n",
    "test_data = TensorDataset(X_test, torch.tensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "for x, y in train_loader:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f0420ed017405429"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "class IMDBModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(IMDBModel, self).__init__()\n",
    "        \n",
    "        # 词嵌入层\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # 双向LSTM层\n",
    "        self.bilstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(hidden_dim*2, num_classes) # 2是因为是双向的\n",
    "        \n",
    "        #Dropout层\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        # 词嵌入\n",
    "        embedded_seq = self.embedding(input_seq)\n",
    "\n",
    "        # 双向LSTM编码\n",
    "        lstm_output, _ = self.bilstm(embedded_seq)\n",
    "\n",
    "        # 获取最后一个时间步的输出\n",
    "        lstm_output = lstm_output[:, -1, :]\n",
    "\n",
    "        # 使用Dropout层防止过拟合\n",
    "        lstm_output = self.dropout(lstm_output)\n",
    "\n",
    "        # 通过全连接层进行分类\n",
    "        output = self.fc(lstm_output)\n",
    "\n",
    "        return output\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "4f48891ddc2c301c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "import torch.optim as optim\n",
    "\n",
    "model = IMDBModel(len(vocab), 128, 128, 2, 2)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 10\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e2685ec1b352282e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, print_every=100, save_path='IMDB_model.pth'):\n",
    "    best_val_accuracy = 0.0\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_loader, 0):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            \n",
    "            # 打印训练信息\n",
    "            if (i + 1) % print_every == 0:\n",
    "                train_loss = running_loss / print_every\n",
    "                train_accuracy = 100 * correct_train / total_train\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Iteration [{i+1}/{len(train_loader)}]')\n",
    "                print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "                running_loss = 0.0\n",
    "                correct_train = 0\n",
    "                total_train = 0\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "\n",
    "        # 验证模型\n",
    "        model.eval()\n",
    "        running_loss = 0.0\n",
    "        correct_val = 0\n",
    "        total_val = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val += labels.size(0)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = running_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct_val / total_val\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "        print(f'Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%')\n",
    "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "        \n",
    "        # 如果验证性能优于当前最佳性能，则保存模型\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = val_accuracy\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f'Saved the best model with validation accuracy: {best_val_accuracy:.2f}%')\n",
    "\n",
    "    # 绘制图像\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss', marker='o')\n",
    "    plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, num_epochs+1), train_accuracies, label='Train Accuracy', marker='o')\n",
    "    plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return train_losses, train_accuracies, val_losses, val_accuracies\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2ae967bae95fcf69"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_losses, train_accuracies, val_losses, val_accuracies = train(model, train_loader, test_loader, loss_fn, optimizer, epochs)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8a954d92105fbc44"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
