1.LSTM
2.GRU
3.BatchNormalization
4.LayerNormalization
5.Dropout
6.Adam
7.Conv2d
8.nll_loss

1.LSTM

import torch
import torch.nn as nn

# 定义一个简单的LSTM模型
class SimpleLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(SimpleLSTM, self).__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = self.fc(out[:, -1, :])  # 取序列最后一个时刻的输出作为最终输出
        return out

# 创建一个简单的LSTM模型实例
model = SimpleLSTM(input_size=10, hidden_size=20, num_layers=2, output_size=1)

# 输入数据
input_data = torch.randn(3, 5, 10)  # 3个样本，每个样本序列长度为5，输入特征为10

# 前向传播
output = model(input_data)

在这个例子中，nn.LSTM 接收输入的大小（input_size）、隐藏层的大小（hidden_size）、LSTM层的层数（num_layers），并返回输出序列和最后一个时刻的隐藏状态。nn.Linear 用于将 LSTM 的输出映射到最终的输出。这只是一个简单的示例，实际应用中，可以根据任务和数据的不同来调整模型的结构和参数。



2.GRU

import torch
import torch.nn as nn

class SimpleGRU(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(SimpleGRU, self).__init__()
        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        out, _ = self.gru(x)
        out = self.fc(out[:, -1, :])
        return out

# 创建一个简单的GRU模型实例
gru_model = SimpleGRU(input_size=10, hidden_size=20, num_layers=2, output_size=1)

# 输入数据
input_data = torch.randn(3, 5, 10)  # 3个样本，每个样本序列长度为5，输入特征为10

# 前向传播
gru_output = gru_model(input_data)

在这个例子中，nn.GRU 接收输入的大小（input_size）、隐藏层的大小（hidden_size）、GRU层的层数（num_layers），并返回输出序列和最后一个时刻的隐藏状态。nn.Linear 用于将 GRU 的输出映射到最终的输出。这只是一个简单的示例，实际应用中，可以根据任务和数据的不同来调整模型的结构和参数。



3.BatchNormalization

import torch
import torch.nn as nn

class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(100, 200)
        self.bn1 = nn.BatchNorm1d(200)
        self.fc2 = nn.Linear(200, 10)

    def forward(self, x):
        x = self.fc1(x)
        x = self.bn1(x)
        x = torch.relu(x)
        x = self.fc2(x)
        return x

# 创建一个简单的模型实例
model = SimpleModel()

# 输入数据
input_data = torch.randn(32, 100)  # 32个样本，每个样本输入特征为100

# 前向传播
output = model(input_data)

在这个例子中，nn.BatchNorm1d 被添加在第一个全连接层后面。在训练时，Batch Normalization 会自动计算每个特征的均值和标准差，并用于标准化输入。在实际应用中，Batch Normalization 层通常被添加在激活函数之前。



4.LayerNormalization

import torch
import torch.nn as nn

class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc1 = nn.Linear(100, 200)
        self.ln1 = nn.LayerNorm(200)
        self.fc2 = nn.Linear(200, 10)

    def forward(self, x):
        x = self.fc1(x)
        x = self.ln1(x)
        x = torch.relu(x)
        x = self.fc2(x)
        return x

# 创建一个简单的模型实例
model = SimpleModel()

# 输入数据
input_data = torch.randn(32, 100)  # 32个样本，每个样本输入特征为100

# 前向传播
output = model(input_data)


在这个例子中，nn.LayerNorm 被添加在第一个全连接层后面。与 Batch Normalization 不同，Layer Normalization 不需要计算每个特征的均值和标准差，而是在每个样本上独立进行标准化。 Layer Normalization 在一些场景下表现良好，特别是在处理序列数据时，例如自然语言处理任务。



5.Dropout
import torch
import torch.nn as nn

class SimpleModelWithDropout(nn.Module):
    def __init__(self):
        super(SimpleModelWithDropout, self).__init__()
        self.fc1 = nn.Linear(100, 200)
        self.dropout = nn.Dropout(p=0.5)  # p是丢弃的比例
        self.fc2 = nn.Linear(200, 10)

    def forward(self, x):
        x = self.fc1(x)
        x = torch.relu(x)
        x = self.dropout(x)  # 在全连接层后应用Dropout
        x = self.fc2(x)
        return x

# 创建一个带有Dropout的简单模型实例
model_with_dropout = SimpleModelWithDropout()

# 输入数据
input_data = torch.randn(32, 100)  # 32个样本，每个样本输入特征为100

# 前向传播
output_with_dropout = model_with_dropout(input_data)

在这个例子中，nn.Dropout 被添加在第一个全连接层后面。p=0.5 表示在训练时每次迭代中，被丢弃的神经元的比例为 50%。 Dropout 的比例是一个超参数，可以根据实际任务进行调整。 Dropout 通常被用于全连接层和卷积层中。



6.Adam
import torch
import torch.nn as nn
import torch.optim as optim

# 创建一个简单的线性回归模型
class SimpleLinearRegression(nn.Module):
    def __init__(self):
        super(SimpleLinearRegression, self).__init__()
        self.linear = nn.Linear(1, 1)

    def forward(self, x):
        return self.linear(x)

# 准备数据
X = torch.randn(100, 1)  # 输入特征
y = 3 * X + 2 + 0.5 * torch.randn(100, 1)  # 添加一些噪声的目标值

# 创建模型和Adam优化器
model = SimpleLinearRegression()
optimizer = optim.Adam(model.parameters(), lr=0.01)

# 定义损失函数
criterion = nn.MSELoss()

# 模型训练
epochs = 1000
for epoch in range(epochs):
    # 前向传播
    y_pred = model(X)
    
    # 计算损失
    loss = criterion(y_pred, y)
    
    # 梯度清零
    optimizer.zero_grad()
    
    # 反向传播
    loss.backward()
    
    # 参数更新
    optimizer.step()
    
    # 每隔一定步数输出一次损失
    if (epoch+1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')

# 查看训练后的模型参数
print("训练后的模型参数:")
for name, param in model.named_parameters():
    print(f"{name}: {param.item()}")


这个例子中，我们首先定义了一个简单的线性回归模型 SimpleLinearRegression，然后使用Adam优化器对模型进行训练。训练过程中，我们使用均方误差损失（nn.MSELoss）来度量模型预测值与真实值之间的差异。在每个训练步骤中，我们通过调用 optimizer.zero_grad() 清零梯度，然后进行反向传播和参数更新。最后，我们输出每100个epoch的损失，以及训练结束后的模型参数。



7.Conv2d
import torch
import torch.nn as nn

# 定义简单的卷积神经网络模型
class SimpleCNN(nn.Module):
    def __init__(self, num_classes):
        super(SimpleCNN, self).__init__()
        # 输入图像的通道数为3（RGB图像）
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.fc = nn.Linear(32 * 8 * 8, num_classes)  # 假设输入图像大小为32x32

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)
        
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)
        
        # 将特征图展平成一维向量，用于全连接层
        x = x.view(x.size(0), -1)
        
        x = self.fc(x)
        return x

# 创建模型实例
num_classes = 10  # 假设有10个类别
model = SimpleCNN(num_classes)

# 定义输入张量（batch_size, channels, height, width）
input_data = torch.randn(32, 3, 32, 32)  # 生成一个大小为32x32的RGB图像

# 模型前向传播
output = model(input_data)

# 打印输出的形状
print("Output shape:", output.shape)


在这个例子中，SimpleCNN 模型包含两个卷积层 (nn.Conv2d)，激活函数 (nn.ReLU) 和池化层 (nn.MaxPool2d)，最后是一个全连接层 (nn.Linear) 用于分类。这个模型可以接受输入大小为 32x32 的 RGB 图像，输出一个包含 10 个类别分数的向量。在卷积层中，in_channels 表示输入通道数，out_channels 表示输出通道数，kernel_size 是卷积核大小，stride 是步长，padding 是填充大小。




8.nll_loss

```python
import torch
import torch.nn.functional as F

# 模型输出和目标标签
output = torch.rand(5, 10)  # 5个样本，每个有10个类别的对数概率
target = torch.randint(0, 10, (5,))  # 随机生成目标标签

# 计算负对数似然损失
loss = F.nll_loss(output, target)

print(loss)
```

假设 `output` 是模型的输出，其中每一行表示一个样本，每一列表示一个类别的对数概率。`target` 是对应的目标标签，表示每个样本的真实类别索引。

1. **模型输出 `output`：**
   ```
   tensor([[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
           [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.1],
           [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.1, 0.2],
           [0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.1, 0.2, 0.3],
           [0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 0.1, 0.2, 0.3, 0.4]])
   ```

   这是一个5个样本、每个样本有10个类别对数概率的输出。

2. **目标标签 `target`：**
   ```
   tensor([2, 5, 7, 4, 9])
   ```

   这是五个样本的目标标签，表示每个样本的真实类别索引。

3. **计算负对数似然损失：**
   - 对于每个样本，找到模型输出中对应目标标签的对数概率，并取负值。
   - 对这些负值求均值，即计算总的负对数似然损失。

   具体计算如下：

   - 对于第一个样本（目标标签为2）：\[ -\log(0.3) \]
   - 对于第二个样本（目标标签为5）：\[ -\log(0.7) \]
   - 对于第三个样本（目标标签为7）：\[ -\log(0.9) \]
   - 对于第四个样本（目标标签为4）：\[ -\log(0.8) \]
   - 对于第五个样本（目标标签为9）：\[ -\log(0.4) \]

   计算总的负对数似然损失：\[ \text{loss} = \frac{1}{5} \left( -\log(0.3) -\log(0.7) -\log(0.9) -\log(0.8) -\log(0.4) \right) \]

   最后，打印得到的总损失。

这个例子中，每个样本的损失是其对应类别的对数概率的负对数，损失越小表示模型对真实类别的预测越准确。