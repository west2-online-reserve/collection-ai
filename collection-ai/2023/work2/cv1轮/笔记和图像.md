第一种方式：Resnet50(参数量好像大了4m)

验证集一个epoch的acc和loss：


32*32的图像，训练明显表现欠拟合现象，卡45%左右上不去。

数据增强的最有效方法是resize 128*128，训练时间飙升，大类15个epoch就能上60，估计一直训练下去，验证集能上80%

然后用迁移学习训练了最后的全连接层，验证集67%左右

![1703625489048](image/笔记和图像/1703625489048.png)

第二种方式：LSTM+resnet18

验证集一个epoch的acc和loss：

![1703625559168](image/笔记和图像/1703625559168.png)

![1703624727379](image/笔记和图像/1703624727379.png)

思路就是RNN+CNN

把张量

shape32,3,32,32

reshape32,3,1024

LSTM层batch_first=True

再把张量变回32,3,1024丢回resnet18

(resnet18调用了预训练模型)，同样用了迁移学习

最后大类验证集61%左右

如果resize 64*64，要让LSTM的 hidden_size取合适的值 , 会炸显存，resize后估计能上65%
