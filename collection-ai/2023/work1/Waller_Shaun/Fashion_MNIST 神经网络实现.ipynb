{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "251e0fd0-873a-4e99-bd77-a2935694cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from d2l import torch as d2l\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #是否用gpu训练\n",
    "BATCH_SIZE = 64 # 每批次处理的数据\n",
    "EPOCHS = 10 #训练数据集的轮次\n",
    "d2l.use_svg_display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72f4df2c-a241-401c-a9c1-3806c8d93d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "def get_dataloader_workers():\n",
    "    \"\"\"使用四个进程来读取数据\"\"\"\n",
    "    return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ccdeeda-502c-4e90-bad7-43a612afd419",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"加载数据并封装的集合\"\"\"\n",
    "def load_data_fashion_mnist(batch_size, resize=None):\n",
    "    trans = [transforms.ToTensor()]\n",
    "    if resize:\n",
    "        trans.insert(0,transforms.Resize(resize))\n",
    "    trans = transforms.Compose(trans)\n",
    "    mnist_train = torchvision.datasets.FashionMNIST(root=\"../data\", train=True, transform=trans, download=True)\n",
    "    mnist_test = torchvision.datasets.FashionMNIST(root=\"../data\", train=False, transform=trans, download=True)\n",
    "\n",
    "    return (data.DataLoader(mnist_train,batch_size, shuffle=True,num_workers=get_dataloader_workers()),\n",
    "            data.DataLoader(mnist_test,batch_size, shuffle=True,num_workers=get_dataloader_workers()))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74975bb6-7d75-4185-9e8a-6bbe71200af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digit(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5) # 1灰度图片的通道 10输出通道 5：kernel卷积核\n",
    "        self.conv2 = nn.Conv2d(10,20,3) #10:输入通道 20：输出通道 3：kernel\n",
    "        #全连接层\n",
    "        self.fc1 =nn.Linear(20*10*10,500) #20*10*10:输入通道，500：输出通道\n",
    "        self.fc2 = nn.Linear(500,10)#500:输入通道，10：输出通道\n",
    "\n",
    "    def forward(self,x):\n",
    "        input_size = x.size(0) #batch_size x 1(灰度） x 28 x 28（像素）\n",
    "        x = self.conv1(x) #输入：batch*1*28*28，输出：batch*10*24*24（28-5+1=24）\n",
    "        x = F.relu(x)#激活函数 保持形状不变 输出：batch*10*24*24\n",
    "        x = F.max_pool2d(x,2,2)#池化层 ,把x变成分块矩阵，找其中的最大值（提取图片最明显的特征，忽略小细节）\n",
    "                                #输入batch*10*24*24 输出：batch*10*12*12 （步长为2，减半）\n",
    "        x = self.conv2(x) #输入batch*10*12*12 输出：batch*20*10*10（12-3+1=10）\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x = x.view(input_size,-1)# 拉平，-1自动计算维度，20*10*10=2000 \n",
    "        x = self.fc1(x) #输入：batch*2000 输出：batch*500（全连接层定义500）\n",
    "        x = F.relu(x) # 保持shape不变\n",
    "\n",
    "        x = self.fc2(x) #输入：Batch*500 输出：batch*10\n",
    "\n",
    "        output = F.log_softmax(x,dim=1) #计算分类后，每个数字的概率值\n",
    "        return output\n",
    "#定义优化器\n",
    "model = Digit().to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())#优化器，用adam每个训练参数的学习率可以自适应变化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb82f539-15b2-46cc-b1fc-fa21c242e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练方法\n",
    "def train_model(model, device, train_loader, optimizer, epoch):\n",
    "    #模型训练\n",
    "    model.train()\n",
    "    for batch_index,(data,target) in enumerate(train_loader):\n",
    "        #部署到device上\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        #梯度初始化\n",
    "        optimizer.zero_grad()\n",
    "        #预测 训练后的结果\n",
    "        output = model(data)\n",
    "        #计算损失\n",
    "        loss = F.cross_entropy(output,target)#交叉熵损失，针对多分类任务\n",
    "        #反向传播 更新权重，神经元参数\n",
    "        loss.backward()\n",
    "        #参数优化\n",
    "        optimizer.step()\n",
    "        if batch_index % 3000 ==0:\n",
    "            print(\"Train Epoch:{}\\t Loss:{:.6f}\\n\".format(epoch,loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09a7478b-6de7-4cda-a779-ad159b72f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试方法\n",
    "def test_model(model, device, test_loader):\n",
    "    #模型验证\n",
    "    model.eval()\n",
    "    #正确率\n",
    "    correct = 0.0\n",
    "    #测试损失\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad(): #不会计算梯度，也不进行反向传播\n",
    "        for data, target in test_loader:\n",
    "            #部署\n",
    "            data,target = data.to(device), target.to(device)\n",
    "            #测试数据\n",
    "            output = model(data)\n",
    "            #计算损失\n",
    "            test_loss += F.cross_entropy(output,target).item()\n",
    "            #找出最大值下标\n",
    "            pred = output.argmax(dim=1)\n",
    "            #累计正确率\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100.0*correct / len(test_loader.dataset)\n",
    "        print(\"Test_Average Loss:{:.4f}\\t Accuracy:{:.3f}%\\n\".format(test_loss,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30d3bb93-dd2e-436a-9330-9e95fc534932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:1\t Loss:2.294102\n",
      "\n",
      "Test_Average Loss:0.0059\t Accuracy:86.630%\n",
      "\n",
      "Train Epoch:2\t Loss:0.351351\n",
      "\n",
      "Test_Average Loss:0.0051\t Accuracy:88.290%\n",
      "\n",
      "Train Epoch:3\t Loss:0.291299\n",
      "\n",
      "Test_Average Loss:0.0044\t Accuracy:89.850%\n",
      "\n",
      "Train Epoch:4\t Loss:0.292003\n",
      "\n",
      "Test_Average Loss:0.0044\t Accuracy:89.840%\n",
      "\n",
      "Train Epoch:5\t Loss:0.297476\n",
      "\n",
      "Test_Average Loss:0.0042\t Accuracy:90.290%\n",
      "\n",
      "Train Epoch:6\t Loss:0.151213\n",
      "\n",
      "Test_Average Loss:0.0044\t Accuracy:90.040%\n",
      "\n",
      "Train Epoch:7\t Loss:0.168174\n",
      "\n",
      "Test_Average Loss:0.0041\t Accuracy:91.490%\n",
      "\n",
      "Train Epoch:8\t Loss:0.310686\n",
      "\n",
      "Test_Average Loss:0.0044\t Accuracy:90.370%\n",
      "\n",
      "Train Epoch:9\t Loss:0.132526\n",
      "\n",
      "Test_Average Loss:0.0043\t Accuracy:91.120%\n",
      "\n",
      "Train Epoch:10\t Loss:0.053007\n",
      "\n",
      "Test_Average Loss:0.0049\t Accuracy:91.020%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#调用方法，输出结果\n",
    "train_loader,test_loader=load_data_fashion_mnist(BATCH_SIZE)\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train_model(model,DEVICE,train_loader,optimizer,epoch)\n",
    "    test_result = test_model(model,DEVICE,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
