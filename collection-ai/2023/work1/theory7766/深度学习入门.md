#work3:mnist集
##安装:[相应的博客链接](https://blog.csdn.net/weixin_47566927/article/details/120918815)
##一、入门基础
###（一）数据操作+数据处理
####1.访问元素
[::3,::2]：每三行一跳，每两列一跳。
####2.数据操作
#####1）张量（n维数组）Numpy:ndarray Pytorch/TensorFlow:tensor
Pytorch张量转换为Numpy张量：X.numpy() 

**构造：**

- a=torch.arrange(12,dtype=torch.float32)
- 使用python列表赋值
- 使用逻辑运算符
- zeros_like(Y)【Y一样的形状且全0】
- 使用numpy张量A初始化torch.tensor(A)
- B=A.clone()

常用：

	# 形状：
	a.shape
	# 改变形状（可使用-1自动计算出另一维度）
	a.reshape(3,4) 
	# 元素总数：
	a.numel()
	# 求和：
	a.sum()
	a.sum(axis=0)
	a.sum(axis=[0,1])
	a.sum(axis=1,keepdims=True)【保持原有维数】
	# 累积求和：
	cumsum(axis=0)
	# 全0/1：
	torch.zeros((2,3,4))
	torch.ones((2,3,4))
	# 合并：
	cat((X,Y),dim=0) 【dim为拼接维度】
	# 平均值【创建时需为float】：
	A.mean(axis=0),A.sum(axis=0）/A.shape[0] 
	A.mean(),A.sum()/A.numel()
	# 执行原地操作：
	X+=Y/Y[:]=Y+X

计算：+  -  *  /  ** 均为按元素运算【存在广播机制】(其中，*为Hadamard product)


Q：view只能作用在连续的张量上（张量中元素的内存地址是连续的）。而reshape连续or非连续都可以。调用x.reshape的时候，如果x在内存中是连续的，那么x.reshape会返回一个view（原地修改，此时内存地址不变），否则就会返回一个新的张量（这时候内存地址变了）。所以推荐的做法是，想要原地修改就直接view，否则就先clone()再改。

#####2)数据预处理
	#读取数据集
	import os

	os.makedirs(os.path.join('..', 'data'), exist_ok=True)
	data_file = os.path.join('..', 'data', 'house_tiny.csv')
	with open(data_file, 'w') as f:
	    f.write('NumRooms,Alley,Price\n')  # 列名
	    f.write('NA,Pave,127500\n')  # 每行表示一个数据样本
	    f.write('2,NA,106000\n')
	    f.write('4,NA,178100\n')
	    f.write('NA,NA,140000\n')
	import pandas as pd
	data = pd.read_csv(data_file)
	#处理缺失值
	inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]
	inputs = inputs.fillna(inputs.mean())（插值法）
	#注意稀疏情况
	inputs = pd.get_dummies(inputs, dummy_na=True)
	# 转换成张量模式
	import torch

	X = torch.tensor(inputs.to_numpy(dtype=float))
	y = torch.tensor(outputs.to_numpy(dtype=float))

#####3）线性代数
A=torch.arrange(20).reshape(5,4)

转置：A.T(A不变）

点乘积：torch.dot(x,y)【仅一维向量】/类似于sum(x*y)

数乘：torch.mul(A,2）

矩阵向量乘法：A是m×n的矩阵，x为n×1的矩阵。矩阵向量积Ax是一个长度为m的列向量
torch.mv(A,x)

矩阵乘法：[mm【二维，无广播机制】,bmm【3维，且第一维度需相等】,matmul/@【均一维为点乘运算,均二维=mm,一维与二维具体详见链接](https://blog.csdn.net/weixin_45640609/article/details/125979352)】

L2范数：tensor.norm(x)【针对向量：元素平方和后开根号】 L1范数：tensor.abs(u).sum()

#####4）矩阵计算

**grad梯度/求导**

- y是标量，x是向量的情况。实际上就是y=f(x1,x2,...,xn)的意思。拿y=f(x1,x2)为例解释，有一个三维坐标轴体系，水平面的横轴和竖轴分别是x1、x2，立面上的轴是y，水平面上任意一个点(x1,x2)都对应y轴上的一个点，很明显这就是一个面，因此他的导数是一个向量，所以结果是横着写的。
- y是向量，x是标量的情况。这实际上就是【y1,y2,...,yn】=【f(x1),f(x2),...,f(xn)】，对x求导就是求出y=yi时那一个点上的斜率，是标量，所以结果是竖着写的。
- y、x都是向量的情况。根据上面描述，求导实际上就是求出了y=yi时，那一个平面形状边缘上的向量，因此是横着写的。

#####5）自动求导

计算一个函数在指定值上的导数

	# 存储梯度
	# 等价于x.torch.arange(4.0,requires_grad=True)
	y = 2 * torch.dot(x, x)
	x=torch.arange(4.0)
	x.requries_grad_(True)
	# 反向传播函数自动计算y关于x每个分量的梯度
	y.backward()
	x.grad == 4*x
	# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值
	x.grad.zero_()
将某些记录移动到记录的计算图之外
	
	y=x*x
	# 将y退化成与x无关的数
	u=y.detach()
	z=u*x
	z.sum().backward()
	x.grad==u
	
	
	
#####6)线性回归

y=<**w**,**x**>+b

w权重，b偏置/偏移量/截距

 **损失函数(拟合程度的度量)**
能够量化目标的实际值与预测值之间的差距。 通常我们会选择非负数作为损失，且数值越小表示损失越小，完美预测时的损失为0。 回归问题中最常用的损失函数是平方误差函数。

在训练模型时，我们希望寻找一组参数（ w∗,b∗
 ）， 这组参数能最小化在所有训练样本上的总损失。

- 线性回归是对n维输入的加权，外加偏差
- 使用平方损失来衡量预测值和真实值的差异
- 线性回归有显示解/解析解
- 线性回归可以看做是单层神经网络

**梯度下降**

通过不断地在损失函数递减的方向上更新参数来降低误差【计算损失函数关于模型参数的导数】

**小批量随机梯度下降(深度学习默认的求解算法)**

每次需要计算更新的时候随机抽取一小批样本B，它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数η
 ，并从当前参数的值中减掉。

算法的步骤如下： （1）初始化模型参数的值，如随机初始化； （2）从数据集中随机抽取小批量样本且在负梯度的方向上更新参数，并不断迭代这一步骤。 对于平方损失和仿射变换，我们可以明确地写成如下形式:

超参数（提前设定好）：B为*批量大小*，η为*学习率*。

超参数通常是我们根据训练迭代结果来调整的， 而训练迭代结果是在独立的验证数据集（validation dataset）上评估得到的。

**线性回归从0开始实现**

使用这个有限样本的数据集来恢复这个模型的参数。 

	# 构造1000个样本数据集
	import matplotlib.pyplot as plt
	import random
	import torch
	
	def synthetic_data(w, b, num_examples):  #@save
	    """生成y=Xw+b+噪声"""
	    X = torch.normal(0, 1, (num_examples, len(w)))
	    y = torch.matmul(X, w) + b
	    # 加入标准差为0.01的噪声
	    y += torch.normal(0, 0.01, y.shape)
	    return X, y.reshape((-1, 1))
	
	true_w = torch.tensor([2, -3.4])
	true_b = 4.2
	features, labels = synthetic_data(true_w, true_b, 1000)
	# features中的每一行都包含一个二维数据样本， labels中的每一行都包含一维标签值（一个标量）
	print('features:', features[0],'\nlabel:', labels[0])
	
	# 新建画布
	plt.figure(figsize=(4,3))
	plt.scatter(features[:,1].detach().numpy(),labels.detach().numpy(),1)
	plt.show()

	# 定义一个`data_iter`函数，
	# 该函数接收批量大小、特征矩阵和标签向量作为输入，
	# 生成大小为`batch_size`的小批量
	def data_iter(batch_size, features, labels):
    num_examples = len(features)
    indices = list(range(num_examples))
    # 打乱下标顺序
    random.shuffle(indices)
    for i in range(0, num_examples, batch_size):
        batch_indices = torch.tensor(
            indices[i: min(i + batch_size, num_examples)])
        yield features[batch_indices], labels[batch_indices]
	# 定义初始化模型参数
	# 从均值为0，标准差为0.01的正态分布采样随机数初始化权重
	w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)
	b = torch.zeros(1, requires_grad=True)
	# 定义模型
	def linreg(X, w, b):  
    """线性回归模型"""
    return torch.matmul(X, w) + b
	# 定义损失函数
	def squared_loss(y_hat, y):  
    """均方损失"""
    return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2
	# 定义优化算法（参数，学习率，批量大小）
	def sgd(params, lr, batch_size):  
    """小批量随机梯度下降"""
	# 更新时不参与梯度计算
    with torch.no_grad():
        for param in params:
            param -= lr * param.grad / batch_size
            param.grad.zero_()
	# 训练
	lr = 0.03
	num_epochs = 3
	net = linreg
	loss = squared_loss
	for epoch in range(num_epochs):
	    for X, y in data_iter(batch_size, features, labels):
	        l = loss(net(X, w, b), y)  # X和y的小批量损失
	        # 因为l形状是(batch_size,1)，而不是一个标量。l中的所有元素被加到一起，
	        # 并以此计算关于[w,b]的梯度
	        l.sum().backward()
	        sgd([w, b], lr, batch_size)  # 使用参数的梯度更新参数
	    with torch.no_grad():
	        train_l = loss(net(features, w, b), labels)
	        print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')
 
**线性回归的简洁实现（使用深度学习框架）**

	import torch
	from torch.utils import data
	# 生成数据集
	def synthetic_data(w, b, num_examples):
	    """生成y=Xw+b+噪声"""
	    X = torch.normal(0, 1, (num_examples, len(w)))
	    y = torch.matmul(X, w) + b
	    # 加入噪声
	    y += torch.normal(0, 0.01, y.shape)
	    return X, y.reshape((-1, 1))
	
	true_w = torch.tensor([2, -3.4])
	true_b = 4.2
	features, labels = synthetic_data(true_w, true_b, 1000)
	
	# 读取数据集
	# is_train表示是否希望数据迭代器对象在每个迭代周期内打乱数据
	def load_array(data_arrays, batch_size, is_train=True):
	    """构造一个PyTorch数据迭代器"""
	    dataset = data.TensorDataset(*data_arrays)
	    return data.DataLoader(dataset, batch_size, shuffle=is_train)
	
	batch_size = 10
	data_iter = load_array((features, labels), batch_size)
	
	# 验证是否正常工作，读取第一个小批量样本
	next(iter(data_iter))
	
	# 定义模型【Sequential类将多个层串联在一起】
	from torch import nn
	# 输入特征形状为2，输出特征形状为1的全连接层模型
	net = nn.Sequential(nn.Linear(2,1))
	
	# 初始化模型参数（选择第一个图层）
	net[0].weight.data.normal_(0, 0.01)# 正态分布
	net[0].bias.data.fill_(0)
	
	# 定义损失函数(平方L2范数）
	loss = nn.MSELoss()
	
	# 定义优化算法（小批量优化算法）
	trainer = torch.optim.SGD(net.parameters(), lr=0.03)
在每个迭代周期里，我们将完整遍历一次数据集（`train_data`），
不停地从中获取一个小批量的输入和相应的标签。
对于每一个小批量，我们会进行以下步骤:

- 通过调用`net(X)`生成预测并计算损失`l`（前向传播）。
- 通过进行反向传播来计算梯度。
- 通过调用优化器来更新模型参数。

为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。
	
	# 训练
	num_epochs = 3
	for epoch in range(num_epochs):
	    for X, y in data_iter:
	        l = loss(net(X) ,y)
	        trainer.zero_grad()# 优化器清零
	        l.backward()
	        trainer.step()# 进行模型更新
	    l = loss(net(features), labels)
	    print(f'epoch {epoch + 1}, loss {l:f}')
	# 比较生成数据集的真实参数和通过有限数据训练获得的模型参数
	w = net[0].weight.data
	print('w的估计误差：', true_w - w.reshape(true_w.shape))
	b = net[0].bias.data
	print('b的估计误差：', true_b - b)
#####7）图像分类数据集

	# 构造人造数据集
	import matplotlib.pyplot as plt
	import torch
	import torchvision
	from torch.utils import data
	from torchvision import transforms
	
	# 读取数据集
	# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
	# 并除以255使得所有像素的数值均在0～1之间
	trans = transforms.ToTensor()
	mnist_train = torchvision.datasets.FashionMNIST(
	    root="../data", train=True, transform=trans, download=True)
	mnist_test = torchvision.datasets.FashionMNIST(
	    root="../data", train=False, transform=trans, download=True)
	# 在数字标签索引及其文本名称之间进行转换。
	def get_fashion_mnist_labels(labels):  #@save
	    """返回Fashion-MNIST数据集的文本标签"""
	    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
	                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
	    return [text_labels[int(i)] for i in labels]
	# 可视化样本
	def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
	    """绘制图像列表"""
	    figsize = (num_cols * scale, num_rows * scale)
	    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
	    axes = axes.flatten()
	    for i, (ax, img) in enumerate(zip(axes, imgs)):
	        if torch.is_tensor(img):
	            # 图片张量
	            ax.imshow(img.numpy())
	        else:
	            # PIL图片
	            ax.imshow(img)
	        ax.axes.get_xaxis().set_visible(False)
	        ax.axes.get_yaxis().set_visible(False)
	        if titles:
	            ax.set_title(titles[i])
	    return axes
	X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
	show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
	
	# 读取小批量
	batch_size = 256
	
	def get_dataloader_workers():  #@save
	    """使用4个进程来读取数据"""
	    return 4
	
	train_iter = data.DataLoader(mnist_train, batch_size, shuffle=True,
	                             num_workers=get_dataloader_workers())
	timer = d2l.Timer()
	for X, y in train_iter:
	    continue
	f'{timer.stop():.2f} sec'
	# 整合所有组件
	def load_data_fashion_mnist(batch_size, resize=None):  #@save
	    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
	    trans = [transforms.ToTensor()]
	    if resize:
	        trans.insert(0, transforms.Resize(resize))
	    trans = transforms.Compose(trans)
	    mnist_train = torchvision.datasets.FashionMNIST(
	        root="../data", train=True, transform=trans, download=True)
	    mnist_test = torchvision.datasets.FashionMNIST(
	        root="../data", train=False, transform=trans, download=True)
	    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
	                            num_workers=get_dataloader_workers()),
	            data.DataLoader(mnist_test, batch_size, shuffle=False,
	                            num_workers=get_dataloader_workers()))
	
	# 图像大小调整功能
	train_iter, test_iter = load_data_fashion_mnist(32, resize=64)
	for X, y in train_iter:
	    print(X.shape, X.dtype, y.shape, y.dtype)
	    break
#####8）softmax实现
	
	import torch
	from torch import nn
	from d2l import torch as d2l
	batch_size = 256
	train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)
	# 初始化模型参数
	# PyTorch不会隐式地调整输入的形状。因此，
	# 我们在线性层前定义了展平层（flatten），来调整网络输入的形状
	net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))
	
	def init_weights(m):
	    if type(m) == nn.Linear:
	        nn.init.normal_(m.weight, std=0.01)
	
	net.apply(init_weights)
	
	# 交叉熵损失函数
	loss = nn.CrossEntropyLoss(reduction='none')
	
	# 优化算法（使用学习率为0.1的小批量随机梯度下降）
	trainer = torch.optim.SGD(net.parameters(), lr=0.1)