{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.429554100Z",
     "start_time": "2024-02-25T06:57:11.410388900Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "import random\n",
    "import jieba\n",
    "\n",
    "class MyChineseBertDataset(Dataset):\n",
    "    def __init__(self, corpus_path, vocab, seq_len, encoding='utf-8'):\n",
    "        \"\"\"\n",
    "        创建数据集\n",
    "        :param corpus_path: 数据集的路径，corpus的意思是语料库\n",
    "        :param vocab: 词典\n",
    "        :param seq_len: 指定的序列长度\n",
    "        :param encoding: 编码方式，默认为utf-8\n",
    "        \"\"\"\n",
    "        self.vocab = vocab\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        self.corpus_path = corpus_path\n",
    "        self.encoding = encoding\n",
    "        \n",
    "        # 将数据集的每一行分割并存储到 self.lines中, 以'\\t'分割，用于下面的__getitem__方法，以强化其在不同任务中的通用性\n",
    "        with open(corpus_path, 'r', encoding=encoding) as f:\n",
    "            self.lines = [line[:-1].split('\\t') for line in f.readlines()]\n",
    "            self.corpus_lines = len(self.lines)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return self.corpus_lines\n",
    "        \n",
    "    def __getitem__(self, item):\n",
    "        # is_next_label: 1表示是下一句，0表示不是下一句\n",
    "        t1, t2, is_next_label = self.random_sent(item)\n",
    "        t1_random, t1_label = self.random_word(t1)\n",
    "        t2_random, t2_label = self.random_word(t2)\n",
    "        \n",
    "        # 在t1_random和t2_random的首尾分别加上[CLS]和[SEP]标志\n",
    "        t1 = [self.vocab.cls_index] + t1_random + [self.vocab.sep_index]\n",
    "        t2 = t2_random + [self.vocab.sep_index]\n",
    "        \n",
    "        # 在句子的标签中加上[PAD]标志, 使得句子的长度都为seq_len\n",
    "        t1_label = [self.vocab.pad_index] + t1_label + [self.vocab.pad_index] \n",
    "        t2_label = t2_label + [self.vocab.pad_index]\n",
    "    \n",
    "        # segment_label 是一个列表，用于指示句子中的每个词属于哪个句子, segment的意思是段落\n",
    "        segment_label = ([0 for _ in range(len(t1))] + [1 for _ in range(len(t2))])[:self.seq_len]\n",
    "        \n",
    "        # 输入由两个句子组成, 将两个句子拼接在一起，并且截断到指定长度\n",
    "        model_input = (t1+t2)[:self.seq_len]\n",
    "        model_label = (t1_label+t2_label)[:self.seq_len]\n",
    "        \n",
    "        # 如果输入的长度小于指定长度，则用[PAD]标签来填充\n",
    "        padding = [self.vocab.pad_index for _ in range(self.seq_len - len(model_label))]\n",
    "        model_input.extend(padding), model_label.extend(padding), segment_label.extend(padding)\n",
    "        \n",
    "        # 将模型输入和标签转换回原始句子\n",
    "        # original_t1 = self.vocab.from_seq(t1, join=True, with_pad=True)\n",
    "        # original_t2 = self.vocab.from_seq(t2, join=True, with_pad=True)\n",
    "        \n",
    "        # 返回模型的输入和标签\n",
    "        output = {\n",
    "            'input': torch.tensor(model_input),\n",
    "            'output': torch.tensor(model_label),\n",
    "            'segment': torch.tensor(segment_label),\n",
    "            'is_next': torch.tensor(is_next_label)\n",
    "        }\n",
    "        \n",
    "        return {key: value.clone().detach() for key, value in output.items()}\n",
    "        \n",
    "        # 生成随机遮蔽的句子，返回遮蔽后的句子和标签\n",
    "    def random_word(self, sentence):\n",
    "        # 对中文token进行分割\n",
    "        tokens = [char for char in sentence]\n",
    "        output_label = []\n",
    "        \n",
    "        for i, token in enumerate(tokens):\n",
    "            # 将15%的词进行替换\n",
    "            prob = random.random()\n",
    "            if prob < 0.15:\n",
    "                prob /= 0.15\n",
    "                \n",
    "                # 80% 的概率进行替换为[MASK]\n",
    "                if prob < 0.8:\n",
    "                    tokens[i] = self.vocab.mask_index\n",
    "                    \n",
    "                # 10% 的概率进行替换为随机字, 增加模型的鲁棒性\n",
    "                elif prob < 0.9:\n",
    "                    tokens[i] = random.randrange(len(self.vocab))\n",
    "                    \n",
    "                # 10% 的概率不进行替换，也是为了增加鲁棒性\n",
    "                else:\n",
    "                    # stoi是string to index的缩写，如果没有找到这个字返回'<unk>'\n",
    "                    tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n",
    "                                            \n",
    "                # 记录被替换的词, 用于计算loss\n",
    "                output_label.append(self.vocab.stoi.get(token, 1))\n",
    "                \n",
    "            else:\n",
    "                tokens[i] = self.vocab.stoi.get(token, self.vocab.unk_index)\n",
    "                output_label.append(0)\n",
    "                \n",
    "        return tokens, output_label\n",
    "    \n",
    "    # 随机获取一对句子和一个标签\n",
    "    def random_sent(self, index):\n",
    "        t1, t2 = self.get_corpus_line(index)\n",
    "        \n",
    "        # 50%的概率获得连续的句子，标记标签1，这样做是为了提升在预测下一句任务上的能力\n",
    "        if random.random() > 0.5:\n",
    "            return t1, t2, 1\n",
    "        else:\n",
    "            return t1, self.get_random_line(), 0\n",
    "        \n",
    "    # 获取数据集的一行\n",
    "    def get_corpus_line(self, item):\n",
    "        return self.lines[item][0], self.lines[item][1]\n",
    "    \n",
    "    # 随机获取数据集的一行\n",
    "    def get_random_line(self):\n",
    "        return self.lines[random.randrange(self.corpus_lines)][0]"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "import tqdm\n",
    "\n",
    "class WordVocab:\n",
    "    def __init__(self, texts, min_freq=1):\n",
    "        print(\"正在构建Vocab词表\")\n",
    "        counter = Counter() # Counter可以接受迭代器，进行计数\n",
    "        for line in tqdm.tqdm(texts):\n",
    "            # # 检查line是不是一个列表， 用来判断是不是连续的（主要应该是处理英文单词的吧，我这里就不修改了，以后好搬用）\n",
    "            # if isinstance(line, list):\n",
    "            #     words = line\n",
    "            # else:\n",
    "            #     # 要处理中文词汇要去除' ' \n",
    "            #     words = list(line.replace('\\n', '').replace('\\t','').replace(' ',''))\n",
    "            # 处理中文的方法\n",
    "            words = [char for char in line]\n",
    "            \n",
    "            # 提取字并计数\n",
    "            for word in words:\n",
    "                counter[word] += 1\n",
    "                \n",
    "        self.freq = counter\n",
    "        counter = counter.copy()\n",
    "        \n",
    "        # itos是index_to_string的缩写\n",
    "        self.itos = ['[PAD]', '<unk>', '[CLS]', '[SEP]', '[MASK]']\n",
    "        for token in self.itos:\n",
    "            del counter[token]\n",
    "            \n",
    "        # 通过词频进行排序， counter.items()返回元组对，lambda无名函数用于获取次数\n",
    "        words_and_freq = sorted(counter.items(), key=lambda tup: tup[0])\n",
    "        # 然后按字母顺序进行排序\n",
    "        words_and_freq.sort(key=lambda tup: tup[1], reverse=True)\n",
    "        \n",
    "        # 去除过少出现的字符\n",
    "        for word, freq in words_and_freq:\n",
    "            if freq < min_freq:\n",
    "                break\n",
    "            self.itos.append(word)\n",
    "        \n",
    "        self.stoi = {token: i for i, token in enumerate(self.itos)}\n",
    "        \n",
    "        self.unk_index = self.stoi['<unk>']\n",
    "        self.cls_index = self.stoi['[CLS]']\n",
    "        self.sep_index = self.stoi['[SEP]']\n",
    "        self.mask_index = self.stoi['[MASK]']\n",
    "        self.pad_index = self.stoi['[PAD]']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    \n",
    "    def to_seq(self, sentence, seq_len=None, with_len=False):\n",
    "        # 由于处理的是中文，不能采用原本的分割方式，所以我改用了jieba的分割\n",
    "        words = jieba.lcut(sentence)\n",
    "            \n",
    "        # 如果word在stoi中，就返回word中对应的数值，否则返回<unk>\n",
    "        seq = [self.stoi.get(word, self.unk_index) for word in sentence]\n",
    "        \n",
    "        origin_seq_len = len(seq)\n",
    "        \n",
    "        if seq_len is None:\n",
    "            pass\n",
    "        elif len(seq) <= seq_len:\n",
    "            # 如果不足长度就补0\n",
    "            seq += [0 for _ in range(seq_len - len(seq))]\n",
    "        else:\n",
    "            seq = seq[:seq_len]\n",
    "            \n",
    "        return (seq, origin_seq_len) if with_len else seq\n",
    "    \n",
    "    def from_seq(self, seq, join=False, with_pad=False):\n",
    "        # 将一个整数序列转换回词的序列，如果idx小于itos的长度,就返回itos[idx]，否则返回'<%d>'%d是idx的数值\n",
    "        words = [self.itos[idx] if idx < len(self.itos) else '<%d>' % idx for idx in seq if not with_pad or idx != 0]\n",
    "        return \"\".join(words) if join else words\n",
    "    \n",
    "    @staticmethod\n",
    "    def load_vocab(vocab_path: str) -> 'WordVocab':\n",
    "        with open(vocab_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "        \n",
    "    def save_vocab(self, vocab_path):\n",
    "        with open(vocab_path, 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.481374700Z",
     "start_time": "2024-02-25T06:57:11.435556100Z"
    }
   },
   "id": "a8b06dce3249c607",
   "execution_count": 256
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[PAD]', '<unk>', '[CLS]', '[SEP]', '[MASK]', '，', '。', '的', '了', '不', '一', '“', '是', '”', '人', '道', '来', '我', '这', '说', '：', '有', '你', '着', '个', '在', '他', '也', '去', '子', '里', '上', '们', '儿', '大', '那', '得', '玉', '出', '只', '宝', '又', '见', '就', '么', '好', '下', '到', '笑', '贾']\n",
      "5209\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "import os\n",
    "if os.path.exists('word_vocab.pkl'):\n",
    "    vocab = WordVocab.load_vocab('word_vocab.pkl')\n",
    "else:\n",
    "    with open('../data/text_for_vocab.txt', 'r', encoding='utf-8') as f:\n",
    "        texts = f.readlines()\n",
    "    vocab = WordVocab(texts)\n",
    "    vocab.save_vocab('word_vocab.pkl')\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(vocab.itos[:50])\n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.514090700Z",
     "start_time": "2024-02-25T06:57:11.483399900Z"
    }
   },
   "id": "d46b3281cefa92c2",
   "execution_count": 257
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': tensor([[   2, 2286, 1281,  405,  102,  592,  172,    5,  839,   53,    4,   23,\n",
      "          133,  134,  136,   97,   15,    4,    4,  350,  452,    4,    4,  113,\n",
      "           90,  523,    4,  254,    4,  230,  642,  460,   64,  338, 1037,    4,\n",
      "            6,  295,  732,  532,    4,  913,  436,    1,    4,    3,  244,   83,\n",
      "            4,  909,   91,  572,  141,   25,   60,   28,    7,  294,    4,  156,\n",
      "           30,    4,    4,   12,  648,  470, 1433, 1179,    7,    4,    4,    5,\n",
      "          171, 1149,  113,   71,  155,  271,    9, 1496, 1735,  154, 1079,  492,\n",
      "          933,    6,  466,    4,   25,  111,  507,    4,   50,  557,  235,   14,\n",
      "            7,   74,  173,  515,    5,  572,  141,    4,  426, 1659,  369,    5,\n",
      "          267,   47,    8, 1398,  863,    4,  429,    6,    4,    4,    4,    4,\n",
      "          141,  320, 1416,    5,   21,   10,   24,  307]]), 'output': tensor([[   0,    0,    0,    0,    0,    0,  172,    0,    0,    0,   61,    0,\n",
      "            0,    0,    0,    0,    0,   11,  366,    0,    0,  229,   77,    0,\n",
      "            0,    0,  103,    0,    5,    0,    0,    0,    0,    0,    0,   17,\n",
      "            0,    0,    0,    0,  223,    0,    0,    0,    1,    0,    0,    0,\n",
      "          245,    0,    0,    0,    0,   25,    0,    0,    0,    0,  386,    0,\n",
      "            0,    5,   57,    0,    0,    0,    0,    0,    0, 1784,  698,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "            0,    0,    0,  240,    0,    0,    0, 1442,    0,    0,    0,    0,\n",
      "            0,    0,    0,   31,    0,    0,  141, 1457,    0,    0,    0,    0,\n",
      "            0,    0,    0,    0,    0, 1352,    0,    0,  171,  626,   12,  572,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'segment': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]]), 'is_next': tensor([0])}\n"
     ]
    }
   ],
   "source": [
    "# 测试读取数据集\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "vocab = WordVocab.load_vocab('word_vocab.pkl')\n",
    "dataset = MyChineseBertDataset('../data/qianbi.csv', vocab, 128)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "loader = next(iter(dataloader))\n",
    "print(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.547382100Z",
     "start_time": "2024-02-25T06:57:11.516089900Z"
    }
   },
   "id": "29c74a50dc054c91",
   "execution_count": 258
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from torch import nn\n",
    "# \n",
    "# class MultiHeadedAttention(nn.Module):\n",
    "#     def __init__(self, h, d_model, dropout=0.1):\n",
    "#         # h表示number of heads， d_model表示hidden_layer_dimension\n",
    "#         super().__init__()\n",
    "#         # 确保每个头的维度都是整数不会出现尺寸不一致的情况\n",
    "#         assert d_model % h == 0\n",
    "# \n",
    "#         # 每个头的查询（Query）和键（Key）的维度\n",
    "#         self.d_k = d_model // h\n",
    "#         self.h = h\n",
    "# \n",
    "#         self.multihead_attn = nn.MultiheadAttention(embed_dim=d_model, num_heads=h, dropout=dropout)\n",
    "# \n",
    "#     def forward(self, query, key, value, mask=None):\n",
    "#         # 默认情况下，PyTorch中的线性层的输入形状是 (batch_size, sequence_length, d_model)，但是在多头注意力中，我们通常希望将序列长度（sequence_length）作为第一个维度，\n",
    "#         query, key, value = [x.permute(1,0,2) for x in (query,key,value)]\n",
    "# \n",
    "#         attn_output, attn_weights = self.multihead_attn(query,key,value,attn_mask=mask)\n",
    "#         return attn_output.permute(1,0,2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.575720500Z",
     "start_time": "2024-02-25T06:57:11.547989900Z"
    }
   },
   "id": "3e96ae636a3e900",
   "execution_count": 259
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import math\n",
    "\n",
    "class Attention(nn.Module):\n",
    "\n",
    "    def forward(self, query, key, value, mask=None, dropout=None):\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "                 / math.sqrt(query.size(-1))\n",
    "\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        p_attn = F.softmax(scores, dim=-1)\n",
    "\n",
    "        if dropout is not None:\n",
    "            p_attn = dropout(p_attn)\n",
    "\n",
    "        return torch.matmul(p_attn, value), p_attn\n",
    "\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        assert d_model % h == 0\n",
    "\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "\n",
    "        self.linear_layers = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(3)])\n",
    "        self.output_linear = nn.Linear(d_model, d_model)\n",
    "        self.attention = Attention()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        query, key, value = [l(x).view(batch_size, -1, self.h, self.d_k).transpose(1, 2)\n",
    "                             for l, x in zip(self.linear_layers, (query, key, value))]\n",
    "\n",
    "        x, attn = self.attention(query, key, value, mask=mask, dropout=self.dropout)\n",
    "\n",
    "        x = x.transpose(1, 2).contiguous().view(batch_size, -1, self.h * self.d_k)\n",
    "\n",
    "        return self.output_linear(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.626693300Z",
     "start_time": "2024-02-25T06:57:11.578974500Z"
    }
   },
   "id": "3692066051e6d78c",
   "execution_count": 260
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# 测试MultiHeadAttention\n",
    "import torch\n",
    "\n",
    "# 定义输入\n",
    "batch_size = 32\n",
    "sequence_length = 10\n",
    "d_model = 64\n",
    "h = 8  # 注意力头的数量\n",
    "dropout = 0.1\n",
    "\n",
    "# 创建 MultiHeadedAttention 实例\n",
    "attention_layer = MultiHeadedAttention(h, d_model, dropout)\n",
    "\n",
    "# 生成随机输入\n",
    "query = torch.randn((batch_size, sequence_length, d_model))\n",
    "key = torch.randn((batch_size, sequence_length, d_model))\n",
    "value = torch.randn((batch_size, sequence_length, d_model))\n",
    "\n",
    "# 调用 forward 方法进行前向传播\n",
    "output = attention_layer(query, key, value)\n",
    "\n",
    "# 打印输出的形状\n",
    "print(\"Output shape:\", output.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.657363700Z",
     "start_time": "2024-02-25T06:57:11.613611200Z"
    }
   },
   "id": "a7689a866c14e5b4",
   "execution_count": 261
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 助于在编码器和解码器层中引入非线性特征映射，增加模型的表示能力。\n",
    "class PositionwiseFeedForward(nn.Module):\n",
    "    # d_ff:Feedforward 层的输出维度\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    # 新版torch加入了gelu，我们就不用再写gelu了\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(F.gelu(self.linear1(x))))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.695368600Z",
     "start_time": "2024-02-25T06:57:11.660363700Z"
    }
   },
   "id": "301156994fd080ae",
   "execution_count": 262
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 10, 64])\n",
      "Output shape: torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "# 测试PositionwiseFeedForward\n",
    "import torch\n",
    "\n",
    "# 创建 PositionwiseFeedForward 模块\n",
    "d_model = 64\n",
    "d_ff = 128\n",
    "dropout = 0.1\n",
    "feed_forward = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "\n",
    "# 生成示例输入\n",
    "batch_size = 32\n",
    "sequence_length = 10\n",
    "input_tensor = torch.randn(batch_size, sequence_length, d_model)\n",
    "\n",
    "# 将输入传递给模块\n",
    "output_tensor = feed_forward(input_tensor)\n",
    "\n",
    "# 打印输出的形状\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(\"Output shape:\", output_tensor.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.744333800Z",
     "start_time": "2024-02-25T06:57:11.697345Z"
    }
   },
   "id": "b095faca416ff805",
   "execution_count": 263
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 残差连接（Residual Connection）和层归一化\n",
    "# 通过堆叠多层网络，可以提高网络的表示能力，但也容易引入梯度消失或梯度爆炸等问题\n",
    "class SublayerConnection(nn.Module):\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = nn.LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, sublayer):\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.788787800Z",
     "start_time": "2024-02-25T06:57:11.745936700Z"
    }
   },
   "id": "cb98ac0b2f0da279",
   "execution_count": 264
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 10, 64])\n",
      "Output shape: torch.Size([32, 10, 64])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 创建一个小的输入张量\n",
    "x = torch.rand((32, 10, 64))\n",
    "\n",
    "# 创建 SublayerConnection 实例\n",
    "size = 64  # 你的模型中的尺寸大小\n",
    "dropout = 0.1  # 你的模型中的 dropout 率\n",
    "sublayer_connection = SublayerConnection(size, dropout)\n",
    "\n",
    "# 调用 forward 方法\n",
    "output = sublayer_connection(x, lambda x: x * 2)  # 这里的 lambda 函数仅用于示例，你需要提供实际的 sublayer 函数\n",
    "\n",
    "# 打印输出张量的形状\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.841192600Z",
     "start_time": "2024-02-25T06:57:11.771979Z"
    }
   },
   "id": "11fa240d8834b11e",
   "execution_count": 265
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden, attn_heads, feed_forward_hidden, dropout):\n",
    "        super().__init__()\n",
    "        self.attention = MultiHeadedAttention(h=attn_heads,d_model=hidden)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model=hidden, d_ff=feed_forward_hidden, dropout=dropout)\n",
    "        self.input_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.output_sublayer = SublayerConnection(size=hidden, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # 表示注意机制的 lambda 函数。注意机制应用于输入序列 _x 三次（查询、键和值相同），并且使用 mask 来屏蔽注意分数中的特定位置。\n",
    "        x = self.input_sublayer(x, lambda _x: self.attention.forward(_x, _x, _x, mask=mask))\n",
    "        x = self.output_sublayer(x, self.feed_forward)\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.846192400Z",
     "start_time": "2024-02-25T06:57:11.796045900Z"
    }
   },
   "id": "52d23bdcbeb8d346",
   "execution_count": 266
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([32, 10, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设 hidden_size=256，attn_heads=8，feed_forward_hidden=1024，dropout=0.1\n",
    "transformer_block = TransformerBlock(hidden=256, attn_heads=8, feed_forward_hidden=1024, dropout=0.1)\n",
    "\n",
    "# 生成一个形状为 (batch_size, sequence_length, hidden_size) 的输入张量\n",
    "input_tensor = torch.rand((32, 10, 256))\n",
    "\n",
    "# 生成一个形状为 (batch_size, sequence_length, sequence_length) 的注意力遮蔽张量，例如屏蔽了对角线以下的元素\n",
    "mask_tensor = torch.triu(torch.ones(10, 10)) == 1\n",
    "\n",
    "# 调用 TransformerBlock 的 forward 方法\n",
    "output_tensor = transformer_block(input_tensor, mask_tensor)\n",
    "\n",
    "# 打印输出张量的形状\n",
    "print(\"Output shape:\", output_tensor.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.897478800Z",
     "start_time": "2024-02-25T06:57:11.848191900Z"
    }
   },
   "id": "40f231c00d7521c",
   "execution_count": 267
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=512):\n",
    "        super().__init__()\n",
    "\n",
    "        # 初始化位置编码矩阵，大小为 (max_len, d_model)\n",
    "        pe = torch.zeros(max_len, d_model).float()\n",
    "        pe.requires_grad = False  # 设置位置编码不需要梯度更新\n",
    "\n",
    "        # 生成位置信息，表示为从 0 到 max_len-1 的浮点数，形状为 (max_len, 1)\n",
    "        position = torch.arange(0, max_len).float().unsqueeze(1)\n",
    "\n",
    "        # 计算位置编码的除数项，形状为 (d_model/2,)\n",
    "        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n",
    "\n",
    "        # 使用 sin 和 cos 函数计算位置编码矩阵中的值，分别作用于偶数和奇数列\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        # 将位置编码矩阵添加一个维度，并注册为模型的缓冲区\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        输入 x 的形状为 (batch_size, sequence_length, d_model)，\n",
    "        输出的位置编码将选择适当长度的部分返回。\n",
    "        \"\"\"\n",
    "        return self.pe[:, :x.size(1)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.940923200Z",
     "start_time": "2024-02-25T06:57:11.883206300Z"
    }
   },
   "id": "42513abea7bbe4e3",
   "execution_count": 268
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 50, 256])\n",
      "Output shape: torch.Size([1, 50, 256])\n"
     ]
    }
   ],
   "source": [
    "# 假设 input_tensor 是你的输入张量\n",
    "d_model = input_tensor.size(-1)  # 获取输入张量的维度大小\n",
    "max_len = 100\n",
    "positional_embedding = PositionalEmbedding(d_model, max_len)\n",
    "\n",
    "# 创建一个示例输入张量\n",
    "batch_size = 32\n",
    "sequence_length = 50\n",
    "input_tensor = torch.randn(batch_size, sequence_length, d_model)\n",
    "\n",
    "# 使用 PositionalEmbedding 进行前向传播\n",
    "output_embedding = positional_embedding(input_tensor)\n",
    "\n",
    "# 打印输出张量的形状\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "print(\"Output shape:\", output_embedding.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:11.963912700Z",
     "start_time": "2024-02-25T06:57:11.942922900Z"
    }
   },
   "id": "c1cfbed605c96ba6",
   "execution_count": 269
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 为输入的句子中的每个词生成对应的段（segment）嵌入（embedding）\n",
    "class SegmentEmbedding(nn.Embedding):\n",
    "    def __init__(self, embed_size=512):\n",
    "        super().__init__(3, embed_size, padding_idx=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:12.004823500Z",
     "start_time": "2024-02-25T06:57:11.966428300Z"
    }
   },
   "id": "78f91e4ef2a839d7",
   "execution_count": 270
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# 为输入的每个词生成对应的词嵌入（word embedding）。\n",
    "class TokenEmbedding(nn.Embedding):\n",
    "    def __init__(self, vocab_size, embed_size=512):\n",
    "        super().__init__(vocab_size, embed_size, padding_idx=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:12.006839900Z",
     "start_time": "2024-02-25T06:57:11.983690800Z"
    }
   },
   "id": "8f99ccecce0fcf1a",
   "execution_count": 271
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class MyBERTEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.token = TokenEmbedding(vocab_size=vocab_size, embed_size=embed_size)\n",
    "        self.position = PositionalEmbedding(d_model=self.token.embedding_dim)\n",
    "        self.segment = SegmentEmbedding(embed_size=self.token.embedding_dim)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.embed_size = embed_size\n",
    "        \n",
    "    def forward(self, sequence, segment_label):\n",
    "        x = self.token(sequence) + self.position(sequence) + self.segment(segment_label)\n",
    "        return self.dropout(x)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:12.033575100Z",
     "start_time": "2024-02-25T06:57:12.010820400Z"
    }
   },
   "id": "70f8ede4ab2965c5",
   "execution_count": 272
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class MyChineseBERT(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, hidden=256, n_layers=12, attn_heads=8, dropout=0.1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.hidden = hidden\n",
    "        self.n_layers = n_layers\n",
    "        self.attn_heads = attn_heads\n",
    "\n",
    "        self.feed_forward_hidden = hidden * 4\n",
    "\n",
    "        self.embedding = MyBERTEmbedding(vocab_size=vocab_size, embed_size=hidden)\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [TransformerBlock(hidden, attn_heads, hidden * 4, dropout) for _ in range(n_layers)])\n",
    "        self.linear_next_sentence = nn.Linear(hidden, 2)\n",
    "        self.linear_mask_lm = nn.Linear(hidden, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, x, segment_info):\n",
    "        mask = (x > 0).unsqueeze(1).repeat(1, x.size(1), 1).unsqueeze(1)\n",
    "\n",
    "        x = self.embedding(x, segment_info)\n",
    "\n",
    "        for transformer in self.transformer_blocks:\n",
    "            x = transformer.forward(x, mask)\n",
    "        x1 = self.softmax(self.linear_next_sentence(x[:, 0]))\n",
    "        x2 = self.softmax(self.linear_mask_lm(x))\n",
    "        return x1, x2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:12.073494200Z",
     "start_time": "2024-02-25T06:57:12.035574800Z"
    }
   },
   "id": "c51f77623f4ca57a",
   "execution_count": 273
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import numpy as np\n",
    "\n",
    "class MyBERTTrainer:\n",
    "    def __init__(self, model, vocab, train_dataloader, lr=0.001, betas=(0.9, 0.999), weight_decay=0.01):\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model = model.to(self.device)\n",
    "        self.vocab = vocab\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=betas, weight_decay=weight_decay)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        print(\"模型总参数量：\", sum(p.numel() for p in model.parameters()))\n",
    "        self.train_losses = []\n",
    "        \n",
    "    def train(self, epochs, dataloader):\n",
    "        data_itr = tqdm.tqdm(enumerate(dataloader), desc=\"正在载入%d epoch的数据\" % epochs, total=len(dataloader))\n",
    "        \n",
    "        loss = 0.0\n",
    "        \n",
    "        for i, data in data_itr:\n",
    "            data = {key: value.to(self.device) for key, value in data.items()}\n",
    "            \n",
    "            next_sent_output, mask_lm_output = self.model.forward(data['input'], data['segment'])\n",
    "            \n",
    "            next_loss = self.criterion(next_sent_output, data['is_next'])\n",
    "            \n",
    "            mask_loss = self.criterion(mask_lm_output.transpose(1, 2), data['output'])\n",
    "            \n",
    "            loss = next_loss + mask_loss\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            loss = loss.item()\n",
    "            self.train_losses.append(loss)\n",
    "            \n",
    "            data_itr.set_postfix({'Epoch': epochs, 'Loss': loss})\n",
    "            \n",
    "        print(\"Epoch %d, Loss: %.4f\" % (epochs, loss))\n",
    "        \n",
    "        return self.train_losses\n",
    "    \n",
    "    def plot_train_loss(self):\n",
    "        plt.plot(np.arange(len(self.train_losses)), self.train_losses, label='Train Loss')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def save_model(self, model_path):\n",
    "        torch.save(self.model.state_dict(), model_path)\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T06:57:12.096022100Z",
     "start_time": "2024-02-25T06:57:12.063901400Z"
    }
   },
   "id": "1e859517481bb9ef",
   "execution_count": 274
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型总参数量： 12150619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在载入0 epoch的数据: 100%|██████████| 114/114 [03:25<00:00,  1.80s/it, Epoch=0, Loss=1.85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.8462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "正在载入1 epoch的数据:  11%|█         | 12/114 [00:23<03:17,  1.93s/it, Epoch=1, Loss=1.91]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[275], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m trainer \u001B[38;5;241m=\u001B[39m MyBERTTrainer(model, vocab, dataloader)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[1;32m---> 10\u001B[0m     trainer\u001B[38;5;241m.\u001B[39mtrain(epoch, dataloader)\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m5\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     12\u001B[0m         trainer\u001B[38;5;241m.\u001B[39mplot_train_loss()\n",
      "Cell \u001B[1;32mIn[274], line 33\u001B[0m, in \u001B[0;36mMyBERTTrainer.train\u001B[1;34m(self, epochs, dataloader)\u001B[0m\n\u001B[0;32m     30\u001B[0m loss \u001B[38;5;241m=\u001B[39m next_loss \u001B[38;5;241m+\u001B[39m mask_loss\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 33\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     36\u001B[0m loss \u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    493\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    494\u001B[0m )\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\Lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    252\u001B[0m     tensors,\n\u001B[0;32m    253\u001B[0m     grad_tensors_,\n\u001B[0;32m    254\u001B[0m     retain_graph,\n\u001B[0;32m    255\u001B[0m     create_graph,\n\u001B[0;32m    256\u001B[0m     inputs,\n\u001B[0;32m    257\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    258\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    259\u001B[0m )\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    vocab = WordVocab.load_vocab('word_vocab.pkl')\n",
    "    dataset = MyChineseBertDataset('../data/qianbi.csv', vocab, 128)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    \n",
    "    model = MyChineseBERT(vocab_size=len(vocab), hidden=256)\n",
    "    trainer = MyBERTTrainer(model, vocab, dataloader)\n",
    "    \n",
    "    for epoch in range(10):\n",
    "        trainer.train(epoch, dataloader)\n",
    "        if epoch % 5 == 0:\n",
    "            trainer.plot_train_loss()\n",
    "            trainer.save_model('save_model/my_chinese_bert_%d.pth' % epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T07:01:01.362798300Z",
     "start_time": "2024-02-25T06:57:12.098021800Z"
    }
   },
   "id": "910f266d0ddee7eb",
   "execution_count": 275
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
