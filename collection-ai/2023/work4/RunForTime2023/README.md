## 关于模型

仿照yolo v1写的模型，将GoogLeNet替换成ResNet18，并（相较原论文）有部分细节删减、改动。

## 部分笔记

YOLO v1是一种one-stage目标检测算法，它将源图片分为S×S个网格，每个网格生成B个检测框用于检测对象（论文中S=7,B=2）。它利用网络输出的特征图进行目标检测。特征图的尺寸为7×7×30，前两维表示网格的坐标，第三维中，前10个参数为两个检测框的信息(包括检测框中心坐标(x,y)，检测框尺寸（w,h）和置信度c（用IoU表示）)，后20个数字为各类别的预测概率。

它的损失函数为一种自定义函数，类似于MSE的组合，包含了目标检测框的偏移的损失、分类偏差的损失等。为了目标检测更加准确，它对检测框偏移施加的惩罚损失更重。

论文中的骨干网络为GoogLeNet的改良版本（有24层），损失函数的系数$λ_{coord}=5$，$λ_{noobj}=0.5$，初始学习率0.01，权重衰减设为5e-4，momentum为0.9，训练了135轮。并且，它对训练数据以20%的概率进行饱和度增强、图片放缩、翻转。

YOLO模型在目标检测取得了成功，各项主要指标（如mAP）均表现不俗，虽仍与Fast R-CNN等在某些方面有一定差距。

v1版本具有一些缺点，如每个网格仅能预测一个类别，对小的目标物体的检测能力差等。这些在yolo的后续版本中得到了修正。
