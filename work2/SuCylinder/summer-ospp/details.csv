programName,difficulty,techTag,Introduce,OutputRequirements
基于RISC-V的Linux操作系统原生无人机飞控开发,进阶,"[[""os"",""Linux""],[""codelang"",""Programming Language""]]",- 项目背景随着低空经济的发展，无人机的需求越来越负责。运行在RTOS上的飞控难以满足复杂的需求，所以Linux原生的飞控逐渐被大家认可，呈现出飞控主控二合一的趋势，具有开发简单，兼容性好，生态丰富的特点。但是Linux实时性可能无法满足飞控的要求，RROS作为Linux硬实时的解决方案，在这个场景中具备明显的优势。RROS是一个双内核实时操作系统，基于Rust-For-Linux（RFL）重构了Xenomai的实时内核。具体来说，使用RFL提供的在Linux中使用Rust编写驱动的框架，与Xenomai社区的dovetail中断虚拟化接口，基于Rust语言实现了一个实时内核。实时内核将Linux内核作为idle任务进行调度，优先调度实时内核的任务，同时RROS兼容了实时核心的用户态接口库libevl。以往无人机飞控和主控都以ARM生态为主，本题目想要基于国产化的RISC-V开发板控制无人机，适配RustPilot飞控。- 项目任务基于Risc-V开发板，支持RustPilot飞控，重点完成RISC-V架构下的实时驱动开发，包括SPI驱动，imu驱动等无人机场景下常用外设。,1. 基于RROS在RISCV开发板上实现针对无人机的实时驱动2. 将实时驱动和RustPilot框架调通3. （进阶）在搭载了RROS的RISC-V开发板上，利用RustPilot做主控驱动无人机，完成调参，并成功完成飞行任务
基于ct-oval的操作系统安全用例数据库及评估用例生成工具在openeuler发行版上的适配开发,进阶/Advanced,"[[""os"",""x86""]]","把ct-oval开源项目对接openeuler的cve数据接口，清洗整理生成相应的openeuler cve评估用例数据库，适配openeuler24.03-lts-next等若干主力版本，达到可以实时输出主力lts版本CVE安全评估用例的效果。保证用例可用openscap正常扫描并输出结果。（1）需要的技能：xml, sql, golang（2）已有的工作: ct-oval项目，在openeuler一个衍生版上的测试报告（3）存在的不足： 未适配openeuler发行版，未对接openeuler cve数据发布接口，未完成多操作系统/多CVE发布接口的架构设计及开发（4）希望改进的点：完成多操作系统/多CVE发布接口的架构设计及开发，完成openeuler发行版及cve接口的适配（5）最终项目实现的目标：各衍生版可以通过少许工作量便可实现适配",1. 完成多操作系统/多CVE发布接口的架构设计及开发，完成openeuler发行版及cve接口的适配
SpiderMonkey 的 64 位 RISC-V 后端修缮工作,进阶/Advanced,"[[""web"",""Web Application""],[""web"",""Desktop Application""],[""dev"",""CI""],[""dev"",""CD""],[""dev"",""SVN""],[""dev"",""Git""],[""os"",""Clang""],[""os"",""Compiler""],[""os"",""GCC""],[""os"",""Linux""],[""os"",""LLVM""]]",Firefox 浏览器的 JS 引擎（代号 SpiderMonkey）支持多个处理器架构的 JIT 编译，即动态生成适合当前平台的机器码，以达到比普通解释器高几个数量级的性能。PC 机常用的 x64 和手机常用的 arm64 是它支持得最好的平台目标，而 riscv64 后端的单元测试通过率甚至已被即将成为历史的 mips64 反超。该项目的主要目的是改善 riscv64 后端代码的品质和测试通过率，并以此机会引导学生接触 Firefox 补丁的上游化流程。,1.改善 Firefox 的 JS 子项目的 riscv64 部分并根据完成进度递交上游，测试错误小于 50 个
NebulaGraph 集成 PyG ,基础/Basic,"[[""datas"",""PyTorch""],[""cloudnative"",""Distributed Storage""],[""datas"",""Database""],[""datas"",""Graph Database""]]",PyG 是一个用于在 PyTorch 中创建和训练图神经网络的强大而灵活的框架。它简化了图数据的处理，并提供了各种 GNN 模型的构建块，助力研究人员和开发者在图结构数据上进行创新。NebulaGraph 是一款开源的、分布式的、易扩展的原生图数据库，能够承载包含数千亿个点和数万亿条边的超大规模数据集，并且提供毫秒级查询。PyG 作为 GNN 的训练推理框架、它的图抽象支持从远程的分布式基础设施上存取，这个抽象叫“remote server”，有了这个抽象，我们可以连接两个项目，让 PyG 社区受益于 NebulaGraph 的超大规模分布式图存储，驱动分布式图申请网络的训练。,1. 设计实现 PyG 的 NebulaGraph remote server ，作为其 FeatureStore 与 GraphStore.
AI 模型和数据集的生命周期管理系统,进阶/Advanced,"[[""datas"",""AI""],[""cloudnative"",""Cloud Native""],[""cloudnative"",""Distributed Storage""]]",在当前AI模型训练和推理的生命周期中，模型和数据集的统一管理是实现高效、可重现开发流程的关键。本项目以开源版Alluxio为缓存和存储系统，基于[Lance协议格式](https://github.com/eto-ai/lance)，对Alluxio社区版的 Python客户端`alluxio-py`进行功能性扩展（），以支持对模型与数据集的检索查询、版本控制、元数据追踪、生命周期管理等高级功能。项目目标是打通数据读写与模型管理链路，提供统一的API接口，提升整体系统的数据访问效率与开发体验。,1. 基于Lance格式的元数据方案，扩展`alluxio-py`支持对模型和数据集的注册、查询与加载；2. 支持模型与数据集的生命周期操作（注册、更新、删除、归档）；3. 实现至少一种持久化方案，元数据可存储在Alluxio或兼容系统中；4. 实现可以很好兼容Pytorch/TensorFlow的对外API；5. 完成单元测试及端到端集成测试；6. PR成功Merge至主干；7. 提交完整项目报告和使用文档，提供API文档与用例说明，便于下游用户集成。
在Occlum 库操作系统中实现Linux AIO系统调用,基础,"[[""os"",""Linux""]]",Occlum是适用于TEE环境下的内存安全的、多进程库操作系统。Occlum为了让Linux原生应用无需修改和编译无缝的迁移到TEE中，为此Occlum实现了150多个兼容Linux的系统调用。,1. 当前Occlum还未实现Linux原生异步IO接口 AIO系统调用，此项目的目标是在Occlum库操作系统中实现兼容Linux AIO的系统调用。
jailhouse到RISC-V移植支持,基础/Basic,"[[""datas"",""Embedded Database""],[""os"",""Virtualization""]]",（1）相关背景：openEuler embedded通过部署混合关键系统(MCS)，允许在单块硬件上同时运行多个操作系统，以实现多样化任务的资源隔离与调度。而为了确保多OS协同运作的安全性，必须确保OS间的资源隔离。openEuler embedded使用了由西门子主导的开源轻量级hypervisor——jailhouse来实现这一目标。（2）已有的工作：openEuler embedded在ARM/X86上已经实现了基于jailhouse部署混合系统，jailhouse本身也支持在ARM/x86的QEMU上运行，并且在RISC-V方面有一定的学术成果。（3）存在的不足：目前jailhouse主干和openEuler embedded使用的版本均缺少对RISC-V的支持，并且已有的RISC-V相关的研究成果对RISC-V新的中断架构AIA研究不足。（4）希望改进的点：- 补充对jailhouse的分析文档，包括对jailhouse的架构设计，jailhouse在RISC-V上的移植方案，以及基于RISC-V AIA支持jailhouse虚拟化中断直通的方案。- 为openEuler embedded使用的jailhouse添加RISC-V以及基于AIA的中断直通支持。（5）最终项目实现的目标：完成对jailhouse设计的全面分析以及jailhouse在RISC-V上的移植方案，在社区进行汇报和分享。并且基于移植方案在实现了AIA的RISC-V环境上使用jailhouse部署中断直通的openEuler embedded。,1. 完成对jailhouse设计的全面分析以及jailhouse在RISC-V上的移植和基于AIA的中断直通方案，并且在社区进行分享。2. 基于移植方案，在支持AIA的RISC-V环境上实现基于jailhouse和中断直通部署的openEuler embedded，并进行性能测试。
TinyEditor 支持协同编辑,进阶,"[[""web"",""Vue.js""]]",随着在线协作需求的日益增长，用户希望在 TinyEditor 富文本编辑器中实现多人实时协同编辑功能。本功能需要从0开始开发，旨在允许多个用户同时对同一文档进行编辑，并且能够实时看到彼此的修改内容，确保团队成员之间的高效协作。,1. 完成 TinyEditor 富文本编辑器的协同编辑功能开发，确保多个用户能够同时对同一个文档进行编辑，且编辑操作能够实时同步到所有参与协作的客户端。2. 用户在编辑器中的操作（如文本输入、删除、格式调整、图片插入、表格编辑等）能够在极短的时间内（不超过 1 秒）反映到其他协同编辑用户的编辑器界面上，确保实时性。不同用户的编辑操作能够在编辑器中以不同的颜色、光标样式或其他可视化方式加以区分，方便用户清楚地了解每个操作是由谁执行的。3. 冲突解决机制 ：在多个用户同时对同一段内容进行编辑时，能够自动检测并合理解决编辑冲突，确保文档内容的一致性和正确性。4. 接口与集成 ：提供与后端服务的接口，实现编辑器内容的实时保存和同步，确保在网络中断或其他异常情况下，用户的编辑内容不会丢失，并且能够在重新连接后继续协同编辑。5. 提供一个或多个完整的示例项目，展示 TinyEditor 协同编辑功能在实际应用场景中的使用方法，包括如何初始化协同编辑、如何处理用户加入和退出协同编辑等情况。编写详细的协同编辑功能使用文档和开发教程，包括功能介绍、操作步骤、接口说明、常见问题解答等内容，帮助用户快速上手并有效使用协同编辑功能。6. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。7. 补充相应的文档和自动化测试用例。8. 建议输出TinyEditor协同编辑的介绍文章和视频
EmbodiedAI-Ops,进阶,"[[""datas"",""PyTorch""],[""datas"",""AI""]]",开发面向端到端具身操作任务的效率优化框架，通过多模态感知融合、动态技能重组与实时决策加速等技术，突破传统方法在数据效率、响应延迟和跨场景适应性方面的瓶颈。针对使用场景如工业装配、物流分拣等中实现操作成功率提升、任务执行时间缩短的目标。,"1.在仿真环境如pushT，metaworld实现对应操作任务，成功率达到70%以上
2. 完成收集真实场景任务数据，如抓取放置。并在真实机器臂部署训练好模型，实现80%以上成功率
3.利用前沿技术如预训练，CoT，仿真与真机数据混合训练等方式，实现完成长程任务并达到成功率80%以上。"
Kmesh特性验证与补充和文档编写,基础/Basic,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""]]",Kmesh 是基于 eBPF 和可编程内核的高性能、低开销服务网格数据平面。去年完成捐赠CNCF。流量治理相关的功能特性也已经基本完善。但Kmesh dual-engine mode下的流量治理特性缺少相对应的验证测试与文档。因此我们希望就以下几个特性完成验证测试与验证文档的编写。locality load balancecircuit breakerrete limitIngressengress其中关于Ingress和egress经过先行测试，欠缺DNS解析的逻辑，需要补充开发。,1. egress特性针对serverEntry的开发2. 其他功能的验证文档
基于MindSpore实现化学材料AI 大模型MoMa的开发及性能优化,进阶,"[[""datas"",""AI""]]",基于MindSpore+NPU进行创新：（1）基于用户模型代码生成MindSpore 计算图，根据模块化计算模型具备动态分支模块与静态结构模块的特点，实现动态+静态编译结合的计算图，并基于此计算图进行性能优化的策略寻优与计算加速，既满足动态分支部分模型对框架灵活性的需求，又能将静态结构模型的优化空间最大化。（2）针对模块化大模型基于运行中间结果选择分支的计算特点，探索动态计算图的并行计算加速策略，基于MindSpore 算子粒度切分的并行切分机制，对模型进行不同并行切分策略下的代价计算，以模型通信、数据通信、计算效率为参考实现并行切分策略的递归搜索，实现最优的计算图切分，实现训练与推理加速。,1. 完成基于MindSpore+NPU的MoMa模型开发。2. 支持模块化计算、具备动态分支的模型在分布式系统中运行速度的优化与提升，在同等算力下，模型取得同等精度所需训练时间缩短30%以上。
openGauss 向量数据库 AI 数据 ETL 框架最佳实践输出,基础,"[[""datas"",""AI""],[""datas"",""Database""]]",完成 Apache Kafka、Firecrawl、VectorETL 对接 openGauss 最佳实践教程输出,1. 基于 openGauss 部署指导文档，完成openGauss Docker 部署2. 参考 Milvus weaviate 等文档，完成 Apache Kafka、Firecrawl、VectorETL 对接 openGauss 最佳实践教程输出3. 将文档提交至 openGauss 社区
为 NestOS 适配 RISC-V 架构,进阶,"[[""os"",""RISC-V""],[""dev"",""GitLab CI/CD""]]",项目描述：清楚描述本项目背景以及要做什么。（1）相关背景NestOS 是基于 openEuler 社区孵化的云底座操作系统，目前仅支持 x86_64 与 aarch64。RISC‑V 硬件生态快速发展，越来越多的云平台与边缘设备采用 RISC‑V 架构。NestOS 具备 rpm‑ostree、Ignition、双根文件系统原子化更新等先进特性，非常适合作为 RISC‑V 上的云原生操作系统底座。（2）已有的工作openEuler RISC‑V SIG 已完成对 openEuler Kernel 的 RISC‑V 引导与内核移植。核心组件（ostree、rpm‑ostree、Butane）已有部分 RISC‑V 移植分支。nestos‑assembler 容器镜像尚未支持 RISC‑V 构建流程。（3）存在的不足构建脚本和 CI/CD 流水线缺少 RISC‑V 交叉编译与打包支持。（4）希望改进的点完善 nestos‑assembler 对 RISC‑V 的支持，包含交叉编译、qemu 测试与镜像产出。（5）最终项目实现的目标能够一键在 x86_64 CI 环境中生产 RISC‑V QCOW2、ISO、PXE、OpenStack 镜像。,1. 可在 x86_64 构建服务器上运行的 nestos‑assembler RISC‑V 构建脚本。2. 基于 qemu 的 RISC‑V 镜像（QCOW2、ISO、PXE、OpenStack）。3. CI/CD 流水线配置示例（GitLab CI 或 GitHub Actions）。4. 完整的用户指南：第 7、8 章新增 RISC‑V 构建与部署内容。
为洛书语言编写交互式学习手册,基础,"[[""codelang"",""Programming Language""]]",本项目要求为处于Beta阶段的洛书 v2.x 版本制作一份交互式学习手册，并以在线站点的形式部署至社区服务器，内容包括：安装与入门、程序结构、数据类型与编码技巧等。该手册要求具备交互式运行支持，基于WASM技术提供 Play Ground 环境，使得用户可以在浏览器环境下体验手册中的样例代码。,1. 根据社区工作进展，完成文档内容编写，要求使用 MarkDown 格式2. 接入交互式运行功能，实现基于浏览器的 PlayGround 环境3. 将项目打包部署至社区服务器
安同 OS Python 2 清除计划,进阶/Advanced,"[[""web"",""Desktop Application""],[""dev"",""CI""],[""dev"",""CD""],[""os"",""Clang""],[""os"",""Debian""],[""os"",""Compiler""],[""os"",""GCC""],[""os"",""Linux""],[""os"",""LLVM""],[""os"",""RISC-V""],[""codelang"",""Programming Language""]]",Python 2.7 已于 2020 年 1 月 1 日正式停止维护，标志着 Python 2 官方支持的终止。然而截至目前，安同 OS（AOSC OS）中仍存在大量 Python 2 软件包及其依赖项，这些残留导致安同 OS 仍需预装 Python 2，这些工作都意味着我们需要重新调查这些软件包的依赖关系、上游更改和代码兼容性，并在必要时编写补丁进行移植。目前，安同 OS 尚有至少 300 个软件包依赖 Python 2。由于 Python 2 不再提供安全补丁与功能更新，继续依赖 Python 2 将导致系统存在潜在的安全隐患及维护负担，并可能拖慢系统更新。本项目的主要目标是彻底移除安同 OS 软件仓库中的 Python 2 相关软件包和依赖，全面迁移至 Python 3。,"1. 在安同 OS 的软件仓库中彻底移除 Python 2，并在符合社区《软件包样式指南》要求的前提下提交相关的代码并进行充分测试和验证工作，完成现有 Python 2 软件包向 Python 3 的依赖迁移、移植或替换工作
2. 对上述软件包逐个进行评估，确认其是否完成 Python 3 移植，或寻找替代软件
3. 使用现有设施（如软件包信息站 packages.aosc.io 及 breaker 脚本等）分析目前依然存在的 Python 2 模块及 ELF 依赖
4. 如有必要，开发 shebang（#! 文件头）依赖分析工具"
llvm与gcc兼容性增强——模板调构造函数使用auto,进阶,"[[""os"",""GCC""],[""os"",""LLVM""]]",llvm和gcc是当下主流的C、C++编译器。应用使用不同编译器编译构建，可能遇到编译或者运行的兼容性问题。为降低客户在从gcc迁移至llvm过程中的人力投入，提升客户体验，需要在llvm编译器中对兼容性进行增强，支持对应场景，例如如下在调用析构函数时使用auto的场景：templatevoid f (T* p){p->~auto(); // p->~T();}int d;struct A { ~A() { ++d; } };int main(){f(new int(42));f(new A);if (d != 1)throw;return 0;}该场景gcc可以编译通过，llvm编译会提示如下报错：test.cpp:4:7: error: expected a class name after '~' to name a destructor4 | p->~auto(); // p->~T();| ^1 error generated.将auto改为对应类型名称后LLVM可以编译通过。出于兼容性考虑，希望可以兼容对应用法。,1. 调研GCC编译器对于对应场景的支持，测试用例迁移，并基于LLVM编译器对对应场景进行兼容2. 针对项目描述中代码中模版函数使用auto的场景，基于LLVM编译器支持可以编译和执行，效果和gcc编译器一致
基于 Node.js 和 Docker 实现的通用游戏服务端程序控制面板,基础/Basic,"[[""dev"",""DevOps""],[""web"",""Vue.js""],[""safe"",""Socket""],[""safe"",""WebSocket""],[""web"",""Webpack""],[""web"",""Web Application""]]",是一款，支持 Minecraft 和大部分 Steam 游戏服务器的 Web 控制面板。此软件在和部分能局域网联机的游戏社区内中已有一定的流行程度，它可以帮助你集中管理多个物理服务器，实现在任何主机上创建游戏服务器，并且提供安全可靠的多用户权限系统，可以很轻松的帮助你管理多个服务器，一直在为，和游戏服务器的管理员，运维人员和个人开发者提供健康的软件支持。1. 支持 Minecraft 和 Steam 游戏 服务器。2. 支持分布式架构，组织多台机器。3. 可拖拽，可高度自定义的网页 UI。4. 支持运行所有 Docker 镜像。5. 多用户管理，资源分配，商业出租。6. 安装简单，一键快速开服。1. NodeJS 生态（90%）后端：Koa，Socket.io，Docker API。前端：Vue3，Vueuse，Antdv。2. Golang 生态（10%）目前团队内的开发者均为用爱发电，大部分为大学生，少部分上班族，有菜鸡也有大佬，主要是中国大陆开发者为主，少数几个不怎么活跃的海外地区开发者。他们来自五湖四海，包容性强，只要你愿意学习，懂一些全栈开发，熟悉子进程控制知识，操作系统基本功，熟悉IO流编程，Docker 生态即可。拒绝有实力但不屑一顾，自恃清高，能用就行态度的学生。,1.为 MCSManager 提升基于 Docker 的可靠性，即主程序崩溃并重启后，能够重新接管存活的 Docker 容器的能力2. 开发 MCSManager 分布式的文件上传能力，实现切片文件上传，断点续传能力3. 修复一些项目上的BUG，提升项目运行稳定性4. (可选项) 实现兼容 Docker for Windows。
openInula 2.0 Antd 核心组件库,进阶,"[[""web"",""React""],[""web"",""UI""],[""web"",""Webpack""],[""web"",""Web Application""]]",openInula2.0 是一个新兴的前端框架，但目前缺乏一套完整的 UI 组件库支持。本项目旨在基于 Ant Design（Antd）的设计规范，开发一套轻量级的核心组件库，为开发者提供高效、易用的基础组件。相关背景：Antd 是 React 生态中广泛使用的 UI 组件库，但 openInula2.0 作为新框架，需要兼容其特性的组件库。已有工作：Antd 的开源代码和设计规范可作为参考。存在的不足：openInula2.0 尚未有官方支持的组件库，开发者需要手动适配 Antd 组件。实现目标：提供一套稳定、高效的 openInula2.0 版 Antd 基础组件库，支持常见场景的开发需求，包括：DatePicker (日期选择框)Form (表单)Tooltip (文字提示)Tree (树形控件）,1.  输出要求的 openInula2.0组件及测试代码2.  完善的文档，包括架构设计、API说明、使用指南和开发文档
OpenFDE的任务管理器,基础,"[[""web"",""AndroidX""]]",项目概述OpenFDE 是一款在 Linux 系统上运行的桌面环境，它支持 Linux 和 Android 应用的原生执行。通过 OpenFDE，用户可以无缝运行丰富的 Linux 和 Android 应用程序及游戏，享受一致的使用体验。目前，OpenFDE 缺乏一款能够同时管控 Linux 和 Android 程序的任务管理器。当某些应用出现内存泄漏或用户同时开启多个大型应用时，可能会导致系统卡顿。在这种情况下，用户往往难以直观地排查问题原因，从而影响使用体验。为了解决这一问题，我们计划开发一款专为 Android PC 化设计的任务管理器。这款工具将能够监控和管理整个设备上正在运行的进程和应用程序，帮助用户实时了解系统资源使用情况，并提供便捷的管理功能，以优化系统性能和稳定性。,"1. 提供Android和Linux 程序详细进程信息，包括 CPU、内存、磁盘和网络使用情况。
2.支持结束进程、启动进程。
3.提供服务管理功能，允许用户启动、停止系统服务。
4.图形化界面，易于操作并提供详细的帮助文档和提示，方便新手用户。"
基于django后端vue前端使用nump处理空数据,基础/Basic,"[[""web"",""Django""],[""os"",""Linux""]]",kytuning是一款自动化基准性能测试工具，能够在页面中展示性能数据。目前kytuning能够正常进行性能测试，性能测试完成后返回服务端测试结果，并能够把测试结果展示在页面中供用户查看，但当数据为空时会导致数据获取失败，其它数据的对比信息也无法展示，本题希望使用nump处理空数据，即使某组或某个数据未获取也不影响其它数据的对比展示。,1、当stream、unixbench、unixbench、lmbench、fio、iozone、jvm2008、cpu2006、cpu2017数据存在空数据时，目前会存在未处理空数据导致页面无法正常显示，此项目希望能够处理空数据，让页面中其他的对比信息能够正确返回。
实现在openGemini Go/JAVA客户端中无缝集成OpenTelemetry,基础,"[[""dev"",""DevOps""],[""datas"",""Database""]]","实现openGemini的Go/Java客户端深度集成OpenTelemetry，为开发者提供​​零侵入、全链路、多维度​​的观测能力，助力构建云原生时代的高效诊断体系。通过标准化协议对接，用户无需修改业务代码即可将数据库请求链路与OpenTelemetry生态无缝打通，实现​链路追踪。通过该功能，开发和运维人员可以实时观测客户端的行为，对异常、性能瓶颈等问题进行快速定位和追踪，同时便于与社区通用可观测性平台集成。在Go/Java Client中实现Otel Collector，采集客户端查询与写入操作的相关信息，如""请求的耗时""、""响应状态""、""错误信息""等。写入到Jaeger中进行数据存储。opentelemetry应用开发Demo链接：https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/examplesopenGemini-go-client: https://github.com/openGemini/opengemini-client-goopenGemini-java-client: https://github.com/openGemini/opengemini-client-java",1. 完成项目的设计、开发、测试并提供架构和使用以及二次开发的文档2. 设计时应符合高可配置性，用户可自定义采集级别和导出端点(exporter)。模块应与现有openGemini 客户端解耦，不影响现有功能的正常运行。3. 符合 openGemini开源社区贡献规范，PR 包含具体开发说明与使用演示4. 开发完成后合入社区相应代码仓
基于LiteFlow框架开发大模型插件以实现类Dify的后端智能体应用表达式编排能力,进阶,"[[""datas"",""AI""],[""web"",""Spring Boot""]]",LiteFlow是国内知名的Java规则引擎，目前被应用在数千家企业核心业务侧，社区人数众多，活跃度高。目前LiteFlow被广泛应用在逻辑编排场景，拥有灵活的DSL规则表示式以及支持度广泛的脚本语言，实用性和特性都非常适合业务复杂的应用侧。随着AI大模型的兴起，社区很多开发者把LiteFlow当做一个“后端Dify”来构造自己的智能体逻辑流。并且已经有相当一部分的社区同学已经成功落地了。但是LiteFlow并没有从框架层面对大模型有任何支持，LiteFlow目前提供的组件是极其开放的，大模型实现的部分还需要开发者自己去实现的。所以这次的课题的目标就是为LiteFlow打造一个AI大模型支持的插件，开发者不用自己再去对接大模型，能够直接引用AI插件已定义好的大模型的各种组件加上LiteFlow原有的强大的编排能力形成一个智能体逻辑流程。这次课题需要涉及当下大模型中的大部分知识块，包括但不仅限于对接主流平台的API，RAG，FunctionCall，MCP等相关概念。,1. 为LiteFlow开发liteflow-ai插件模块2. 为大模型插件提供完善的测试用例工程liteflow-ai-test模块，需要对每一个细分功能点，场景进行支持3. 为开发好的liteflow-ai插件创建演示工程liteflow-ai-example工程，综合利用liteflow-ai开发的演示工程。
为 treeland 实现锁屏管理协议,进阶/Advanced,"[[""web"",""Qt""],[""os"",""Wayland""]]",Treeland 是一个基于 Wayland 协议的合成器，致力于提供轻量级、模块化且可扩展的桌面环境体验。随着  Wayland 生态的完善，ext-session-lock-v1 协议已经成为管理会话锁定（如锁屏）的标准接口。当前 Treeland  尚未支持该协议，无法与 linux 社区广泛使用的锁屏应用兼容。本项目旨在为 Treeland 实现完整的  ext-session-lock-v1 协议支持，提升其功能完整性和生态兼容性。waylib 是 treeland 的核心开发库，提供了 wlroot 的 QtQuick 风格封装，此任务的核心工作在于完善此开发库。,1. 可以运行 swaylock ，hyprlock 等使用 ext-session-lock 协议的客户端，完成锁屏
为 Dubbo Admin 实现多种部署模式和 AI 智能管控运维能力,进阶,"[[""cloudnative"",""Cloud Native""],[""dev"",""LLMOps""],[""datas"",""AI""]]",1. Dubbo Admin作为宏观的控制中心，需要对运行在k8s以及非k8s环境下的Dubbo微服务进行统一的服务管理，流量管控。目前Dubbo微服务有三种形态：a. universal模式，该模式下dubbo微服务使用传统注册中心（nacos，zookeeper）进行服务发现，运行环境为虚拟机或其他非k8s环境。b. half模式，该模式下dubbo微服务使用传统注册中心进行服务发现，使用k8s作为运行的基础设施。c. k8s模式，该模式使用istio和k8s作为注册中心和运行基座。目前Admin已经支持了前两种，需要对第三种模式进行完善。2. 随着微服务集群规模的扩大，企业内异地多活，容灾备份的场景越来越常见。Admin需要对多注册中心，多k8s集群进行支持。3. Dubbo Admin作为统一的控制面，可以掌握到数据面的运行时数据，服务发现数据，以及可观测数据。当数据面中某个微服务出现问题时，利用服务运行信息以及监控（metric），日志（log），链路追踪（trace）等数据，结合llm，agent等技术，在Admin控制台中提供一个智能机器人，给开发者提供可能的排查方向和问题根源。,"1. 完善 Dubbo Admin 多种部署模型能力的支持
2. 提供结合 AI 进行问题诊断能力"
DragonOS云厂商移植支持,进阶,"[[""cloudnative"",""Cloud Native""],[""os"",""Linux""],[""os"",""x86""]]",DragonOS 是一个自主研发、基于 Rust 编写的现代化操作系统，目前已支持在腾讯云CVM上运行。然而，在实际运行中尚存在网络等关键功能不完善的问题，以及一些稳定性问题。例如，运行于腾讯云的 DragonOS  CVM实例，目前暂时无法稳定响应 HTTP 请求。本项目旨在进一步提升 DragonOS 在各大云平台上的可用性与稳定性，主要目标包括：,1. 将DragonOS移植至2个及以上的云平台，包括腾讯云、阿里云、华为云。能够正常进入用户态，并完成内核及启动流程的适配2. 移植sshd，能够通过ssh连接DragonOS3. 成功在DragonOS上部署 Nginx，提供静态网页服务：可通过公网访问，稳定运行72小时以上4. 实现DraconConfig自动初始化工具：主要包括网络配置模块、移植必要的网络管理工具等5. 技术文档与操作手册：提供完整的文档体系，支撑用户与开发者的使用与二次开发。
在skywalking-go中增加trace profiling功能,进阶/Advanced,"[[""dev"",""DevOps""],[""dev"",""DevSecOps""]]","目前skywalking-go已经实现对诸多插件的trace追踪, 在此基础上便可以结合pprof中的labels功能中将trace和goroutine中的profiling分析相互绑定并分析, 最终可以在UI中展示出火焰图此功能为新功能，需要和导师沟通功能范围，和提交设计和实现方案。","1. 完成Trace Profiling功能, 并且完成E2E自动化验证"
增强Volcano Agent以支持Cgroup V2与Systemd,基础/Basic,"[[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""],[""os"",""Cgroups""],[""os"",""Linux""]]",Volcano Agent 是云原生混部场景下的核心 SLO (Service Level Objective) Agent，通过统一调度、资源隔离和动态资源超卖等机制提高了资源利用率，并通过 OoS (Out-of-Service) 保障机制确保高优先级任务的服务质量。当前，Volcano Agent 主要支持 Cgroup v1，这与目前主流操作系统逐步迁移至 Cgroup v2 和 Systemd 的趋势不符，同时也限制了与配置不同的 Kubelet 节点的兼容性，阻碍了端到端混部能力的完整实现。本项目旨在增强 Volcano Agent 的基础能力，使其能够原生支持 Cgroup v2 和 Systemd。通过适配新的资源管理机制，Volcano Agent 将能更好地与现代操作系统集成，并与配置不同的 Kubelet 节点协同工作，为用户提供一致的混部体验，从而进一步完善其在云原生混部场景下的资源管理和 SLO 保障能力。,1. 支持 Cgroup v2 的 Volcano Agent: 提供能够与 Cgroup v2 系统正常工作的 Volcano Agent 版本。2. 支持 Systemd 的 Volcano Agent: 提供能够与 Systemd 系统良好集成的 Volcano Agent 版本。3. Kubelet cgroup-driver 兼容性: 实现与 Kubelet 不同 cgroup-driver 配置（包括 systemd 和 cgroupfs）的兼容性，确保 Volcano Agent 在不同配置下都能正确运行和管理资源。4. 功能测试与验证: 提供充分的单元测试、集成测试和端到端测试，验证 Volcano Agent 在 Cgroup v2 和 Systemd 环境下的核心功能（统一调度、动态资源超卖、OoS 保障等）的正确性，并验证与不同 Kubelet cgroup-driver 的兼容性。5. 配置和部署文档更新: 更新 Volcano Agent 的配置和部署文档，详细说明如何在 Cgroup v2 和 Systemd 环境下部署和配置 Agent，以及与 Kubelet cgroup-driver 相关的配置说明。6. 社区集成与发布: 将开发成果集成到 Volcano 社区主干分支，并按照社区流程进行版本发布。
基于MindSpore Quantum实现自适应偏置场热启动QAOA算法 ,基础,"[[""datas"",""AI""]]",任务背景：1. 热启动策略：利用GW算法生成初始解，通过旋转编码为量子态，替代传统均匀叠加态。2. 自适应偏置场：混合哈密顿量引入纵向偏置场，随优化过程更新，引导量子态向更优解演化。3. 统一框架与理论分析，涵盖WS-ab-QAOA、WS-QAOA等变体。任务需求：基于MindSpore Quantum框架复现论文arXiv:2503.20048v1，实现热启动自适应偏置场QAOA，能够高效求解最大割问题，相对于论文中的对比对象有性能提升。,1. 要求使用MindSpore Quantum 0.10复现论文中3个图（figure2.4.5）；2. 提交规范的技术报告，需包含：a.具体的算法流程，复现的技术细节，例如量子线路；b.分析方法的运行机理 c.该算法适用场景和局限；3. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准；4. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。
为 Arthas 实现 JFR 解析和前端UI库,基础,"[[""dev"",""AIOps""],[""web"",""React""],[""web"",""RESTful API""]]",JFR 是 JDK 里非常重要的性能分析工具，它生成的结果文件需要解析展示出来。期望可以使用 React 并基于 Ant Design 组件库实现解析展示。参考链接,1. 在Server端使用 JDK 的 JFR API解析 .jfr 文件，提供 RESTful API2. 在前端以火焰图方式展示分析结果3. 需要支持 CPU Time/Allocated Memory/File IO Time/File Read Size/Exception 等常见 Event 的分析展示
k8s任务与k8s集群链接优化,基础/Basic,"[[""cloudnative"",""Kubernetes""]]",目前DolphinScheduler中的worker在接受到master下发的k8s任务运行指令时会根据k8s的信息创建一个k8s链接，通过该链接与k8s集群之间保持联系。但当任务并发量大时，k8s集群要为每一个k8s任务维护一个链接，现有方案会造成信息同步效率差甚至与k8s集群失联。本课题针对该问题提出优化方案，为一个DolphinScheduler的worker节点创建一个链接池（考虑会有多个k8s集群的情况，一个k8s集群一个链接），为每一个k8s集群创建一个公用链接，该worker中所有k8s节点通过链接池中的链接与k8s集群交互。该方案可以减少k8s对链接维护的成本，可以提高k8s任务类型并发量，提高状态同步效率。,1. 完善k8s任务 e2e测试2. 完成k8s链接池部分unitTest测试3. 本地测试阶段，完成k8s任务并行验证
Apache ShardingSphere: 增强 SQL Server SQL 解析引擎，适配更多 DDL、DML 语句,基础,"[[""datas"",""MySQL""]]",背景:Apache ShardingSphere 是一款分布式数据库生态系统。目前，ShardingSphere 对 SQL Server 的 SQL 解析支持仍存在局限性，部分复杂 DDL（数据定义语言）和 DML（数据操作语言）语法无法被准确解析，导致用户在分片、读写分离、数据加密等场景中无法充分利用 SQL Server 的功能。此任务的目标是提升 ShardingSphere SQL 解析引擎对 SQL Server 的 SQL 支持度，提升对 SQL Server 的生态兼容性，满足用户需求。任务:参考 SQL Server 语法文档：https://learn.microsoft.com/zh-cn/sql/t-sql/language-reference，适配常用的 DDL 和 DML 语句，并补充对应的测试用例。相关任务如下：,1. Apache ShardingSphere 目前已经对 SQL Server 进行了初步适配，支持通过 JDBC 连接底层存储，实现数据加密、数据脱敏等增强功能。为了提升对 SQL Server 语句的支持度，需要增强 Apache ShardingSphere 内部的 SQL Server 解析引擎，适配更多的 DDL、DML 语句，并且增加  SQL Server 自动化测试程序，保证数据加密和数据脱敏功能可用。
ArceBoot引导程序设计,进阶,"[[""os"",""RISC-V""]]",ArceBoot是基于ArceOS组件生态设计的轻量级引导程序，旨在通过模块化方式实现内核启动能力。项目聚焦UEFI实现路径，与ArceOS组件深度集成，利用ArceOS的驱动、文件系统等组件，减少重复开发并构建一个安全、高效的引导程序，支持从存储介质加载内核并跳转执行，ArceBoot引导程序的实现也可以同时丰富ArceOS的组件生态。ArceBoot引导程序设计项目的主要目标是：基于ArceOS的驱动组件（axdriver）和文件系统组件（axfs），实现引导介质的探测与内核文件（/EFI/BOOT/*.EFI）的加载，解析PE/COFF格式的内核文件，将其加载到内存，并通过UEFI标准接口跳转执行，以达成启动内核的目的。若ArceBoot引导程序实现时，其依赖的ArceOS组件仍不完善，为ArceOS提交的合并请求也计入本项目的贡献中。,1. 完成ArceBoot的UEFI引导程序实现，支持在QEMU或者真实硬件上加载并启动内核。2. 提供完整的构建与使用文档，包括示例配置和跨平台测试指南。
Apache HertzBeat 日志监控能力,进阶/Advanced,"[[""web"",""Angular""],[""web"",""Spring Boot""]]",Apache HertzBeat 是一个开源的实时监控系统，专注于提供高效、灵活的监控解决方案。它支持多种数据源的监控，广泛应用于云原生环境下的运维场景。然而，随着用户对日志监控需求的增加，本项目需要开发一个 日志监控模块，以增强 HertzBeat 在日志监控领域的功能覆盖。本项目的核心目标是构建一个轻量级的日志监控模块，为用户提供从日志采集、存储到查询展示的完整解决方案。具体而言，项目将实现以下关键能力：该项目的实施将显著提升 HertzBeat 在日志监控领域的竞争力，同时为开发者和运维人员提供更加便捷的日志管理工具，助力企业在复杂分布式系统中的故障排查与性能优化。,"1. 设计日志上报接入层,支持 OpenTelemetry sdk上报，Kafka消息流收集，FileBeat上报等消息中间件收集日志2. 统一的日志存储3. 友好的日志查询分析界面4. 统一的日志阈值规则5. 测试代码覆盖"
实现 dynamic-tp 的自建管理端功能,进阶,"[[""web"",""Spring Cloud""],[""web"",""Spring Boot""]]",dynamic-tp 是一款轻量级 java 动态线程池增强框架，内置监控告警功能，集成常用三方中间件线程池管理，目前 dynamic-tp 主要是基于配置中心实现的。自开源以来，有不少用户问过有没有做管理端的打算，因为不是所有公司都有搭建配置中心，也不是所有用户都习惯配置中心的弱交互操作。dynamic-tp 作为最基础的组件，应该是尽可能满足各类用户的需求，自建管理端能使 dynamic-tp 真正成为一站式线程池管理框架。,1. server 端采用 springboot3 构建，实现权限管理、首页大盘、线程池管理、告警渠道管理、日志管理等。2. 前端采用 soybean-admin 框架进行搭建。3. 跟 server 交互的 client 最好是以单独包存在，不要过多的侵入现有配置中心代码。4. 保证测试质量，无明显 bug。5. 支持 docker 快速部署。
dora-rs 样例开发和改进文档,基础/Basic,"[[""codelang"",""Programming Language""],[""os"",""Linux""],[""os"",""Ubuntu""],[""os"",""ARM""],[""os"",""Clang""]]",目前，dora - rs 生态系统中中文内容匮乏，代码使用样例稀缺，给社区开发者带来诸多不便，阻碍了技术的推广应用。本项目旨在解决这些问题，全面开发并丰富 dora 示例，涵盖 Rust、C++ 和 Python 语言开发。针对每种语言精心制作一系列详细代码样例，并配套编写逐步指导文档，阐述代码逻辑与预期效果，同时打造 Read the Docs 风格文档，方便开发者快速查阅信息。此外，还将制作 B 站系列视频，以直观方式引导开发者使用示例。项目内容会同步更新中英文版本，最终确保所有示例均经过测试，并配有包含安装、配置及代码运行等方面的完整文档指南，提升 dora - rs 对社区开发者的易用性，促进社区的参与和创新。,1. 开发工作
基于 Rust 的 RROS 实时与非实时代码分离与优化,进阶/Advanced,"[[""os"",""RTOS""]]",本项目旨在通过将实时与非实时代码在 RROS 操作系统中进行分离，以提高系统的实时性能和安全性。利用 Rust 强大的类型系统来实现内存安全、并发安全和高效的资源管理，特别适用于需要高安全性和高性能的系统。分离实时与非实时代码将有效提升系统的资源管理、错误防止以及并发控制能力，为构建下一代高可靠的实时系统提供理想的技术基础。项目将通过以下几个关键步骤进行：通过本项目，旨在为高实时性要求的应用（如自动驾驶、工业控制等）提供更高效、更安全、更易维护的操作系统平台。,1. 实时与非实时代码分离：成功在 RROS 操作系统中实现实时与非实时代码的分离，确保两者之间互不干扰并且能够独立运行。
Sermant动态配置能力增强——支持Apollo配置中心,进阶,"[[""cloudnative"",""Cloud Native""]]",1. 项目背景Sermant作为云原生无代理服务网格框架，其核心能力依赖于动态配置的实时下发与生效。目前Sermant已支持Nacos、Zookeeper、Kie，但在实际企业场景中，携程开源的Apollo配置中心因高可用性、灰度发布、权限管理等特性被广泛使用。当前Sermant对Apollo的适配尚未完善，导致用户需自行开发适配逻辑，存在以下痛点：- 企业用户迁移成本高：使用Apollo的企业需改造现有配置体系才能接入Sermant，阻碍技术栈统一。- 动态配置能力受限：现有配置中心插件未充分利用Apollo特有的“灰度发布”“配置回滚”等高级特性。2. 已有工作**- 配置中心抽象层：Sermant通过模块抽象了配置监听、数据解析等通用逻辑。- 现有实现：已支持Nacos、Zookeeper、Kie等配置中心，支持配置热更新与动态生效。3. 项目目标完成Sermant动态配置服务对Apollo配置中心的支持,"1. 在Apollo配置中心的特性支持下，实现DynamicConfigService定义的所有接口，使其具备配置监听、下发、删除、更新等操作，从而实现服务治理规则的变更
2. 编写自动化测试用例，覆盖边界场景
3. 通过Benchmark测试验证万级配置项的监听与推送性能，确保生产可用性。 
4. 编写使用说明和文档示例"
BMF DiffusionFlow,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""]]",BabitMF（BMF）是字节开源的多媒体处理框架，已支持音视频及 AI 算法的模块化调度。本项目将 Stable Diffusion（SD）端到端生成流程，封装为一系列可在 BMF Graph 中以节点化方式调用的 Module，进一步丰富框架在 AIGC 场景下的表现力。,1. 完成 SD 全链路基础 BMF Module 的设计、开发与单元测试，比如  Text Encoder、 Diffusion Scheduler、VAE Decoder 等2. 产出 Text-to-Image、Image-to-Image 两个场景的完整示例3. 实现点击／拖拽式 Graph 编辑器，并能预览生成结果
面向工业制造的具身智能基准测试套件,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""datas"",""AI""]]",随着工业制造智能化进程加速以及工业机器人、柔性产线、检测装备持续升级，云边协同成为支撑具身智能系统在复杂生产场景中落地的关键技术。当前工业领域对具身智能服务的需求已从单一任务执行向高精度感知决策、实时动态适应性、跨设备协同控制等方向演进，但通用具身智能基准测试普遍缺乏对工业场景具身特性的针对性评价，本项目基于 KubeEdge-Ianvs 协同人工智能基准测试框架，配套工业场景测试数据集、测试环境和性能指标，构建面向工业制造的行业级具身智能测试能力。,1. 引入具身智能领域工业数据集，按四大类标准化任务分类并重新整理现有数据集：感知（如多视角表面质检）、移动（如料箱搬运、堆拆码垛）、操作（如精密装配、精密插装、多工序柔性总装、多品类柔性装配、卷盘转运、设备入盒包装、混合物品分拣）、复合（如电子设备柔性测试、电力巡检），输出数据集调研报告2. 在KubeEdge-Ianvs中选择至少一种上述场景提供标准化测试套件，包括数据集、测试环境、测试指标，以标准化统一数据格式梳理数据集3. 在KubeEdge-Ianvs中基于标准化测试套件实现具身智能基线算法
TinyVue组件增加全局配置动效方案,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",在开发应用时，为组件添加全局配置的动效方案是一种提升用户体验的好方法。这种方案允许开发者通过统一的方式控制所有组件的动画效果，从而保持应用的一致性和美观性，可参考Uiverse。,1. 定义全局动效配置，你需要定义一个全局的动效配置对象，这个对象可以包含各种动效相关的属性，比如动画类型、持续时间、延迟等。2. 创建动效函数库，创建一些通用的动效函数（js函数或者less通用类），这些函数可以根据全局配置来执行特定类型的动画。例如，你可以为淡入淡出、滑动和缩放等常见动画创建函数。3. 组件集成，每个组件都可以根据需要调用上述动效函数，并传入全局配置或局部配置。4. 动态调整配置，可以希望提供一种方式来动态地改变全局动效配置，以便于在不同的场景下使用不同的动画效果。5. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。6. 补充相应的文档和自动化测试用例。7. 建议输出TinyVue组件增加全局配置动效方案的介绍文章和视频
为RustPilot添加MuJoCo/Nvidia Isaac仿真平台的支持,进阶/Advanced,"[[""codelang"",""Programming Language""],[""os"",""ARM""],[""os"",""Linux""]]",RustPilot 是一款采用 Rust 语言开发、运行于 Linux 系统的开源飞控软件。项目以简洁性与可维护性为核心，基于模块化设计与仿真驱动开发，为开发者、无人机爱好者及研究人员提供灵活可靠的飞控解决方案，同时降低小型无人机的开发门槛。目前，RustPilot 已支持在 Gazebo 环境中进行仿真调试（SITL）。Gazebo 在飞控控制功能的验证方面具备一定优势，适用于通用仿真场景。然而，由于其物理引擎建模能力相对有限，在接触建模、高自由度系统模拟等方面不及 MuJoCo 与 NVIDIA Isaac。此外，Gazebo 的视觉效果较为粗糙，难以满足合成数据生成和视觉模型训练等现代需求。因此，为更好地对接强化学习生态，RustPilot 需扩展支持 MuJoCo 和 NVIDIA Isaac 等更先进的仿真平台。MuJoCo 是由 Emo Todorov 开发、目前由 DeepMind 维护的高精度物理仿真引擎，并已于 2021 年开源。其主要特点包括：高效的求解器、多接触动力学建模、低延迟模拟能力，广泛应用于强化学习、机器人控制和优化等领域。MuJoCo 适用于复杂多体系统的高精度仿真，便于嵌入研究环境，并支持大规模训练任务。NVIDIA Isaac 平台 是 NVIDIA 推出的机器人开发平台，采用 Omniverse + PhysX 引擎，具有出色的图形渲染能力与 GPU 加速仿真性能。该平台支持高保真的传感器模拟（如摄像头、激光雷达等），可与 ROS / ROS 2 系统无缝集成，同样适合用于大规模强化学习训练与系统验证。本项目旨在为 RustPilot 增加对 MuJoCo 或 NVIDIA Isaac 仿真平台的支持，并至少完成对其中一个平台的适配工作。针对每个平台，主要开发任务包括但不限于：参考资料：[1] RustPilot: https://github.com/Ncerzzk/RustPilot,1.  实现 RustPilot 对至少一个仿真平台（MuJoCo 或 NVIDIA Isaac）的支持2. 开发 RustPilot 模块，完成仿真器与飞控系统的数据交互接口，实现对仿真飞行器的姿态、位置读取与电机控制功能3. 设计并实现多个贴近现实的仿真场景，用于测试与演示4. （可选）完成四旋翼角度环和角速度环的调试与验证流程
基于 Occlum 实现 System V 信号量系统调用,基础,"[[""os"",""Linux""]]",Occlum 是一个适用于 Intel SGX 的内存安全、多进程库操作系统（LibOS），可以让旧应用无需修改源码就运行在 SGX 之上，从而以透明的方式保护用户应用的机密性和完整性。目前，Occlum已实现基于共享内存的进程间通信（IPC）与基于 futex 的线程同步机制。然而，一些旧应用程序仍会使用System V信号量进行 IPC 与线程同步，该机制尚未在 Occlum中实现，从而这些应用无法在 Occlum 上正确运行。,1. 本项目的目标是在 Occlum 中实现 System V 信号量机制（包括 semget、semctl、semop、semtimedop 等系统调用），使得 Occlum 能支持更多应用程序。
使用仓颉语言编写的洛书运行环境,基础,"[[""codelang"",""Programming Language""]]",该项目要求使用仓颉编程语言进行实现一个嵌入式的洛书运行环境，可以在仓颉工程中插入洛书编写的脚本代码，提高工程的灵活性与拓展性。本项目要求实现以下功能：,1.完成项目的基本功能要求，实现在仓颉工程中使用洛书脚本，实现动态执行。2.在此基础上，基于FFI机制，实现基本脚本功能模块，如（IO、字符串、数学等）3.（可选）遵循仓颉社区规范，将本项目贡献至 Cangjie-SIG
Cloudpods 大模型一键部署,进阶,"[[""datas"",""LLM""],[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""]]","基于 Cloudpods 容器主机和 GPU 透传功能开发一键部署大模型工具。制作主流大语言模型( deepseek, qwen, llama 等）容器运行镜像， 命令行工具调用 Cloudpods API 运行大模型容器主机与 Dify LLM开发应用平台容器主机，通过 Dify 容器访问大语言模型容器服务。容器内大模型服务运行可使用 Ollama 开源 LLM 服务部署框架。","1.  能通过 Cloudpods 容器主机一键部署主流大语言模型服务( deepseek, qwen, llama 等）。2. 能通过 Cloudpods 容器主机一键部署 Dify LLM开发应用平台，能通过 Dify 访问部署的大语言模型服务。3. 代码以 PR 形式提交到 https://github.com/yunionio/cloudpods 仓库4. 产出项目开发使用文档"
为IvorySQL开发基于uuid-ossp的sys_guid函数,基础,"[[""datas"",""PostgreSQL""]]",(1)相关背景：IvorySQL是一个开源的基于PG的数据库，支持多种Oracle兼容特性。目前IvorySQL需要一个强大并确保数据库级别唯一的sys_guid函数。(2)已有的工作PG内核提供一个类似sys_guid()的函数，即基于伪随机数的gen_random_uuid ()。(3)存在的不足缺少sys_guid函数。(4)希望改进的点基于uuid-ossp/e2fs开发这样一个函数。(5)最终项目实现的目标代码以PR的形式提交到Github。,"1. 通过修改插件 uuid-ossp 的代码 contrib/uuid-ossp/uuid-ossp.c 实现sys_guid()函数。需要判断如下逻辑：如果系统有uuid-ossp，就使用uuid_make()，否则看有没有uuid-e2fs，如果有的话，就调用 uuid_generate_random(), 否则就调用 arc4random() 。同时修改代码使得IvorySQL能够自动载入uuid-ossp插件。"
uORB 订阅发布机制组件,基础,"[[""os"",""RTOS""]]",uORB（微型对象请求代理）是一种轻量级的发布-订阅通信机制，广泛应用于PX4等实时系统中，用于模块间高效数据交互。RT-Thread作为一个灵活的嵌入式RTOS，目前缺乏类似的统一通信机制，模块间通信主要依赖传统的事件、信号量或消息队列，效率和扩展性有待提升。本项目要求参赛者为RT-Thread设计并实现一个uORB风格的订阅发布机制组件，参考PX4的uORB实现，结合RT-Thread的内核特性（如线程调度、内存管理等）进行优化。,1. 设计并实现一个基于RT-Thread内核的uORB订阅发布机制组件，包括核心API（如发布、订阅、主题管理）。2. 优化组件性能，确保其在RT-Thread的实时环境下具有低延迟和高吞吐量，支持多线程并发访问。3. 提供至少两个示例应用（如传感器数据发布、控制命令订阅），展示组件的实际使用场景。4. 集成组件到RT-Thread的构建系统中，支持menuconfig配置启用/禁用。5. 提交详细的开发文档，包括组件架构说明、API参考手册及使用教程。
基于OrangePi AIpro和鸿蒙系统的智能网联小车开发,进阶,"[[""datas"",""AI""]]",随着无线通信、鸿蒙系统、人工智能技术的快速发展，利用Orange Pi AIpro开发板及支持鸿蒙系统的移动终端开发智能网联小车成为了科研用户快速利用国产化软硬件技术掌握车联网开发的一种有效手段。,1. 利用Orange Pi AIpro开发板和高清摄像头搭建智能网联小车，小车利用OrangePi AIpro开发板作为主控板控制智能网联小车运动，小车利用OrangePi AIpro开发板上部署的AI算法通过摄像头辅助远程控制者进行目标检测、车道线检测、车道偏移计算等辅助控制功能。2. 基于具有wifi通信功能的鸿蒙终端开发应用程序，实现控制者通过wifi远程控制智能网联小车运动，智能网联小车采集的视频数据能实时通过wifi传输到鸿蒙终端帮助远程控制者实时操控。
开源软件 API 图谱构建与基于图谱的开源软件生态评估,进阶/Advanced,"[[""datas"",""LLM""]]",一、项目介绍随着开源软件在全球范围内的广泛应用，理解和评估开源软件、洞悉开源软件生态的结构与动态十分关键。本项目计划构建API签名并搭建开源软件 API 图谱，覆盖功能、参数类型、来源三方库、编程语言等信息。并基于该图谱对开源软件生态进行评估，帮助开发者和企业更好地了解开源软件的内部结构、依赖关系，以及整个开源生态的健康状况。这不仅有助于提升软件的开发效率，也为开源项目的可持续发展提供数据支持和决策依据。基于开源API图谱还能实现相似开源软件的精准识别与推荐，助力开发者高效发掘适用的开源资源，推动开源生态的蓬勃发展。二、相关技术1.数据采集：借助 Python 的 Scrapy 框架，从 GitHub、GitLab 等主流开源代码托管平台，采集开源项目的代码及项目名称、开发者信息、版本号等元数据。运用编程语言专属工具与库，如 Java 的反射机制、Python 的 ast 模块，解析代码文件，提取 API 调用信息，并借助自然语言处理技术，从 API 文档、代码注释中抽取 API 功能描述。2.图谱构建：采用图数据库 Neo4j，以节点代表开源软件、API、开发者等实体，用边表示它们之间的依赖、调用、协作等关系。为每个 API 节点添加功能描述属性，构建具备丰富信息的图谱。使用 Graphviz、NetworkX 等知识图谱构建工具，进行图谱的可视化与初步分析。3.生态评估与应用：运用机器学习和数据挖掘算法，如 PageRank 算法、社区发现算法，对图谱数据进行分析，评估开源软件的影响力、核心度以及生态系统的社区结构。基于图谱中开源软件的 API 使用模式、功能特性，采用余弦相似度、Jaccard 系数等算法，识别相似开源软件，并实现个性化推荐。同时，借助自然语言处理技术，对开源项目的文档、论坛讨论等文本数据进行情感分析，了解开发者对项目的反馈与评价。,1. API 图谱数据集：构建涵盖多种主流编程语言的开源软件 API 图谱数据集，数据集包含开源项目信息、API 调用关系、API 功能描述及相关元数据，为后续分析与应用筑牢数据根基。2. 图谱可视化与应用平台：开发基于 Web 的图谱可视化与应用平台，用户可在平台上直观查看开源软件的 API 图谱，进行节点搜索、关系查询、图谱缩放等操作。同时，平台支持相似开源软件的识别与推荐，以及开源软件生态健康状况的可视化展示。3. 生态评估与应用报告：基于图谱分析结果，撰写开源软件生态评估与应用报告，内容包括开源软件生态健康状况评估、关键项目与开发者识别、相似开源软件推荐策略，以及对未来发展趋势的预测。报告需提供数据支撑与案例分析，为开源软件生态的优化提供参考。
实现 nydusify copy 的不落盘能力,进阶,"[[""datas"",""AI""],[""cloudnative"",""Kubernetes""],[""os"",""FUSE""]]",镜像是容器基础设施中的一个重要部分，目前 OCI 标准镜像的缺陷之一是容器需要等待整个镜像数据下载完成后才能启动，这导致了容器启动时消耗了过多的端到端时间。开源容器镜像加速项目 Nydus 能够使得容器做到秒级冷启动，在镜像构建，分发与运行时，以及性能与安全性上有诸多探索，目前 Nydus 服务了每日百万级的容器创建，也在 AI 模型镜像分发上有着诸多落地场景。本题目是实现 nydusify copy 的不落盘能力，nydus 在构建及运行时工具链上都支持了 RISC-V64 架构。,1. nydus 提供的镜像 copy 工具目前存在性能问题，数据拷贝过程中大量数据会落盘，我们需要优化掉该行为，且进一步优化并发拷贝性能，并编写单元测试，集成测试，以及用户文档。
mermaid 可视化能力扩展,基础/Basic,"[[""web"",""UIKit""]]",扩展mermaid（https://github.com/mermaid-js/mermaid）能力，使其支持更强大的表格和图表能力（VChart 和 VTable）。扩展成果会作为VisActor Demo，同时向mermaid社区提交pr。,1. 替换mermaid 原饼图、桑基图、xy图表的实现为VChart2. 迁移剩余VChart 图表到mermaid3. 添加VTable  表格能力到mermaid4. 技术设计文档和功能使用教程
Optimize NegativeAck feature of Pulsar C++/Go Client.,Basic,"[[""datas"",""Kafka""]]","Pulsar provides sdk in many promgaming language, like Java, C++, Go...The most cutting-edge features and optimizations are provided in Javd sdk first. We have reduce the memory occupation of NegativeAck in Java sdk by 95+%, while sdk in other languages are not optimized.We can implement this great improvement in Pulsar C++/Go Client.",1. Reduce the memory occupation2. Improve the performance of sdk
为 Rainbond 实现 Kubeblocks 集成,进阶,"[[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""]]",是一个云原生应用管理平台，使用简单，不需要懂容器、Kubernetes和底层复杂技术，支持管理多个Kubernetes集群，和管理企业应用全生命周期。主要功能包括应用开发环境、应用市场、微服务架构、应用交付、应用运维、应用级多云管理等。KubeBlocks 是一个开源的 Kubernetes 数据库 operator，能够帮助用户在 Kubernetes 上运行和管理多种类型的数据库。为 Rainbond 集成 KubeBlocks 实现数据库的创建、管理、备份等。（可以提供 Cursor 会员账号）,1. 产出设计文档2. 为 Rainbond 实现 KubeBlocks 功能
移植sysboost到RISC-V架构,进阶,"[[""os"",""RISC-V""]]","（1）相关背景通过sysboost代码重排技术对可执行文件和动态库文件在线重排操作，优化代码与运行环境的CPU微架构的适应性, 提升程序性能。该技术在保证程序语义和意图不变的情况下, 优化汇编指令, 代码布局, 数据布局, 内存大页, 系统调用等。sysboost是openEuler原创应用，目前还不支持RISC-V架构。（2）已有的工作（3）存在的不足（4）希望改进的点（5）最终项目实现的目标完成项目移植，合入官方仓库。",1. 完成项目移植，合入官方仓库。
用数据库存储代码提升开发效率,基础,"[[""os"",""RISC-V""],[""os"",""Compiler""]]",设计并实现一种通过数据库存储代码的方式，有效解决 OpenHarmony 开源软件社区应用代码现存的三大痛点。当前，开发者在使用 OpenHarmony 开源代码时面临诸多不便：其一，下载代码存在大量冗余，不必要的代码文件增加存储负担；其二，相关文档缺失或不完善，导致开发者难以快速获取关键信息；其三，每次使用都需重新配置环境，从下载全部代码、搭建运行环境，到在庞大的源码中精准定位所需功能模块，最后将其集成到自身项目，整个流程耗时耗力，极大影响开发效率。​针对上述问题，本方案将开源软件中的功能点或接口所涉及的函数，整合存储至数据库中。开发者只需借助专用查询工具，即可快速检索并提取所需功能的开源代码，直接集成到自己的项目中，无需再进行繁琐的全量代码下载与环境配置，显著简化开发流程。​本项目聚焦 OpenHarmony 应用代码，通过提升开发者获取和使用开源代码的便捷性，加速 OpenHarmony 应用生态的建设与繁荣，为开发者营造高效、便利的开发环境，推动 OpenHarmony 生态的蓬勃发展。,1. 实现一个可以将软件按函数拆分并将每个函数转为数据库一条数据的工具。2. 设计一种可以处理好函数调用关系链的方案。3. 实现一个将多个数据库中函数拼凑成一整个可运行程序的工具。4. （进阶）开发函数关系可视化Openharmony应用客户端。
铜锁密码库支持密码设备接口（SDF）和智能密码钥匙接口（SKF）功能,进阶,"[[""safe"",""RSA""],[""safe"",""PKI""],[""safe"",""SSL/TLS""],[""safe"",""AES""]]",铜锁/Tongsuo是一个提供现代密码学算法和安全通信协议的开源基础密码库，为存储、网络、密钥管理、隐私计算等诸多业务场景提供底层的密码学基础能力，实现数据在传输、使用、存储等过程中的私密性、完整性和可认证性，为数据生命周期中的隐私和安全提供保护能力。密码设备应用接口规范，对应标准为GM/T 0018-2023，定义了密码卡设备的调用接口。智能密码钥匙接口规范，对应标准为GM/T 0016-2023定义了智能密码钥匙设备的调用接口。目前，Tongsuo开源项目只支持部分的SDF接口，需要参考SDF标准，支持完整的SDF接口。Tongsuo开源项目还不支持SKF接口，需要参考SKF标准，支持完整的SKF接口。补齐Tongsuo项目的SDF和SKF接口能力，为了帮助密码应用程序和用户更好的管理和控制密码卡和密码智能钥匙设备。企业会帮忙协调密码硬件设备。,1. 完善Tongsuo中的SDF功能，至少适配一种密码卡或密码机2. 开发SKF接口，至少适配一种智能密码钥匙
SeaTunnel on Flink cdc connector 支持schema evolution,进阶/Advanced,"[[""cloudnative"",""Flink""]]",目前SeaTunnel已经定义好了schema evolution相关的api接口，并且已经在zeta引擎上实现，该课题目标是在Flink引擎上实现该功能。,1. 功能实现落地方案2. 实现Flink引擎schema evolution功能3. 编写完善的单元测试 + 集成测试
基于高性能RISC-V处理器核“香山”的微架构UT验证——FTQ 与后端及取指令单元交互,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""dev"",""pytest""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。本项目基于开源高性能RISC-V处理器核“香山”的最新架构昆明湖，通过参与，您将深入了解到高性能处理器设计，有机会进入贡献排行榜、获得实习Offer、RISC-V中国峰会差旅补贴，为开源芯片的发展贡献力量。FTQ是取指目标队列，在处理器前端设计中承担着重要作用，负责前端分支预测单元BPU和取指令单元IFU之间的交互，以及前端与后端之间交互。本项目是FTQ完整验证任务的下半部分，涉及了FTQ与取指令单元IFU之间的交互，以及FTQ与后端交互的内容。,1. 验证环境+API：验证环境和API是代码成果，是针对待验证对象（DUT）的数据职责（引脚）和行为职责（逻辑）的封装，需要提供特定的可复用的接口、 测试套件、测试覆盖率等的定义。2. 测试用例：测试用例是代码成果，定义了用于测试的输入组合，以及预期的输出组合。3. 验证报告：验证报告是文字成果，包括对环境、测试点和测试用例的介绍，复现代码所需的环境和指令，以及对测试覆盖率等衡量指标的报告。
面向RISC-V向量扩展的性能评估基准测试的开发,进阶,"[[""os"",""RISC-V""],[""os"",""ARM""],[""os"",""x86""]]","向量硬件是一种通过单指令多数据（SIMD）架构实现高效并行计算的处理器组件，当前主流处理器架构均有功能类似但各不相同的向量扩展指令集。向量指令作为这类硬件的编程接口，允许软件使用向量硬件的加速能力优化性能，已经成为现代高性能计算的关键技术。在高级语言层面，使用向量指令优化软件性能的方法主要有三类：直接使用高级语言编写算法，依赖编译器自动向量化生成向量指令；使用向量硬件的通用向量语言编写优化算法；使用特定硬件的专用向量语言编写优化算法。：开发者高级语言编写算法，依赖编译器的自动向量化功能将标量代码转换为向量指令，这种方法的适用场景最广，开发者通常只需关注算法逻辑而无需了解底层硬件细节。：通过跨平台向量编程库（如Google Highway、C++标准库std::simd），开发者使用抽象化的向量类型和操作直接编写向量化的算法逻辑，并由跨平台向量编程库在编译时适配不同硬件指令集，生成对应的向量指令。这种方法避免直接绑定特定硬件指令集，同时提供比编译器自动向量化更强的优化能力。：通过向量内建函数（如x86的AVX Intrinsics、ARM的NEON Intrinsics、RISC-V Vector Intrinsics），直接使用目标硬件的向量内建函数编写向量化算法逻辑，这种方法通常具有最佳的性能表现。RISC-V是一个具有模块化特点的新兴指令集架构，向量扩展（RISC-V Vector）为其添加了单指令多数据并行能力，具备可变长向量特性。本项目希望构建一个性能评估基准测试用于评估当前主流C++编译器面向RISC-V向量扩展的自动向量化能力、评估跨平台向量编程库在RISC-V向量扩展上的性能、对比人工优化的RISC-V Vector Intrinsic与其他平台Intrinsic的性能优化效果。性能评估基准测试应当包含一组由不同领域算法组成的测试用例，每个测试用例均有对应的C++标量实现、Google Highway向量化实现、x86 SSE/AVX Intrinsic、ARM NEON Intrinsic 和 RISC-V Vector Intrinsic实现版本；且由测试框架驱动，能够面向多种架构交叉编译，在不同设备上评估性能。测试用例的选择和实现可从现有开源软件中摘取，如OpenCV, OpenBLAS等；同时也可选择不同领域的经典算法自行实现不同版本。",1. 一个基准测试集
基于RISC-V架构的全同态加密NTT运算加速设计与优化,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""SSL/TLS""]]",全同态加密（FHE）是一种允许在加密数据上直接进行计算的技术，近年来在隐私保护计算领域获得了广泛关注。然而，FHE 方案的计算复杂度较高，尤其是其核心算子——快速数论变换（NTT），在通用处理器上的执行效率较低，难以满足实际应用的需求。RISC-V 作为一种开源指令集架构，凭借其高度的可定制性和灵活性，成为加速特定计算任务的理想选择。其模块化设计和开放的生态系统使得开发者能够针对如 FHE 这样的计算密集型应用进行深度优化。因此，基于 RISC-V 架构对 FHE 中的 NTT 算法进行加速，已成为同态加密领域的重要研究方向之一。在现有研究中，针对FHE-NTT算法的加速已取得一定进展，但仍存在显著不足。软件层面，开源FHE库（如Microsoft SEAL、HElib）通过算法优化提升了NTT性能，但其计算效率受限于通用处理器的架构特性，难以突破性能瓶颈。硬件层面，已有研究尝试基于ASIC或FPGA实现NTT加速，但这些方案往往缺乏与RISC-V生态的深度融合，难以满足开源硬件生态的灵活性与可扩展性需求。此外，尽管部分研究已在RISC-V中集成支持后量子密码的NTT指令扩展，但这些扩展未针对FHE-NTT的特定计算模式（如大规模多项式运算、高精度模乘）进行定制化优化，导致其在FHE场景下的加速效果有限。本项目改进要点在于设计面向FHE-NTT特性的RISC-V专用指令扩展，优化大规模多项式运算与高精度模乘的核心计算模式；设计高效的硬件架构，加速NTT中的“蝶形运算”；构建软硬协同优化框架，实现从算法到硬件的无缝集成，从而显著提升FHE-NTT的计算效率与能效比，同时保持与RISC-V开源生态的兼容性。最终项目实现的目标是开发一款高性能、低功耗的RISC-V硬件加速器，专为FHE-NTT运算优化，实现相较于纯软件方案至少300倍的性能提升和30倍的能效比提升；支持主流FHE算法（如CKKS）的完整NTT/INTT运算流程，满足从边缘计算到云端的多样化应用需求；提供开源RISC-V IP核设计，兼容Linux驱动层与主流RISC-V开发工具链，推动FHE技术在开源硬件生态中的广泛应用与标准化发展。,1.为FHE-NTT设计RISC-V专用指令扩展，相较于纯软件方案有至少300倍的性能提升和30倍的能效比提升2. 构建软硬件协同框架集成算法与硬件加速，实现兼容主流FHE算法（如CKKS）的NTT/INTT运算3. 编写硬件加速器性能测试与能效评估报告，输出RISC-V指令扩展与优化方案技术文档
使用 Nacos 实现 FIT 集群的注册中心,基础,"[[""web"",""Spring Boot""],[""codelang"",""Programming Language""]]",FIT 集群跨进程服务间调用采用的是传统通用的服务注册与发现的机制，在开源前已经存在一版内部C++的注册中心实现，同时，为了方便调试，又提供了一版Java内存版的简单实现。不管是哪一种实现，都是使用的 FIT 标准的插件来实现的，且注册中心的若干个插件提供的能力属于整个 FIT 系统最关键最基础的能力，已经拥有标准的接口定义（SPI），也就是说，不管是哪一种插件的实现，对于核心框架来说，代码都是不感知的。当前开源之后，需要接入业界最流行的 Nacos 注册中心体系，相当于基于 Nacos，实现一个新的注册中心插件，要求实现所有注册中心的 SPI，让 Nacos 的注册中心插件可以成为 FIT 集群跨进程通信的稳定生产插件。,"1. 一个由 Java 语言实现的 FIT 插件
2. 使用该插件，FIT 集群（当前需要在 FIT for Java、python 两种语言的 FIT 运行时上）可以正常通信"
Volcano准入控制从Webhook到声明式策略的演进与迁移,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""]]",当前，Volcano 依赖大量的 Webhook 组件对 Kubernetes 集群中的 Pod、VCJob、Queue 等核心资源进行准入控制，包括验证资源的有效性（Validating）和根据策略进行默认值设置或修改（Mutating）。虽然 Webhook 机制能够实现灵活的准入控制逻辑，但在 Kubernetes 高版本集群中，引入了更高效且与 CRD 深度集成的声明式准入控制方案，例如 Kubebuilder 对 CEL (Common Expression Language) 的支持，以及 Kubernetes 原生的 ValidatingAdmissionPolicy 和 MutatingAdmissionPolicy API。本项目旨在对 Volcano 现有的准入控制机制进行现代化改造，核心目标是将当前由 Webhook 实现的部分或全部准入控制逻辑迁移到这些声明式的策略定义中。通过利用 CEL 在 CRD 层面定义校验规则，以及使用 ValidatingAdmissionPolicy 和 MutatingAdmissionPolicy API 实现更灵活的资源准入控制，可以减少外部 Webhook 调用的开销，潜在地提升 Volcano 的性能，并简化准入控制策略的管理和维护。此外，为了保证与不同 Kubernetes 集群版本的兼容性，本项目还需要考虑在 Helm 安装时提供灵活的部署选项。对于不支持 CEL 和 Admission Policy API 的旧版本集群，应继续使用现有的 Webhook 机制。而对于支持这些新特性的高版本集群，则默认或可选地启用新的声明式准入控制模式。通过本次项目的实施，Volcano 将能够更好地融入现代 Kubernetes 生态，提升在高版本集群中的运行效率和可维护性，并为未来的准入控制策略扩展奠定基础。,1. CEL 校验规则实现: 将现有 Webhook 中可迁移的验证逻辑转化为 CRD 上的 CEL 表达式。2. Admission Policy 实现: 将现有 Webhook 中适合的验证和修改逻辑分别通过 ValidatingAdmissionPolicy 和 MutatingAdmissionPolicy API 实现。3. Helm Chart 集成与版本兼容: 修改 Volcano 的 Helm Chart，使其在安装时能够动态检测 Kubernetes 集群的版本，并自动启用与当前集群版本相对应的准入控制策略：对于支持 CEL 和 Admission Policy API 的高版本集群，启用新的声明式策略；对于不支持这些 API 的低版本集群，则启用现有的 Webhook 策略。4. 文档与测试: 提供清晰的项目设计文档（包括迁移策略和测试计划等），更新 Volcano 的用户文档以说明在高版本 Kubernetes 集群中准入控制策略的变化和配置方式，并提供充分的单元测试、集成测试和端到端测试，验证新的声明式准入控制策略的正确性、兼容性以及与现有 Webhook 机制的协同工作。5. 社区集成与发布: 将开发成果集成到 Volcano 社区主干分支，并按照社区流程进行版本发布。
MindSpore 框架下纯视觉 3D 检测模型（LSS 类）迁移与优化,进阶,"[[""datas"",""AI""]]",Lift-Splat-Shoot 类纯视觉 3D 目标检测通过单目图像预测物体三维坐标，在自动驾驶、机器人等领域至关重要。当前主流模型多基于 PyTorch，需迁移至 MindSpore 框架以提升生态兼容性。,1. 完成模型结构复现、算子适配（如自定义 3D 坐标变换算子）2. 针对 NPU 硬件特性优化模型推理速度3. 开发一个相应的应用案例
利用 GraphAr Spark API 实现 LDBC SNB Datagen 对 GraphAr 格式的直接输出,基础/Basic,"[[""datas"",""Database""],[""datas"",""Graph Database""],[""datas"",""Spark""]]",本项目旨在增强 Apache GraphAr (incubating) 在 Spark 环境下的数据加载能力，使其能够直接从 LDBC SNB Datagen Spark 接口导出 GraphAr 格式的数据。Apache GraphAr 致力于提供一种标准的图数据存储文件格式框架，底层支持 CSV、Apache Parquet、Apache ORC 等多种格式，便于图数据在不同系统间高效流通和互操作。GraphAr 提供了相应的 Spark API 来支持读写其格式数据。LDBC SNB Datagen 是一个基于 Spark 的工具，专门用于生成 LDBC 社交网络基准测试所需的大规模、具备真实社交网络特性的有向带标签图数据集。虽然该工具的标准输出通常是结构化的 CSV 文件集合，描述了顶点、边及其属性，但本项目的目标是直接利用其在 Spark 内部生成的数据结构（如 RDDs 或 DataFrames），而非读取这些已生成的输出文件。- 代码仓库：- 说明文档：目前，虽然 LDBC Datagen 生成的数据常用于图系统测试，但在 Spark 环境下要将这些数据的标准输出文件导入图数据库或图计算系统进行处理，通常需要用户编写额外的定制代码或转换脚本来读取 CSV 文件。GraphAr 则为其中的数据传输提供了便捷，而本课题则进一步优化，旨在避免中间的CSV文件读写环节。本课题的核心目标是在 Apache GraphAr 项目中，利用其现有的或扩展的 Spark API，开发一个或一套功能模块，使其能够直接接收并处理 LDBC SNB Datagen 在 Spark 内存中生成的数据结构，并将其无缝转换为 GraphAr 格式的内存结构或文件存储，即实现从 LDBC Datagen 内部数据到 GraphAr 格式的直接管道。通过这项工作，用户将能够直接利用 GraphAr 提供的 Spark 写入/转换接口，处理 LDBC Datagen 在 Spark 环境中生成的数据，而无需将数据先写入标准输出文件再读取。这样可以在 Spark 环境中以 GraphAr 格式进行后续的图分析和处理。这将极大地简化 LDBC 数据集与 GraphAr 生态的对接流程，降低用户使用门槛，并进一步推广 GraphAr 作为标准图数据加载和处理格式的应用。,1. 核心加载功能实现： 在 GraphAr 项目中，基于 GraphAr Spark API 实现从 LDBC SNB Datagen 直接导出 GraphAr 格式数据的功能代码。2. 测试用例： 编写充分的单元测试和集成测试，验证加载功能的正确性和性能（至少覆盖主要实体类型和关系类型）。3. 使用文档： 提供清晰、详细的英文文档，说明如何使用新的 Spark 加载接口。4. 示例代码： 提供至少一个可运行的示例，演示如何加载 LDBC SNB Datagen 生成的数据。
P2P 支持基于 TCP 协议的文件传输,进阶,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""],[""safe"",""TCP/IP""],[""cloudnative"",""Docker""],[""cloudnative"",""Distributed Storage""]]",Dragonfly 是开源的一款高效 P2P 文件分发系统，现为 CNCF 孵化级项目，旨在解决大规模数据传输中的效率瓶颈。其核心设计理念是通过 P2P 技术将每个节点（Peer）同时作为数据的消费者和提供者，最大化利用闲置带宽，从而显著提升下载速度并大幅降低对源站的依赖和压力。支持 TCP 协议的 P2P 数据传输机制是尤其重要的，确保了数据传输的可靠性与高效性，使其能够在多种网络环境下高效运行。本项目需要支持采用 TCP 协议作为底层数据传输基础，利用其可靠性（通过连接管理和错误重传）和顺序性（确保数据按序到达）特性，保证节点间数据传输的完整性。这使得 Dragonfly 能够在多种网络环境下稳定运行，适应复杂的企业级需求。并且需要适配 Dragonfly 基于 Piece 级别的应用层协议 Vortex，确保完整 Piece 元信息以及数据。并且针对大文件/AI 模型/镜像在数据传输部分优化，保证能够最大化利用网络带宽。通过支持 TCP 协议的 P2P 传输机制，将闲置带宽转化为分发效率，显著提升下载速度，同时减少对源站的负载。其应用场景包括容器镜像分发、大规模文件传输及 AI 数据处理等。,"1. 完整的方案设计。
2. 支持采用 TCP 协议作为底层数据传输基础。
3. 适配 Dragonfly 基于 Piece 级别的应用层协议 Vortex。
4. 确保数据完整、可靠、高效传输。
5. 需要完成 Unit testing、Benchmark、E2E testing。
6. 根据 Benchmark 优化数据传输性能。"
基于数据依赖的任务编排与 Volcano Global 调度,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Spark""],[""cloudnative"",""HDFS""],[""os"",""Linux""]]",Volcano Global 作为 Volcano 社区新发布的多集群调度平台，旨在为 AI、大数据、HPC 等高性能计算任务提供跨集群的统一调度能力，目前已支持队列和作业优先级、以及多租户公平调度。然而，在大数据场景下，任务之间往往存在复杂的数据依赖关系，例如任务 C 依赖任务 A 生成的数据。当前 Volcano Global 尚不支持此类依赖约束，导致在跨集群调度时，任务的实际可调度性受限于数据在目标集群上的可用性。运维人员需要人工分析和配置任务与数据源的对应关系，这不仅效率低下，还容易导致集群负载不均衡。尤其是在跨数据中心场景下，由于无法直接跨集群读写数据，需要通过平台的数据同步管道来保证数据安全，使得数据依赖的满足更加复杂。本项目旨在为 Volcano Global 设计并实现一个可插拔的第三方依赖检测机制，以支持大数据任务的数据依赖约束调度。该机制允许用户在任务定义中声明其所需的数据表（或其他数据源）以及目标集群，通过外挂的依赖检测插件，Volcano Global 可以在调度时查询集群的数据可用性，从而将任务调度到满足其数据依赖的集群上。,1. 数据依赖声明机制： 研究并实现一种在 Volcano Global 任务定义中声明数据依赖的方式（例如 Annotation 或 CRD 字段），能够清晰地指定任务所需的数据表或其他数据源。2. 数据依赖 Filter 插件实现： 基于 Volcano 调度器的 Filter 接口，实现数据依赖 Filter 插件，明确其输入参数（任务声明的依赖、目标集群信息等）和输出结果（是否满足依赖），并能够根据配置的数据位置检测服务查询集群的数据可用性。3. 与第三方数据位置检测服务集成方案： 定义 Filter 插件与用户自定义的数据位置检测服务之间的交互方式和数据格式，确保插件能够有效地查询集群的数据可用性。4. Volcano Global 调度流程集成： 实现数据依赖 Filter 插件在 Volcano Global 调度过滤阶段的注册和调用逻辑。5. 插件配置与管理方案： 提供灵活的插件配置和管理方法，允许用户选择和配置数据依赖 Filter 插件，并指定其所需的数据位置检测服务。6. 完善的测试与验证报告： 提供单元测试和集成测试报告，验证数据依赖 Filter 插件的功能和在 Volcano Global 调度流程中的集成效果。7. 详细的用户和开发者文档： 编写用户手册和开发指南，介绍如何声明任务的数据依赖以及如何配置和使用数据依赖 Filter 插件。
Cloudberry Clean Room 原型系统设计与实现,进阶,"[[""safe"",""OAuth""],[""datas"",""PostgreSQL""],[""datas"",""Structured Database""]]",本项目旨在基于 Apache Cloudberry 的安全机制，设计并实现一个数据 Clean Room 原型系统，借鉴 Snowflake 和 AWS Clean Room 的理念，探索在多方数据协作中保护用户隐私、确保数据合规使用的技术实现路径。该原型系统将支持以下核心能力：该项目最终将输出一套以 Cloudberry 为底座的原型实现、用例和基础文档，为未来在 Cloudberry 中正式支持数据 Clean Room 提供基础探索。,1. Cloudberry Clean Room 原型代码（支持 provider / consumer 模型）2. 一套权限控制配置模板（行级 / 列级）3. 简单的差分隐私机制实现（基于聚合函数注入噪声）4. 一份技术设计文档（支持 Markdown 格式，说明设计原理与接口）5. 一份部署及使用说明手册（含本地运行环境）
基于 Box64 实现 x86_64 用户态程序在 AArch64 和 RISC-V 系统上的运行支持,进阶/Advanced,"[[""os"",""Linux""],[""codelang"",""Programming Language""],[""os"",""x86""],[""os"",""RISC-V""]]",（1）相关背景在国产 CPU 与 openEuler 操作系统推广过程中，工业仿真、医疗生物等行业中仍存在大量基于 x86_64 架构的软件，这些软件缺乏源码且无人维护，兼容性成为亟需解决的问题。Box64 是一款轻量级用户态动态二进制翻译器，可在 AArch64 和 RISC-V 平台上运行 x86_64 Linux 程序，具备对 Wine 等复杂软件的兼容潜力。（2）已有的工作Box64 项目已经开源，并成功支持多个 AArch64 Linux 系统，能运行多种图形和命令行程序。（3）存在的不足openEuler 系统对 Box64 支持不完善，缺乏官方封装和适配文档，且在动态链接库加载、系统调用兼容性方面存在问题，导致部分程序运行失败或不稳定。（4）希望改进的点改进 Box64 在 openEuler 上的运行环境和配置集成提供构建脚本和依赖环境准备方案修复已知的兼容性问题（如常用库加载、线程模型等）编写面向社区的使用手册与调试指南（5）最终项目实现的目标实现 Box64 在 openEuler AArch64 和 RISC-V 平台上的稳定运行，能够兼容常见 x86_64 用户态程序，并形成标准化的适配文档与测试样例。,1. 完善 Box64 在 openEuler 上的运行支持2. 提供完整构建脚本和工具链配置3. 提交修复补丁解决兼容性问题4. 补充测试案例与验证说明文档5. 撰写社区使用说明与调试文档
基于MindSpore的YOLOv12实现智能交通分析,进阶,"[[""datas"",""AI""]]",交通管理和道路安全对于现代智慧城市至关重要。检测交通违规行为、确保道路安全和改善城市交通需要创新的解决方案。这就是“智能交通监控：使用 YOLOv12N 进行实时闭路电视分析”项目的用武之地。本项目需要基于MindSpore+Ascend迁移YOLO12模型开发应用。,1.基于MindSpore框架和套件，迁移Yolo12模型，精度性能达到论文水平。2. 基于Yolo12模型，完成一个交通安全的案例应用:检测紧急车道违规并识别阻碍紧急车辆的车辆;分析基于车道的交通流速和拥堵情况，以确定交通状况;对车辆进行计数并对类型进行分类，以提供有关不同车辆类型的数据。3.  完成以下功能模块的开发:
SimpleRenderer ⾼性能渲染优化与结构优化,进阶,"[[""os"",""x86""],[""os"",""GCC""],[""os"",""Perf""]]",,"1. 光栅化算法优化
a. 实现基于块/图块的光栅化算法（Tile-based Rasterization），代替现有的像素级处理⽅式
b. 增加视锥体裁剪和背⾯剔除测试，提前过滤不可⻅三⻆形
2. 内存管理优化
a. 预分配⽚段缓冲区，避免渲染过程中的动态内存分配
b. 改进数据布局，提⾼缓存利⽤率
c. 实现共享内存机制，减少线程间的重复内存访问
3. 深度测试优化
a. 实现早期深度测试，在光栅化阶段直接剔除被遮挡的⽚段
b. 减少⽚段⽣成和着⾊器调⽤次数
c. 优化深度缓冲区访问模式
4. 多线程架构改进
a. 减少线程间的数据合并次数和同步开销"
国产数据库读写组件开发,进阶,"[[""datas"",""Database""],[""datas"",""Hadoop""],[""datas"",""HDFS""]]",项目背景：openGauss 和 KingbaseES（金仓）作为两款主流的国产数据库管理系统，凭借其高性能、高可用性和安全性，在政府、金融、能源等多个关键行业得到了广泛应用。为了提升πFlow平台的数据源兼容性，并推动数据处理流程的国产化转型，有必要开发针对openGauss和 KingbaseES（金仓）数据库的读写组件，实现高效的双向数据交互。：一、数据库技术调研●研究openGauss和和 KingbaseES（金仓）数据库的技术特点及接口规范，包括其SQL语法、事务管理机制以及批量操作性能优化策略。二、四个核心组件开发●openGauss数据库读取组件：负责从openGauss数据库中读取数据，并将数据加载到Spark DataFrame中，为后续的大数据处理提供基础支持。●openGauss数据库存储组件：负责将上游组件处理后的DataFrame结果存储回openGauss数据库，支持多种存储模式（如插入、更新、批量写入等），以满足不同场景的需求。●KingbaseES数据库读取组件：负责从KingbaseES数据库中读取数据，并将其加载到Spark DataFrame中，为后续的大数据处理提供基础支持。●KingbaseES数据库存储组件：负责将上游组件处理后的DataFrame结果存储回KingbaseES数据库，支持多种存储模式（如插入、更新、批量写入等），以满足不同场景的需求。三、文档编写与发布●编写详细的文档，包括使用指南、开发文档和测试案例库，确保用户能够快速上手并正确使用该组件。：本项目要求采用Scala语言编写。Scala作为一种多范式编程语言，结合了面向对象和函数式编程的特点，具有简洁、优雅的语法，非常适合Spark生态圈的开发。它能够帮助我们快速构建高效、可扩展的组件，同时无缝集成到πFlow平台中。,"1. 四个核心组件开发：1）openGauss数据库读取组件；2）openGauss数据库存储组件；3）KingbaseES数据库读取组件；4）KingbaseES数据库存储组件。

2. 文档编写：编写详细的文档，包括使用指南、开发文档和测试案例库，确保用户能够快速上手并正确使用该组件。"
KubeEdge Dashboard UI优化与多语言（中文）支持,基础,"[[""web"",""React""],[""web"",""UI""],[""web"",""Material UI""]]",全面优化 KubeEdge Dashboard 的 UI 体验，统一界面风格、提升交互友好性，并引入中文语言包支持。针对页面结构、交互逻辑、表单体验等方面进行逐步改进，使其更加贴合用户使用习惯。同时提供国际化方案基础框架，未来可拓展至更多语言。,1. 引入国际化框架（如 react-i18next 或 MUI 内置的多语言支持机制），实现中英文切换2.  提炼所有文案为可配置项，统一管理语言资源文件（如 en.json / zh.json）3. 优化整体 UI 风格（如统一按钮样式、字体、色彩系统等），并提升交互体验（表单校验、空状态提示等）4. 优化移动端或小屏展示适配（可选），提升多终端可访问性5. 针对中国用户习惯（例如表格操作、分页、时间格式等）进行本地化适配
VSCode 插件增强-支持手表模拟器可视化布局,基础,"[[""os"",""RISC-V""],[""os"",""Linux""]]",面向智能设备开发者提供的一站式集成开发环境，其中 GUI Builder 则用于用户在进行穿戴应用开发时快速在 PC 上看到 UIKit 模拟效果，而当前 GUI Builder 的实现受限于 GrapesJS 开源软件，界面布局可扩展性不足，且开源义务包袱繁重，需要尽快有自研方案，提升界面美观度，灵活度。,1. 使用 VSCode 代码。2. 自研代码打造GUI Builder界面，界面可参照nxp的GUI Guider，支持C++代码生成和代码编译。
Sentinel AI 应用场景 Token 限流调研和实现,进阶,"[[""datas"",""AI""],[""web"",""Web Application""]]",Sentinel 作为面向分布式应用场景、多语言异构化服务架构的流量治理组件，以丰富的流量防护能力满足了各种应用场景的限流需求。当下 AI 应用成为广大开发者关注的领域，但是想要将 AI 应用真正用于生产，高可用的能力是必不可少的，由此也出现了很多 AI 应用场景下新的流量防护需求，例如 Token 限流，Token 这个 AI 场景下的常用单位，在作为限流的统计维度时存在着限流时机与统计时机不一致，强需求集群限流等特点。现有的限流能力难以很好地满足需求，因此需要在 Sentinel 中实现 Token 限流的能力，来限制 AI 应用的 Token 消耗，保障 AI 应用的整体稳定性。,1. Go 语言 AI 应用框架（eino、langchaingo等）流量防护能力以及需求调研报告2. 基于 sentinel-golang，构建 Token 限流的能力3. 编写 Token 限流的核心设计文档、用户使用文档4. 进阶：支持限流后的动态 fallback 能力
数据库敏感列智能识别工具,基础,"[[""datas"",""Natural Language Processing (NLP)""],[""datas"",""Database""],[""dev"",""AIOps""]]",随着数据隐私法规（如 GDPR、CCPA）的普及，企业需对数据库中的敏感信息（如身份证号、手机号、地址等）进行精准识别与管理。当前 ODC 产品已具备数据脱敏功能，能够基于用户配置的敏感列识别规则对数据库敏感列进行扫描进行数据脱敏，但依赖用户对敏感列进行人工标注，存在效率低、误判率高的问题，亟需自动化工具提升识别准确性与效率。此项目旨在通过结合对字段语义进行自动理解和推断，实现敏感列识别的智能化：最终目标是通过 AI 赋能，使工具能够生成自动识别敏感列信息，帮助数据库管理员高效的管理数据库，提升数据安全。,"1. 敏感列规则配置模块
  ○ 支持用户通过前端交互或配置文件的方式配置敏感列识别规则，例如：
    ■ 基于规则的敏感列识别
    ■ 基于模型推断的敏感列识别
  ○ 设计一个友好、易用的规则配置交互模块。2. AI 语义推断模块
  ○ 集成先进的预训练语言模型（如 BERT、GPT），实现字段名语义理解，自动判断字段是否含敏感信息，并评估风险等级。例如：
    ■ id：常规自增类型，无敏感信息，无风险。
    ■ account_no：用户账号名，存在敏感信息，低风险。
    ■ password：密码，存在敏感信息，高风险。
  ○ 模型训练与微调，并优化推断结果稳定性，与工具深度集成。3. 自动化敏感列识别模块
  ○ 提供自动化敏感列识别功能：
    ■ 规则优先：优先应用用户配置规则，条件满足时直接判定风险等级。
    ■ 推断优先：当规则匹配失败时，自动触发 AI 语义分析。
    ■ 联合识别：同时应用规则匹配与 AI 推断算法，两者结果一致时直接返回；若不一致，则优先规则结果并提供推断结果作为辅助建议。4. 工具整合与兼容性
  ○ 新模块需与现有 ODC 工具无缝集成，支持以下功能场景：
    ■ ODC 查看表结构时自动识别敏感列并给出提示
    ■ SQL Console 执行查询时敏感列自动识别并基于已有脱敏模块进行数据脱敏
  ○ 保证下兼容已有功能，同时升级工具的智能化能力。5. 项目文档与测试用例：
  ○ 提交项目全过程文档，包括：
    ■ 功能说明与设计方法
    ■ 模块架构设计
    ■ 用户交互指南
  ○ 提供测试用例：
    ■ 用户场景覆盖：基于规则和模型的识别效果展示。
    ■ 测试数据样例：各种场景表结构与的敏感列识别表现。"
MateChat模板VSCode插件兼容支持,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",根据用户使用习惯的不同，用户可能希望通过在VSCode中使用matechat来进行与模型的对话，目前matechat仅支持了pc端。本项目要求提供一套基于pc端一站式解决方案模板自动生成VSCode插件模板的方案，在pc端一站式解决方案的模板迭代后，通过脚本或插件的方式，自动更新VSCode插件的模板，不再需要人工维护多份模板。,"1、编写一个脚本或插件，用于将pc端的一站式解决方案模板自动生成VSCode插件模板
2、脚本或插件，尽量使用简单"
为Apollo提供完善的OpenAPI方式接口能力,进阶,"[[""web"",""Spring Boot""],[""web"",""Web Application""]]",Apollo作为一款可靠的分布式配置管理中心，提供不同环境、不同集群应用集中化配置管理，配置修改后能够实时推送到应用端，并且具备规范的权限、流程治理等特性，适用于微服务配置管理场景。Apollo目前主要提供的配置管理方式为基于Web Portal的配置管理方式，配置操作需要人工操作，为了更好的支撑自动化配置场景，以满足更加丰富的配置管理场景，考虑为Apollo增加一套完善的OpenAPI接口，实现自动化配置管理功能。,1. 完成Apollo配置管理功能的梳理，并遵循Restful规范，完成OpenAPI接口设计2. 按照设计的OpenAPI接口实现接口能力（共 29 个接口）3. WebPortal前端调整，接口与OpenAPI接口统一（共 123 个接口）
构建AI+硬件陪伴玩具,基础,"[[""chip"",""Chip Design/Verification""],[""codelang"",""Programming Language""]]",小X宝是面向多病种患者和家属提供辅助信息的平台，从2024年开始已经在多个平台完成了线上版本应用搭建，逐渐我们发现患者和家属还需要更多陪伴和关爱，不仅仅是咨询信息。所以在本期项目中我们发布《AI+硬件》的开源项目，帮助使用者能够和AI硬件陪伴玩具进行对话、获取及时信息、获得陪伴。除了小X宝平台，在沟通中发现很多公益和开发者团队希望将已经有的Agent软件落地到硬件中，无论是Agent还是AI硬件不只是属于少数头部玩家团队，更应该是通过开源项目推出适用于不同平台的开源框架和教程，帮助小X宝、帮助更多公益和其他非公益开发者团队构建AI硬件项目。软件层包括扣子、Dify、FastGPT、腾讯混元等，这些都是标准化的Agent软件，希望嵌入到硬件中提供语音交互功能。功能上包括1V1心里咨询、互动聊天、通过Agent获取信息、通过语音方式记录美好时光等等。硬件上包括普通芯片和玩偶，在本开源项目中核心关注软硬件结合与适配。这是一次开源挑战，参与该项目你将从0到1获得一个完整项目开发的机会，将获得包括产品设计、软件编码、硬件开发以及项目管理的能力，并且由你参与完成的这个开源项目将会让更多团队快速构建自己的AI+硬件项目。,1. 对Agent封装，能够通过软件方式进行调用2. 通过硬件能够进行基础对话3. 和硬件进行对话的数据能够记录保存，对数据进行可视化展示
基于 Spring AI Alibaba 的本地可观测与调试平台（前端）,基础,"[[""web"",""Vue.js""]]",1. 项目背景本项目属于 Spring AI Alibaba 社区本地开发调试平台的一部分，平台涵盖前端与后端开发，本项目主要完成前端部分。该平台用于快速跟踪定位Agent运行链路、可视化快速与 Agent 交互等，需要提供sdk埋点、graph埋点、可视化平台后端逻辑、沙箱运行环境与通信协议实现等。2. 学生职责&目标：在这个项目中，学生将和社区导师与开发者一起平台前端部分开发，重点完成可视化链路展示、agent交互界面开发、prompt管理、页面交互效果优化等。3. 学生要求&技术栈,1. 在这个项目中，学生将和社区导师与开发者一起平台前端部分开发，重点完成可视化链路展示、agent交互界面开发、prompt管理、页面交互效果优化等。
补充IPsec和offload Authorization的端到端测试,进阶/Advanced,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""]]",Kmesh在1.0版本引入了IPsec特性和将部分Authorization能力下沉到操作系统内核中。但是缺少相应的测试以看护这部分的功能。导致代码上线和新版本发布的时候存在隐藏风险。因此需要为这两个特性编写e2e测试，并且编写使用文档。1、IPsec2、Offload Authorization其中IPsec是确保节点间通信安全的特性，需要进行跨节点的测试。需要自己设计测试方案。Offload Authorization是Kmesh独有的，将IP和Port鉴权能力下沉到Linux内核xdp中的特性，因此需要针对Authorization的用户态程序和内核中的xdp prog进行测试。并且针对补全的鉴权场景进行不同的测试,1. IPSec的E2E测试代码2. Offload Authorization的E2E测试代码3. Ipsec和offload Authorization的测试文档与执行文档
实现位置共享,基础/Basic,"[[""web"",""Desktop Application""],[""web"",""Electron""],[""web"",""Mobile Application""],[""web"",""npm""],[""web"",""React""],[""web"",""React Native""],[""web"",""UI""],[""web"",""UIKit""],[""web"",""UX""],[""web"",""Web Application""],[""web"",""Yarn""]]",修复并实现桌面和移动应用消息编辑器中的按钮，用于分享用户当前位置和实时位置。创建组件，使用操作按钮渲染位置信息，以便在第三方应用上打开位置信息进行导航。位置信息可通过 iOS、Andriod 和 HarmonyOS 移动设备或浏览器共享。理想情况下，能够共享指定时间段内的实时位置信息。,1. 移动应用上的“分享我的位置”按钮2. 桌面/网页应用上的“分享我的位置”按钮3. 桌面/网页应用上的“分享我的位置”按钮
面向 openEuler 的高效并行 I/O 子系统 SIONlib 构建及相关工具链支持,进阶/Advanced,"[[""datas"",""HPC""]]","（1）相关背景SIONlib 是由德国尤利希研究中心开发的高性能并行 I/O 库，广泛应用于科研计算场景下的性能数据采集与处理。在操作系统 openEuler 推广过程中，部分 HPC 应用,尤其是超算、工业仿真、生物、气象等HPC应用对该库有强依赖，但目前尚未软件支持，完成兼容性集成。（2）已有的工作SIONlib 已作为 OpenHPC 社区推荐组件，具备良好的跨平台移植性，支持 GNU/Linux 系统环境中的多编译器（GCC、Clang）与 MPI 框架。（3）存在的不足openEuler 缺乏该库的官方支持，存在构建配置复杂、依赖关系不清、与国产编译器/环境兼容性不足的问题，阻碍了其在 HPC 场景中的使用。（4）希望改进的点a、构建适用于 openEuler 的 SIONlib 并打通构建链路b、支持与 GCC、OpenMPI 等工具链的联动测试c、输出 RPM 源码包和统一构建脚本，便于后续打包与维护d、编写用户编译使用文档和社区贡献指南（5）最终项目实现的目标在 openEuler 操作系统上完成 SIONlib 的稳定构建、运行验证与包管理支持，为国产操作系统在 HPC 领域中的广泛应用提供并行 I/O 能力基础。",1. 支持 SIONlib 在 openEuler 上编译构建2. 完成 OpenMPI 等框架的集成测试验证3. 提供构建脚本和 RPM 打包支持4. 提交用户手册与社区贡献文档
openGauss 向量数据库集成Llama Stack,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",实现Llama Stack与openGauss的适配，构建基于该数据库的LLM应用全栈解决方案，输出各层对接代码及部署方案。,1. 开发openGauss向量存储对接层，支持索引构建与检索。2. 构建从数据接入到API服务的完整案例，输出包含监控方案的部署文档，代码合入社区。
运行时渲染解决方案,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",当前TinyEngine仅支持出码方案，本赛题需要实现运行时渲染功能，能够支持开发态运行时预览与生产态部署运行。,"1. 实现运行时渲染模块，支持设计态、预览态与生产运行场景，并统一渲染能力(重构当前画布与预览渲染能力)。2. 实现现上预览、部署运行能力。3. 确保运行时渲染性能，避免性能瓶颈。(与出码方案性能相比不能有较大差距。建议指标：中等复杂度页面首屏≤2s, TTI≤3.5s)4. 提供详细的方案文档、使用文档，确保用户能够轻松使用该功能。5. 界面引导清晰，交互友好，无明显问题；代码逻辑清晰，模块划分合理，可维护性强，符合项目开发规范。"
为 vsag 增加 PC 端（Windows/macOS）开发和运行支持,基础,"[[""datas"",""AI""],[""datas"",""Vector Database""],[""os"",""x86""]]",当下大模型和RAG的爆火带来了许多新的向量检索需求，有许多场景发生在 PC 端上，例如为了隐私考虑，希望图片搜索功能发生在本地而不是云上。windows/macOS 系统作为桌面端，和linux系统有许多不同，包括开发工具、第三方库等等，vsag 目前还不支持在 windows/macOS 平台上开发和运行。增加 windows/macOS 平台的适配，有助于将 vsag 中的高效向量检索算法应用到更多场景中。希望你将 vsag 索引库与 windows/macOS 系统进行适配，使 vsag 能够在 windows/macOS 平台上开发和高效运行，为终端应用上的向量检索提供更好的向量检索算法。,"1. 为 vsag 核心代码增加跨平台编译支持（windows 或 macOS），使 vsag 核心代码可以在多平台上编译运行；
2. 开发 PC 平台的容器环境，输出对应的 Dockerfile；
3. 开发 PC 平台的 pyvsag 包，使得在 PC 平台可以通过 pip install pyvsag 获取可用的 python 向量检索包；
4. 编写 PC 平台（windows 或 macOS）的开发手册，帮助开发者在 PC 平台上使用 vsag 索引库；"
基于MindSpore Quantum实现薛定谔-海森堡变分算法,基础,"[[""datas"",""AI""]]",任务背景：目前对于XXZ等自旋模型的基态或者化学分子的基态求解这个问题，VQE是一种可以高精度的方法，但是VQE方法目前局限于对小规模系统的求解。当系统规模增加的时候，为了实现高精度求解，VQE线路的层数需要增加，且变分参数的训练也会非常耗费资源。因此，最近一种薛定谔-海森堡变分算法被提出，用来减少量子线路所需层数，这种方法将部分的训练开销转移到可以被经典高效模拟的Clifford线路，因此是一种更加高效的方法，探究这个方法的适用场景和局限性非常重要。任务需求：基于MindSpore Quantum框架实现薛定谔-海森堡变分算法最新版本复现薛定谔-海森堡变分算法，对于XXZ自旋模型，能够高效实现求解，相比于传统的VQE提升性能。,1. 使用MindSpore Quantum 0.10.0复现论文中的图2和图3；2. 提交规范的技术报告，需讨论a.针对给定的模型如何设计变分Clifford线路；b.阐述复现的薛定谔-海森堡变分算法；c.该方法的适用场景和局限性；3. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准；4. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。
探索LLVM AArch64架构后端的代码生成优化机会,进阶,"[[""os"",""Compiler""]]",编译器优化在助力设备整机性能上的重要越来越高。当一些常见的编译优化，比如向量化、内联、反馈优化、链接优化等遇到优化瓶颈的时候，编译器后端在紧密结合底层硬件和操作系统的条件下，仍然能够进一步优化程序性能。在编译器后端优化当中，指令级别的优化，比如指令选择，指令窥孔优化等是基础的优化手段。目前寻找指令级别的优化方法往往依赖专业人员对AArch64指令的了解程度，然后在分析大的应用程序性能时，发现指令级别优化机会。这种手段依赖专家先验知识，而且依赖具体的应用场景暴露优化机会，很难系统、全面的覆盖所有的指令窥孔类的优化机会。该项目建议用新的方法，脚本化的方式，基于很小的代码片段去寻找潜在的AArch64后端的指令级别优化机会。实现思路：1：使用llvm-extract工具将llvm的LIT case拆分成各个小函数，LIT case目录为llvm-project/llvm/test/Transforms llvm-project/llvm/test/CodeGen/AArch64(后续可能增删LIT case范围)2：使用llvm c backend https://github.com/JuliaHubOSS/llvm-cbe 将步骤一拆分出来的每个单个函数的LIT文件编译成对应的C函数3：使用最新的gcc(14.2)/clang(https://gitee.com/openeuler/llvm-project/tree/dev_19.1.7/) 编译步骤2的C函数(-march=armv8.6-a+sve -O3)，找出最优的指令序列（指令数目最少），若clang没有产生最优的序列，那就是一个优化机会,1. 完成项目描述中实现思路步骤1/2/3的框架脚本2. 文档，里面包括归好类的所有的优化机会，每个优化机会需要提供简易的复现方法
为 deepin RISC-V 移植 GCC 12 的 RISC-V Vector (RVV) 扩展支持,进阶/Advanced,"[[""codelang"",""Programming Language""],[""os"",""Complier""],[""os"",""Linux""],[""os"",""RISC-V""]]",deepin 操作系统正积极拓展对 RISC-V 架构的支持，旨在为用户提供在该新兴架构上的流畅、完整的桌面体验。GCC 作为 Linux 世界最核心的编译器套件之一，其功能和性能直接影响着整个系统的构建和运行效率。RISC-V Vector (RVV) 扩展为处理器提供了强大的并行计算能力，对于提升多媒体、科学计算、人工智能等应用的性能至关重要。虽然较新版本的 GCC (如 GCC 13+) 对 RVV 的支持已趋于成熟，但 deepin 23/25 基于稳定性考虑，仍选用或维护 GCC 12 作为其主要的系统编译器。为了让 deepin 在 RISC-V 平台上充分利用硬件特性，将新版 GCC 中的 RVV 支持向后移植（Backport）到 GCC 12 具有重要意义。本项目旨在系统性地将 GCC 13 或更高版本中稳定且关键的 RISC-V Vector (RVV) 扩展支持相关代码补丁，向后移植到 deepin 社区使用的 GCC 12 分支中。,1. 分析差异： 对比 GCC 12 与 GCC 13+ 在 RISC-V 后端，特别是 RVV 支持方面的代码差异，识别出实现 RVV intrinsics、自动向量化以及相关优化的关键补丁集。2. 补丁筛选与调整： 筛选出适合向后移植的、相对稳定且依赖较少的补丁。由于 GCC 代码库的演进，直接应用补丁可能存在冲突，需要进行细致的代码调整和冲突解决。3. 编译与构建： 在 Deepin 的构建环境或模拟环境中，使用移植后的源码构建针对 RISC-V 架构的 GCC 12 工具链。4. 功能验证： 编写或利用现有的测试用例，验证移植后的 GCC 12 是否能正确识别 RVV 相关的编译选项（如 -march=rv64gcv -mabi=lp64d），是否能正确处理 RVV intrinsics，以及自动向量化功能是否能在支持 RVV 的目标上生效。5. 测试与基准： 运行 GCC 官方的 RISC-V 测试套件，并针对性地增加 RVV 相关测试。利用支持 RVV 的模拟器（如 QEMU TCG）或硬件平台，进行简单的基准测试，初步评估 RVV 支持带来的性能提升。6. 文档与交付： 整理移植的补丁集，编写详细的移植说明、测试报告和使用指南。将成果以规范的格式提交给 Deepin 社区。
基于算子学习的疾病负担外推与以糖网为例的气象环境——基因互作下的代谢病解析,进阶,"[[""datas"",""Deep Learning""],[""datas"",""Machine Learning""]]",1. 【项目1】全国/区域尺度的疾病负担预测模型：利用ERA6气象数据（高频率、高空间分辨率）与UK Biobank数据（低频率、精确样本位置）之间在经纬度和时间尺度上的积分或统计映射关系，探索算子学习或高保真模拟在疾病预测中的可行性以及输出全国尺度热力图预测。2. 【项目2】UK Biobank样本级疾病研究子项目：将每位样本的时间与经纬度匹配气象背景，分析气象外因与基因内因对糖尿病视网膜病变发病非对称性的影响，包括气象-基因交互建模、个体糖网发病风险评估。,"1.代码方面的验收标准：两个项目都请参考模型复现指南中的验收标准部分 https://paddlescience-docs.readthedocs.io/zh/latest/zh/reproduction/#3
2.论文方面的验收标准：任选1个项目，撰写一篇达到发表水平（EI检索）的论文"
基于高性能RISC-V处理器核“香山”的微架构UT验证——ICache预取和取指,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""dev"",""pytest""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。本项目基于开源高性能RISC-V处理器核“香山”的最新架构昆明湖，通过参与，您将深入了解到高性能处理器设计，有机会进入贡献排行榜、获得实习Offer、RISC-V中国峰会差旅补贴，为开源芯片的发展贡献力量。ICache（Instruction Cache）即指令缓存，负责接收 FTQ 的取指和预取请求并从向 ITLB 获取物理地址和通过 Tilelink 获取指令数据，最终将指令数据或者异常数据发送给 IFU。本项目涉及了Icache预取流水线，元数据缓冲队列、取指流水线、缺失处理单元和先入先出队列。,1. 验证环境+API：验证环境和API是代码成果，是针对待验证对象（DUT）的数据职责（引脚）和行为职责（逻辑）的封装，需要提供特定的可复用的接口、 测试套件、测试覆盖率等的定义。2. 测试用例：测试用例是代码成果，定义了用于测试的输入组合，以及预期的输出组合。3. 验证报告：验证报告是文字成果，包括对环境、测试点和测试用例的介绍，复现代码所需的环境和指令，以及对测试覆盖率等衡量指标的报告。
多媒体处理框架中的动态流式处理接口C++实现,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""]]",在BMF中 python和cpp的builder层都是基于connector层构建的，其中python利用了binding技术，目前BMF支持通过python调用dynamic系列接口，支持在BMF graph运行时动态更改节点，比如新增、删除、重置。此项目的实现可以借鉴现有的python builder实现，来补齐cpp缺失的dynamic系列接口。,1. 用C++实现dynamic_remove，dynamic_add，dynamic_reset，update接口，并完成测试用例。
基于MindSpore NLP实现Open-R1算法,进阶,"[[""datas"",""AI""]]",随着deepseek的开源，当前开源社区有不少deepseek-r1的复现实现，但是缺少mindspore的对标实现，本任务需要基于MindNLP（MindSpore动态图）+昇腾实现和huggingface Open-R1能力完全对标的R1算法实现。,1. 使用MindNLP实现Open-R12. 复现aha moment3. 提交项目报告（ACL论文格式4. 最终项目代码需要通过审核并合入MindSpore NLP仓。
基于MindSpore生成式套件，构建多智能的多Agent交互金融语音客服,进阶,"[[""datas"",""AI""]]",基于MindSpore套件构建一个高效、安全的智能语音客服系统应用案例，以金融银行业务为例；语音交互层使用生成式套件的ASR + lm +TTS功能，用Dify搭建多智能体交互的多Agent协作引擎；包含的功能有语音导航与意图识别，金融产品推荐和风险提示，反欺诈，投诉与纠纷处理等；系统还需要具备隐私保护，审计溯源和防攻击能力。,1. 项目需应用MindSporeNLP和生成式套件的ASR + lm +TTS功能2. 搭建多个业务智能体，包括认证，查询，投资顾问，投诉等；完成多个智能体交互和意图识别功能3. 搭建后端服务层：大数据引擎用于用户画像；风控引擎用于规则和安全
RISC-V架构下CMSIS-DSP半精度和双精度运算函数向量化优化（V扩展指令）,进阶,"[[""os"",""RISC-V""],[""os"",""Compiler""]]",CMSIS-DSP 是 ARM 为 Cortex-M 系列微控制器量身打造的高效数字信号处理（DSP）库，专为嵌入式系统的实时信号处理需求设计。RISC-V 芯片架构产品也同样需要高效数字信号处理（DSP）库，参照 ARM 通过 RISC-V RVV 向量化实现运算函数加速计算。CMSIS-DSP中整数、单精度运算函数接口已经通过 RISC-V RVV 向量化实现，半精度和双精度运算函数还不支持RISC-V RVV向量化加速。项目实现RISC-V架构下CMSIS-DSP数字信号处理函数的向量化优化。,1. 使用 RISCV 编译器2. 单精度运算函数接口已经通过 RISC-V RVV 向量化实现3. CMSIS-DSP 已有的测试用例测试pass
Dromara孵化器网站优化建设和主网站优化,基础,"[[""web"",""Vue.js""]]",Dromara 是由顶尖开源项目维护者自发组织的开源社区。提供包括流行工具，安全认证，调度编排，前端和应用框架，AI等开源产品，累计获得 300K+ Star，服务成千上万团队。技术栈全面开源共建，保持社区中立。希望让每一位开源爱好者，体会到开源的快乐。Dromara 开源社区目前拥有10+顶级项目和50+孵化器项目，我们的主服务和孵化器都有对应的官方网站。此课题需要对两个官方网站 孵化器官网和主官网 进行UI风格统一设计，架构统一，页面完善优化，官网功能特性新增等，突出主官网和孵化器项目的展示，优化博客提交流程，编写官网使用文档等。,1. 优化完善孵化器网站UI页面和官网UI页面2. 设计和完善网站内容展示3. 统一孵化器网站和官网的技术架构，升级使用最新对应的技术版本，提供相应的构建文档和本地部署文档等4. 其它网站页面开发
开发基于 LLM 的 OpenDigger 项目自动化标签系统,进阶/Advanced,"[[""datas"",""Data Science""]]","- 👥: [@Frank](https://github.com/frank-zsy)- 💪: [Python](https://www.python.org/), [DeepSeek](https://deepseek.com/), [TypeScript](https://www.typescriptlang.org/), [Yaml](https://yaml.org/), [Node.js](https://nodejs.org/en/)- ⌛: 350 小时- 📈: 困难- 📎: https://github.com/X-lab2017/open-digger/issues/1695- 💬: OpenDigger 主要为开源代码库生成 CHAOSS 和 OpenRank 指标。为了更深入地了解开源数据，我们需要更丰富、多维度的数据聚合方法，例如获取与国家、企业和技术领域相关的指标。这些指标高度依赖于高质量的标签数据。擅长文本处理的大语言模型（LLM）可能会为 OpenDigger 生成技术领域数据提供一种全新的方法。- 🎯：该系统希望开发者能够结合大语言模型（LLM）与传统自然语言处理（NLP）技术，从 OpenDigger 的全部数据中提取技术领域标签。这种方法将形成一个完整的系统，帮助 OpenDigger 快速发现和分类开源生态系统中的新项目。根据 OpenDigger 的格式规范生成并存储数据到 OpenDigger 仓库中，以便后续进行指标生产和开源数据分析。",1. 一种基于 LLM 和 NLP 的开源生态项目自动化标签系统
提升 Higress Console 对 AI 编码的兼容性,进阶,"[[""datas"",""AI""]]",### 项目背景随着人工智能（AI）技术的飞速发展，越来越多的开发场景开始融入 AI 工具与技术，以提升开发效率、优化用户体验并探索新的功能实现方式。Higress Console 作为 Higress 的配置管理和运维平台，目前在支持 AI 开发流程方面仍有较大的提升空间。为了更好地适应未来开发趋势，满足开发者对高效、智能开发环境的需求，我们计划对 Higress Console 进行针对性的优化与改进。### 已有工作目前，Higress Console 已经具备了基本的前端开发框架，采用 Typescript 语言和基于 React 的飞冰（ICE）框架构建，能够实现一些常规的控制台功能，如服务来源管理、路由管理、插件管理等。然而，其在对接 AI 编码工具方面还没有进行较多的实践。### 存在的不足- 代码结构与扩展性问题：现有的代码结构在一定程度上限制了 AI 编码工具的接入能力，需要进行重构以更好地适应未来的发展需求。- 缺乏指导性文档：对于开发者如何利用 AI 技术进行 Higress Console 的开发或优化，目前缺乏系统的指导性文档，提高了使用 AI 技术开发 Higress Console 时的上手难度。### 希望改进的点- 重构代码结构：对 Higress Console 的代码进行必要的重构，优化其架构设计，使其能够更好地支持 AI 开发流程的集成，提高代码的可维护性和扩展性。- 编写指导性文档：编写详细的使用 AI 技术进行 Higress Console 开发的指导性文档，包括利用 AI 编码工具开发 Higress Console 的操作方法、最佳实践案例等，降低开发者的学习成本，帮助更多开发者快速上手。### 最终项目实现的目标- 提升兼容性：通过代码重构和功能优化，使 Higress Console 能够更好地兼容 AI 开发流程，支持开发者能够更高效的利用 AI 技术来进行 Higress Console 的开发和优化。- 提供完善的开发指导：完成一套高质量的指导性文档，为开发者提供清晰、详细的 AI 开发指导，降低开发者上手 Higress Console 开发的学习成本。- 优化用户体验：通过优化界面设计和功能实现，提升开发者在使用 Higress Console 进行 AI 开发时的整体体验，使其成为 AI 开发场景下的高效工具。- 推动社区发展：项目的成功实施将吸引更多开发者关注 Higress Console，提升社区的活跃度和贡献度，为 Higress Console 后续的功能快速迭代打下良好的技术。,1.对 Higress Console 进行必要重构使其更好的兼容 AI 编码流程，让AI更容易理解代码结构的目标和让人理解代码结构是一致的2. 编写使用 AI 编码工具进行 Higress Console 开发的指导性文档，可以用做Curosr/通义灵码等AI编码工具的提示词，使用此提示词结合需求描述，可以快速完成功能开发，至少实现可以在无需人参与的有限次对话下，完成下面几个功能的开发（当前使用通义灵码生成的代码基本不可用）
kernel: Backport steal-time support for RISC-V,进阶,"[[""os"",""Linux""],[""os"",""RISC-V""]]",（1）相关背景steal-time 是指当管理程序为另一个虚拟处理器提供服务时，虚拟 CPU 等待真实 CPU 的时间。当主机将这些资源分配到其他地方（例如，分配给另一个客户机）时，会出现 steal-time 现象。该功能 RISC-V 支持进入了主线 6.8 版本内核。（2）已有的工作rvck-olk 内核仓库是基于 openEuler OLK-6.6 开发的 RISC-V 同源仓库，已合入多种 RISC-V 芯片支持、主线特性回合，具备自动化测试等基础设施。（3）存在的不足缺少 steal-time 支持（4）希望改进的点Backport 主线 steal-time RISC-V 支持（5）最终项目实现的目标完成在 openEuler RISC-V 上的功能验证，代码合入 rvck-olk 内核仓库,1. 完成在 openEuler RISC-V 上的功能验证，代码合入 rvck-olk 内核仓库
基于MindSpore实现材料属性预测模型MatterSim的迁移开发,进阶,"[[""datas"",""AI""]]",通过大规模的预训练，覆盖尽可能多的分子及晶体结构，得到高泛化性的力场及属性预测模型，成为一种趋势。MatterSim在2024年由微软开发，对材料空间广泛覆盖，可以在多种体系和多种属性上进行精确预测。,1. 基于MindSpore+NPU，结合AI化学套件MindSpore Chemistry现有能力，实现材料属性预测模型MatterSim的迁移开发，并对齐论文精度和性能。
基于RISC-V架构的KubeVirt虚拟化支持与生态适配,进阶/Advanced,"[[""os"",""RISC-V""],[""os"",""Linux""],[""os"",""Virtualization""],[""datas"",""AI""],[""cloudnative"",""Cloud Native""]]",随着 RISC-V 架构在开源硬件领域的迅速发展，其在 AI 推理/训练和视频编解码等高性能计算场景中的应用潜力日益凸显。为了充分利用 RISC-V 的优势，构建支持分布式虚拟化直通的解决方案变得尤为重要。KubeVirt 作为 Kubernetes 的虚拟化扩展，为容器化环境中的虚拟机管理提供了强大的支持。然而，目前 KubeVirt 尚未原生支持 RISC-V 架构，这限制了其在新兴硬件平台上的应用。目前，已实现了在 RISC-V 上重构基本的容器镜像，并且构建工具链已适配 RISC-V 架构 。本项目旨在深入探索 RISC-V 的虚拟化特性，特别是结合 QEMU 和 KVM 的支持，完善 KubeVirt 在 RISC-V 上的适配工作。具体包括：实现对 RISC-V 虚拟化扩展的支持、提供分布式虚拟化直通的能力、确保与现有社区生态的兼容性等。通过本项目的实施，期望将 RISC-V 的支持合并到 KubeVirt 的上游社区，推动其在新兴硬件平台上的应用。这不仅有助于推动在云原生虚拟化领域的影响力，也为 AI 推理/训练和视频编解码等高性能计算场景提供坚实的基础。,1. 为 KubeVirt 提供 RISC-V 虚拟机创建和直通支持2. 为 Kubevirt RISC-V 支持开发虚拟化验证测试用例3. 为上游社区合并提供自动化验证能力4. 为适配方案编写技术文档与用户指南
为Zino框架实现AI服务抽象,进阶,"[[""web"",""Web Application""],[""web"",""RESTful API""],[""datas"",""AI""]]",,1. 通过trait抽象集成国内外主流的大模型服务，并支持流式输出。2. 实现对话记忆、函数调用、RAG检索、向量存储等功能的支持。3. 提供一定的AI工作流编排能力。
利用汇编优化riscv架构下musl的memory性能,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""codelang"",""Programming Language""]]",1. musl项目中针对string，在arm/aarch64/i386/x86_64架构中已经实现了对memory相关函数的汇编优化，目前riscv64架构缺少相关的实现。2. 当前在一些开源项目中可能已有类似的实现，但是musl中还未实现，所以需要考虑版权问题，不可直接移植其它项目的源码。3. 为了充分利用硬件特性，直接针对 riscv64 架构的指令集进行优化，可以大幅提高在高频调用相应函数下的性能。,1. 完成memset、memcpy、memmove汇编函数实现2. 完成实现过程的分析文档3. 完成汇编版本与原有版本的性能对比
为 Overleaf LaTeX 协作平台接入 LLM Copilot 功能,进阶/Advanced,"[[""datas"",""AI""],[""web"",""Web Application""]]",是一款开源在线 LaTeX 协作平台，通过将 LaTeX 环境打包在服务器中，让用户无需在本地配置环境即可在浏览器上撰写 LaTeX 文档，还可以邀请好友加入协作，是各高校及研究人员的科研利器。目前，Overleaf 主要面向其商业版开发，开源版本功能落后，很多核心功能缺失。我们希望能够维护一个完全开源的分支，尽力将商业版功能及其他科研中需要的功能加入进来。本项目希望为 Overleaf 接入 LLM API，为 LaTeX 公式、格式等提供辅助写作(Copilot)功能，减少用户学习 LaTeX 的难度。,1. Overleaf LLM Copilot 功能2. GitBridge Git备份服务
基于Agent实现数据分析报告场景应用,基础,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""LLM""]]","背景：AI Agent已成为企业数据分析领域的重要提效智能化手段，随着大模型技术从""生成式对话""向""任务自动化""加速演进，以及MCP、Manus等技术的发展，数据分析领域的分析工具目前的主流趋势还是人+Copilot的方式，大模型主要还是作为辅助工具。因此，如何借助MCP、Agent等实现数据分析Manus，优化分析范式是数据分析领域重要的研究课题。需要在DB-GPT中开发新的数据分析应用，为AI Agent在数据分析领域提供可复用的技术范式预期目标：1. 全流程自动化分析Agent使数据分析更高效：基于自然语言自动化编排Agent+MCP实现趋势分析、多维洞察等智能数据分析能力2. 端到端分析模式使数据分析更深入：全流程追溯中间分析过程和结果，并结合分析结果生成分析图表/归因结果/决策建议等分析报告3. 基于大模型及RAG等技术知识增强：私有业务知识检索增强，提升数据分析口径准确性",1. 项目设计文档（含架构图、原理图、实现细节等）2.  数据分析应用源代码（包含数据分析应用中的后端、前端代码等）3. 数据分析使用文档（提供完整的使用教程文档）4. 输出可复用的垂直场景模板（提供垂直场景最佳实践演示demo、测试数据集）
基于 Dubbo Triple 协议的零信任、高性能、可靠 Steaming 能力实现,进阶,"[[""web"",""Web Application""],[""web"",""Spring Cloud""],[""safe"",""JWT""],[""safe"",""OAuth""],[""safe"",""OpenIDConnect""]]",Dubbo Triple 是 Apache Dubbo 推出的新一代基于 HTTP/2 的 RPC 协议，兼容 gRPC，支持 RESTful 风格、Streaming 通信、HTTP/3 等特性，适用于构建现代云原生微服务架构。本任务旨在围绕 Dubbo Triple 协议，构建一个完整的微服务通信框架，涵盖接口定义、认证授权、安全通信、性能优化及流式通信等关键功能。支持常见的 OAuth 2.0 授权流程，如授权码模式、客户端凭证模式等，确保资源的安全访问 。实现请求和返回数据的零拷贝读写，减少内存复制，提高数据处理效率。在 Triple Streaming 通信模型的基础上，设计支持网络抖动、进程重启等异常情况的编程 API 模型，确保用户可以低成本构建可靠的 Streaming 通信功能,"1. 提供完整的代码实现，满足项目描述中要求的能力
2. 提供详细的文档，涵盖使用说明、API 文档等"
Prometheus remote write 请求零分配解析,基础,"[[""cloudnative"",""Prometheus""],[""datas"",""Non-relational Database""],[""web"",""Apache""]]",Prometheus作为一款广泛使用的开源监控和告警系统，在大规模分布式环境中扮演着核心角色。其远程写入（Remote Write）机制是连接监控数据采集和存储后端的关键组件。远程写入技术允许Prometheus将监控指标数据高效地推送到不同的时间序列数据库中，如 Apache HoraeDB、InfluxDB 等。然而，在高并发和大规模数据场景下，传统的远程写入实现往往面临。零分配（Zero Allocation）解析成为优化这一过程的重要技术路径。零分配解析的核心思想是在数据传输和处理过程中最大限度地减少内存分配和垃圾回收开销。通过精细的内存管理和高效的数据结构设计，可以显著提升Prometheus远程写入请求的处理性能，降低系统延迟，减少资源消耗。这种技术优化对于构建高性能、低延迟的监控系统具有重要意义，特别是在需要实时处理海量指标数据的云原生环境中。项目产出要求,1. 基于开源版本的 easyproto，采用 Rust 语言实现 Remote Write 请求的解析2. 与 Rust 生态内的其他 protobuf 序列化（prost、rust-protobuf 等）框架做 benchmark，并根据压测结果优化实现
量子启发算法超参数搜寻模块开发,基础,"[[""datas"",""AI""]]",任务背景：通过量子启发式算法求解组合优化问题时，优化结果会受到量子启发算法中的超参数选取的显著影响。对于合适超参数的搜寻，目前通常是基于经验调整或者进行暴力的参数搜索，这往往会耗费很多时间。本问题希望针对量子启发算法的特性，开发对应的自动化量子启发算法超参数寻优流程，以提升量子启发算法最优超参数的搜寻效率。任务需求：针对bSB、dSB、CAC和CFC这四种典型的量子启发算法，在四种典型的二值组合优化问题下（变量取值±1）开发对应的量子启发算法超参数优化策略。具体四类组合优化问题包括：1、一般形式的二阶二值优化问题；2、一般形式的高阶二值优化问题（最高8阶）；3、特殊的高阶二值优化问题1——任意3阶二值问题表达式的平方；4、特殊的高阶二值优化问题2——任意两个3阶二值问题表达式的平方求商，通过Dinkelback方法转化出的高阶二值优化问题,"1. 针对需求描述中给出的4种典型的问题，基于提供的数据集（4种典型问题，每个问题50个数据集，合计200个），算法有60%的结果优于基线方法给出的结果。
对于一般形式的二值优化问题，基线为MindSpore Quantum的QAIA库中的默任参数；对于其他问题，基线为QAIA算法+现有的调参模块hyperopt在相同时间内给出的优化结果（代码的运行时间包括参数搜索部分耗时）；2. 提交详细的技术报告，包括：（1）对代码采用的参数搜寻策略的详细分析，（2）bSB、dSB、CAC和CFC算法下代码针对200个数据集的优化结果和基线结果的比较分析；3. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准；4. 最终项目代码需要通过审核并合入 MindSpore Quantum代码仓。"
飞桨PaddleNLP-前沿模型模块化设计,进阶,"[[""datas"",""Natural Language Processing (NLP)""],[""datas"",""AI""]]",目前LLM模型结构迭代迅速，适用于多种领域的多样模型不断涌现，为社区带来蓬勃生机。但是，在模型构造上也存在多种多样的问题，初学者想要构造或者修改完整模型结构较为困难，同时性能优化手段需要多次重复在不用模型上实现和验证，较为费时费力。本选题目标为实现前沿模型模块化设计，并通过libcst等工具实现源码分析和转换的功能。最终目标期望基于Llama模型结构自动化实现Qwen2等模型的自动化构造。,"1. PaddleNLP套件支持前沿模型模块化构造
2. PaddleNLP套件Qwen2模型结构可通过模块化设计生成，并通过前后精度验证。
3. PaddleNLP套件Qwen2模型并行能力可通过模块化设计生成，并通过前后精度验证。"
基于ZVM自动构建openEuler embedded混合部署系统,进阶/Advanced,"[[""os"",""Virtualization""],[""datas"",""Embedded Database""],[""os"",""RTOS""]]",（1）相关背景：ZVM是openEuler embedded混合部署系统中的一个虚拟机底座，可以支持在单个硬件上使用虚拟化技术运行多个操作系统（例如Zephyr和Linux），以完成不同任务之间的隔离和资源的贡献。（2）已有的工作：ZVM现阶段已经集成到openEuler embedded混合部署系统当中，可以同时启动一个openEuler embedded和一个Zephyr。（3）存在的不足：现阶段编译ZVM的方式是在openEuler embedded外部编译，在启动的时候将镜像加载到硬件当中去，而不是通过oebuild一次性编译成一个统一的镜像文件（原因是以前的基础设施不支持将Zephyr源码放入整个系统当中）。（4）希望改进的点：将ZVM源码放入openEuler embedded源码仓库中去，并通过oebuild统一编译成一个可以运行的镜像。（5）最终项目实现的目标：实现ZVM与openEuler embedded源码级集成，方便一次性构建和部署。,1. 将openEuler/zvm仓库源码中的ZVM集成到openEuler embedded源码仓库中，并可以一次性统一构建出单个镜像；2. 构建的镜像可以在qemu模拟器或者真实硬件开发板（RK3568）上运行；3. 支持同时运行的操作系统大于等于2个（例如Zephyr和openEuler embedded）.
GCC-Fortran 的 Function Multi-Versioning 功能实现,进阶,"[[""os"",""GCC""]]",Fortran 是一种特别适用于数值计算和科学计算的编程语言，这样的程序往往很容易被CPU的指令集扩展所加速，如 AVX2 、 AVX512 等等。然而，如果我们直接通过 `-march` 或 `-mcpu` 指定指令集扩展，会导致所编译的程序二进制失去跨平台兼容能力。此外，对于程序中的某些部分，编译时选择最佳的指令集扩展有时反而会引入显著的性能下降。因此，在函数粒度对函数多版本行为进行控制，不仅能够保证程序二进制的跨平台兼容性，同时还能够提升程序的性能。在 GCC 中，我们可以在 C / C++ 通过 target 和 target_clones 两个 attribute 使编译器为函数生成支持不同指令集扩展集合的版本，并在运行时根据CPU所支持的指令集扩展选择其能够支持的最佳的函数。然而，GCC 中尚且缺乏对 Fortran 的函数多版本支持。,"1. 基于 GCC master 分支，为 Fortran 语言的 subroutine 与 function 声明添加 target / target_clones 的 ATTRIBUTES 支持。
2. 将该实现提交给开源上游"
在Seata Console端提供MCP Server,进阶/Advanced,"[[""datas"",""AI""]]",项目背景MCP（Model Context Protocol，模型上下文协议）是由Anthropic推出的一种开放标准，旨在统一大型语言模型（LLM）与外部数据源和工具之间的通信协议。Seata计划在Console端进行MCP Server建设，基于Console和Server现有的功能并新增相应模块实现MCP Server能力。供用户能够在相关的MCP Client端中进行与Seata的相关的事务管控、运维管理及数据报表功能 项目目标 最终目标是提供给用户易用的MCP生态，鼓励挖掘Seata其他MCP功能，最终完成以下需求：1. 提供seata console端的MCP Server，新增模块进行MCP相关功能建设2. MCP Server（实现SSE协议）也需要能够接入类似Claude Desktop、curosr的客户端进行使用3. 根据以上功能，产出相关设计及功能使用文档,1. 提供seata server console端的MCP Server，新增模块进行MCP相关功能建设。2. 根据以上功能，产出相关设计及功能使用文档，MCP Server也需要能够接入类似Claude Desktop或其他支持MCP协议的客户端进行使用 P1
基于MindSpore和多视角立体匹配技术的稠密重建模型,进阶,"[[""datas"",""AI""]]",基于深度图的三维重建技术常常借助于多视角立体匹配方法，这是一种通过多视角且已标定的图像恢复场景三维信息的方法。而基于深度学习的多目立体匹配技术在传统多目立体匹配方法的基础上越来越多地引入了深度学习的优势，这些算法通常能够在处理复杂场景和大规模数据时取得更好的性能，但是它们一方面通常需要大量的训练数据和计算资源来进行训练和推理，另一方面需要注意处理输入图像之间的不一致性、遮挡和噪声等问题，以获得更准确的重建结果。,1. 基于MindSpore框架搭建一种基于深度学习的多视角立体匹配技术，允许借鉴开源方法，但是需要展示pipeline的创新处，最终需要在ETH3D数据集上进行在线评估，将评估结果与SOTA方法进行对比。
KWDB语法和计算功能扩展,基础,"[[""datas"",""Database""]]",KWDB支持非常广泛的SQL语法和计算能力，然而市场持续有新增语法支持和计算能力支持的需求。本项目期望参赛者实现指定的SQL语法支持和函数算子的实现，通过严谨的自测，在工程化和流程完整性方面达到产品化的标准。,1. 针对下面列出的8-12项语法或函数算子（有*标记作为扩展项）输出研发过程性文档，完成代码实现和充分的黑盒和白盒测试，把测试用例和代码集成到一个代码分支，提出PR且经过评审合并到指定的代码分支。
openGauss向量数据库对接airbyte,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",完成airbyte 与openGauss向量数据库适配，添加destination-connector为openGauss向量数据库的选项，提交适配代码到openGauss社区，并输出案例和详细使用文档。,1. 基于openGauss 容器部署指导文档、airbyte部署指导文档，基于docker完成服务部署。编写应用代码，完成destination-connector为openGauss向量数据库的适配。2. 根据airbyte适配流程，输出使用openGauss作为desitination-connection的案例以及详细使用文档，完成端到端流程的打通和验证，适配代码和相关文档需合入openGauss社区。
研究面向企业级应用Linux系统的性能评价方法及验证工具,基础,"[[""os"",""Linux""]]",目前针对Linux操作系统的性能评价没有一套完整的解决方案，普遍存在仅使用各种性能测试工具跑数据无法清晰给出性能评价方法的问题，本项目通过调研面向企业级应用的操作系统的核心性能指标并选型合适的性能测试工具，形成一套针对企业级应用的操作系统的性能测试/评价方案，并基于openEuler社区mugen测试框架开发对应的测试/评价脚本，项目的目标是建立针linux操作系统的性能完整的评价/测试方案。,"1. 调研操作系统在企业应用中在内存、CPU、io、存储、网络等方面被关注的核心性能指标，形成调研文档，要求调研结果能相对比较真实的反映各项性能指标在企业应用中的关注程度，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/performance_test 目录下。
2、根据上述1中的调研结论，调研用于测试对应性能指标的测试工具，形成调研文档，对于多个性能测试工具，需要进行对比并做选型，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/performance_test 目录下2. 学习了解openEuler开源社区的mugen测试框架（https://gitee.com/openeuler/mugen），掌握测试套/测试用例的开发方法以及运行调试方法3. 根据上述2中的调研结论，结合上述3中的知识点，开发性能测试的测试套和测试用例，测试用例中可根据调研结果初步设定一组基准值，测试套上传至 https://gitee.com/oepkgs/os-autotest/tree/master/suite2cases/performance_test 目录下，测试用例上传至 https://gitee.com/oepkgs/os-autotest/tree/master/testcases/performance_test 目录下（注：os-autotest 是基于mugen框架，旨在建立针对操作系统完整测试方案的测试框架/脚本库）4. 上述4中提交的测试套和测试用例需要在 os-autotest 中执行通过，提交MR时需附执行通过截图"
为 Excelize 公式计算引擎添加公式计算函数,基础/Basic,"[[""codelang"",""Programming Language""]]",目前Excelize开源电子表格文档基础库，已经覆盖数学与三角函数、逻辑、财务、文本、统计、工程日期与时间、查找与引用等分类下的累计452项公式计算函数，本课题的目标是在此基础上，扩展涉及文本处理和财务两个分类的2项新计算函数BAHTTEXT和DOLLAR,1. Excelize 公式计算引擎能够正确计算带有 BAHTTEXT 和 DOLLAR 公式计算函数的单元格2. 在 calc.go 源代码文件中进行实现3. 具有完备的文档和单元测试，在 calc_test.go 源代码文件中编写测试，增量行测试覆盖度达到 100%4. 高质量的代码实现，具有良好的性能表现
支持Agent2Agent服务管理模块,进阶/Advanced,"[[""datas"",""AI""],[""cloudnative"",""Cloud Native""]]",# 背景A2A是Google推出一个同步Agent之间相互通信的模型协议，使得不同提供商的Agent之间可以进行跨平台和云环境的通信。在协议中Google针对Agent之间的发现提出了多种思路，其中基于Regsitry的方法在大规模的Agent相互发现以及协作中具有重要意义。Nacos作为微服务的注册配置中心，在Agent注册发现的场景中具有天然的模型优势。因此Nacos社区希望在“开源之夏2025”期间，基于Nacoa实现一整套A2A协议的Regsitry能力，使得Agent能够通过Nacos做相互发现，注册以及搜索能力。# 目标完成Nacos的Agent2Agent服务管理模块，补充定义 AI Registry，基于服务发现和配置管理在AIAgent上做服务发现以及描述信息管理，联合A2A社区功能完善，并且辅助A2A做自信息自发现；,1. A2A Registry协议的定义和完善2. 基于协议在Nacos中实现整套Agent服务的注册和发现逻辑3. 实现控制台管理Agent服务的能力
为 GreptimeDB 实现异步索引构建机制,进阶/Advanced,"[[""datas"",""Database""],[""cloudnative"",""Cloud Native""]]",随着 GreptimeDB 索引类型的日益丰富（包括 minmax、倒排索引、全文搜索、布隆过滤器等），当前基于 SST 文件层级的同步构建机制已成为写入性能的瓶颈。现有的做法将索引构建与 flush/compact 操作耦合，阻塞了写入流程；而通过 DDL 操作修改 region 元数据实现灵活索引管理，以及查询优化器可智能选择索引的能力，为实现异步索引构建提供了可行性。本项目将重构当前索引构建流程，实现与写入解耦的异步机制。通过引入 double-read 操作，将索引构建与数据持久化解耦，为未来如远程索引器、基于数据分布的自适应索引选择等特性奠定基础。,1. GreptimeDB 支持异步构建索引：把建索引过程从写入路径中摘除出来，并实现自动或按需为无索引的数据文件构建索引2. （可选）可继续实现接续的旧数据重建索引功能和远程索引器
为opentelemetry-go-auto-instrumentation提供eino框架的大模型可观测能力,进阶,"[[""os"",""Perf""]]",在https://github.com/alibaba/opentelemetry-go-auto-instrumentation项目中，通过插件的方式提供对https://github.com/cloudwego/eino 框架的大模型可观测能力，并支持OpenTelemetry GenAI的规范。,1.  在https://github.com/alibaba/opentelemetry-go-auto-instrumentation项目中，通过插件的方式提供对https://github.com/cloudwego/eino 框架的大模型可观测能力，并支持OpenTelemetry GenAI的规范。相关代码合入主干分支。
基于OpenYurt本地部署高可用Kubernetes集群,进阶,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""],[""cloudnative"",""Cloud Native""]]",由于Kubernetes架构的复杂性，用户在自有IDC（互联网数据中心）中运维、管理和升级Kubernetes集群存在诸多困难。OpenYurt社区提供了云边一体化的解决方案，将Kubernetes控制面部署在云上，支持从云上来纳管IDC内的资源。然而，面向大规模IDC资源及业务管理（尤其在大规模AI训练、批处理等场景）时，会面临巨大的云边带宽压力。因此，需要提供一种在IDC内部高效地运维Kubernetes集群的方案。本项目借助OpenYurt的云管边的能力，采用Kubernetes-On-Kubernetes架构，将租户集群的控制面下沉到IDC内，由OpenYurt来管理租户集群的控制面，并提供部署、升级及扩容等能力，同时，支持IDC节点的高可用接入。,1. 提供Kubernetes集群控制面组件的高可用部署能力。2. 提供Kubernetes集群控制面组件的扩缩容能力。3. 为IDC节点提供高可用的接入能力。
openInula 2.0 升级迁移工具,基础,"[[""web"",""Babel""],[""web"",""React""],[""web"",""UI""],[""web"",""Webpack""],[""web"",""Web Application""]]",提供一个自动化工具，帮助开发者将1.0版本的React Like代码迁移到2.0版本。该工具应支持对代码结构、API的变动进行适配，减少手动修改的工作量，降低错误率。已有工作：1、1.0版本到2.0版本之间的升级规律已基本总结，涉及API、生命周期、函数调用等方面的差异。存在的不足：1、缺少自动化的工具来协助代码迁移。2、手动修改的方式容易遗漏细节，导致项目出错。目标：1、总结1.0到2.0的升级规律，生成完整的迁移方案。2、开发一个自动化工具，帮助开发者从1.0版本的React代码迁移到2.0版本。,1. 技术栈要求：JavaScript（ES6+），Node.js，codemod 编译基础。2. 功能要求
优化 FIT for Python 的插件使用体系,基础,"[[""codelang"",""Programming Language""],[""dev"",""DevOps""]]",当前 FIT 编程框架支持 Java 和 Python 两种语言，其中 Java 语言的插件体系比较完善，支持插件的聚散部署，即 2 个插件，既可以聚合成一个进程启动部署（单体应用），也可以分散为 2 个进程分别启动部署（微服务），但 Python 语言的插件体系暂时不是很完善，虽然也支持聚散部署，但是存在较多的限制。下面就对这些限制进行细化说明：例如，在 Java 中，每一个 Java 插件都有自己独立的依赖，当不同插件聚合部署时，插件与插件之间可以做到很好的隔离（通过不同的 ClassLoader 完成），因此，Java 插件就算依赖冲突，也可以聚合部署。但是 Python 插件聚合部署就必须限制所有插件的依赖不冲突。这个限制非常强，在互相独立的插件开发过程中，是无法感知到对方的依赖情况的，因此，在 Python 插件体系还不完善的时候，强行使用 Python 的聚合对用户的使用造成了比较大的困扰。基于上面的原因，Python 插件的带隔离功能的聚合部署将会成为一个远期的探索方向，当前，需要约定，每次仅部署一个 Python 插件，能够让用户方便使用，并接入 ModelEngine 体系的工具及 MCP 服务。,"1. 能够使用 FIT for Python 熟练编写插件，并输出一个示例插件。
2. 能够通过 ModelEngine 的本地安装文档，快速熟练搭建本地环境进行验证。
3. 在搭建的 ModelEngine 本地环境中，能够将 FIT for Python 的示例插件通过脚本等形式快速接入，使得 ModelEngine 中搭建的 AI 应用能够立即使用插件提供的工具服务。"
物理一致可交互室内仿真场景生成：基于KubeEdge-Ianvs实现,进阶/Advanced,"[[""datas"",""PyTorch""],[""datas"",""AI""]]",边缘计算业务下的具身智能场景生成往往在云侧协助具身智能模型训练，训练所得的具身智能模型部署到边侧推理。目前已有诸多研究致力于室内场景生成问题，如 ProcTHOR、PhyScene、HOLODECK 等，通过自动构建三维室内环境，广泛应用于具身智能仿真任务。然而，这些仿真平台在物理交互属性上与真实世界存在显著差距，缺乏对物体形变反馈、力觉反馈、触觉反馈、温度反馈等多维物理特性的建模。例如，当机械臂接触窗帘时，窗帘应展现出柔性形变、相应的反馈力、触觉信号乃至热传导特性，这些在当前仿真环境中难以真实还原。如何在生成高保真物理场景的同时，赋予场景内物体与现实世界一致的可交互性与物理属性，仍是亟需解决的关键问题。为此，本项目计划基于KubeEdge-Ianvs 分布式协同基准测试框架，构建一套物理一致的可交互室内仿真场景生成流程。借助 Ianvs 提供的仿真控制、超参搜索、性能评测等工具，系统性评估和优化仿真场景中的物理属性建模效果，助力合成高质量具身智能训练数据，提升模型在复杂交互任务中的泛化能力，加速具身智能系统的训练与迭代。,1. 基于KubeEdge-Ianvs单任务学习，集成具身智能模型并实现一个物理一致仿真场景生成算法基线，支持室内环境中物体多种物理属性（形变反馈、力觉反馈、触觉反馈、温度反馈）的物理属性标注、反馈建模与交互仿真，适配具身智能训练需求2. 基于KubeEdge-Ianvs单任务学习，实现数据格式的标准符合性检测算法3. 基于KubeEdge-Ianvs单任务学习，提供标准化测试套件，包括典型具身智能操作任务（如推拉窗帘、握持物体）对应的仿真数据集、物理一致性评价指标（如力反馈误差、形变响应误差、触觉信号匹配度）、测试脚本，支持在 Ianvs 框架内测试与复现
基于 KubeEdge 的云边视频流通信机制扩展,进阶,"[[""cloudnative"",""Kubernetes""],[""safe"",""WebSocket""]]",随着远程感知、视觉识别等边缘智能场景的持续发展，对于云边之间实时视频流传输的支持需求日益增长。然而，KubeEdge 现有的云边通信主要面向日志和控制信号的传输，缺乏对流式数据（如实时视频流）的支持，限制了以视觉为核心的应用在复杂网络环境下的落地与拓展。本项目将在 KubeEdge 框架基础上扩展新的通信机制以支持边缘节点稳定向云端推送视频流，并围绕流式数据在典型边缘场景中的传输问题，探索更具弹性和资源效率的通信方式。项目将关注在多源请求环境下的链路共享、传输稳定性和连接管理问题，使得 KubeEdge 具备视觉数据流通信能力，从而进一步支撑船岸远程监控等应用场景。,1. 基于 KubeEdge，提出面向流式数据的新型云边通信机制2. 形成适用于多请求场景的链路共享策略，缓解重复连接带来的资源消耗问题3. 实现连接维护与断线重试机制，能在不稳定网络条件下保持视频流传输的连续性与稳定性4. 编写完整的技术文档，包含方案背景、方法说明、部署建议与测试参考，支持后续拓展与集成
secGear新增CCA TEE插件并对接global-trust-authority统一证明框架,进阶,"[[""os"",""ARM""]]",1. secGear机密计算远程证明统一框架，实现TEE插件框架，支持不同TEE平台的远程证明报告获取和验证，已支持itrustee、virtCCA及部分CCA的TEE插件。本项目需要新增支持CCA attester插件。2. global-trust-authority目标构建统一可信计算和机密计算远程证明的新项目，为复用secGear中TEE插件，需开发适配层，对接global-trust-authority统一证明框架。3.,1. 新增CCA attester插件，在QEMU仿真平台获取CCA报告2. 联合CCA verifier插件，在QEMU仿真平台验证CCA报告3. 开发TEE插件适配层，实现secGear TEE插件对接到global-trust-authority统一证明框架4. 提交代码、说明文档、验证报告到secGear代码仓
支持在Windows OS上使用KubeEdge部署工具keadm,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""]]",keadm是KubeEdge的安装部署工具，可以使用keadm join/reset/upgrade等子命令对KubeEdge边缘组件EdgeCore进行安装、重置、升级等操作。在工业场景中有很多设备使用Windows操作系统，而且许多企业级应用（如 .NET Framework、IIS、SQL Server等）依赖Windows生态，无法直接迁移到 Linux。为了让企业能在统一平台上管理混合操作系统，Kubernetes和Containerd都已支持Windows，EdgeCore也已经能在Windows上正常运行及工作。然而由于keadm工具依旧没有适配windows，目前EdgeCore在Windows上只能手动使用二进制包启动，运维管理存在着很多问题。本课题需要重新设计如何用keadm工具和边缘子命令操作EdgeCore在Windows设备上的部署升级等，进行生命周期管理。,1. 输出完善的设计方案2. 在Windows设备上成功使用keadm join/reset/upgrade子命令安装、重置和升级边缘组件EdgeCore3. 完善KubeEdge的编译打包脚本，支持直接发布keadm等KubeEdge组件的Windows版本。
EulerPublisher-EUR集成与Web管理界面开发,基础,"[[""cloudnative"",""Docker""]]",EulerPublisher是openEuler社区重要的软件制品构建分发平台，当前已支持容器镜像和云镜像的自动化构建。随着社区发展，用户对软件包构建与分发的需求日益增长。本项目旨在将EUR(openEuler User Repo)功能集成到EulerPublisher平台中，通过开发友好的Web界面，为用户提供完整的软件包构建、测试和发布能力，进一步完善openEuler生态工具链。,1. 完成EUR(openEuler User Repo)与EulerPublisher的集成2. 实现软件包的构建、测试和发布全流程功能3. 开发完整的Web用户界面，支持用户交互操作
Sentinel 自适应熔断功能的调研和实现,进阶,"[[""web"",""Web Application""]]",Sentinel 作为面向分布式应用场景、多语言异构化服务架构的流量治理组件，以丰富的流量防护能力满足了各种应用场景的限流需求。其中熔断能力，能够在应用依赖的服务提供方出现异常（慢调用、调用异常等）时根据配置的规则进行熔断处理，避免由于应用依赖的服务提供方的异常导致应用本身的稳定性受到影响。但是在用户的实际使用过程中，熔断规则中具体参数的配置以及现行的单次探测行为都在一定程度上提高了该功能的使用门槛，降低了该功能的使用效果。因此，我们希望在现有熔断能力的基础上调研并实现自适应熔断规则，让熔断能力变得更加智能更加易用。,1. 业界常见的自适应熔断需求以及方案调研报告2. 基于 Sentinel 构建自适应熔断能力3. 编写自适应熔断的核心设计文档、用户使用文档
QuCOOP：迭代式求解复合二元优化问题,基础,"[[""datas"",""AI""]]",任务背景：当前使用量子设备求解优化问题都集中在QUBO模型上，比如量子退火或者QAOA算法，他们都是关于二元变量的二次函数。本工作将拓展二元优化问题拓展到连续函数提出QuCOOP框架对复合函数进行优化。任务论文：《QuCOOP: A Versatile Framework for Solving Composite and Binary-Parametrised Problems on Quantum Annealers》（arXiv:2503.19718）任务需求：1. 请基于MindSpore Quantum框架复现论文中的图2和图6中结果。（使用QAOA替换退火机，包含比特数20以内结果）；2. 请拓展到一般连续函数并针对常见的连续优化函数如BBOB测试集测试表现。,1. 基于MindSpore Quantum0.10版本，复现论文《QuCOOP: A Versatile Framework for Solving Composite and Binary-Parametrised Problems on Quantum Annealers》（arXiv:2503.19718）中的图2和图6中结果；测试BBOB测试集中连续函数的表现；2. 提交规范的技术报告，需包含工作原理和代码函数介绍以及复现效果；3. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准；4. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。
基于 WebRTC/WHEP 协议的实现录制回放功能,进阶/Advanced,"[[""web"",""Web Application""]]",Live777 作为实时音视频传输和分流服务，有些场景下（比如视频会议，智能监控）经常需要录制回放功能。回放功能经常需要拖动进度条，所以需要索引分片的格式，如 M3U8，MPEG-DASH常规的实现需要需要以来 FFmpeg 或者其他一些 C 库来实现。如果录制不做编码转换，那可以使用纯 Rust 来一个非常高效的实现可以在 Live777 里取到 RTP 包，然后从容器提取出编码后的视频流，然后把视频流放到新的容器（MPEG-DASH）里来分片存储当然还有一种思路，录制就是把 RTP 包保存起来，实现一种私有格式，回放就是把保存的 RTP 包重放，如果要保存为私有格式，这样就要额外实现一个转换器转换为公开格式方便和其它应用对接目前已经实现 Live777 和一个独立的工具包 Whepfrom，Whepfrom 可以把使用 WHEP 协议进行拉流并把流转换成 RTP 或者 RTSP。dash.js，利用浏览器的 MSE（Media Source Extensions）接口来实现 MPEG-DASH 的支持。存储部分可以使用 opendal，opendal 已经支持了很多云存储服务商，并提供了统一接口我们可以使用 Whepfrom 和 FFmpeg 来实现一个简单的录制，然后用 opendal 来存储。由于不需要编码转换，FFmpeg 并不是必要的，可以用纯 Rust 的实现，只需要实现一个容器格式的转换最终我们可以得到一个纯 Rust 实现的非常高效的录制回放的实现,1. 录制2. 存储3. 回放
Scheme-langserver兼容Goldfish Scheme+R7RS,进阶,"[[""codelang"",""Programming Language""]]",Goldfish Scheme是三鲤Scheme的社区版，它是墨干理工套件生态的一部分。Scheme-langserver是专为Scheme语言设计的LSP（Language Server Protocol）服务器，使用一些非常简单的Abstract Interpretation、Partial Evaluation和Type Inference技术为开发者提供现代集成开发环境（IDE）的核心功能，如代码补全、定义跳转、类型推断等。本项目的目标是让Scheme-langserver服务墨干理工套件生态，这包括：,1. 修改Scheme-langserver的Abstract Interpretaion、Partial Evaluation和Type Inference部分，以兼容R7Rs-small标准；2. 为Abstract Interpretation添加规则以兼容Goldfish Scheme语法，包括具名参数、函数式数据管道、case class、@语法等；3. 结合墨干生态应用需求，建立10个左右的开源的Goldfish Scheme项目作为测试Scheme-langserver兼容性测试的Benchmark。
面向大语言模型的多级编译优化集成,进阶,"[[""os"",""Compiler""],[""os"",""RISC-V""]]",在大语言模型端到端编译通路的基础上，集成各层级编译优化，例如算子融合、多核并行、向量化优化、循环分块等。,1. 大语言模型推理的多级编译优化实现2. 大语言模型推理的多级编译优化性能测试3. 大语言模型推理的多级编译优化开发文档
PGO反馈优化可用性增强,基础,"[[""os"",""Compiler""],[""os"",""LLVM""]]",PGO反馈优化在各领域已经在广泛使用。该优化技术对于CPU前端瓶颈使用的应用场景优化效果非常显著。但是PGO优化依赖运行时Profile信息采集和二次编译，使用方法较为复杂，且面对不同的应用场景，也呈现了不同的Profile采样需求。希望可以基于当前PGO使用方法，进行如下两部分功能增强：增加一个计数器置零功能，如通过signal信号支持profile count重置为0，使用方式尽可能方便通用。增加clang -fprofile-use支持profraw自动合并功能或者新增如-fprofile-use-dir选项支持该功能，省掉llvm-profdata merge的步骤。,1. 支持PGO计数器置零功能；2. 支持-fprofile-use选项实现自动合并profraw的功能3. 输出上述功能1和功能2的实现技术方案报告和代码，输出完备测试用例，且不影响原功能。
mugen 框架测试结果智能分析,基础,"[[""os"",""RISC-V""]]",mugen 是 openEuler 社区提供的开源自动化测试框架，它提供公共配置和方法以便社区开发者进行测试代码的编写和执行。在 mugen 的测试和修复过程中，需要了解多种软件包功能和测试用例。为缩减和优化测试用例分析和修复过程，可以将 mugen 与 LLM 结合，快速分析测试用例和失败原因等，并给出修复建议。,1. 可以将 mugen 基础框架给 LLM 分析2. 将具体的测试用例和测试结果给 LLM 分析3. 快速分析测试用例和失败原因等，并给出修复建议
基于vllm-mindspore实现beamsearch算法功能,基础,"[[""datas"",""AI""]]",vllm-mindspore是让vLLM在MindSpore 框架上运行的组件。vLLM-MindSpore将MindSpore高效算子、模型、算法在vLLM中使能起来，拥抱生态；beam search功能是一种用于生成文本时寻找最优序列的搜索算法，在vllm-mindspore中支持beam search功能可以提升生态兼容性。,1. 基于vllm-mindspore实现beamsearch功能;2. 基于基于qwen2.5模型，提供自验报告，精度和性能对标vLLM开源社区；3. 代码贡献到vllm-mindspore仓；
基于 eBPF 实时锁竞争感知的 sched_ext 调度策略优化,进阶,"[[""os"",""GNU""],[""os"",""Linux""],[""os"",""Perf""],[""os"",""Ubuntu""],[""os"",""x86""],[""os"",""Clang""]]","在现代多核处理器系统上，应用程序或内核内部的锁竞争是常见的性能瓶颈。当多个线程或进程试图同时获取同一个锁（如 mutex, spinlock）时，失败者要么忙等待（spin-waiting，消耗 CPU 周期），要么进入睡眠等待，这都会导致执行流中断和性能下降。标准的 Linux 调度器虽然可以通过优先级继承等机制缓解部分问题，但通常缺乏对具体哪个锁正在被激烈竞争、谁是持有者、谁在等待的实时、细粒度信息。sched_ext 框架提供了实现更精细化调度逻辑的机会。本项目旨在利用 eBPF 强大的动态追踪能力，实时监测内核或用户态（通过 futex）的锁操作，。这些实时竞争态势信息将被传递给自定义的 sched_ext 调度器，使其能够实施，例如：优先调度持有关键锁的任务以尽快释放锁，或者更智能地管理等待锁的任务，从而减少无效等待和 CPU 资源浪费，提升高竞争场景下的应用性能。",1. 一套 eBPF 程序源代码，用于实时监测内核/用户态锁竞争状态2. 一个基于 sched_ext 框架的自定义竞争感知调度器源代码3. 清晰定义的 eBPF 与 sched_ext 调度器交互接口文档和实现4. 一套用于复现高竞争场景性能测试的基准工作负载、测试脚本和环境配置说明5. 一份详细的项目报告，包含锁竞争监测方法、竞争感知调度策略设计、实现细节、性能测试结果（图表化展示吞吐量、延迟等关键指标）、分析与结论。
Sermant 控制面实现用户认证与SSO集成能力,基础,"[[""cloudnative"",""Cloud Native""]]",1. 相关背景Sermant是一款基于Java Agent的云原生服务治理工具，其控制面负责管理多个Agent实例的配置、监控及治理策略下发。目前控制面作为核心管控组件，缺乏用户认证机制，存在未授权访问风险。为保障企业级部署的安全性，需为控制面提供开箱即用的用户认证能力。2. 已有的工作- Sermant控制面已实现基础的RESTful API接口，支持Agent注册、动态配置下发等功能。- 当前用户可直接通过HTTP请求访问控制面，无任何身份验证流程。3. 存在的不足- 未认证用户可直接操作控制面，可能导致配置篡改或敏感数据泄露- 缺乏标准化的用户管理模块（如用户名密码登录、SSO集成），无法满足企业级安全合规要求- 现有架构未预留认证插件化接口，难以快速对接第三方认证系统4. 希望改进的点- 实现基于用户名密码的本地认证，支持用户注册、密码加密存储及会话管理- 支持OAuth2/OpenID Connect协议，实现与常见SSO服务（如Keycloak、GitHub OAuth等）的集成- 提供默认安全配置（如内置管理员账户），允许用户通过配置文件快速启用/禁用认证功能5. 最终项目实现的目标完成一个与Sermant控制面深度集成的认证模块，支持用户名密码登录与SSO登录两种模式，确保用户需通过身份验证后方可执行敏感操作。最终提供完整的API文档、测试用例及默认安全配置方案，使Sermant控制面满足生产环境的安全准入要求,"1. 认证功能开发：提供核心接口（如登录鉴权、Token签发、会话管理），支持用户名密码登录与SSO登录两种模式，支持切换认证模式
2. 测试覆盖：编写自动化测试用例，覆盖边界场景 
3. 文档与指南：提供完整的SSO与第三方服务的对接指南，包含配置参数说明"
面向openHiTLS增加国密SM9的快速实现功能,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""PKI""],[""safe"",""SSL/TLS""]]",目前openHiTLS已包含部分国密算法如SM2、SM3、SM4的实现，但是尚未集成SM9算法。当前已有部分SM9参考实现，但接口不统一、缺少平台化集成，影响开发效率和可靠性验证。本项目计划将SM9迁移并集成至openHiTLS平台，补齐测试、接口、文档等能力，提升模块化管理与自动化测试水平。,"1. 为 SM9 加解密、签名验签等核心特性开发自动化性能测试功能模块； 
2.为 SM9 算法集成OpenHiTLS 提供统一的注册与调用机制； 
3.为上层应用提供 SM9 密钥生成、签名验签、加解密等功能接口； 
4.基于 OpenHiTLS 测试框架自动化生成 SM9 算法的简易测试报告； 
5.编写 SM9 算法在 OpenHiTLS 中的实现说明文档，输出用例报告"
State 存储改造并进行性能压测对比,基础,"[[""datas"",""Database""],[""datas"",""Embedded Database""],[""datas"",""Flink""]]",在流式计算引擎规则中，会通过 State 来存储算子的状态。目前 eKuiper 存储算子状态是通过 sqlite 进行存储。我们希望将所使用的 State 存储替换为 pebble kv 存储，并针对现有和改造后的流式规则，设计并实施高吞吐、多规则的性能压测对比。,1. State 存储替换为 pebble kv 存储2. 设计并实施高吞吐、多规则的性能压测对比
Karmada 官方文档体系优化与国际化建设,基础,"[[""cloudnative"",""Kubernetes""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。作为 CNCF 孵化的多云编排核心项目，Karmada 的官方文档体系直接影响着全球开发者对多云集群管理技术的采用效率与社区贡献意愿。本项目旨在构建符合 CNCF 标准的​​文档体系​​，通过重构知识架构、补充场景化指南、实现中英实时同步，并引入交互式工具链，系统性降低多云编排技术的使用门槛。,1. 升级Docusaurus 框架至V3：输出V3迁移方案并设计合理的迁移路径，逐步迁移现有网站资源。2. 项目文档结构调整：输出项目标准文档结构设计并逐步调整既有内容。3. 补充关键缺失文档：涉及PropagationPolicy、OverridePolicy、ResourceInterpreter。4. 文档国际化：翻译现有文档至中文，国际化率达到80%+。
为 vsag 增加 ARM 指令集支持,进阶,"[[""datas"",""AI""],[""datas"",""Vector Database""],[""os"",""ARM""],[""os"",""Linux""]]",随着大模型的发展和向量检索的的广泛应用，出现了许多国产化 CPU 和端上设备的向量检索需求。当前 vsag 库对于 ARM 平台只做了最基础的适配，而向量检索是一个计算密集型的任务，为了提升效率，一般需要使用 CPU 的 SIMD 指令集来加速。当前 vsag 已经实现了在 x86 平台的指令集计算代码（SSE/AVX/AVX2/AVX512），并支持根据运行平台的指令情况运行时切换。希望你为 vsag 索引库增加 ARM 平台的指令集计算代码（SVE/NEON），并且实现和 x86 平台一样的运行时检测和切换功能。,"1. 在 vsag 的 simd 模块中增加 SVE/NEON 指令的距离计算函数；
2. 增加 simd 模块中对于 SVE/NEON 指令的运行时检查和切换；
3. 增加 ARM 平台的测试用例；
4. 输出指定 ARM 平台上，标准数据集的性能报告/参考；"
OpenSeek开源共建大模型项目,进阶/Advanced,"[[""datas"",""AI""]]",OpenSeek是由北京智源人工智能研究院（BAAI）发起的开源项目，旨在联合全球开源社区，推动算法、数据和系统的协同创新，开发出超越DeepSeek的下一代模型。 该项目从Bigscience和OPT等大模型计划中汲取灵感，致力于构建一个开源自主的算法创新体系。 自DeepSeek模型开源以来，学术界涌现出众多算法改进和突破，但这些创新往往缺乏完整的代码实现、必要的计算资源和高质量的数据支持。 OpenSeek项目期望通过联合开源社区，探索高质量数据集构建机制，推动大模型训练全流程的开源开放，构建创新的训练和推理代码以支持多种AI芯片，促进自主技术创新和应用发展。,1. 优化flagscale训练和推理效率2. 提升模型数据效率（数据配比和数据质量等）3. 提升模型算法效率（课程学习，初始化，强化学习等）
OI Wiki 外链自动存档和链接替换系统,进阶,"[[""datas"",""AI""],[""datas"",""Deep Learning""],[""datas"",""MongoDB""],[""datas"",""Natural Language Processing (NLP)""],[""datas"",""MySQL""],[""datas"",""Scikit-learn""],[""datas"",""SciPy""],[""dev"",""CI""],[""dev"",""CD""]]",OI Wiki 在编写过程中参考了大量外部资源， 同时这些资源在已有内容之上可能有更丰富的细节，经常能够帮助读者更深入地理解页面上的内容。然而，这些外部链接指向的内容有可能因变动而变得无法访问，影响学习质量和使用体验。本项目计划开发一个作为 CI 和定期服务运行的软件工具，可以自动将外部资源提交到诸如互联网档案馆的存档服务存档，以及定期扫描死链并自动替换为链接，来保证外部资源的可访问性，从而提高文档服务的可靠性。,1. 在 PR 合入主线时执行 CI 将新增的外部资源提交到存档服务（例如：互联网档案馆）2. 在从 markdown 编译生成 HTML、LaTeX 或 Typst 的过程中添加对存档服务提供的外部资源的引用3. 定期扫描 repo 并将不可用的链接替换为存档链接，提高外部资源的可用性
基于 SKF 接口实现支持 OpenSSH 连接认证的 PKCS#11 用户态密码模块,进阶/Advanced,"[[""os"",""Linux""]]",相关背景随着信息安全要求的提升，越来越多的系统在身份认证、密钥管理等领域采用硬件密码模块（HSM）或安全密码设备（如 USB Key、智能卡）来实现私钥的安全存储与使用。在我国，符合国家密码管理规范的接口标准主要是国家密码管理局颁布的 SKF（Secure Key Framework）接口。与此同时，国际通用的 PKCS#11 接口规范被广泛用于用户态密码模块的标准化开发，很多安全应用（如 OpenSSH、OpenSSL、GnuPG 等）都通过 PKCS#11 访问硬件安全模块，加载密钥并进行加解密或签名操作。已有的工作目前，已有多个开源或商业实现提供了 PKCS#11 接口的中间件，如 OpenSC、SoftHSM 等。它们可以用于模拟或适配各种硬件设备。然而，这些实现通常基于国际主流硬件（如 YubiKey、Thales HSM 等），底层驱动与 SKF 接口不兼容，不能直接应用于国产密码设备或国产密码算法环境。同时，OpenSSH 自 7.2 版本起原生支持通过 PKCS#11 接口加载私钥用于 SSH 认证，从而提供无需将私钥导出的高安全性身份认证方案。存在的不足当前国产密码设备（如支持 SM2 算法的 USB Key）虽已逐步支持 SKF 接口，但缺乏一个面向 PKCS#11 应用的软件桥接层，导致无法直接将 SKF 设备用于依赖 PKCS#11 的工具，如 OpenSSH。在缺少中间层库的情况下，无法将符合国密标准的私钥用于主流安全协议认证流程中。此外，已有的国产密码模块多数是闭源实现，限制了灵活的定制与集成能力，阻碍了在教学、研究与国产密码生态推广中的应用。希望改进的点本项目旨在构建一个面向国产 SKF 接口、符合 PKCS#11 标准、支持 OpenSSH 身份认证的用户态密码模块，实现 SKF 到 PKCS#11 的接口转换，使得 OpenSSH 等工具可以通过 PKCS#11 访问 SKF 设备，实现国密 SM2 私钥的非导出式 SSH 认证。该模块应具有以下特性：符合 PKCS#11 v2.20 接口规范；兼容国密算法（SM2/SM3/SM4）；对接 SKF 接口调用底层设备；可被 OpenSSH 识别并用于认证；用户态实现，便于部署与调试。最终项目实现的目标开发一个用户态动态链接库（如 libpkcs11_skf.so），实现标准 PKCS#11 接口，底层调用 SKF API，实现私钥的管理与签名操作。最终目标包括：完成必要的 PKCS#11 接口函数实现（如 C_Initialize、C_OpenSession、C_Login、C_Sign 等）；支持通过 OpenSSH 的 ssh -I 参数加载本模块进行 SM2 认证；提供简单的配置工具，用于选择 SKF 设备、管理密钥对象等；编写配套文档和示例，说明如何生成密钥对、配置 OpenSSH 客户端，并成功完成 SM2 算法下的 SSH 连接认证；支持在 Fedora、CentOS 或 openEuler 等国产操作系统环境下编译与部署。,1. 实现一个符合 PKCS#11 规范的共享库2. 通过 SKF 接口调用完成密钥与签名功能3. 实现 OpenSSH 客户端认证集成流程4. 提供 SM2 密钥加载与使用的工具脚本5. 编写项目构建、配置、使用的完整文档6. 提供至少一次完整 SM2 SSH 认证演示
为doc-apis提供可配置的接口文档出入参下划线驼峰互转功能,基础,"[[""web"",""RESTful API""],[""web"",""Spring Boot""]]","当前根据代码及注释生成的接口文档中,是按照JAVA代码中的字段命名及注释自动生成接口文档,由于JAVA代码大多都遵循了阿里代码规范,在命名上基本都遵循驼峰命名,但在个别场景下,用户仍需要将接口出入参按照下划线方式进行传输,例如T3接口以及部分老接口,要求接口的出入参必须为下划线,由框架内部自动完成下划线和驼峰之间的互相转换,但提供出来的接口文档必须是下划线格式,否则会给联调的前后端开发者造成误导和干扰.因此,如果能提供可配置的驼峰和下划线互转功能,即可解决这部分用户的困扰.","1. 通过JavaParser解析出来的接口入参,进行驼峰和下划线互转,需要处理父类字段及递归处理每个嵌套子类2. 通过JavaParser解析出来的接口出参,进行驼峰和下划线互转,需要处理父类字段及递归处理每个嵌套子类3. 提供Springboot配置项,支持用户通过配置是否启用驼峰下划线互转,默认值为不启用.4. 驼峰及下划线出入参可支持在线调试,能够正确向对应接口发起请求并获取预期结果"
基于图像处理的 VChart 退场特效,基础/Basic,"[[""web"",""UIKit""]]",VChart 渲染完成之后，可以通过接口拿到原始图像数据，在此基础上可以利用已经成熟的图像处理算法，移植图像特效到图表退场动画上。,1. 移植10种图像处理特效2.  接入到VChart 动画流程中
跨平台客户端 Monobean 实现代码仓库、GitHub 同步和去中心化传输,进阶,"[[""dev"",""Git""],[""os"",""FUSE""],[""web"",""GTK""]]",,1. 实现跨平台，要求在 MacOS、Linux 和 Windows 下功能一致；2. Monobean 可以通过 Mega 的去中心化服务实现从多个客户端传输代码；3. Monobean 可以实现本地仓库的一个目录映射为 GitHub 的一个仓库，实现代码、PR、Issue 的双向同步；4. 通过滑动窗口算法等算法实现 Git Pack 文件的 encoding ，改进 decoding 部分算法，提升整体速度；5. 在当前版本上继续完善 Monobean 的功能，对接 Mega 的代码管理 API ，实现仓库管理能力以及客户端基本配置能力；
GStreamer Backend for vhost-device-sound,Advanced,"[[""os"",""Virtualization""],[""os"",""Emulation""],[""os"",""KVM""],[""os"",""Linux""]]",virtio-sound device emulation has recently been developed in the Rust [vhost-device-sound](https://github.com/rust-vmm/vhost-device/tree/main/vhost-device-sound) crate.The crate currently contains audio backends for the ALSA and PipeWire sound APIs. The aim of this project is to build a new[GStreamer](https://gstreamer.freedesktop.org/documentation/?gi-language=c) audio backend.Audio backends are written by implementing the [AudioBackend trait](https://github.com/rust-vmm/vhost-device/blob/b113dc6b288ff2b75968e245a716dc7e1436aec1/vhost-device-sound/src/audio_backends.rs#L20).Refer to [alsa.rs](https://github.com/rust-vmm/vhost-device/blob/main/vhost-device-sound/src/audio_backends/alsa.rs) and[pipewire.rs](https://github.com/rust-vmm/vhost-device/blob/main/vhost-device-sound/src/audio_backends/pipewire.rs) for examples of existing backends.The [Stream](https://github.com/rust-vmm/vhost-device/blob/6ca911eb5f6a73c534e234eedea90cf26d1d71ad/vhost-device-sound/src/stream.rs#L174) and[Buffer](https://github.com/rust-vmm/vhost-device/blob/6ca911eb5f6a73c534e234eedea90cf26d1d71ad/vhost-device-sound/src/stream.rs#L242) structs are used totransfer audio samples between the virtio-sound device and the sound API (e.g. GStreamer).The backend should be implemented using the [GStreamer Rust bindings](https://gitlab.freedesktop.org/gstreamer/gstreamer-rs/-/tree/main). Mono and stereoplayback and capture should be supported. The GStreamer pipelines for playback and capturewill be hardcoded and only Linux needs to be supported.,1. Functional GStreamer Audio Backend2. Integration with vhost-device-sound3. Automated Testing4. Documentation and Upstreaming
基于KubeEdge-Ianvs的VLA微调数据配比优化算法,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""PyTorch""],[""cloudnative"",""Kubernetes""]]","视觉-语言-动作（Vision-Language-Action, VLA）模型在机器人操作和具身智能等领域获得广泛应用，其中VLA模型在云侧训练、边侧推理是具身智能领域的一种常见范式。但是如何在训练过程中合理配置多源异构数据以提升模型在复杂任务中的泛化能力，成为亟需解决的问题。相比计算机视觉与自然语言处理领域，VLA 数据配比策略的研究仍然薄弱，当前多采用静态经验权重或均匀混合，难以适应不同数据子域对特定下游任务的差异化贡献。尽管已有如OpenVLA、Re-Mix等在数据加权方面的探索，复杂多模态 VLA 任务下的数据配比仍缺乏系统性方案。为此，本项目拟依托 KubeEdge-Ianvs 分布式协同 AI 基准测试框架，构建一套面向 VLA 任务的数据配比优化流程，结合 Ianvs 提供的仿真、超参搜索、评测报告等工具，探索多源数据在具身智能训练中的合理配比，推动 VLA 模型在机器人与具身智能应用中的泛化能力与训练效率的提升。",1. 基于KubeEdge-Ianvs单任务学习，参考已有如 Re-Mix 等思路，集成VLA模型并实现数据配比优化算法基线，数据配比应支持多源数据的动态加权与调度，适配不同机器人平台、任务类型与场景2. 基于KubeEdge-Ianvs单任务学习，提供标准化测试套件，包括用于评估 VLA 微调性能的数据集、评价指标（如任务成功率、泛化能力、最坏情况性能）、测试环境配置脚本3. 结合 Ianvs 超参数网格搜索工具和评测工具生成标准化报告，展示不同数据配比策略对 VLA 模型下游任务性能的影响，包括平均性能与最坏情况性能对比4. 对数据配比优化算法基线进行改良或替换，以动态调整数据子域权重，提升 VLA 模型在下游任务性能5. （可选）优化数据配比算法在边缘设备的资源适配能力，确保算法未来在资源受限环境下具备良好的执行效率和扩展性，适配不同边缘节点的计算与通信能力
基于 tree-sitter.mbt 进行结构化查找/替换的 Visual Studio Code 插件,基础/Basic,"[[""codelang"",""Programming Language""]]",该项目将会开发 tree-sitter.mbt 的 Visual Studio Code 插件。用户会通过该插件输入 query language 的查询，插件负责将该 query language 表达式编译成合法的 tree-sitter query （或者其他等价的技术方案实现），通过查询 tree-sitter 生成的 AST 来获取符合用户输入的代码位置，并动态地显示/更新到 UI 上。除此之外，用户也可以通过额外输入一个插值字符串，将query language 中捕获的代码片段插入到字符串中来生成合法的 AST，从而实现结构化的代码替换，保证大规模重构过程中的安全性。,1.   基于 tree-sitter.mbt 开发 VSCode 结构化查找/替换插件。2. 设计并改进现有的 query language 设计，使其在编辑器插件中有更加友好的用户体验。
NB-CLI 命令行工具交互优化,基础,"[[""web"",""UI""],[""dev"",""DevOps""]]",NB-CLI 作为 NoneBot 生态的核心入门与管理工具，主要负责新手引导项目创建、项目运行以及插件管理几大功能。目前该脚手架工具仍存在几点缺陷：首先，作为插件管理工具，由于存储数据的局限性，无法很好地展示用户项目当前安装插件状态，并进行卸载等操作；其次，当前插件管理高度依赖云端 registry 提供插件信息，在离线情况下完全无法使用；最后，由于插件信息繁多，工具未能向用户展示充分的信息，交互复杂 体验较差。以上问题对用户使用 NB-CLI 管理项目插件造成了极大的阻碍。本项目希望重点针对插件管理部分，重构工具插件管理模块，完善框架缺陷，并通过缓存等方式确保可用性。其次，调研同类工具方案与 TUI 等相关技术，优化信息展示能力、用户交互方式，提升工具整体交互体验。,1. 重构 NB-CLI 插件管理模块2. 提升 NB-CLI 交互体验
RustSBI文档检索优化,进阶,"[[""datas"",""AI""],[""datas"",""LLM""],[""os"",""RISC-V""],[""datas"",""PyTorch""]]",在RAG系统中，检索模块的主要功能是根据用户的问题，检索出对应的文档并且传递给大模型，进行答案生成。因此检索模块也是最重要的模块之一，检索出一个相关性高的文档，更有利于模型生成优质的答案。然而由于Rust文档通常以英文的形式呈现，而用户的问题可能是中文的形式，这将会导致检索效果有所下降。因此本项目期望通过调研较为主流的检索方案，来优化RustSBI文档的检索效果。,1. 完成检索模块代码，包括基本的语义检索、排序等2. Top20准确率不低于80%，召回率不低于80%3. 提供代码使用说明
开发一款插件，用于在 ONLYOFFICE 编辑器中按照现代标准格式化中文文本,基础/Basic,"[[""web"",""Web Application""],[""web"",""Desktop Application""]]",本项目旨在为 ONLYOFFICE 开发一款插件，可根据现代书写标准自动格式化中文文本。该插件将调整标点符号样式、中文和拉丁字符之间的间距、全角与半角符号使用等。该插件可能会使用 zhlint 或 zh 等开源工具，帮助用户轻松创作出简洁、规范且专业的中文内容。,"1. 适用于 ONLYOFFICE 文档、电子表格、演示文稿和表单编辑器的插件
2. 插件能够自动格式化中文文本的标点符号、空格和字符宽度
3. 插件提高可读性并确保符合现代格式标准"
MindSpore Quantum HUBO求解器开发,基础,"[[""datas"",""AI""]]","任务背景：目前, MindSpore Quantum的qaia(量子退火启发式算法)部分仅提供了QUBO/Ising的求解器接口, 对于HUBO问题的支持仍为空白. 这限制了MindSpore Quantum在更广泛优化问题场景中的应用潜力. 尽管HUBO问题可以转化为QUBO问题, 但这往往是以牺牲计算复杂度等来实现的, 因此, 本项目旨在扩展MindSpore Quantum平台的优化求解能力, 开发并集成一个原生的HUBO求解器。任务需求：设计MindSpore Quantum HUBO求解器, 内容包括:1. 问题输入格式及读取；2. 使用tensorflow的ragged tensor实现python原生版的HUBO求解器, 需要实现的算法包括MindSpore Quantum中qaia下的所有算法, 且需实现CPU和GPU两个版本；3. 使用C++和cuda实现CPU和GPU两个版本的HUBO求解器, 并写好python接口；4. 比较原生python和C++两个版本的HUBO求解器的求解速度。","1. 对于给定的数据集能够完成读取, 求解, 且保证一定的求解质量(对于特定的问题, 准确率需达到100%)；2. 给出python和C++版本的HUBO求解器的性能比较；3. 提交规范的技术报告，内容包括求解器详细的使用说明, 实现过程中用到的关键技术以及给出1, 2点列出的实验结果；4. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准5. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。"
  VTable  甘特图 zoom 交互,基础/Basic,"[[""web"",""React""],[""web"",""UI""],[""web"",""Vue.js""]]",为VTable 甘特图（https://www.visactor.io/vtable/guide/gantt/Getting_Started）添加zoom 交互。在已有事件系统之上进行扩展。,1. 鼠标滚轮进行zoom交互2. 触屏通过双指缩放进行zoom交互3. 交互过程中动态显示和隐藏相关数据
面向学生贡献度的定制化计算模块设计与实现,基础,"[[""web"",""Spring Boot""],[""web"",""Vue.js""],[""web"",""Webpack""],[""web"",""Web Application""],[""web"",""Babel""]]",目前在高校课程或开源实践教学中，学生通常以团队协作的方式参与项目任务，但现有的学生评价体系大多基于结果导向，难以准确评估每位学生在协作过程中的实际贡献。例如，仅依赖提交次数或最终产出会导致评分结果失真，难以体现过程性、综合性贡献，也影响学生的积极性与公平性。本项目旨在设计并实现一套面向学生贡献度的定制化计算模块，通过对多维度协作行为（如代码提交量、Issue参与、PR评论、文档撰写等）的数据采集与加权建模，实现对学生个人贡献的量化评估。该模块支持教师灵活配置评价维度及权重参数，适应不同课程的教学目标与项目需求。系统将以可插拔的形式提供 REST API 接口，方便集成至现有教学平台，并提供教师与学生可视化查看的评分反馈机制，提升教学公平性与激励效果。本项目的目标是开发一个独立、可配置、透明化的学生贡献度计算系统原型，并在典型教学场景中验证其实用性和准确性。,"1. 为该平台开发学生贡献度计算模块  
2. 实现可配置的评价维度与权重设置  
3. 为模块设计贡献度计算核心逻辑  
4. 基于行为数据自动生成评分结果  
5. 提供评分结果可视化展示界面  
6. 编写模块使用说明文档与开发文档"
KubeEdge设备管理实践案例优化,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""safe"",""MQTT""]]",目前KubeEdge在边缘IoT设备管理领域提出了基于物模型的设备管理API，并构建了mapper开发框架mapper-framework，实现IoT设备的云原生化管理。随着KubeEdge Device IoT能力日趋成熟，需要构建针对最新版本的最佳实践案例，并对旧版本的案例进行迭代优化，为用户使用提供参考,1. 基于最新版本的Mapper-Framework，开发一个Modbus协议的Mapper设备管理插件，并使用Modbus模拟软件模拟一个温度传感器。Mapper插件需实现对该传感器的管理，包括设备数据采集、状态上报等功能，同时通过Mapper提供的RESTful API实现对设备的写入和控制。最终，所实现的代码需合并至KubeEdge Example仓库，并附带完整的使用说明文档，确保用户能够便捷地理解和应用该案例。2.  针对KubeEdge Example仓库中原有的Device-IoT领域案例，至少选择其中一种进行迭代优化，案例包括kubeedge-counter-demo、web-demo等。优化的重点为提升兼容性、性能和易用性，确保用户能够在最新版本的KubeEdge中无缝使用这些案例。优化后的案例需合并至KubeEdge Example仓库，并附带完整的使用说明文档
openKylin虚拟键盘语音输入支持,进阶/Advanced,"[[""os"",""Linux""],[""os"",""x86""],[""web"",""Qt""]]",（1）相关背景为解决Linux系统上好用虚拟键盘输入法缺少问题，openKylin社区InputMethod SIG和fcitx社区进行密切合作，于2022年底首次实现了fcitx5对虚拟键盘的支持，解决了fcitx5输入法框架不能支持虚拟键盘输入的问题，使得基于fcitx5开发虚拟键盘输入法成为可能！在此基础上，openKylin社区InputMethod SIG成功开发了支持fcitx5虚拟键盘接口的openKylin虚拟键盘，使得openKylin成为首个基于fcitx5输入法框架提供虚拟键盘输入法的操作系统，实现从0到1的突破！为了不断优化openKylin虚拟键盘，使得其可以满足不同输入场景，需要让openKylin虚拟键盘支持语音输入功能。（2）已有的工作目前只支持键盘输入场景。（3）存在的不足不支持语音输入和手写输入。（4）希望改进的点增加语音输入功能。（5）最终项目实现的目标可以实现语音输入。,1. 完成对离线开源语音引擎的调研2. 完成对openKylin系统AI SDK的调研3. 完成语音引擎功能开发
为 HGraph 索引实现 INT8 类型支持,进阶,"[[""datas"",""AI""],[""datas"",""Vector Database""],[""os"",""Linux""],[""os"",""x86""],[""os"",""ARM""]]",在非结构化数据检索场景中，最常见的向量是 float32 类型。其实 float32 类型外，还有一些 embedding 模型输出的向量是 int8 类型。和 float32 的向量相比，int8 向量计算距离时所用的距离函数、指令集和支持的量化方法会有不同。HGraph 是 vsag 算法库新增加的图类型索引，目前只适配了 float32 类型的向量。希望你为 HGraph 增加 int8 类型的适配，使得 HGraph 能在 int8 类型的向量上构建索引和检索。,"1. 给 HGraph 索引增加 INT8 类型的处理逻辑；
2. 给 HGraph 索引增加 INT8 类型可选的量化方法；
3. 编写不同 CPU 平台 INT8 类型的距离计算函数（SSE, AVX, AVX2, AVX512）；
4. 增加 INT8 类型的测试用例；"
基于 Webhook 自动注入 P2P 分发扩展,进阶,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""]]",Dragonfly 是一个开源的、基于 P2P 的智能镜像和文件分发系统，旨在提高大规模文件分发效率和可靠性，尤其是在云原生场景下。当前，将 Dragonfly 的 P2P 能力（如使用 dfget 拉取文件或共享 P2P 代理的配置）集成到用户的 Kubernetes Pod 中，往往需要手动修改 Pod 的 YAML 定义来添加特定的 Volume、VolumeMounts 或调整容器命令，这个过程相对繁琐且容易出错，增加了用户的使用门槛。为解决此问题，本项目旨在通过在 Dragonfly 的官方 Helm Chart 中引入一个 Kubernetes Mutating Admission Webhook，来自动化 P2P 能力的注入过程。该 Webhook 将能够拦截带有特定注解（Annotation）或标签（Label）的 Pod 创建请求，并根据预设规则自动修改 Pod 定义，注入所需的配置（如挂载 Dragonfly Daemon 的 Volume、自动添加 dfget 代理命令等）。通过这种方式，用户将无需手动修改其应用 Pod 的 YAML 文件，从而显著简化在 Kubernetes 环境下配置和使用 Dragonfly P2P 客户端能力的过程，降低集成复杂度，提升用户体验。,"1. Webhook核心代码，实现 Mutating Admission Webhook以及健壮的错误处理和日志记录。
2. 用于构建 Webhook 服务容器镜像的 Dockerfile 等 CI 相关的构建过程支持。
3. Dragonfly Helm Chart更新，添加用于部署 Webhook（Deployment、Service、RBAC、MutatingWebhookConfiguration 等）的模板文件。
4. 针对 Webhook 核心注入逻辑的单元测试以及 E2E 测试。
5. 更新用户使用文档。"
基于高性能RISC-V处理器核“香山”的微架构UT验证——ITLB模块,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""dev"",""pytest""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。本项目基于开源高性能RISC-V处理器核“香山”的最新架构昆明湖，通过参与，您将深入了解到高性能处理器设计，有机会进入贡献排行榜、获得实习Offer、RISC-V中国峰会差旅补贴，为开源芯片的发展贡献力量。ITLB 模块为 instruction translation lookaside buffer 的缩写，是 MMU 模块的一部分。MMU 模块即 memory management unit，负责虚拟内存地址向物理内存地址的映射，这种映射将通过多级页表存放在内存中，TLB 则是处理器访问该页表的一个加速硬件，用于存储部分使用更为频繁的页表条目，以加速处理器的内存访问过程。在工作流程中，TLB 将负责接收需要存储的页表映射并将其暂存，再次访问时就会命中 TLB 并快速返回结果。ITLB 特指专用于处理指令页的 TLB。本项目需要验证完整的ITLB模块。我们将通过测试完整度（覆盖率等）进行分级，在验证过程中，您将需要按自选的功能点自行划分测试点进行测试，功能点详细描述请参考。,1.向 UnityChip 仓库提交 PR 并同时提交如下成果：
为 RobustMQ 实现可观测体系,基础/Basic,"[[""cloudnative"",""Kafka""],[""safe"",""MQTT""],[""web"",""Web Application""]]",本项目需要为 RobustMQ 搭建可观测体系。可观测体系包含三部分工作：RobustMQ Dashboard： 指 RobustMQ 的Web 管理平台的建设。这部分工作包括页面的开发（技术栈是 JavaScript），RobustMQ 内核的开发（Rust）。RobustMQ CLI： 指 RobustMQ 的 CLI 工具的建设。这部分主要包括命令行和内核的功能接口开发（Rust）RobustMQ Metrics： 指为 RobustMQ 内核添加可观测指标。基于 opentelemetry 规范添加指标，制作 Grafana模板等。这个项目会让你学到：1. 前端页面的开发。基于 JavaScript 技术栈。2. RobustMQ 内核的开发。基于 Rust 的技术栈。3. 开源项目的可观测体系的搭建。会涉及opentelemetry、Prometheus、Grafana等技术。,1.1 完成RobustMQ MQTT Dashboard 的第一版的开发2. 完成 RobustMQ MQTT Command 主体功能的建设3. 完成 RobustMQ MQTT 所有指标的注册和采集展示
使用 hb 框架建构 openEuler 嵌入式系统,进阶,"[[""os"",""Linux""]]",当前 openEuler 嵌入式系统沿用 Yocto 项目。hb 是 OpenHarmony 项目的构建工具。实际的状态是增强原先的生态为主，而与服务器版本的生态形成了割裂，存在组件代码不同源等问题。OpenHarmony 作为万物互联的操作系统，项目中存在许多单板硬件的资源。这样有利于复用社区之间的共性工作，也有利于欧拉与鸿蒙的能力融合。希望能够实作以 hb 工具构建 openEuler 嵌入式系统，来解决遇到的上述问题。,1. 学习和理解 hb 构建系统的组成和运作原理2. 针对 openEuler 嵌入式系统的场景分析问题和提出解决方案3. 用改进的结果建构一个可以运行的最小嵌入式系统4. 产出对应的说明文档和演示灯片
OpenHarmony 浏览器AI能力增强,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""datas"",""AI""]]",本项目基于Openharmony社区版本浏览器，利用人工智能技术增强浏览器的使用体验，包括以下主要功能：智能搜索、内容推荐、实时翻译、智能分类和标签等。借助智能搜索，系统可精准理解用户语义需求，快速呈现最贴合的搜索结果；内容推荐功能依托 AI 算法，依据用户浏览习惯和兴趣偏好，推送个性化的优质内容。​实时翻译功能打破语言壁垒，支持多语种即时互译，方便用户浏览全球资讯；智能分类和标签则能自动梳理网页内容，高效聚合同类信息，帮助用户快速定位所需资源，大幅提升信息检索效率与浏览便捷性，为用户带来更智能、流畅、高效的浏览器使用体验 。,1. 提供代码、可执行文件、技术文档。2. 智能搜索功能实现要求3. 内容推荐功能实现要求4. 实时翻译功能实现要求5. 智能分类和标签实现要求6. 进阶要求
openGauss向量数据库对接知识工程最佳实践,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",完成WhyHow 与openGauss向量数据库适配，达成简单知识文档导入、对接大模型完成RAG端到端验证，输出openGauss适配脚本及RAG最佳实践文档。,1.  基于openGauss 容器部署指导文档、Whyhow部署指导文档，基于docker完成服务部署。编写应用代码，完成WhyHow对接openGauss功能适配。2. 根据WhyHow适配流程，对接配置嵌入模型、LLMs，完成基于openGauss的RAG端到端验证，并输出对接文档，对接文档需合入openGauss社区。
适用于Kendryte芯片的组件化系统驱动解决方案,进阶,"[[""os"",""RISC-V""]]","Kendryte-hal 是 RustSBI HAL 组开发的针对嘉楠科技 Kendryte 系列 RISC-V 芯片的硬件抽象层项目。该项目旨在为 K230 等 Kendryte 系列 AI 视觉处理芯片提供 Rust 语言的底层驱动支持。作为 RustSBI 生态的重要组成部分，本项目致力于建立安全、高效的 RISC-V 芯片 Rust 开发环境。目前项目需要完善以下功能：1. 实现i2c, spi, pwm等中任意一到两个外设驱动支持(1) 编写外设控制器寄存器的访问代码(2) 完成外设的 embedded-hal trait 实现(3) 编写示例代码，展示如何使用外设接口与常见设备通信2. 完善芯片运行时支持(1) 实现中断初始化与处理框架(2) 实现interrupt和exception宏(2) 支持多核心运行3. 设计辅助 Kendryte 裸机固件开发的工具(1) 支持 ELF 到二进制格式的转换(2) 实现 ELF 直接生成可烧录镜像的功能","1. 实现i2c, spi, pwm等中任意一到两个外设驱动支持2. 完善芯片ROM运行时支持3. 设计辅助 Kendryte 裸机固件开发的工具"
SUSE操作系统集成openGauss 6.0.0 LTS,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",将openGauss 6.0.0 LTS版本集成到openSUSE源中，支持zypper install opengauss,1. 输出 openGauss 构建 SUSE 打包 RPM 脚本；2. 将构建脚本上传至 openGauss 社区
Nacos 客户端可观测性补强,基础/Basic,"[[""cloudnative"",""Cloud Native""]]",## 背景在开源之下2023期间，Nacos通过课题为Nacos客户端添加了一些基础指标，并将这些基础指标对接了的观测性标准，同时探索了服务和配置的注册、订阅的追踪能力。但仅是一些基础状态指标已经不能满足在实际生产环境中快速定位应用使用Nacos客户端时的状态和阶段，从而让问题的排查进入误区，消耗了大量的时间和精力。因此Nacos社区希望在“开源之夏2025”期间，对Nacos客户端的可观测性内容进行补强，帮助Nacos的运维人员和应用开发人员，快速获取Nacos客户端的运行状态，这其中包括服务及配置的订阅状态、服务的注册状态、进程中Nacos 客户端实例数，连接数、收到推送的次数，成功率及最后更新时间等内容。## 目标基于开源之下2023课题的基础，为Nacos客户端的可观测性内容进行补强，添加包括但不限于如下Metrics指标，并实现对应指标的轻量上报能力：,1. 梳理并设计Nacos客户端需要补强的指标内容，并设计能够将这些指标轻量化上报至服务端的机制；2. 按照设计，是想Nacos客户端的可观测性指标补强；3. 按照设计，实现Nacos客户端及服务端中可观测性指标上报至服务端的逻辑。4. 按照Nacos 的ADMIN API标准，为Nacos服务端添加相应的获取客户端可观测指标的接口，用于获取客户端可观测指标。5. 添加如何为Nacos客户端新增其他可观测指标的相关文档，及新增AdminAPI的相关文档，方便后续扩展及使用。
为 openHiTLS 适配 RISC-V 架构，添加在 RISC-V 架构 CPU 上的算法性能优化,进阶,"[[""os"",""Linux""]]",（1）相关背景openHiTLS的目标是提供高效、敏捷的全场景开源密码学开发套件。（2）已有的工作当前，openHiTLS 支持ARM、x86架构CPU上的算法性能优化。（3）存在的不足openHiTLS 虽然有对各算法提供通用的 C 语言实现，但对 RISC-V 架构 CPU 支持情况未知。且不支持 RISC-V 架构 CPU 上的算法性能优化。（4）希望改进的点在编译配置中添加对 RISC-V 64 架构的支持，添加支持 RISC-V 架构 CPU 上的算法性能优化，并将 openssl 中已经对 RISC-V 架构 CPU Zbb 进行了性能优化的 SHA256/SHA512 两个算法移植过来。（5）最终项目实现的目标在 openEuler RISC-V 架构上支持 openHiTLS 软件包，且可以根据 RISC-V 架构 CPU 的指令集特性选择合适的性能优化版本算法。,1. 在编译配置中添加对 RISC-V 64 架构的支持，添加支持 RISC-V 架构 CPU 上的算法性能优化，并将 openssl 中已经对 RISC-V 架构 CPU Zbb 进行了性能优化的 SHA256/SHA512 两个算法移植过来，使得运行时可以根据当前 CPU 支持的指令拓展判断要调用的算法。
基于 AI 的数据库模拟数据生成工具,基础,"[[""datas"",""AI""],[""datas"",""LLM""],[""os"",""Linux""]]",在数据库测试和开发场景中，模拟数据生成是重要的工具，用于帮助开发人员验证代码逻辑和功能。已有的工具（ODC 的模拟数据功能 等）能够根据列的数据类型（如字符串、整数、日期等）生成随机模拟数据，但这些数据往往性，无法贴近实际业务场景。例如生成的随机字符串或无法体现字段语义属性，例如列应表示真实姓名，而列应生成真实地址。此项目旨在通过结合对字段语义进行自动理解和推断，实现数据生成的、：最终目标是通过 AI 赋能，使工具能够生成契合业务场景的模拟数据，帮助开发者快速验证代码功能，提升项目效率。,"1. AI 语义推断模块：
  ○ 使用预训练模型（如BERT、GPT或其他文本处理模型），自动分析数据库表列名的语义，生成适配的语义规则。例如：
    ■ name → 常见姓名（如“张三”、“John Smith”）
    ■ address → 生成格式化地址（如“中国北京市海淀区中关村”）
    ■ email → 生成邮箱地址（如example@example.com）
    ■ date_of_birth → 生成合理范围内的日期值（如1980-01-01）。
  ○ 提供模型的训练及推断过程，与工具深度集成。
  ○ 若非通用字段（如自定义列名custom_code），支持生成不特定语义的随机数据作为备选方案。2. 智能数据生成模块：
  ○ 构建数据生成框架，结合 AI 的推断结果，生成贴合实际场景的模拟数据，支持：
    ■ 范围控制：如日期范围限定（2020至2023年）、年龄范围（18至75岁）。
    ■ 格式控制：支持正则表达式限定字段值，例如phone_number字段匹配中国手机号规则。
    ■ 数据分布：支持常见分布定义（如正态分布、均匀分布）。3. 用户规则配置模块：
  ○ 支持用户通过 JSON 或 YAML 配置文件覆盖AI默认语义推断的逻辑，例如：
    ■ 指定某列的具体生成规则（如年龄字段指定生成19至25的区间值）。
    ■ 排除某些字段的生成（例如用户定义不生成temporary_field列的数据）。
  ○ 设计一个友好、易读的配置解析工具模块。4. 工具整合与兼容性：
  ○ 将扩展的 AI 模块和数据生成模块集成到现有的 ODC 模拟数据模块中，用户可选择启用语义生成或随机生成模式。
  ○ 保证下兼容已有功能，同时升级工具的智能化能力。5. 项目文档与测试用例：
  ○ 提供详细的项目文档（包括功能介绍、模块设计、使用说明等）。
  ○ 提供 AI 推断结果与数据生成结果的多种测试样例，展示工具能力与适配性。"
Improving Embox RTOS as a RTOS for IoT,Advanced,"[[""dev"",""Git""],[""os"",""RTOS""],[""os"",""QEMU""],[""os"",""Linux""],[""os"",""GNU""],[""os"",""GDB""],[""os"",""GCC""],[""os"",""Complier""],[""safe"",""Socket""],[""safe"",""TCP/IP""],[""codelang"",""Programming Language""]]","Embox is already has some support for IoT for example it supports some IoT protocols, such as MQTT, HTTP etc,We also developed some IoT examples on STM32 such as:***The goals of this project is to improve the Embox's opporunities  to desing a IoT divices and demonstrate some of themFor example you can add support for WiFi (or LTE) and demonstrate remote control of a robots or other IoT devices types. Also it is nice if you can add web-sockets (they are not support good in Embox now) and  use them to the remote control.",1. Add support for wireless interfaces (WiFI or LTE)2. Design a demo application for remote control of the system3. Port to some embedded platform and test the decision
评估 eBPF 在资源受限的嵌入式 RISC-V 平台上的可行性与性能开销,进阶,"[[""os"",""Clang""],[""os"",""Debian""],[""os"",""GNU""],[""os"",""Linux""],[""os"",""Perf""],[""os"",""RISC-V""],[""os"",""Ubuntu""],[""os"",""x86""]]",RISC-V 架构因其开放、模块化和可定制性，在嵌入式系统和物联网 (IoT) 领域正获得越来越广泛的应用。这些平台通常具有严格的资源限制，如有限的 RAM（几十至几百 KB）、较低的 CPU 主频（几十至几百 MHz）以及可能缺乏硬件 MMU。eBPF 技术以其在内核态安全、高效执行代码的能力，为这些嵌入式设备带来了新的可能性，例如实现低开销的监控、网络过滤、传感器数据预处理或简单的事件响应逻辑。然而，eBPF 及其运行时（解释器或 JIT 编译器）本身也需要消耗 CPU 和内存资源。在资源极其受限的 RISC-V 平台上部署 eBPF 面临着可行性和性能开销方面的挑战。本项目旨在。研究将选取代表性的 eBPF 应用场景，在模拟或真实的嵌入式 RISC-V 硬件上进行量化分析。,1. 一套在选定嵌入式 RISC-V 平台（或模拟器）上运行 eBPF 应用样例的完整环境搭建指南和测试脚本2. 针对所选 eBPF 应用样例和运行时模式（解释器/JIT），在目标平台上的详细性能和资源开销测量数据（内存占用、CPU 周期/时间等）3. 一份综合评估报告，分析 eBPF 在资源受限 RISC-V 环境下的可行性、性能瓶颈、适用场景以及解释器与 JIT 模式的优劣对比
CubeFS 数据子系统多副本引擎数据分区均衡（节点级别）,进阶/Advanced,"[[""cloudnative"",""Distributed Storage""],[""cloudnative"",""CubeFS""],[""cloudnative"",""Cloud Native""]]",项目背景：在 CubeFS 分布式存储系统中，DataNode 是存储副本数据的核心组件。随着集群规模的增长和数据量的增加，通常需要通过扩容来添加新的 DataNode 节点以应对不断增长的数据存储需求。然而，在当前架构下，数据不会自动在各个节点之间进行均衡分布。这导致了一个问题：一些已有节点的空间被写满而无法继续提供写入能力，而新扩容的节点则处于相对空闲状态。这种不平衡严重影响了集群的整体写入能力和数据修复效率。已有能力：目前，CubeFS 的 DataNode 支持手动迁移数据分片（DP）。这意味运营人员可以通过手动操作将特定的数据分片从一个节点迁移到另一个节点，以此来缓解局部过载的问题。存在的问题：尽管支持手动迁移，但这种方法存在显著的不足：- 人工干预：需要人为判断哪些数据分片应该被迁移以及它们应被迁移到哪个节点，这对运营人员来说是一项复杂且耗时的任务。- 效率低下：对于大规模的集群，手动迁移不仅效率低下，而且容易出错，难以保证数据分布的合理性和均衡性。- 缺乏动态响应：不能根据实时的负载情况、空间使用率等因素动态调整数据分布，限制了集群性能的最大化利用。改进目标：为了克服上述挑战并提升系统的自动化水平和灵活性，本项目旨在设计并实现一种基于 DataNode 级别的数据分区自动均衡方案。具体改进点包括：1) 自动均衡策略：- 设计一种智能算法，考虑 DataNode 节点的空间使用率、DP 数量以及负载情况，确保各节点之间的资源利用率趋于均衡。- 可以启用自动化的数据迁移过程，无需人工干预，提高操作效率和准确性。2) 相关的功能特性：- 审计功能：记录每次均衡操作的详细信息，便于后续分析和追踪。- 进度查询：提供接口或命令行工具，允许用户随时查看当前正在进行的均衡操作的状态。- 取消功能：为用户提供停止正在进行中的均衡任务的能力。- 异常监控与报告：当均衡过程中出现异常时，能够及时上报相关 metrics，帮助快速定位问题。3) 集成CLI工具：- 将所有与均衡相关的命令整合到现有的 CLI 工具中，简化用户的操作流程，提升用户体验。注意事项:- DP的多个副本在一个故障域（nodeset）内迁移，如果nodeset内空间不足，需要全部副本迁移到另外一个nodeset，避免破坏故障域。可参考mp的均衡- 多于多AZ的卷，副本分布在不同zone，也必然分布在不同的nodeset，所以可以不考虑nodeset内迁移。多AZ多个nodeset group可以暂不考虑支持。- 均衡过程会涉及数据迁移流程，请关注迁移过程对于迁移负载均衡的考虑，必要时可以优化当前的迁移相关逻辑，提高均衡的效率参考资料：多副本子系统: https://cubefs.io/zh/docs/master/design/datanode.html多副本分区DP迁移相关：https://cubefs.io/zh/docs/master/ops/auto-ops.html磁盘故障处理：https://cubefs.io/zh/docs/release-3.3.2/maintenance/troubleshoot/strategy.html#%E7%A3%81%E7%9B%98%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86NodeSet: https://cubefs.io/zh/docs/master/ops/zone.html#%E9%BB%98%E8%AE%A4%E5%88%86%E5%8C%BA,"1. 为分布式文件系统CubeFS提供多副本引擎数据的分区均衡能力
2. 提供完整的代码、测试用例、运营文档、测试文档"
RT-Thread 玄铁全系列RISC-V内核支持,基础,"[[""os"",""RISC-V""],[""os"",""RTOS""]]","将玄铁的E,R与C系列的RISC-V内核适配到RT-Thread的主线仓库中，使用RT-Thread主线的通用RISC-V libcpu移植文件。移植的内核主要有E系列的E906，C系列的C906与R系列的R908等，运行平台是玄铁QEMU包括xiaohui与smartl两个平台。",1. 代码实现：将具体的内核按RT-Thread的BSP规范做成BSP添加至主线，libcpu使用RT-Thread提供的common libcpu。2. 测试方法：在玄铁QEMU上运行，并运行通过rt-thread的内核测试用例。3. 文档说明：在bsp目录下提供完整的使用说明。
基于Triton语言的高性能AI算子开发与模型应用,进阶,"[[""os"",""Compiler""],[""datas"",""GPU""],[""datas"",""HPC""],[""datas"",""PyTorch""],[""datas"",""AI""]]",随着人工智能技术的快速发展，对算力和计算效率的需求日益增长，传统通用算子已难以满足高性能模型在推理与训练中的要求。Triton语言作为一种由OpenAI提出的新型并行编程语言，能够更高效地在GPU上开发自定义AI算子，提升模型运行效率和硬件利用率。本项目面向主流大模型的核心算子与关键计算模块，采用开源编程语言和编译技术进行开发与优化，并在实际应用中验证其性能优势，为AI模型部署提供更强的性能支撑与技术保障。FlagGems 是一个用 OpenAI Triton语言实现的高性能通用算子库。它旨在提供一套内核函数，以加速大语言模型（LLM）的训练和推理。通过在 ATen 后端进行注册，FlagGems 允许用户无需修改模型代码即可切换到 Triton 函数库，并体验显著的性能提升。项目地址：https://github.com/FlagOpen/FlagGems,"1. 为FlagGems开源项目开发和优化10个指定大模型算子，性能达到基线的85%以上
2. 在指定国产AI芯片上基于FlagGems部署大模型，性能达到基线的75%以上
3. 形成大模型采用FlagGems的应用方案说明"
VMind 图生图表,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""]]",基于LLM 的多模态能力，开发 图生图表能力，转化图像为VChart/VTable 源码。,1. 定义图像识别图表和表格的标准DSL2.  接入大模型，产生标准的DSL3. 转化DSL 到VChart /VTable  源码4.  产出完整设计、教程文档
为 KWOK 添加 模拟真实 Pod 行为的策略配置,进阶,"[[""cloudnative"",""Kubernetes""]]",", 当前还缺少模拟真实行为的策略配置最终我们的目的是将按照真实的 Pod 可能发生的行为, 为其写独立可插拔的策略配置供用户选择开发流程- 触发并记录 Kubernetes 各种 正常/异常 行为- 总结其根本变化并为其编写模拟文件- 如果在开发中发现缺少某些功能, 经过讨论有需求的话也要考虑添加支持在这个目录下https://github.com/kubernetes-sigs/kwok/tree/main/kustomize/stage/pod/general","1. 模拟真实 pod 行为的模拟配置 ( 约 13-16 个 yaml 文件, 每个文件约 20 - 120 行 )"
为 openEuler 文档开发生产 开发智能化写作助手,进阶,"[[""datas"",""AI""]]",当前，openEuler 文档开发生产中，缺乏一款基于 VS Code 的智能化插件，无法为开发人员提供全流程的文档创作支持。该插件旨在通过 AI 技术赋能文档开发，解决技术文档编写过程中存在的效率低、格式规范难统一、术语准确性不足等问题，最终构建一个集智能编辑、实时纠错、自动化润色、多模态内容生成于一体的文档生产工具链，助力 openEuler 社区打造高质量、标准化的技术文档体系。智能编辑辅助：集成自然语言处理模型，实现语法纠错、术语标准化建议、技术文档模板自动生成等功能；跨语言协作优化：针对中英双语技术文档提供实时翻译与本地化润色，确保术语一致性；,1. 设计并实现vscode写作助手2. 设计并实现完整的测试方案3. 提供规范的用户手册和开发者文档
基于MindSpore框架下GaussionLSS的迁移与优化,进阶,"[[""datas"",""AI""]]",纯视觉BEV分割技术作为自动驾驶和智能机器人领域的核心感知算法，其性能优劣直接影响环境建模与决策规划的精准度。MindSpore正在积极构建纯视觉BEV分割模型，帮助科研用户快速复现各种BEV分割模型,1. 完成GaussionLSS模型的复现、模块适配（深度不确定性建模、3D不确定性转换等）2. 使用自动驾驶数据集nuScenes，完成模型训练和评估3. 针对 NPU 硬件特性优化模型推理速度4. 开发出相应的应用案例
openKylin文件管理器办公文件预览支持,进阶/Advanced,"[[""os"",""Linux""],[""os"",""x86""],[""web"",""Qt""]]",在数字化办公时代，文档处理已成为个人和企业日常工作的核心需求。WPS Office、Microsoft Office 等办公软件生成的文档（如 .docx、.xlsx、.pptx）因其格式复杂、功能丰富，成为全球最广泛使用的文件类型之一。然而，用户在管理海量文档时，往往需要在文件管理器中快速定位目标文件，而传统的文件管理器仅能通过文件名、图标或简单元数据（如文件大小、修改时间）辅助用户识别内容，缺乏对文档内容的直接预览能力。这种局限性导致用户不得不反复打开办公软件查看文件内容，显著降低了工作效率，尤其在大规模文件整理、跨部门协作或快速检索场景中，这一问题更加突出。为了优化openKylin文件查阅体验，满足用户快速直接了解文件内容的需求，需要在文件管理器中新增wps、office文件预览的功能，包括word、excel、ppt等文件格式。目前只支持文件信息的预览，只显示文档的图标仅能查看文件的一些信息，包括类型、大小与一些时间信息，无法直接了解文件里面的内容，影响用户查找文件需要选中文件的时候，不需要打开文件，可以直接在文件管理器的预览界面查看文件内容，让用户可以更详细的了解文件的信息，从而方便文件的查找。1)选中文件后，不仅可以在预览界面预览文件的内容，而且还可以上下使用滚动条翻页并滚动放大缩小，从而让用户可以更灵活的预览文件内容。2)可以接入AI解析文件，从而生成文件摘要或提取文件关键信息，方便用户不用打开文件就可以知道文件的大致内容或拿去到关键信息。,1. 完成对word文件的预览功能2. 完成对excel文件的预览功能3. 完成对ppt文件的预览功能4. 完成对pdf文件的预览功能5. 可在文件预览窗口处生成文件摘要信息与提取文件关键信息
使用形式化的方法对openHiTLS中chacha20算法实现进行功能正确性验证,基础,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""SSL/TLS""]]",背景：目标：,1. 完成openHiTLS中chacha20算法的功能正确性验证
为 NebulaGraph Exchange 支持数据源插件化,基础/Basic,"[[""datas"",""Database""],[""datas"",""Graph Database""],[""datas"",""Spark""]]",NebulaGraph Exchange 是一款专业的数据导入工具，致力于将各类异构数据源的高效导入到 NebulaGraph 图数据库中。当前版本已支持包括关系型数据库、NoSQL、大数据平台等在内的十余种主流数据源。但 NebulaGraph Exchange 的数据源都是内嵌在 NebulaGraph Exchange 的核心代码中，每添加一种新数据源都需要进行代码扩展和代码修改，然后进行重新打包发版，存在数据源与核心代码高度内聚的问题，使得添加新数据源和维护已有数据源的成本增加。基于以上背景，该项目旨在实现 NebulaGraph Exchange 数据源的插件化架构，通过标准接口和扩展机制，使 NebulaGraph Exchange 能够在无需修改核心代码的情况下，通过引入插件 JAR 包的方式灵活支持新的数据源。,1.对当前 NebulaGraph Exchange 架构进行优化改进，将数据源相关的功能流程抽象化，实现数据导入和数据源管理的低耦合结构。2. 实现不同数据源的插件化模块化开发，利用反射实现 NebulaGraph Exchange 对不同数据源插件 jar 包的动态加载和调用，从而实现各个数据源的独立化维护，增强 NebulaGraph Exchange 的数据源支持的能力，实现 NebulaGraph Exchange 数据源的插件化开发和维护，为用户自定义特殊的数据源提供抽象能力。
基于高性能RISC-V处理器核“香山”的微架构UT验证——ICache顶层和控制处理,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""dev"",""pytest""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。本项目基于开源高性能RISC-V处理器核“香山”的最新架构昆明湖，通过参与，您将深入了解到高性能处理器设计，有机会进入贡献排行榜、获得实习Offer、RISC-V中国峰会差旅补贴，为开源芯片的发展贡献力量。ICache（Instruction Cache）即指令缓存，负责接收 FTQ 的取指和预取请求并从向 ITLB 获取物理地址和通过 Tilelink 获取指令数据，最终将指令数据或者异常数据发送给 IFU。本项目涉及了Icache顶层、元数据SRAM、数据SRAM、替换策略单元和控制单元。,1. 验证环境+API：验证环境和API是代码成果，是针对待验证对象（DUT）的数据职责（引脚）和行为职责（逻辑）的封装，需要提供特定的可复用的接口、 测试套件、测试覆盖率等的定义。2. 测试用例：测试用例是代码成果，定义了用于测试的输入组合，以及预期的输出组合。3. 验证报告：验证报告是文字成果，包括对环境、测试点和测试用例的介绍，复现代码所需的环境和指令，以及对测试覆盖率等衡量指标的报告。
为Fury GO实现编译时代码生成功能,进阶/Advanced,"[[""codelang"",""Programming Language""]]",当前Fury Go使用反射来实现结构体的序列化和反序列化功能，反射在性能上存在不足。在Java等语言，Fury会通过运行时动态生成代码来加速执行性能。但是Golang里面运行时生成代码，需要生成汇编代码，开发维护复杂性过高，而业界也主要以编译时提前生成代码为主，通过go generate 在编译时生成代码，比如ffjson 等json库。本项目需要为Fury的二进制序列化协议实现类似的代码生成能力，通过在编译时提前解析结构体，面向Fury跨语言二进制协议，生成对应的序列化和反序列化代码，来加速整个序列化的执行效率,1. 为Struct/List/Map实现元数据解析器2. 为Struct/List/Map实现代码生成器3. 扩展序列化器Dispatcher，支持分发到生成的序列化器
为openEuler使能VTK并基于VTK实现医学图像三维重建demo程序,进阶/Advanced,"[[""os"",""x86""]]",随着科学计算、医学成像和工程仿真领域的快速发展，高效的可视化工具成为数据处理和结果展示的核心需求。VTK（Visualization Toolkit）作为一款开源的跨平台三维可视化库，因其强大的数据处理能力和灵活的渲染功能被广泛应用于学术界和工业界。然而，在openEuler操作系统中，VTK尚未被原生支持，用户需自行编译安装，存在依赖管理复杂、版本兼容性差等问题。本项目的目标是为openEuler操作系统提供VTK的官方支持，将其集成到系统软件仓库中，并基于VTK实现医学图像三维重建demo程序。通过优化VTK在openEuler上的编译配置和性能调优，解决依赖管理问题，同时设计医学图像三维重建demo程序，展示VTK在科学计算和工程领域的核心能力，为开发者提供开箱即用的可视化解决方案。,1. 完成VTK在openEuler上的适配：提供适配openEuler的VTK软件包（RPM），支持主流硬件架构（x86_64、aarch64）。2. 开发基于VTK的demo程序：实现医学图像三维重建功能。3. 提交完整代码及文档：包括基于社区提交VTK仓库、demo源码、测试报告等。
基于Dubbo-go-Pixiu构建AI网关及AI治理能力集成,进阶/Advanced,"[[""datas"",""LLM""],[""safe"",""HTTP""],[""cloudnative"",""Cloud Native""]]",随着人工智能技术的飞速发展，越来越多的应用开始集成大型语言模型（LLM）等 AI 服务。传统的 API 网关主要面向微服务（如 HTTP/Dubbo/gRPC）设计，难以满足 AI 服务特有的需求，例如对流式协议（SSE/WebSocket）的深度支持、基于 Token 的流量管理、AI 特有的可观测性指标以及与 AI 控制平面的集成。本项目旨在增强 Apache Dubbo-go-Pixiu 网关的能力，使其成为一个功能强大的 AI 网关。项目将基于 Dubbo-go-Pixiu 现有的框架，完成以下关键改进：目前，Dubbo-go-Pixiu 已有初步的 AI 协议（HTTP/SSE）支持和 Token 计算的基础工作。本项目将在此基础上，进一步完善这些核心能力，实现一个面向未来、支持混合治理的 AI 网关。,1. 实现对 OpenAI 兼容协议（/v1/chat/completions 等）的完整支持，包括 SSE/HTTP/2 的流式数据处理2. 实现可用的基于 Token 的动态限流过滤器3. 实现 Token 用量统计功能，并集成到 Prometheus 指标中4. 实现可用的模型回退策略5. 为新增功能编写相应的单元测试、集成测试和文档
Apache ShardingSphere: 增强 Hive SQL 解析引擎，适配更多 DDL、DML 语句,进阶,"[[""datas"",""Hive""]]",Apache ShardingSphereApache ShardingSphere 是一款分布式的数据库生态系统， 可以将任意数据库转换为分布式数据库，并通过数据分片、弹性伸缩、加密等能力对原有数据库进行增强。Apache ShardingSphere 设计哲学为 Database Plus，旨在构建异构数据库上层的标准和生态。 它关注如何充分合理地利用数据库的计算和存储能力，而并非实现一个全新的数据库。 它站在数据库的上层视角，关注它们之间的协作多于数据库自身。Page: https://shardingsphere.apache.orgGithub: https://github.com/apache/shardingsphere背景：Apache ShardingSphere 目前已经对 Hive 进行了初步适配，支持通过 Hive JDBC 连接底层存储，实现数据加密、数据脱敏等增强功能。为了提升对 Hive SQL 语句的支持度，需要增强 Apache ShardingSphere 内部的 Hive SQL 解析引擎，适配更多的 DDL、DML 语句，并且增加 Hive 自动化测试程序，保证数据加密和数据脱敏功能可用。任务：参考 Hive SQL 参考文档：https://hive.apache.org/docs/latest/languagemanual_27362030/，适配常用的 DDL、DML 语句，具体任务列表如下：想要完成这些 SQL 解析任务，你需要先参考 ShardingSphere 社区的入门文章：https://mp.weixin.qq.com/s/p1ESy2YKEfyX3Rc6o2eFhw，了解基本的 Antlr 知识及调试技巧，然后对照 Hive SQL 参考文档，调整 G4 文件及 visit 逻辑，最后需要增加 SQL 解析测试用例。更多细节可以参考下面的 PR：https://github.com/apache/shardingsphere/pull/34654,1. SQL 解析引擎支持任务列表中要求的 SQL 类型，并增加 SQL 解析 IT 测试；2. 支持 Hive 数据脱敏功能，并增加 Hive 数据脱敏 E2E 测试；3. 支持 Hive 数据加密功能，并增加 Hive 数据加密 E2E 测试；
基于三维引擎的BMC硬件展示,基础,"[[""web"",""Vue.js""]]","BMC前端页面用来管理BMC，给操作人员提供一个可视化的操作界面。其中服务器信息、固件信息和机箱信息等系统信息仅通过文字展示，并不能够直观的让操作人员获取信息。在原项目的基础上，开发一个新的页面，用尽可能轻量的3d技术模拟展示机箱内部的元器件所有信息，精确到具体空间长度，可多角度切换观察。具体数据由后端提供，前端获取数据后使用3d技术展示。开发阶段可先使用静态模拟数据，数据内容可参考如下（可自行修改内容和格式）：{""机箱信息"": {""基本信息"": {""长"": ""120cm"",""宽"": ""70cm"",""高"": ""20cm""},""内置元器件"": {""风扇1"": {""位置"": [20, 10, 0],""基本信息"": {""长"": ""10cm"",""宽"": ""10cm"",""高"": ""10cm""}},""风扇2"": {""位置"": [40, 10, 0],""基本信息"": {""长"": ""10cm"",""宽"": ""10cm"",""高"": ""10cm""}},""BMC卡"": {""位置"": [0, 30, 0],""基本信息"": {""长"": ""10cm"",""宽"": ""10cm"",""高"": ""1cm"",""存储容量"": ""64GB""}},""内存条1"": {""位置"": [30, 10, 0],""基本信息"": {""长"":""0.2cm"",""宽"":""5cm"",""高"":""0.1cm"",""内存大小"":""1GB""}},""内存条2"": {""位置"": [30, 11, 0],""基本信息"": {""长"":""0.2cm"",""宽"":""5cm"",""高"":""0.1cm"",""内存大小"":""1GB""}},""内存条3"": {""位置"": [30, 12, 0],""基本信息"": {""长"":""0.2cm"",""宽"":""5cm"",""高"":""0.1cm"",""内存大小"":""1GB""}},""内存条4"": {""位置"": [30, 13, 0],""基本信息"": {""长"":""0.2cm"",""宽"":""5cm"",""高"":""0.1cm"",""内存大小"":""1GB""}},""电源"": {""位置"": [60, 10, 0],""基本信息"": {""长"":""10cm"",""宽"":""20cm"",""高"":""3cm""}}}}}",1. 新页面可以以3d的形式直观的展示机箱内各个元器件及其对应属性，并且要有明显的科技感。
基于MindSpore代码助手系统开发,基础,"[[""datas"",""AI""]]",MindSpore作为华为推出的深度学习框架，提供了高效的计算性能和灵活的模型开发环境。然而，许多新用户在使用MindSpore时常常面临入门门槛较高、安装配置复杂、调试困难等问题，影响了他们的学习和使用体验。MindSpore助手旨在降低新用户的学习难度，帮助他们快速上手并有效利用MindSpore框架，从而促进MindSpore的生态发展。智能问答系统作为MindSpore代码助手的核心模块，旨在通过结合知识库和RAG（检索增强生成）技术，为用户提供基于自然语言的问题解答、代码调试和优化建议。系统需支持多轮对话、上下文保持和多种问题类型的高效回答，提升用户的学习和开发体验。,"1. 收集MindSpore的官方文档、API参考资料、教程等，建立多层次的知识库。
2. 基于MindSpore NLP套件，实现检索增强（RAG），基于用户的问题内容从知识库调取相关信息并与语言模型生成的内容整合，提供全面、准确的答案。
3. 实现多轮对话管理模块，能够识别并保持用户对话的上下文，以提供连贯、逻辑清晰的回答。"
面向对象的格点lattice生成,基础/Basic,"[[""datas"",""NumPy""]]","本项目提出在库中实现一个统一且可扩展的 API，用于表示不同的格点几何结构。它引入了一个AbstractLattice基类，以及用于周期性结构 (TILattice) 和通用结构 (CustomizeLattice) 的派生类。该 API 提供了访问基本格点属性（如格点坐标、抽象标识符）的接口，以及查找最近邻和更远邻居的方法 (get_nearest_neighbors,get_neighbor_pairs)。关键的是，它还包含一个.show()方法，用于方便地可视化格点结构和连接性。定义和使用格点几何结构是模拟许多物理系统的基础。当前，用户通常依赖于：nx.graph本项目旨在提供一个结构化、可复用、几何信息明确且易于可视化的格点定义框架，为后续开发里德堡模拟哈密顿量模拟做好准备。AbstractLatticeTILatticeSquareLatticeHoneycombLatticeCustomizeLatticeget_neighbor_pairs(k)show()提供了一种标准化的方式，使用坐标和标识符明确地定义格点几何。AbstractLatticeCustomizeLattice当前，TensorCircuit 的templates.graphs模块中存在一些格点类。我们将编写一个全新的模块（可能命名为templates.lattice），并将旧的graphs子模块标记为弃用。","1. 实现以下 API，并支持导师给出的各种格点几何的实现： # 创建一个 3x3 的方形格点，具有周期性边界条件，晶格常数为 1.0
sq_lattice = SquareLattice(size=(3, 3), pbc=True, lattice_constant=1.0)

# 访问格点属性
print(f""格点数: {sq_lattice.num_sites}"")
print(f""维度: {sq_lattice.dimensionality}"")

# 获取索引为 4 的格点信息（中心格点）
idx, ident, coords = sq_lattice.get_site_info(4)
print(f""格点 {idx}: ID={ident}, 坐标={coords}"")

# 获取格点 4 的最近邻 (NN)
nn_indices = sq_lattice.get_neighbors(4, k=1)
print(f""格点 {idx} 的最近邻: {nn_indices}"")

# 获取所有唯一的最近邻配对
nn_pairs = sq_lattice.get_neighbor_pairs(k=1, unique=True)

# 定义 Kagome 晶格片段的坐标
kag_coords = [ [0,0], [1,0], [0.5, np.sqrt(3)/2], # 三角形 1
               [2,0], [1.5, np.sqrt(3)/2],       # 三角形 2 (基底平移)
               [1, np.sqrt(3)] ]                 # 顶部格点
kag_ids = list(range(len(kag_coords))) # 简单的整数标识符
# 使用自定义格点类创建 Kagome 片段
kag_lattice = CustomizeLattice(dimensionality=2, identifiers=kag_ids, coordinates=kag_coords)
kag_lattice._build_neighbors(max_k=1)  # 基于距离计算最近邻
print(f""\nKagome 片段格点 2 的最近邻: {kag_lattice.get_neighbors(2, k=1)}"")"
面向PikaPython的AI驱动Python-C编译加速器与自动化验证平台设计,进阶/Advanced,"[[""datas"",""AI""],[""codelang"",""Programming Language""],[""dev"",""CD""],[""dev"",""CI""],[""os"",""Compiler""],[""os"",""FreeRTOS""],[""os"",""GCC""],[""os"",""RTOS""]]","PikaPython 是一个专为嵌入式设备设计的超轻量级 Python 解释器，以其 4KB 的内存占用和零依赖特性成为资源受限场景的首选方案。然而，Python 的动态类型机制和解释执行特性导致其在计算密集型任务中性能显著低于 C 语言（通常存在 10~100 倍的性能差距）。尽管 Cython、Shed Skin 等工具可将 Python 转换为 C/C++，但它们仅针对 CPython 优化，无法适配 PikaPython 的语法特性和内存模型，且缺乏针对嵌入式场景的自动化编译流程。因此，亟需一种AI 驱动的 Python 到 C 语言编译加速方案，通过智能转换关键函数为 C 扩展模块，显著提升 PikaPython 的性能。然而基于AI的跨语言编译方案的生成结果可能存在语法错误、逻辑缺陷、性能反优化等各种不稳定问题，亟需构建完整的测试验证基础设施，因此需要与AI编译方案同步构建 PikaPython Playground 验证基础设施，Playground 作为一个 AI agent 可以调用的工具函数和系统服务， 提供固件编译、模拟运行、错误代码收集、批量测试的全套闭环验证功能。降低嵌入式开发门槛：开发者无需手动编写 C 代码，即可利用 PikaPython 的灵活性和 C 语言的性能优势。提升资源受限设备的算力：通过 AI 编译加速和 Playground 基础设施，使嵌入式设备能够高效执行复杂算法（如 AI 推理、实时图像处理）。推动 Python 在边缘计算中的应用：为 PikaPython 生态提供可持续的性能优化方案，拓展其在 IoT 和工业控制领域的落地场景。PikaPython 的特性：支持嵌入式设备的超轻量 Python 运行环境，但受限于 Python 解释器的性能瓶颈。AI 编译 agent 在 cpython 上进行的预研，支持python->C的转换和自动化验证。1. 手动优化成本高：现有工具需开发者手动标注类型或重写关键函数，无法适应快速迭代的嵌入式开发需求。2. AI 编译结果不可靠：AI 生成的代码可能存在语法错误、逻辑缺陷或性能反优化，需依赖自动化测试与验证流程保障质量。3. 测试与验证流程缺失：无自动化工具链支持 Python-C 代码的性能对比、错误日志收集及加速比分析。4. 开发环境分散：缺乏统一的 Playground 基础设施支持 AI agent 的代码生成、编译、测试全流程闭环。1. AI 驱动的编译 agent：使用 AI 模型自动分析 Python 函数的动态类型和逻辑，生成高效的 C 代码。2. 自动化测试与验证基础设施：构建 PikaPython Playground，通过 JSON API 实现以下功能：- 代码生成：AI agent 提交 Python 函数，生成对应的 C 代码。- 固件编译：集成 GCC 工具链，自动生成可烧录的固件。- 测试脚本生成：自动生成 Python 和 C 代码的测试脚本，覆盖边界条件和异常场景。- 运行与日志收集：执行固件并收集运行时间、错误日志及内存占用数据。- 结果对比与修复：自动比较 Python 与 C 代码的执行时间，若存在性能下降或错误，触发 AI agent 的修复流程（如重构循环结构、减少内存拷贝）。3. Playground 基础设施设计：- JSON API 接口：提供标准化接口（如 /compile, /test, /analyze），支持 AI agent 的全流程调用。- 嵌入式仿真环境：模拟 PikaPython 的运行环境（如外设接口），确保测试结果的准确性。1. 核心功能：- 开发一个 AI agent，将指定的 Python 函数（如二维矩阵乘法）自动转换为 C 语言扩展模块。- 提供完整的 **PikaPython Playground 基础设施**，支持从代码生成到固件烧录的全流程自动化。2. 性能提升：- 在嵌入式设备上验证典型算例（如矩阵乘法、图像滤波）的加速比，目标达到10~50 倍的性能提升。- 生成可视化报告，展示 Python 与 C 代码的执行时间对比、内存占用差异及加速比。3. 示例实现：- 二维矩阵乘法：# Python 函数def matrix_multiply(A, B):return [[sum(a*b for a, b in zip(A_row, B_col)) for B_col in zip(*B)] for A_row in A]转换为 C 代码后，在 PikaPython 固件中调用，验证其性能提升。- **其他算例**：图像灰度化处理、快速排序算法、傅里叶变换等。","1. 开发 AI 编译 Agent：实现 Python 函数（如矩阵乘法）到 C 代码的自动转换。2. 支持基于 AI Agent 自动生成 PikaPython 的 C 模块拓展的代码和对应的测试代码。3. 构建 PikaPython Playground：提供 JSON API 接口（/compile, /write, /test），支持代码生成、固件编译、测试脚本生成及运行结果对比。4. 自动化测试闭环：通过 Playground 收集错误日志并触发 AI 修复流程，确保多轮修复后代码的正确性。"
RT-Thread 代码覆盖率测试,基础,"[[""os"",""RTOS""]]",随着嵌入式实时操作系统的广泛应用，代码质量和稳定性成为开发中的核心关注点。RT-Thread 作为一个成熟的嵌入式RTOS，其内核和组件的测试覆盖率直接影响系统的可靠性和安全性。本项目要求参赛者设计并实现一套针对RT-Thread的代码覆盖率测试方案，基于现有工具（如gcov、lcov等）或自研方法，分析RT-Thread内核及主要组件的测试覆盖情况。最终目标是交付一个可自动化运行的覆盖率测试框架，并生成详细的覆盖率报告，为RT-Thread的开发者和用户提供质量评估依据，提升系统的可信度。,1. 搭建一套适用于RT-Thread的代码覆盖率测试环境，集成现有覆盖率分析工具（如gcov）。2. 编写自动化脚本，用于在RT-Thread内核及主要组件（如文件系统、网络协议栈）上执行测试并收集覆盖率数据。3. 实现覆盖率数据的可视化输出，支持生成HTML报告或图形化统计图表。4. 提供测试用例设计说明，覆盖RT-Thread核心功能的典型场景。
MateChat新增附件组件,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",随着用户使用场景的深入，将附件发送给模型进行分析是有实际使用场景的，但是目前matechat还未提供附件组件。本项目要求新增一个附件组件，支持上传文件和图片。,"1、编写一个附件组件，能够选择文件，并获取文件信息，具备良好的交互体验
2、附件组件能够整合到一站式解决方案中"
dpdk的RISCV性能优化,进阶,"[[""os"",""RISC-V""]]","DPDK is a set of libraries and drivers for fast packet processing.It supports many processor architectures and both FreeBSD and Linux.目前dpdk存在基于x86, arm的优化，但缺乏基于RISCV的优化此任务希望对标arm, 完成lib中RISCV的优化工作",1. 参考arm(lib/xx/neon)，选择以下五个模块中的4-5个基于RISCV进行优化2. 使得选择的模块性能提高，并通过功能测试和性能测试。
重新设计BMQ调度算法中运行队列的当前任务,进阶,"[[""os"",""Linux""]]",目前BMQ调度算法中运行队列的当前任务同时在运行队列中，考虑到这种设计不利于ELF BMQ(Enqueue Lock-Free BMQ)中全局运行队列的实现，否则全局队列中会存在多个CPU当前运行的当前任务，本选题目标为重新设计BMQ调度算法中运行队列的当前任务，令当前任务不在运行队列中，并修订由此引起的设计改动。,1. 在开发分支上完成本选题目标2. 开发分支上的内核编译的BMQ调度算法可以通过虚拟机和真实机器测试
为TDgpt 增加 Prophet 时序数据分析模型,进阶,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""Structured Database""]]",TDgpt 是搭配 TDengine 主进程 taosd 的外置式时序数据分析智能体。TDgpt 能够将时序数据高级分析服务无缝集成在 TDengine  查询执行流程。TDgpt 是一个无状态的平台，其内置了经典的统计分析模型库 Statsmodel、Pycularity 等，内嵌了 Pytorch/Keras  等机器/深度学习框架库，此外还通过请求转发和适配的方式直接调用涛思数据自研的时序数据基础大模型 TDtsfm (TDengine time  series foundation model)。作为一个分析智能体，TDgpt 整合了多种第三方时序基础模型的 MaaS 服务，仅修改分析模型调用参数（algo）就能够在 SQL 语句中调用最先进的时间序列模型服务。 TDgpt 是一个开放的分析智能体，用户能够根据需求添加预测分析、异常检测、数据补全、数据分类算法。除此之外，TDgpt 还内置多种时序数据预测分析模型和异常检测模型。本项目的目标是将时序数据预测分析模型 Prophet 整合到 TDgpt，成为其内置的时序数据预测分析模型。,1. 编写完成的代码需要通过代码检查工具的检查，并合并到主干分支。2. 编写 Python 语言的单元测试用例和集成测试用例，测试用例需要覆盖新添加的代码。3. TDgpt 能够正确加载 Prophet 预测分析模型到系统中。4. 能够使用 SQL 语句调用 Prophet 分析模型进行时序数据预测分析服务，并生成结果。5. 修改使用说明相关部分内容，增加 Prophet 预测模型的相关介绍内容。
P2P 支持基于 QUIC 协议的文件传输,进阶,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""],[""cloudnative"",""Distributed Storage""]]",Dragonfly 是开源的一款高效 P2P 文件分发系统，现为 CNCF 孵化级项目，旨在解决大规模数据传输中的效率瓶颈。其核心设计理念是通过 P2P 技术将每个节点（Peer）同时作为数据的消费者和提供者，最大化利用闲置带宽，从而显著提升下载速度并大幅降低对源站的依赖和压力。支持 TCP 协议的 QUIC 数据传输机制是尤其重要的，确保了数据传输的可靠性与高效性，使其能够在多种网络环境下高效运行。本项目需要支持采用 QUIC 协议作为底层数据传输基础，利用其可靠性（通过连接管理和错误重传）和顺序性（确保数据按序到达）特性，保证节点间数据传输的完整性。这使得 Dragonfly 能够在多种网络环境下稳定运行，适应复杂的企业级需求。并且需要适配 Dragonfly 基于 Piece 级别的应用层协议 Vortex，确保完整 Piece 元信息以及数据。并且针对大文件/AI 模型/镜像在数据传输部分优化，保证能够最大化利用网络带宽。通过支持 QUIC 协议的 P2P 传输机制，将闲置带宽转化为分发效率，显著提升下载速度，同时减少对源站的负载。其应用场景包括容器镜像分发、大规模文件传输及 AI 数据处理等。,1. 完整的方案设计。 2. 支持采用 QUIC 协议作为底层数据传输基础。 3. 适配 Dragonfly 基于 Piece 级别的应用层协议 Vortex。 4. 确保数据完整、可靠、高效传输。 5. 需要完成 Unit testing、Benchmark、E2E testing。 6. 根据 Benchmark 优化数据传输性能。
为Easy-Es实现向量查询功能,进阶,"[[""cloudnative"",""Elasticsearch""]]","目前,随着AIGC爆火,‌RAG（Retrieval-Augmented Generation，检索增强生成）技术得到了广泛的应用,Elasticsearch(后简称es)官方也在es8及以上版中提供了这种向量检索的能力,但官方提供的API使用难度和门槛较高,对于大多数初学者来说仍然难以驾驭,亟需一款可以简化向量CRUD的工具可以帮助用户快速实现RAG,让用户更加专注于RAG本身的优化上而非实现难度上.当前Easy-Es已经支持自动创建索引,极简的CRUD,但针对ES官方最新的向量查询尚未做开箱即用的支持,用户使用时仍要通过原生语法进行使用,使用难度较高,代码量较大.期望能提供开箱即用的简化版向量CRUD相关API,支持当前Mybatis-plus风格语法的向量查询能力,可以大幅降低用户的学习和使用成本,并减少大量代码,提升研发效率,目前社区内已有大量关于向量支持的用户呼声.需要提供RAG自动化案例,使用户能够通过Easy-Es快速搭建RAG,屏蔽技术实现细节,用户只需要聚焦业务而非RAG底层实现.","1. 增强IndexFieldField自定义注解,使其能够支持向量相似度算法的指定及索引自动创建2. 新增向量查询API,使框架能够通过LambdaQueryWrapper中指定向量查询条件,并简化查询,并能正确查询向量数据3. 在已有的新增和更新数据API中,兼容向量数据新增及更新4. 提供RAG实战案例,模拟实际对接具体知识库后,计算知识向量值,计算时用到的相似度算法不作限制(例如KNN临近算法),向量计算后将值与知识绑定关系通过前面步骤封装的索引自动化接口创建索引,并通过前面完成的创建/更新接口入库,再通Lambda语法查询得出给定关键词命中相似度最高的数据,按得分由高到低返回."
Text2Gremlin 的数据生成和模型微调系统,进阶,"[[""datas"",""Data Science""],[""datas"",""Graph Database""],[""datas"",""AI""],[""os"",""Compiler""],[""codelang"",""Programming Language""]]","通过 RAG/Agent 与数据库交互完成数据查询/调优等工作是业内的的落地趋势，其中重要的一环是Text2SQL/Text2GQL（这里 GQL 在 HugeGraph 里主要指的）类的任务在面向图数据库的 Text2Gremlin 任务中，我们也面临训练数据少 + 数据生成/衍生难 + 数据标注成本高的 3 大核心问题，也感谢 TuGraph 社区已经提前做了不少相关的开源铺垫和实践, 已基于 Cypher 为主的图查询语言设计和实现了一个初版的基于 AST + LLM 组合的语料生成方案, 详见备注参考链接等说明[1][2][3]但由于 Cypher 和 Gremlin 的 AST 结构相差很大, Gremlin 本身函数式的风格也更为灵活多变, 所以之前的系统版本还无法简单兼容 Text2Gremlin 的生成, 需要单独实现这块的 AST + Rule 逻辑我们期望能在 TuGraph/XiYan 等社区的初版代码基础上, 来进一步共建和完善 Tex2GQL 的语料生成 + 模型微调的环节/社区生态, 让它支持 Gremlin 并能更好的适配例如常见 Qwen-Coder 等模型的快速微调, 并分 2 个大阶段来进行代码开发:1. 实现给定 Schema + 基础/初始数据集的语料增强生成 (阶段一: 垂类生成/微调)2. 实现基于 AST/RBO 的不限 Schema + 通用数据集的语料生成 (阶段二: 通用生成/微调)希望有对此感兴趣和探索意愿的同学进行参与/共建, 欢迎提前沟通思路后再编写 proposal~ (实现方式/语言不限)","1. Text2Gremlin 系统的技术设计文档（架构图 + 核心点）2. 实现给定 Schema + 基础/初始数据集的语料增强生成, 拆分为如下 (阶段一)3. 实现基于 AST/RBO 的不限 Schema + 通用数据集的语料生成 (阶段二)"
KWDB原生RESTful接口面向性能的重构,进阶,"[[""datas"",""Database""]]",为了便于多元化的时序数据系统接入，KWDB原生支持REStful API便于用户实现数据写入以及一些简单的数据操作。从内部测试的情况来看，当前的RESTful接口相对于传统的JDBC或ODBC接口仍然存在一定的性能差距，并且其中一部分性能差距的原因是已知的。此项目期望参赛者能够解决已知的性能问题，并探索其它的性能提升机会，从而实现RESTful接口的大幅度性能提升。,"1. 重构已有代码中RESTful 服务使用数据库连接驱动的代码，改为直接调用数据库内核的请求处理接口2. 改造已有代码中RESTful服务登录认证的逻辑，适配RESTful请求直连数据库内核3. 改造已有代码中RESTful的连接管理逻辑，实现RESTful服务到数据库内核的连接池4. 使用测试工具进行改造前后以及类似JDBC应用的性能对比测试，产出测试报告
其中上述1) - 3)项要求产出合规的设计文档，完成代码实现和充分的黑盒测试、白盒测试、压力测试，把测试用例和代码集成到一个代码分支，提出PR且经过评审合并到指定的代码分支。"
SpinalHDL库与Verilator后续版本兼容性提升,进阶/Advanced,"[[""chip"",""Chip Design/Verification""]]",SpinalHDL是一种基于Scala的硬件描述语言（HDL），提供丰富的函数库支持，可帮助用户高效生成和验证数字电路设计。当前版本的SpinalHDL在生成Verilog代码进行仿真时，仅能兼容最高至Verilator 4.228的版本。然而，由于Verilator机制在后续版本中的变化，SpinalHDL的仿真流程出现了兼容性问题，导致无法利用Verilator 5及以上版本的最新功能。针对此问题，本项目要求深入分析Verilator版本更新对SpinalHDL的影响，定位不兼容原因，修复SpinalHDL的仿真生成代码，使其兼容Verilator 5及更高版本。最终需通过跨平台（Linux/windows/macOS）环境测试，确保在不同操作系统上的仿真一致性及性能优化。,1. 分析并明确Verilator 5及以上版本与SpinalHDL的不兼容原因，提供清晰的技术报告。2. 修复或适配SpinalHDL仿真生成代码，验证其可成功与Verilator 5及后续版本配合仿真。3. 完成跨平台（支持Linux、Windows和macOS）环境测试，提供测试结果及日志。4. 功能均需通过仿真测试、版本兼容性验证及跨平台测试。
Apache Doris：BE Coredump 磁盘故障预防策略,基础/Basic,"[[""datas"",""Database""]]",Apache Doris的 BE 节点目前在 RocksDB 遇到磁盘故障（例如，由于硬件故障导致的读/写错误）时以 coredump 终止，不仅破坏集群可用性，还会使故障恢复复杂化。该项目旨在通过以下方式增强 BE 的集群还原能力：开发核心模块：,"1. 高可靠磁盘故障处理机制
- 拦截 RocksDB I/O异常（如Status::IOError）并将其转换为非致命错误
- 将 BE 节点标记为只读状态，阻断异常节点写入同时保持健康副本的读取能力2. 故障注入测试框架
- 在 RocksDB 核心操作（如Env::NewSequentialFile）中实现I/O异常注入接口
- 验证所有依赖 RocksDB 的核心操作（包括Compaction、WriteBatch、WAL 重放等）的异常处理逻辑"
Hippo4j Server 端参数协议升级与 SPI 扩展验证,基础,"[[""dev"",""DevOps""]]",项目背景Hippo4j 是一款基于 Java 开发的轻量级动态线程池管理框架，专注于解决传统线程池配置僵化、监控缺失等痛点，通过对接配置中心（如 Nacos、Apollo 等），Hippo4j 支持线程池参数的实时动态调整，包括核心线程数、最大线程数、队列容量等，无需重启应用即可适配业务流量变化，显著提升系统弹性与稳定性。框架提供多维监控指标（活跃度、拒绝率、任务耗时等），并集成报警通知功能，帮助开发者快速定位资源瓶颈。其兼容性强，无缝支持 Spring Boot、Dubbo、RocketMQ 等主流框架的线程池托管，同时提供开箱即用的控制台，实现线程池配置可视化管理。作为开源项目，Hippo4j 设计简洁、扩展性强，适用于微服务架构下的高并发场景，助力企业构建高效、可控的异步任务处理体系。项目任务Hippo4j Server 通过事件推送机制实现线程池参数动态生效，但当前 Client 端依赖全量参数 MD5 比对策略，存在严重缺陷：：Server 端参数结构升级，如字段重命名时，Client 因 MD5 不匹配持续触发无效刷新。：Server 端新增扩展参数，如新增阻塞队列类型等关键参数，Client 因 MD5 不匹配持续触发无效刷新。本项目旨在重构参数比对协议，支持多版本兼容与增量更新，同时设计阻塞队列 SPI 扩展与验证框架，保障动态线程池升级的平滑性与安全性。阻塞队列 SPI 介绍：项目中已经提供 SPI 注入队列的功能，但 ServerThreadPoolDynamicRefresh#changePoolInfo 中，强制写死只能固定 ResizableCapacityLinkedBlockingQueue 的类型，服务端新增可以选定自定义队列的入口，像拒绝策略一样支持。,1. 支持多版本协议的 Server/Client 端完整实现，段级比对算法核心代码（支持忽略可选字段、类型兼容转换等）2. 阻塞队列 SPI 接口定义及至少 1 种内置队列的实现示例3. 官网文档补充如何支持 SPI 自定义阻塞队列说明
基于MindSpore实现小数据集训练粗网格高精度PDE求解模型,基础,"[[""datas"",""AI""]]",对于PDE求解，传统FVM等方法精度要求越高，求解时间和算力成本越高。AI模型理应能够以更低的训练推理成本达到高精度PDE求解。P2C2Net即为一种基于低数据量、粗网格的高精度PDE求解模型。开发者需参考论文，在MindSpore+NPU完成对方案的复现，所有场景下均能与论文训练推理精度差别不超过10%，交付动态图、静态图版本，能够一键切换。,1. 基于MindSpore+NPU，结合AI流体仿真套件MindSpore Flow现有能力，实现小数据集训练粗网格高精度PDE求解模型P2C2Net，并对齐论文精度和性能。
基于Ray+MindSpore+Milvus实现开箱即用的分布式RAG应用,基础,"[[""datas"",""AI""]]","对标谷歌NotebookLM,Meta的llama-cookbook多模态领域特定知识库RAG问答机器人","1.以MindSpore帮助QA机器人为例，也可以自行选择“法律、医疗、工业、学生考试复习资料”等不同的领域知识为例。2. 对话用的智能体基于vLLM-MindSpore或MindNLP或MindSpeed本地部署。3. 预期输入若干个服务器上多个文件路径（ip1:/path1;ip2:path2;......;ip_n:/path_n），其中包含Markdown,PDF，Docx,图片，PPTX，Github issues.csv文件，教学视频语音等多模态数据文件，预处理并Embedding到向量数据库Milvus。4. Docker compose的多容器本地开发环境，需要包含一个Slave（worker）节点和一个Master(head)节点 3. 用户查询返回知识库专家指导的回答信息，对话回答内容可以是NLP，如有必要还需包含语音和视频等chunk原始文件位置索引。5. 不需要支持多轮回答，核心目标是每个问题都能精准找出数据库中正确关联的chunk。重点落在RAG Recall召回率的提升。在中文RAG评价benchmark https://github.com/IAAR-Shanghai/CRUD_RAG 挑选中文数据集记录召回率，添加benchmarks记录到https://paperswithcode.com/task/rag 中。6. 【联网功能】按钮，爬取Bing实时搜索前50条搜索记录的html文档，加到RAG问题搜索范围内。"
面向复杂Text2GQL任务的数据模拟和模型训练,基础,"[[""datas"",""Graph Database""],[""datas"",""AI""]]",近年来，在关系型数据库的Text2SQL领域，随着大型语言模型 (llm) 经历了快速的迭代和进化，传统的Spider、BIRD等由较为简单的语料对构成的Text2SQL数据集已经无法对大模型的翻译能力构成挑战，最新的如Spider2.0，BIRD-CRITIC等数据集已经开始对大模型在更复杂、更接近生产的环境中的翻译能力，及完整的workflow执行能力提出了挑战。与Text2SQL对应的图数据库Text2GQL 领域在学术界的研究则才刚刚起步，相关的语料十分匮乏，Awesome-Text2GQL框架借助语法解析与大模型的能力实现了Text2GQL语料的快速泛化，弥补了Text2GQL领域语料不足的缺陷，但生成的语料依然与复杂的生产环境有一定的距离。因此，如何借助大模型的能力生成复杂的Text2GQL任务并提高大模型在不同数据集上的迁移能力和在更复杂的Text2GQL任务中的翻译能力成为了重要的研究课题。,1.   技术设计文档（含架构图与细节描述）2.   数据模拟生成框架源代码3.   Text2GQL智能体源代码4.   Text2GQL Benchmark测试报告
具身推理器Embodied-Reasoner,基础,"[[""datas"",""AI""],[""datas"",""Computer Vision(CV)""],[""datas"",""Deep Learning""]]","Embodied-Reasoner（具身推理器）是一种将深度思考能力扩展到具身交互任务的新方法。其核心逻辑是：有效的具身推理不仅需要处理多模态输入的能力，还需要生成适应交互不同阶段的多样化思考过程（分析、规划、反思）。Embodied-Reasoner的核心贡献如下：·数据引擎：构建了能自动生成连贯观察-思考-行动(Observation-Thought-Action)轨迹链的数据引擎。这些轨迹链融合了多样化的具身专属思考过程，例如情境分析(situational analysis)、空间推理(spatial reasoning)、自我反思(self-reflection)、任务规划(task planning)和双重验证(double verification)。这些图文交织的连贯轨迹链可指导模型基于交互历史和空间布局进行规划与推理，从而提升其时空推理能力。·迭代训练流程：进一步设计了包含模仿(imitation)、自我探索(self-exploration) 和自我纠正(self-correction) 三阶段的具身模型迭代训练框架。首先通过合成轨迹的模仿学习培养基础交互能力，接着通过拒绝采样微调增强探索能力，最后通过反思微调实现自我纠错。·交互式评估框架：在12个与训练场景不同的新颖情境中构建了809个测试案例，人工设计指令并标注对应的关键动作与最终状态：<指令，关键动作，最终状态> (<Instruction, Key Action, Final state >)。值得注意的是，我们的测试集包含25个精心设计的超长跨度任务，每个任务涉及4个子任务和14-27个关键动作。现有工作的不足，当前场景如果存在多个同名物体时，尚无法恰当区分。希望能通过文本或图像进行描述并交由具身推理器进行有效支持。",1.在本项目资助下，对具身推理器进行深度改进，使其具备在复杂场景中精确区分同名物体及大型物体不同部位的能力，并据此执行精准导航与高效操作任务。通过多模态技术整合，显著提升具身推理器在复杂环境中的定位精度与操作灵活性。当前 Embodied-Reasoner 的导航功能存在两处核心障碍，严重限制了其在真实场景中的应用效能。其一，在存在多同名物体时（如图书馆场景中多个书架），仅依据物体名称导航将导致系统决策瘫痪；其二，大型物体（如 L 型沙发）的宽泛导航区域（可达 2.5 平方米）使后续操作（如精准放置物品）的成功率不足，亟需通过空间细分技术优化。建议可采用的方法：
镜像站文档与 CLI 工具代码自动同步生成工具的研发,进阶,"[[""os"",""Linux""]]",hust-mirrors (https://github.com/hust-open-atom-club/hust-mirrors) 是华中科技大学开源镜像站（）的前端项目，包括镜像站点的页面以及文档，hustmirror-cli (https://github.com/hust-open-atom-club/hustmirror-cli) 是一款能够帮助支持 POSIX shell 的操作系统快速换源的小工具。但是，目前该项目存在帮助文档未能及时更新，部分关键镜像源文档缺失，CLI 工具和文档不统一等问题，为解决本问题，本选题目标为，以维护常见软件源的文档和 CLI 工具。,1. 完成一个可以使得镜像站文档和 CLI 工具保持统一的工具：接收统一格式的镜像源定义作为输入，并能据此自动生成符合 hust-mirrors 项目要求的文档片段（以 MDX 格式）和 hustmirror-cli 工具所需的配置逻辑或 shell 脚本代码。2. 利用研发出的自动化工具，完成对 HUST 镜像站至少 15 个主流开源镜像源的定义、生成和集成工作。3. 完善 CLI 工具的测试，例如使用 docker 或 cloud-init 等工具完成自动化的测试。4. 测试 CLI 工具在各个 shell（如 bash，zsh，fish）的兼容性，并修复存在的兼容性问题.
MySQL审核规则优化，实现子查询嵌套层数建议,基础,"[[""datas"",""MySQL""],[""datas"",""Relational Database""],[""dev"",""DevSecOps""]]",SQLE 是一款 SQL 审核工具，旨在帮助研发团队规范 SQL 编写。为了持续提升 SQL 审核能力，SQLE 的一项重要目标是。目前，编号为 SQLE00108 的 MySQL 审核规则已经能够对子查询的嵌套层数进行基础的检测。然而，在实际应用中我们发现，对于某些特定的复杂 SQL 语句，该规则存在未能触发提示的场景，导致部分过度嵌套的子查询未能被有效识别。本次，我们将对编号为 SQLE00108 的 MySQL 审核规则进行优化，希望通过更精细化的检测逻辑，解决上述未触发的问题，确保当子查询嵌套层数超出预设阈值时能够准确发出系统提示，从而更有效地帮助开发者避免编写过于复杂的嵌套查询。,1. 参考当前 SQLE 审核规则的设计模式完成规则的优化2. 参考当前 SQLE 规则测试用例添加3. 代码需接受复审并合并到 SQLE 开源仓库主分支4. 总结本次规则优化过程中的经验，形成文档
Dromara 开源社区一体化管理系统,基础,"[[""web"",""Vue.js""],[""web"",""Spring Boot""],[""web"",""RESTful API""]]",（一）背景在开源蓬勃发展的当下，Dromara 开源社区规模持续扩大，项目数量不断增多，参与人员愈发复杂。现有的管理方式相对分散，缺乏一个集中、高效的人员与项目管理系统，导致项目孵化过程难以追踪，人员与项目关联不清晰，权限管理混乱等问题，严重影响社区运作效率与协同效果。（二）已有工作目前社区依靠多个独立工具进行部分管理工作，如使用 Excel 记录项目基础信息，通过邮件、即时通讯工具沟通项目进展，利用不同平台管理人员信息等。但这些方式缺乏系统性与集成性。（三）存在不足（四）改进要点（五）项目目标构建一个功能完善、操作便捷的开源社区人员与项目管理系统，提升社区管理效率，促进社区成员更好地协作与交流，推动开源项目的顺利开展。,1. 完成系统的前后端架构设计，绘制详细的架构图，包括模块划分、接口设计等。2. 开发开源项目管理模块，实现项目孵化流程全生命周期管理，包括项目创建、审核、进度跟踪、文档管理等功能。3. 开发社区人员管理模块，实现人员信息录入、编辑，人员与项目关联关系管理，展示人员在项目中的贡献信息。4. 完成系统测试，包括功能测试、性能测试、安全测试等，并提交测试报告。5. 撰写系统使用文档，包括管理员使用手册、普通用户使用手册，方便社区成员使用。
自由及开源软件简中本地化工作,基础,"[[""web"",""Desktop Application""],[""web"",""UI""],[""web"",""UX""]]",当前我国国内有相当数量的 Linux 及各大开源或自由软件 (F/OSS)  使用者，但在使用过程中，用户们不难发现，各种软件的简中翻译及本地化质量参差不齐，错漏繁多；Inkscape、virt-manager 等常用应用的本地化质量相对较低；而我社的 Wiki  站点简中文档翻译也时常欠完整或更新。该项目的主要目的是改善当前开源或自由软件的本地化质量及覆盖率。综合培训学生完成上游工作与沟通及参与安同开源社区项目的需要，我们鼓励学生在完善如下项目的简中本地化：,"1. 完善社区推荐完善项目至少两个的简体中文本地化
2. 将对应贡献提交至上游"
Git-based STEM Wiki system for Mogan STEM,Basic,"[[""dev"",""CD""],[""dev"",""CI""],[""dev"",""Git""],[""dev"",""AIOps""],[""dev"",""LLMOps""],[""os"",""Debian""]]","This project is to encourage people to use Mogan STEM, and share their STEM writings as wiki with the help of Git and LLM.",1. Design a multi-language STEM wiki for wiki contributors (Finding at least 10 human wiki contributors)2. Github or Gitee CD to generate the static site of the STEM wiki3. LLM bot to review the pull requests4. LLM bot to create wiki entries as Github or Gitee pull requests
为 Karmada Dashboard 引入自动化测试,基础,"[[""cloudnative"",""Kubernetes""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。Karmada Dashboard 已经发布第一个正式的版本。为了保证Karmada Dashboard 可以在快速迭代的过程中保证功能的稳定性，因此希望可以为Karmada Dashboard引入自动化测试的能力，结合CI能力，保证每次提交代码时运行自动化测试用例，保证Karmada Dashboard 功能的稳定性。 由于Karmada Dashboard是一个全栈项目（包含了go后端、react前端、npm组件包），设计自动化测试需要了解的技术栈相对较多。,1. 功能介绍文档：自动化测试设计文档2. 功能实现3. 项目扩展：
基于Linux操作系统的关键进程自愈机制实现,进阶,"[[""dev"",""DevOps""]]",（1）相关背景操作系统自愈机制是指操作系统在检测到错误或故障时，能够自动采取措施进行修复或恢复，从而保证系统的稳定性和可靠性。这种机制在现代操作系统中变得越来越重要，尤其是在高可用性和容错性要求较高的场景中。（2）已有的工作当前，一些监控工具可以对系统和服务的状态进行监控，并在检测到异常时发送告警通知。然而，这些工具大多需要人工介入来解决问题，未能实现完全的自动化恢复。（3）存在的不足现有的方法依赖于管理员手动干预以重启失败的服务或进程，这种方式不仅效率低下，而且可能导致服务中断时间延长，影响用户体验和业务连续性。（4）希望改进的点设计并实现一种针对关键进程的实时监控与自动恢复解决方案，该方案能够在检测到进程崩溃后立即尝试重启进程，减少人工干预，提高系统稳定性。（5）最终项目实现的目标开发一个高效、可靠的Linux环境下关键服务进程自愈系统，确保即使在发生意外故障的情况下也能保持服务的持续可用性，同时提供灵活的配置选项和详细的日志记录以便于维护。,1. 实现对指定关键进程的实时健康检查。2. 开发自动化的进程恢复逻辑，包括但不限于重启策略、重试机制等。3. 提供用户友好的配置指南和操作手册。
向 mugen 测试框架中添加特性 RPM 国密签名，国密算法，secDectector 测试套和测试用例,基础,"[[""os"",""RISC-V""]]",mugen 是 openEuler 社区提供的开源自动化测试框架，它提供公共配置和方法以便社区开发者进行测试代码的编写和执行。目前 openEuler 支持的 RPM 国密签名，国密算法，以及secDectector特性在 mugen 中还有相关测试套和测试用例，需要添加。,1. 添加的测试套和测试用例可以覆盖这些特性的基本功能测试2. 测试套和测试用例在 x86 和 RISC-V 架构都可以执行pass3. 提交pr时，需要附上在 x86 和 RISC-V 架构执行pass的截图4. 编写文档，用来说明测试用例具体测试方法和内容
HugeGraph Gremlin 性能与安全优化 (Java 17),基础,"[[""codelang"",""Programming Language""],[""datas"",""Database""],[""datas"",""Graph Database""]]","HugeGraph 现在主要的查询语言 Gremlin 源自图查询语言框架 Apache TinkerPop， 目前 HugeGraph 使用的是的 TinkerPop, 它内置的 Groovy 引擎灵活但安全性欠佳, 想保证安全性需要牺牲不小的性能和写许多黑白名单, 对用户使用不友好而 Gremlin 的新版本已经正式支持了 Java17， 并更新了 Groovy  4 大幅改善了性能和安全性 ， 是一次意义重大的升级/提升， 完成它的适配意味着 HugeGraph 所有组件可以正式使用 Java17 的新特性， 不仅修复了大量查询的 Bug， 优化了不少 Perf/API/Security 相关的优化， 可以提升 HugeGraph 的性能表现。我们希望完成 Gremlin 与 Java 新版的的升级适配, 并重构 HugeGraph 关于 Groovy Security 这块的代码逻辑.","1. 完成适配新的 `Gremlin` 版本 3.7.x 相关编码任务, 确保 CI 和使用正常2. 整个 HugeGraph 层升级/兼容 Java17，产出与 Java11 的性能对比文档（关键接口）3. 改进 HugeGraphSecurity 的实现方式, 尽可能在不影响性能的情况下, 避免 Groovy 脚本的安全问题"
StreamPipes Extension Services Load Balancer,Advanced,"[[""codelang"",""Programming Language""],[""cloudnative"",""Cloud Native""]]","Apache StreamPipes is a self-service Industrial IoT toolkit designed to help non-technical users connect, analyze, and explore IoT data streams. Extension services are compute-intensive services that run adapters and pipeline elements.Since Apache StreamPipes is an IoT data stream processing system, it is critical to provide powerful computing power. A load balancer needs to be implemented to optimize the scalability of extension services.","1.Collect resource utilization metrics (such as CPU, memory) for extension services.2. Implement resource management (such as memory management) and rate limiters for extension services.3.  Implement a dynamic load balancer based on the collected resource data to optimize the performance of the extended service"
基于 Rust-For-Linux 重构 HyperEnclave 驱动,基础,"[[""os"",""Linux""]]",HyperEnclave 是基于虚拟化技术构建的可信执行环境。其驱动中有大量与 Linux 交互的代码。目前 HyperEnclave 驱动是以 C 语言进行实现的。现有的 HyperEnclave Driver 虽然功能完备，但是由于 C 语言天然存在内存安全隐患、数据并发竞争隐患、抽象成本过高等问题，给后续的代码迭代与维护增加了一定的难度。另一方面，Rust 语言作为内存安全的编程语言，正在被广大的项目所采纳，Linux 也不例外。通过 Linux 社区的 Rust-For-Linux 的框架，开发者能够使用 Rust 语言编写 Linux 内核态的代码。本项目聚焦 HyperEnclave 驱动的核心功能（HyperEnclave 启动、HyperEnclave 虚拟内存与物理内存管理，HyperEnclave 可信功能管理等），旨使用 Rust 语言，重写驱动，并提升 HyperEnclave 驱动的内存安全、并发安全、可维护性。,1. 基于 HyperEnclave 的开源驱动，对现有的功能进行学习、分析与归纳，基于 Rust 的编程语言进行重写。
基于seata 的 AI Agent Workflow,进阶/Advanced,"[[""datas"",""AI""]]",项目背景：在分布式系统和微服务架构的快速发展下，分布式事务管理成为确保数据一致性和系统可靠性的关键技术。Seata提供了多种事务模式，包括AT、TCC、Saga和XA，其中Saga模式因其灵活性和对长事务的支持而广泛应用于微服务场景。Seata的Saga模式基于状态机引擎实现，开发人员需要通过状态图定义服务调用流程，并生成JSON格式的状态语言定义文件。这一过程支持单选、并发、子流程、参数转换、参数映射、状态判断和异常捕获等功能。然而，传统的手动定义Saga工作流存在以下挑战：-复杂性高: 状态机设计需要深入理解业务逻辑和分布式事务机制，对开发人员的技术要求较高。-维护成本高: 业务需求变化时，需频繁更新状态机定义，增加了维护工作量。-错误风险: 手动配置可能引入逻辑错误，影响事务一致性。-扩展性有限: 在大规模微服务系统中，手动管理多个复杂工作流变得难以应对。随着人工智能技术的进步，LLM在自然语言处理（NLP）、模式识别和生成式任务中展现出强大能力。LLM不仅能够理解和生成人类语言，还可以通过训练处理结构化数据生成任务，例如生成代码、配置文件或工作流定义。近期研究（如 WorkflowLLM）表明，LLM在工作流编排领域具有显著潜力，可以通过自然语言输入生成复杂的工作流配置。这为使用LLM自动化Seata Saga工作流编排提供了理论和实践基础。,1. seata-go saga 能力建设2. Saga 模式下支持接入AI Agent3. 通过自然语言生成的 AI Agent workflow 的能力
面向云原生场景的Device Plugin GPU虚拟化与型号上报统一管理,基础/Basic,"[[""datas"",""AI""],[""datas"",""GPU""],[""dev"",""Git""],[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""]]",Volcano Device Plugin 目前分别在不同分支提供了 GPU 虚拟化（基于较旧上游版本）和 GPU 型号上报（基于较新 v0.16.1 版本）两项重要功能。为了解决由此带来的维护和使用不便，本项目计划将这两项能力整合到统一的代码分支中，并进行适当重构。最终目标是提供一个功能完备、接口统一的 Device Plugin，更好地支持云原生环境下的 GPU 资源虚拟化和精细化管理，提升用户体验并促进社区协作。,1. 统一功能分支: 提供包含 GPU 虚拟化和型号上报的统一 Volcano Device Plugin 代码分支。2. 功能验证: 通过充分测试（单元、集成、端到端）确保两项功能在统一分支中的正确性和兼容性。3. 对相关代码进行重构，提升质量和可维护性。4. 完善文档: 提供项目设计、用户使用和开发者说明文档。
isocut在RISC-V架构环境下的完整适配和验证,基础,"[[""os"",""RISC-V""]]","目前isocut工具在RISC-V环境下参考官方文档操作，只有部分场景验证可以正常运行，需要对失败场景进行修复，并补充文档清楚描述本项目背景以及要做什么。（1）相关背景isocut工具在RISC-V环境下进行ISO镜像裁减，定制化，生成的ISO需在qemu环境下安装运行（2）已有的工作根据官方文档场景一和场景二都可以正常安装运行（3）存在的不足根据官方文档，但是场景三存在问题，定制后的ISO不能正常安装运行（4）希望改进的点修复场景三的问题，并完善当前的文档（5）最终项目实现的目标isocut工具在RISC-V环境下对ISO镜像进行定制化裁减出的ISO,安装后的系统可以正常运行，并有详细的参考文档",1. isocut工具根据文档定制化裁减出来的ISO要可以正常安装运行使用，并完善当前文档
openKylin系统设置应用卸载支持,进阶/Advanced,"[[""os"",""Linux""],[""os"",""x86""],[""web"",""Qt""]]",期望在openKylin控制面板内实现一个插件，此插件具有卸载应用和驱动的功能。对比Window系统设置应用和功能分类中提供应用卸载功能，以及当前openKylin提供的应用卸载功能比较分散（软件商店下载的应用提供卸载、开始菜单中右键支持下载、驱动不支持卸载），基于以上原因，openKylin控制面板提供应用统一卸载入口。●当前控制面板使用插件化机制实现，新增“安装的应用”插件继承已有插件机制。●其它应用已提供应用卸载能力。●当前提供的应用卸载功能比较分散，用户习惯在Window操作习惯，亟需提供统一应用卸载入口。●openKylin控制面板提供应用统一卸载入口。解决openKylin应用卸载功能比较分散问题，控制面板提供应用统一卸载入口。,1. 完成“安装的应用”为名的插件并放到应用大类下2. 完成安装的应用排序功能3.完成安装的应用搜索功能4. 完成安装的应用卸载功能5. 完成安装的应用来源检测跳转功能
AI Gateway,基础,"[[""web"",""Web Application""],[""codelang"",""Programming Language""]]",以小X宝为例，现在对接了FastGPT、Dify、智谱、腾讯混元、扣子等多个平台，还对接过多个RAG工具和知识库，在前端进行调用的时候比较难，有较多的接口。现在有OneAPI对后端模型进行封装，只能封装模型层，对于FastGPT、Dify等Agent平台的能力还没有覆盖。其他AI类应用也有相同的问题，这类应用更关注上层应用，需要和底座能力进行解耦。最近MCP协议很火，需要统一为AI和Agent类应用进行封装，调用其他组件和被其他组件调用都在这个项目中进行封装。在这个项目中你将获得项目设计和管理能力，将会锻炼使用多个Agent工具平台能力，将获得提炼知识体系和框架的能力。,1. 对多个Agent进行封装，提供前端统一调用接口2. 将应用平台进行封装，方便被其他平台和组件进行调用3. 配套使用说明和类似工具调研报告
为Fury Rust实现基于元数据共享的类型前后兼容模式序列化,进阶/Advanced,"[[""codelang"",""Programming Language""]]",（1）背景：Fury是一个高性能的序列化库，支持跨语言的二进制协议。目前基于Rust语言的应用逐渐增加。Rust语言以其内存安全和并发性能而被广泛使用，同时也面临着需要与不同版本和类型结构兼容的序列化挑战。针对Rust语言的序列化，保证类型的前后兼容性对于长期项目演化和多版本支持至关重要。（2）已有的工作：目前Fury已经在Java/Python/NodeJS等语言中实现了高效的序列化和反序列化，但在Rust中相关工作仍处于早期阶段，只支持在对象类型Schema严格一致时进行序列化和反序列化。随着项目的扩展和复杂性增长，序列化方案需要更加完整且高效，以支持版本演进。（3）存在的不足：现有的Fury Rust序列化机制尚未充分支持结构类型的前后兼容性。在类型更新时，缺乏适配机制来处理新增字段或移除字段，以保证序列化数据的稳定性和一致性。同时，元数据的高效共享机制还未形成最佳实践。（4）希望改进的点：希望通过实现一种基于元数据共享的类型兼容机制，使得Fury Rust序列化能够支持类型的动态更新，并且保证前后版本之间的兼容。通过高效的元数据共享方式，实现对新增、修改、移除字段的智能序列化处理，以减少版本变动带来的开发负担和运行风险。（5）最终项目实现的目标：最终目标是为Fury Rust实现一个能够支持类型前后兼容的序列化框架。该框架将利用Fury二进制序列化协议的元数据共享机制，实现上可以参考Fury Java/NodeJS等语言的实现，最终自动适应类型结构的变化，确保不同版本之间的数据能够被正确序列化和反序列化，提升Fury在Rust生态中的应用广度和深度。,1. 实现元数据编码和解析模块，编译时获取类型元数据，并按照Fury元数据协议进行编码2. 实现元数据共享模块，多个相同类型对象只序列化一次类型元数据3. 编译时解析元数据，生成针对类型不一致场景的反序列化器
NeuCharFramework：AI 原生模块化快速开发框架,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""datas"",""Database""],[""cloudnative"",""Docker""],[""dev"",""Git""],[""cloudnative"",""Kubernetes""],[""web"","".NET""],[""datas"",""Semantic Kernel""]]",NCF（ NeuCharFramework）是一整套可用于构建基础项目的企业级通用框架，严格遵循 DDD 设计模式，使用高度集成和可扩展的 AI 原生架构，包含了基础的缓存、数据库、模型、验证及配套管理后台等等系统基础要件，NCF 支持容器化和微服务部署，也支持单体应用部署，NCF 系统高度模块化，具有高度的可扩展性和耐造性。本次项目将重点围绕下一代由 AI 赋能的多智能体Multi-Agent 以及 MCP 等技术，自动开发及运维软件解决方案的具体模块进行设计、开发和完善。项目基于已经成熟的 Senparc.AI 基础人工智能中间件模块，同时支持对接公有或私有化模型完成开发任务。,1. 完善基于 Senparc.AI 的 自动化架构和运维模块，完成 AI 对自动化智能体软件架构和生成的模块建设、测试和至少预览版上线2. 完善基于微服务的前后端分离架构3. 完善 AI 应用市场对接
面向循环中SVE访存指令的基址+偏移模式的冗余指令消除,基础,"[[""os"",""LLVM""],[""os"",""Linux""],[""os"",""GDB""]]",sve memory operations包括gather/scatter场景，会使用base+index的方式进行访存，用户编写代码时可能会出于开发习惯和代码整洁的原因而选择更新index来对不同的内存进行访问，但是在SVE场景中性能可能并不如修改base地址。编译器可以帮助用户进行这方面的优化，在保证用户开发便捷的前提下完成性能增强。,1. 完成对llvm中相关优化pass的开发，支持所有相关gather/scatter指令上针对项目描述中相关寻址优化
为 NebulaGraph 支持向量近似近邻检索,进阶/Advanced,"[[""datas"",""Database""],[""datas"",""Graph Database""],[""datas"",""Vector Database""],[""datas"",""LLM""]]",LLM(Large Language Model)的创新推动了很多 AI 应用的落地，构建此类应用通常采用 RAG(Retrieval-Augmented Generation) 架构模式，RAG 被认为是解决 LLM AI 幻觉的有效方式，并可以为其提供更丰富的上下文使得 LLM 的响应更准确。向量近似近邻检索，即 Approximate Nearest Neighbor (ANN) Search，可以在高维向量空间中快速检索相似向量并为 RAG 提供后端支持。然而，目前 NebulaGraph 尚未支持向量相关的功能，这限制了其在 AI 场景中的应用潜力。若在 NebulaGraph 中支持向量，将为其提供向量持久化存储能力、利用数据库的扩展性来满足业务数据规模扩张需求、实现知识图谱和向量检索结合的 GraphRAG 来改善传统 RAG 的一些痛点。(),1. 实现向量数据类型并支持其持久化。2. 实现向量相关的 DDL 语句，包括 create tag、create index 等语句。3. 实现向量相关的 DML 语句，包括 insert、update、delete 等语句。4. 设计并实现 ANN Search 语句。5. 满足分布式一致性和可用性要求，保证向量数据副本一致性及内存磁盘数据一致性。6. 保证 leader change、宕机重启等情况下向量相关功能的可用性。7. 对 ANN Search 性能进行优化以满足业务需求。
Koupleless 模块运维调度链路增加心跳 revision 版本控制,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""web"",""Spring Boot""]]",Module-Controller 是 Koupleless 的运维调度核心组件，采用 Virtual-Kubelet 将基座进程映射成 k8s Node，模块实例映射成 k8s Pod，达到直接复用k8s完成模块安装、调度、扩缩容等能力，极大地降低企业内建设模块运维调度能力的成本，帮助更加平滑地往 Serverless 演进。但由于当前模块 Pod 实例缺少 revision 版本控制能力，导致在并发情况下模块的状态与预期不符或者出现不必要的状态跳变，导致模块实例无法正常运维调度，使得 ModuleController 运维调度组件无法在生产真正规模化使用。比如，模块pod 替换导致 JVM 进程内模块实例消失。因此，希望建设心跳 revision 版本控制，修正模块运维调度链路。,1. Module Controller Pod Revision 控制 PR
Cirno：支持以写入时复制（CoW）模式进行依赖管理的应用框架,进阶,"[[""web"",""Desktop Application""]]",当前，Koishi Desktop 为用户提供了开箱即用的桌面体验，但随着 Cordis 生态的扩展，我们需要一个更加轻量、通用的框架来支持多种 Cordis 应用的开发。Cirno 是 Cordis 生态中的下一代跨平台桌面应用框架。其核心特色在于：1. CoW 模式的包管理器通过依赖复用和全局 GC 技术，实现了低硬盘占用的应用版本管理和自动备份等功能；2. 基于系统原生 WebView 构建 GUI 框架，在显著减小应用安装体积的同时保持类似 Electron 的开发体验；3. 相比传统应用，Cirno 支持普通包、Zero-Install 包、Docker 镜像等多种分发形态，满足不同场景下的应用分发需求；本项目需要学生使用 Rust 语言完成 Cirno CLI 和 App 框架的完整开发，包含包管理器、App 内核、WebView 模块等多个组件。,1. Cirno CLI2. Cirno App Core3. Cirno WebView
Kmesh支持多集群,进阶/Advanced,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""],[""safe"",""SSL/TLS""]]",Kmesh作为高性能服务网格数据面，现在仅支持在单集群中使用。但现在istiod的多集群支持已经实现，我们能够推进Kmesh的多集群适配工作，以支持Kmesh在多集群环境下使用。适应现在的大模型和大数据的多集群生产环境。,1.实现Kmesh多集群特性代码2. 使用文档3. 测试用例
基于agentUniverse多智能体框架的智能体对话能力增强,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""],[""web"",""Vue.js""],[""web"",""React""],[""web"",""Angular""]]",agentUniverse是一个专业多智能体框架，帮助开发者轻松构建具备专业Knowhow的智能应用。在智能应用实践中，问答交互场景占据核心地位，本项目亟需打造一套完整的智能体专属问答解决方案。该方案需具备三大核心能力：1）支持智能体服务的即开即用式页面接入2）提供可视化交互界面（包含实时聊天窗口、结构化卡片渲染模块）3）实现智能体思维过程的可视化呈现（思考链展示系统）。目前我们已完成智能问答所需的前端组件SDK的开发，后续需要在此基础上进行功能增强与框架级集成，通过模块化架构设计实现与agentUniverse框架的无缝接入，最终形成覆盖智能问答全链路的标准化解决方案。,1. 为agentUniverse多智能体框架的智能体对话提供必要页面与接口2. 提供必要的单元测试与测试报告3. 撰写设计与功能说明文档
Karmadactl init 支持设置组件启动参数,基础,"[[""cloudnative"",""Kubernetes""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。Karmadactl init 用于用户自定义安装 Karmada 控制面组件。组件启动参数是指在启动软件或服务时传递给可执行文件的参数，这些参数用于控制组件的行为、配置运行环境或指定特定的操作模式。它们可以影响从日志级别、监听端口到性能调优选项等多个方面。具体的作用取决于每个参数的设计目的和使用场景。因此，我们计划在命令 karmadactl init 中引入支持设置组件启动参数的能力，提高用户可自定义程度。,1. 功能介绍文档：介绍此功能特性的文档2. 功能实现：Karmadactl init 支持设置组件启动参数3. 测试覆盖：编写测试用例覆盖新增功能
支持 AIBrix 的 LLM 请求会话追踪功能,进阶/Advanced,"[[""datas"",""LLM""],[""datas"",""AI""],[""cloudnative"",""Kubernetes""]]",为了充分挖掘现代大语言模型（LLM）推理任务的优化机会，向AIBrix暴露应用级元数据至关重要，这样AIBrix才能做出包括以下特性的高级资源调配决策：AIBrix的当前版本独立处理每个LLM调用，如果不了解应用级信息，由于队首阻塞可能会导致显著的累积等待时间。我们希望设计一个接口来整合应用级信息。这可以引入会话和进程表的概念，这些表保存所有应用程序及其对应任务的元数据（如中所述）。这个项目可以进行调整以支持程序感知调度方法，该方法会考虑整个程序的结构和依赖关系，从而实现更高效的执行。,"1. 实现一个基于LLM 应用的session, 其中可能包含键值（KV）缓存信息以及与每个会话相关的“进程/线程”信息。"
pgcrypto 扩展支持 SM2/SM3/SM4 等国密算法,进阶,"[[""datas"",""PostgreSQL""],[""datas"",""Structured Database""],[""datas"",""Database""]]",Cloudberry 作为一个基于 PostgreSQL 的分布式数据库系统，其安全性对于用户至关重要。目前，Cloudberry 通过 pgcrypto 扩展提供加密功能，但尚未支持国密算法标准支持，如 SM2、SM3 和 SM4。本任务旨在扩展 Cloudberry 的 pgcrypto 模块，增加对国密算法的支持，使 Cloudberry 能够满足用户对数据安全和合规性的要求。具体来说，需要实现以下国密算法：实现这些算法后，用户将能够在 SQL 查询中使用国密算法进行数据加密、解密和签名验证操作，提高数据安全性并满足合规要求，该任务将为 Cloudberry 用户提供更多的加密算法选择。,1. 支持 SM2/SM3/SM4 算法的 pgcrypto 扩展代码2. 全面的单元测试和集成测试，验证算法的正确性3. 性能测试报告，比较国密算法与现有加密算法的性能差异4. 详细的设计文档，包括算法实现原理和接口设计5. 用户文档，说明如何使用国密算法功能
优化客户端和服务器端的通讯方式,进阶,"[[""codelang"",""Programming Language""],[""safe"",""TCP/IP""],[""cloudnative"",""Distributed Storage""],[""os"",""CentOS""],[""os"",""GCC""],[""os"",""GDB""],[""os"",""GNU""],[""os"",""Linux""]]",目前volclava中客户端和主服务间使用的是select方式的 I/O 多路复用机制。服务器端接收请求后，如果请求是查询类型，则服务器端会fork子进程进行响应；如果请求是“操作类型”，那么主进程直接负责处理。这种方式，在高并发场景，尤其是连接数众多且有大量活跃连接的情况下导致服务器响应客户请求的速度慢。思考如何优化客户端和服务器通讯和响应方式，这是个开放的问题，没有具体的性能提升多少的要求，提供优化先后的单位时间服务器响应求情的数量对比。,1. 探究优化方案，构建相应方案的原型系统。变更通讯和响应机制后，客户端请求的响应表现显著改善，运行状态流畅且结果准确无误。量化评估优化方案在高并发场景下的响应速度提升效果。
基于Rust语言的轻量化TPM软件栈的实现,基础,"[[""os"",""Linux""]]",本项目针对传统 TPM 软件栈（TSS） 因 C 语言实现导致的内存安全隐患、代码冗余及性能瓶颈等问题，提出基于 Rust 语言重构轻量化 TSS 子集的解决方案。基于HyperEnclave现有的 TSS 实现虽功能完备，但存在潜在的内存安全问题和同步 I/O 效率低下等缺陷，而现有开源Rust生态中相关项目对TPM调用均以bind C 方式实现，并未实现全栈Rust。因此通过设计分层模块化架构（异步通信、零拷贝编解码、类型安全 API），本项目聚焦 TPM 2.0 核心功能（密钥管理、PCR 操作、数据密封），再结合 Rust 所有权模型与zeroize等安全库消除内存安全风险，利用异步实现高并发通信。最终目标为交付一个内存安全、兼容TCG规范且吞吐量提升 30% 的 Rust 原生 TSS 库，为机密计算基础设施提供更安全、高效的开发范式，推动硬件安全与现代系统语言的深度整合。,1. 开发一个轻量级、内存安全的 Rust 库，支持 TPM 2.0 基础功能（如密钥生成、数据密封/解封、PCR 操作），并验证其安全性和兼容性。
Apache Doris 分区功能增强,基础/Basic,"[[""datas"",""Database""]]",本项目旨在通过引入四大核心能力提升 Apache Doris 分区功能的易用性、扩展性和灵活性：这些改进将显著增强 Apache Doris 在大规模数据自动化管理场景下的能力，降低运维复杂度。,1. 实现批量分区操作2. 系统表元数据增强3. 动态分区前缀优化4. 表达式分区列（可选，高难度）
Casbin核心权限库改进（Go + Java）,进阶,"[[""cloudnative"",""Cloud Native""],[""safe"",""OAuth""]]",Casbin采用独特的PERM模型语法（model）来实现强大、灵活的访问控制。Casbin Golang版本作为Casbin的第一个语言实现，拥有最多的用户以及最先进的feature。我们希望在Casbin Golang上： 1）增强Casbin语法的表达能力，满足用户多样化的策略制定需求； 2）优化Casbin在大规模规则集上（百万以上）的策略评估性能。 jCasbin是Casbin的Java版本，它需要及时跟踪Golang Casbin主库的最新feature并移植到Java版本中来。同时维护Java特有的生态,1. 增强Casbin语法的表达能力，满足用户多样化的策略制定需求2. 优化Casbin在大规模规则集上（百万以上）的策略评估性能3. 跟踪Casbin-Go最新特性并移植到jCasbin4. 维护完善jCasbin的周边生态，如开发jCasbin的各类插件，便于与其他软件集成5. 解决Casbin-Go和jCasbin以及相关仓库中的issues
面向隐私-效用评测的云边协同大模型仿真环境,进阶/Advanced,"[[""datas"",""LLM""],[""datas"",""PyTorch""],[""cloudnative"",""Kubernetes""],[""datas"",""TensorFlow""]]",用户隐私保护是边侧大模型应用一大关键需求，这是因为传统云端LLM部署要求用户将敏感提示上传至远程服务器，造成严重隐私风险。然而，纯边缘部署的轻量级模型性能有限。本项目旨在基于KubeEdge-Ianvs的云边协同推理过程，对隐私保护和模型效用进行量化权衡，并提供仿真方法。,1. 基于KubeEdge-Ianvs中云边协同推理范式，设计并实现一套大模型隐私-效用权衡评估方法，包括模型效用指标和隐私保护指标2. 基于KubeEdge-Ianvs中云边协同推理范式，开发一个边缘仿真环境，用于评估各种提示重构攻击下的大模型算法鲁棒性3. （可选）基于KubeEdge-Ianvs中云边协同推理范式，提供针对不同边缘设备能力的资源优化适配方案
为 turnstile 实现兼容 logind 的会话管理 API,进阶/Advanced,"[[""os"",""Linux""]]",基于 Systemd 的 Linux 桌面环境中，许多关键组件（如 Polkit 用于权限管理，WirePlumber 用于音视频会话管理）依赖于 systemd-logind 提供的 D-Bus API 或 libsystemd C API 来追踪和查询用户 session 和 seat 信息。eweOS 和 Chimera Linux 用以管理用户 session 的 turnstile 目前缺乏一套 API 供应用程序查询会话和席位信息。这导致依赖这些 API 的桌面应用程序在 eweOS 等使用 turnstile 的系统上无法正常工作或功能受限。本项目旨在与 turnstile 的上游 (Chimera Linux) 进行沟通和协作，在 turnstile 中实现一套必要的会话管理 API，以让依赖 session 跟踪 API 的桌面应用程序能够运行在采用 turnstile 的 Linux 系统上，并最终在 eweOS 上启用那些因缺少该 API 而被禁用的功能。可选开发一个兼容层(wrapper library)以提供对现有依赖 libsystemd 风格 API 的应用程序的兼容性。,1. 调研必要的 API 集合2. 参与上游讨论，确认技术选型3. 功能实现4. 编写文档5. API 兼容层（可选但推荐）6. 测试与验证7. 代码贡献
移植RunC到DragonOS,进阶/Advanced,"[[""cloudnative"",""Docker""],[""cloudnative"",""Docker Compose""],[""cloudnative"",""Kubernetes""],[""cloudnative"",""Cloud Native""],[""os"",""Cgroups""],[""os"",""Linux""],[""os"",""x86""]]",DragonOS是一个面向云原生场景的OS，其核心目标是为容器化工作负载提供高度优化的运行环境。在容器生态中，runc作为符合OCI（开放容器倡议）标准的轻量级容器运行时，已成为Kubernetes等编排系统的核心组件。目前，DragonOS已支持overlayFS，并且，namespace、cgroup等内核特性的开发正在进行中。但是，这部分特性的支持仍然不完善或存在缺失，且runC所需的一些系统调用尚未实现。本选题目标为，完善DragonOS内核的namespace及cgroup等特性，并移植runC到DragonOS上，在DragonOS上创建一个符合OCI规范的容器,1. 协助完善DragonOS内核的PID/mount/network等namespace隔离机制2. 实现容器资源管理所需的cgroup v2基本功能模块3.  补全runC依赖的关键系统调用，基于DragonOS内核特性完成runC运行时的移植适配4. 在DragonOS上，运行符合OCI规范的容器（如busybox或其他任意的容器）5. 编写相关技术文档及结项报告
优化KubeEdge Dashboard数据处理逻辑，引入新特性,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""web"",""React""]]",在现有KubeEdge Dashboard的基础上，优化其数据处理逻辑。建立数据处理中间层，用于对数据进行预处理，并引入数据筛选、排序、分页等新功能，用以提升用户前端性能及用户体验,1. 引入具有数据筛选、排序、分页等功能的数据处理中间层，并在UI界面中加入相关操作2. 在数据处理中间层中预处理前端展示的数据，减少数据传输量，以提升用户体验3. 对资源创建、更新等操作进行数据的校验4. 优化现有网络请求逻辑
基于MoonBit和TEA架构的UI组件库,基础/Basic,"[[""web"",""Web Application""],[""web"",""UI""]]",该项目将基于MoonBit的前端框架rabbitTEA，实现一套常见UI组件。组件包括Accordion、Alert、Avatar、Badge、Breadcrumbs、Button等等。UI的样式使用tailwindCSS编写，设计风格参考material-tailwind 组件库。支持响应式布局。,1.使用MoonBit和RabbitTEA开发一套常见UI组件库，封装方式和接口符合TEA的设计风格。
基于转录组表达建模的药物扰动大模型开发,进阶,"[[""datas"",""AI""]]",药物扰动对细胞状态的影响是精准医学的重要基础。随着技术的发展，能够在一定分辨率下观测药物处理前后的转录响应，捕捉不同细胞类型对干预的异质性反应。本项目拟开发一个面向药物扰动数据的大模型框架，借鉴语言模型思想，将药物、细胞系状态类比为“词语”，基因表达变化建模为“句子”，引入类CLS-token以捕捉全局扰动特征。模型将同时支持表达谱预测、扰动相似性计算、responder分类、等多任务学习，实现从 bulk 到单细胞场景的泛化与迁移。最终模型将为药物筛选、机制推断、虚拟药物敲除等任务提供统一建模框架。,1. 完成一套基于 Mindspore 的药物扰动建模大模型框架，实现支持 AnnData 格式数据的处理、训练、推理、结果可视化等完整工作流，模型支持多种下游任务，包括表达预测、方向性判断、虚拟筛选；预训练模型在公开数据（如 LINCS L1000）上性能达到 SOTA；输出技术报告，形成模型库与应用指南，具备转化潜力。
面向openEuler distroless镜像的SDF自动生成工具开发,进阶,"[[""cloudnative"",""Cloud Native""],[""codelang"",""Programming Language""]]",（1）相关背景Distroless镜像是一种精简的容器镜像，旨在最小化容器的大小和攻击面。与一般的容器镜像不同，distroless镜像不包含操作系统的许多组件，只包含运行应用程序所需的最小依赖项。openEuler社区陆续通过EulerPublisher和splitter发布了多个语言类distroless容器镜像。社区制作distroless镜像的基本思路是：首先，使用splitter将openEuler软件包在逻辑概念上分成一个个小粒度的slice，如下图所示输入图片说明这样，软件包B依赖于软件包A等价于B_slice1和B_slice2依赖于A_slice1、A_slice2，在生成B的应用镜像时，可以不再打包A_slice3所包含的文件。然后，EulerPublisher使用slice作为原材料来构建Distroless镜像。（2）已有的工作splitter根据Slice Definition File（SDF）来将软件包切分成slice，其中24.03-LTS分支已由人工构建部分SDF。（3）存在的不足当前SDF均由人工手动构造，效率低下，难以满足多版本、多软件SDF的生成需求（4）希望改进的点SDF可以自动生成（5）最终项目实现的目标开发自动生成openEuler软件包SDF的工具,1. 开发自动生成openEuler软件包SDF的工具，要求：
Kmesh-daemon升级流量无中断,进阶/Advanced,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""],[""os"",""Linux""]]",Kmesh 是一种基于 eBPF 和可编程内核的高性能、低开销服务网格数据平面。而Kmesh-Damon作为kmesh用户态的管理程序，负责与控制面的通信和下发网格的配置。在之前的版本中Kmesh已经实现了kmesh-daemon重启的时候不会中断已经建立的链接，也能够按照之前的策略进行流量治理。现在希望将这个便利的功能能够覆盖Kmesh-daemon升级的场景。在Kmesh-daemon升级的时候也能够做到流量无中断的效果。现在的瓶颈是如何比较升级前后的bpf map的结构是否发生了变化。,1. 功能实现代码2. 文档3. 测试代码
基于MindSpore生成式套件的虚拟试衣SOTA模型复现+应用案例开发,进阶,"[[""datas"",""AI""]]",随着虚拟试衣技术需求日益增长，MindDiffusion套件凭借其在图像生成任务中的强大性能，可以为虚拟试衣提供了新的解决方案。复现基于MindDiffusion的虚拟试衣SOTA模型，不仅能验证其在该领域的适用性，还能为后续优化提供基础。复现过程虽面临数据集、模型架构和训练成本等挑战，但也带来了结合新技术提升性能和效率的机遇，对推动虚拟试衣技术发展具有重要意义。,1.参与调研业界diffusion models toolkit，并实现相关API2. 追踪最新diffusion model论文，并基于MindSpore框架复现相关SOTA模型3. 开发一个虚拟试衣镜的应用，能够实现生成试衣效果
完善TinyVue对于nuxt工程的全面支持,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]","SSR服务端渲染在首屏加载性能、SEO等方面存在一定的优势，因此也有很多应用场景，完善TinyVue对于nuxt工程的全面支持，适配剩余暂时不支持ssr的组件（file-upload、pop-upload、mindMap、huichart）,增加全局ID配置，ZIndex管理、Teleport处理等功能，可以参考elements-plus的SSR章节。",1. 适配剩余暂时不支持ssr的组件（file-upload、pop-upload、mindMap、huichart）。2. 增加全局ID配置，因为不同的 IDs 容易发生SSR中的水合率错误3. 增加ZIndex管理，在SSR适配过程中可以能会遇到 z-index 引起的水合错误4. 增加 Teleport 处理，有多个组件使用到了 Teleport ，所以在SSR期间需要特殊处理。（如果不用改源码，可以供给解决方案文档）5. 补充对应的使用文档，并跑通TinyVue已经提供的E2E测试用例6. 将以上特性集成到 TinyVue Nuxt 模块中，给用户提供开箱即用的 Nuxt 模块7. 确保代码符合项目规范，有完整的TypeScript类型声明8. 建议输出完善TinyVue对于nuxt工程的全面支持的介绍文章和视频
Qudit 界面支持,进阶/Advanced,"[[""datas"",""TensorFlow""],[""datas"",""PyTorch""],[""datas"",""GPU""]]","TensorCircuit 主要专注于基于量子比特的量子线路。虽然存在一些变通方法来模拟量子d维系统（qudit），（），但这些方法通常不够直观，并且未能充分利用 TensorCircuit-NG 接口的优雅性。这一局限性影响了对探索基于 qudit 量子计算感兴趣的用户，例如：*   **专为量子d维系统设计的量子算法：** 某些量子算法自然地使用量子d维系统进行表述，并且可能效率更高（例如，一些量子行走、高维量子信息处理）。*   **具有更高维度自由度的物理系统的模拟：** 在量子化学或凝聚态物理中，对系统进行建模可能会受益于直接使用量子d维系统表示。*   **量子信息理论研究：** 探索更高维度量子系统的理论优势需要用于操纵和模拟量子d维系统线路的工具。本项目旨在通过提供以下功能来解决这些局限性：*   **原生量子d维系统线路表示：** 将引入一个新的类 `tc.QuditCircuit` 来表示由量子d维系统组成的量子线路。*   **直观的用户界面：** 该界面应与现有的用于量子比特的 `tc.Circuit` 保持一致，从而允许用户平滑过渡，并利用现有的 TensorCircuit 功能。目标接口是 `tc.QuditCircuit(n_qudits, d=dimension)`。*   **高效的模拟：** 利用 TensorCircuit 的张量网络功能来确保对量子d维系统线路的高效模拟，并可能针对量子d维系统特定的操作进行优化。如果可能，还可以实现带有 `tc.MPSQuditCircuit` 接口的 MPS + 量子d维系统模拟。*   **可扩展性：** 将框架设计为可扩展的，从而允许将来添加新的量子d维系统门和功能。本项目的范围侧重于：*   **核心 `QuditCircuit` 类：** 实现用于定义量子d维系统线路的基本结构和功能。*   **基本量子d维系统门：** 实现一组基本的量子d维系统门，这些门可以在 https://arxiv.org/abs/2501.07812 中找到。*   **状态准备和测量：** 支持量子d维系统状态的初始化以及在计算基中的测量。*   **与现有 TensorCircuit 功能集成：** 确保与现有的 TensorCircuit 功能兼容，例如自动微分、JIT 和 GPU 支持，这些功能应该会在成功实现的情况下自动工作。","1. 基本界面及对应的文档测试案例

import tensorcircuit as tc
import numpy as np

# Create a qudit circuit with 3 qudits, dimension d=3
n_qudits = 3
d = 3
qc = tc.QuditCircuit(n_qudits, d=d)

# Apply a generalized Pauli-X gate on qudit 0
qc.x(0) # Generalized X, equivalent to cyclic permutation

# Apply a generalized Hadamard gate on qudit 1
qc.h(1) # Generalized Hadamard

# Apply a controlled-phase gate between qudit 0 (control) and qudit 2 (target)
phase = np.exp(1j * np.pi / 4)
qc.cphase(0, 2, phase=phase)


# Get the state vector of the qudit circuit
state_vector = qc.state()

# Measure qudit 0 in the computational basis
measurement_result = qc.measure(0)2. MPS qudit 界面支持

c = tc.MPSQuditCircuit(N, d)"
基于MindSpore Transformers实现AI孪生人Second Me,进阶,"[[""datas"",""AI""]]",Second Me 是一个开源AI身份系统，旨在为用户创建完全私有的个性化AI代理。它不仅仅是一个AI助手，而是一个能够代表用户真实自我的数字分身。通过本地训练和部署，Second Me 确保用户的数据完全由自己掌控，避免了传统AI系统中数据被大公司掌控的风险。,"1、利用GiteeAI里的QwQ-32B（或其他MindSpore模型）做数据合成及对齐
2、从MindSpore Transformers里挑选合适的Base模型作为Second Me的模型进行训练
3、提供简单清晰的模型推理UI界面"
ArceOS：基于Rust的组件化Unikernel架构操作系统内核,基础/Basic,"[[""os"",""RTOS""],[""codelang"",""Programming Language""],[""os"",""QEMU""],[""os"",""Linux""]]","随着AI、物联网、AIoT等领域的快速发展，根据某个特定场景，对操作系统进行改造和定制的工作一直是人们关注的热 点。通过分析不同的场景，开发者调整内核的架构设计，选择性的强化或者忽略 某些部分的功能，从而更好地发挥对应场景下的特点。但当前的操作系统内核难以适应这种多样化的需求。组件化Unikernel架构操作系统内核ArceOS由清华大学陈渝老师操作系统实验室团队贾越凯博士等主持开发，它使用Rust语言编写，旨在通过组件化的设计思想，提供一个灵活、可定制的内核，满足不同应用乃至不同场景的需求。项目开源代码可以在Github上（ https://github.com/arceos-org/arceos ）获取。ArceOS作为组件化操作系统，有着灵活的可定制性功能，利用Rust的条件编译机制，完成对ArceOS的不同模块的功能定制，即通过开发者传入的feature信息，将它传递给模块层和元件层的不同模块中，从而实现对整体内核的条件编译，达到Unikernel要求的最简化内核镜像的要求。ArceOS由多层功能组件组成，每层的基本功能如下：1. 元件层（ArceOS crates）：由 ArceOS 开发者开发的、与内核无关的组件库。任意内核都可以尝试接入这些组件，而几乎不需要对组件本身的内容进行修改。绝大多数组件均发布到了crates.io上，可以便捷地为其他开发者复用。2. 模块层（ArceOSmodules）：与ArceOS相关的组件库。它包括了各类内核基本功能组件，如内存管理、调度器、IO设备驱动等，可认为是传统意义上的“内核”,用来管理硬件并为应用提供服务。3. API 层（ArceOS API）：将模块层的功能封装为API的形式，以供应用程序调用。ArceOS为Rust和C语言编写的应用程序分别提供了不同的API，并针对语言的特点做了快速路径优化。4. 内核级用户库层（Kernel-level ArceOSulib）：进一步封装API层提供的功能，提供对Rust标准库、libc 库等已有内核级用户库的兼容，以便内核级应用程序的移植。5. 内核级应用程序层（Kernel-level UserApps）：目前ArceOS提供了对Rust和C这两种语言编写的内核级应用程序源码级别的支持。当前ArceOS由几十个相对独立的内核级Crates组成，并支持基于其的组件化宏内核、Hypervisor、微内核等操作系统的开发，为面向AI、物联网、AIoT等领域的新一代操作系统的开发提出了新的思路和实现方法。为支持同学们高效地学习Rust编程、组件化操作系统内核等知识，掌握基于Rust开发操作系统内核的能力，我们提供了对应的开源操作系统训练营（ https://opencamp.cn/os2edu/camp/2025spring  https://github.com/learningos ），帮助大家学习和提升能力。",1. ArceOS Tutorial Book扩展改进完善2. ArceOS基础实验实例扩展改进完善3. ArceOS 在github/gitlab/gitee/gitlink等上CI/CD支持4. 撰写组成ArceOS的内核功能Crates的分析文档5. 改进完善组成ArceOS的内核功能Crates的功能/性能/安全性6. 移植组成ArceOS的内核功能Crates到x86/arm/riscv/loongarch的开发板上7. 改进ArceOS与组件化宏内核的接口设计与实现8. 改进ArceOS与组件化hypervisor的接口设计与实现
支持RISC-V架构的Casibase AI知识库系统,进阶,"[[""os"",""RISC-V""],[""datas"",""AI""],[""datas"",""Database""]]",Casibase是一套开源的AI云操作系统，适合个人或者组织作为自己的专属内部AI知识库来使用。用户可以在Casibase上创建、编辑、分享和管理知识库。本项目将致力于将Casibase适配到RISC-V架构，优化其在RISC-V下的性能表现，以满足物联网、嵌入式等RISC-V应用场景下的知识库需求。主要目标包括：1. RISC-V架构支持：使Casibase后端服务可以在RISC-V64架构下编译运行。提供RISC-V64的Docker镜像。2. 跨平台前端适配：优化前端，提高在RISC-V等资源受限平台的运行效率，降低内存占用。3. 知识组织与AI功能增强：优化知识库文档的组织结构和分类方式，提高检索效率。改进搜索算法和推荐机制，提升搜索结果的准确性和相关性。集成更多AI模型接口，丰富知识处理和应用场景。4. 用户体验优化：优化、美化Casibase的Web管理界面，提供更友好、直观的用户交互体验。5. 性能优化与测试：在RISC-V开发板或者QEMU模拟器上，对Casibase进行性能测试，找出性能瓶颈并优化。,1. 实现Casibase在RISC-V64架构下的运行，并提供二进制包和Docker镜像2. 优化Casibase前端，提高其在资源受限环境下的性能表现3. 集成更多AI模型接口，丰富知识处理和应用场景4. 优化、美化Casibase的Web管理界面，提供更友好、直观的用户交互体验5. 在RISC-V开发板或QEMU环境下，对Casibase进行性能测试6. 解决Casibase主仓库&相关仓库中的issues（数量至少7个）：https://github.com/casibase/casibase/issues
openGauss向量数据库对接Embedding模型最佳实践,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",使用HuggingFace、Cohere 、BentoML嵌入式模型对文本进行向量化，保存至openGauss，并构建索引、对接大模型完成知识问答RAG端到端验证，输出RAG最佳实践文档。,1. 基于openGauss 容器部署指导文档、分别完成 HuggingFace、Cohere 、BentoML部署指导文档，基于docker完成服务部署。编写应用代码，HuggingFace、Cohere 、BentoML嵌入模型对接openGauss。2. 对接LLMs，完成基于openGauss的知识问答RAG端到端验证，并输出对接文档，对接文档需合入openGauss社区。
Clang 编译 GLIBC 支持,进阶,"[[""os"",""Compiler""]]","目前isocut工具在RISC-V环境下参考官方文档操作，只有部分场景验证可以正常运行，需要对失败场景进行修复，并补充文档清楚描述本项目背景以及要做什么。（1）相关背景isocut工具在RISC-V环境下进行ISO镜像裁减，定制化，生成的ISO需在qemu环境下安装运行（2）已有的工作根据官方文档场景一和场景二都可以正常安装运行（3）存在的不足根据官方文档，但是场景三存在问题，定制后的ISO不能正常安装运行（4）希望改进的点修复场景三的问题，并完善当前的文档（5）最终项目实现的目标isocut工具在RISC-V环境下对ISO镜像进行定制化裁减出的ISO,安装后的系统可以正常运行，并有详细的参考文档主要的问题包括：（1）Clang和GCC对于部分语法的理解有问题（2）Clang不支持部分GCC的builtin函数（3）Clang处理浮点数时，对于一些边缘情况处理错误（4）其他很多情况已有工作:Glibc的主要维护者之一 azanella 已经进行了很多的工作https://sourceware.org/git/?p=glibc.git;a=shortlog;h=refs/heads/azanella/clang","1. 有可能需要修复LLVM，也有可能需要修复Glibc。

最终实现使用LLVM编译GLIBC。
并且可以通过GLIBC所有的单元测试。

1）修复当前的编译失败和测试失败
2）分析 azanella 仓库中对Glibc的修改，分析实际上应该对LLVM进行的修改，相应修复LLVM
3）向LLVM提交修复补丁 （Github PR）
4）向Glibc提交修复补丁（libc-alpha邮件列表）"
P2P 基于感知带宽的节点侧二次调度,基础,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""]]",Dragonfly 是一款基于 P2P 的高效、稳定、安全的文件分发和图片加速工具。但是，目前下载 Dragonfly 文件片段的 Parent 选择方法基于 FCFS 方法（即，首先从哪个 Parent 获取某个 Piece 元数据，然后从该 Parent 下载相应的 Piece）。这种选点方式无法动态感知 Parent 节点状态（网络带宽、磁盘 IO）的变化，无法充分利用带宽资源。本课题需要从节点侧感知 Parent 网络带宽、磁盘 IO 等进行二次调度，提升整体带宽利用率。,1. 完整的方案设计。 2. 支持节点侧感知 Parent 网络带宽、磁盘 IO 等进行二次调度。 3. 需要完成 Unit testing、Benchmark、E2E testing。 4. 根据 Benchmark 优化带宽利用率。
LLVM内核地址消毒功能增强：支持riscv32架构的OpenHarmony轻量系统内核,进阶,"[[""os"",""RISC-V""],[""os"",""LLVM""]]",KASAN(Kernel Address Sanitizer) 是动态内存错误检测工具，支持‌内存越界访问‌、使用已释放的内存‌、‌无效的内存释放操作‌的检测。OpenHarmony轻量系统内核支持地址消毒，有效解决踩内存问题，提升项目开发效率。OpenHarmony 轻量系统内核已经支持 KASAN 功能，即 LMS(Lite Memory Sanitizer)，但缺少 LLVM 编译器内存检测插桩功能的支持。希望 LLVM KASAN 支持 riscv32 芯片架构（LLVM已经支持arch64、arm、riscv64等），最终实现 riscv32 架构的 OpenHarmony 轻量系统内核支持地址消毒功能。,1. LLVM KASAN 支持 riscv32 芯片架构。2. clang 编译 riscv32 程序支持 -fsanitize=kernel-address 选项，并完成内存检测函数插桩。3. 在 OpenHarmony 轻量系统内核开启LMS功能下，clang 使用 -fsanitize=kernel-address 选项编译测试程序，测试程序在 OpenHarmony 轻量系统平台运行，检测到内存越界访问等错误时报错并打印输出动态内存错误相关信息。
基于 KEDA 实现 llmaz Serverless 弹性扩展,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""datas"",""LLM""],[""dev"",""LLMOps""],[""dev"",""MLOps""]]",（1）相关背景：llmaz 是一个基于大语言模型的推理平台开源项目（架构因其按需分配资源、自动弹性扩展的特性，成为优化成本和性能的理想选择。KEDA（Kubernetes Event-Driven Autoscaling）是一个事件驱动的自动扩展框架，能够与 Kubernetes 集成，支持多种触发器实现弹性扩展。（2）已有的工作：llmaz 当前主要依赖手动配置的 Kubernetes 集群进行资源管理和部署，模型推理服务通过固定分配的 Pod 提供支持。KEDA 已被广泛应用于 Kubernetes 生态，支持基于 CPU、内存或外部事件（如消息队列）的自动扩展，但 llmaz 项目尚未集成 KEDA 或实现 Serverless 能力。（3）存在的不足：当前 llmaz 的部署方式需要预先分配固定资源，无法根据实际负载动态调整，导致资源利用率低或高负载时响应延迟增加。此外，手动管理 Pod 的扩展和缩减增加了运维复杂度，且不支持从零到一的弹性能力，难以实现真正的 Serverless 架构。（4）希望改进的点：通过集成 KEDA，llmaz 可以基于负载事件（如 HTTP 请求量、队列消息数）实现自动扩展和收缩，支持从零实例到多实例的动态调整。同时，优化资源分配逻辑，降低空闲时的资源浪费，提升高负载时的响应性能，简化运维流程。（5）最终项目实现的目标：基于 KEDA 实现 llmaz 的 Serverless 弹性扩展能力，支持事件驱动的自动伸缩，优化资源利用率，提供从零到一的动态实例管理，最终构建一个高效、低成本、易运维的 Serverless 大语言模型推理服务平台。,"1. 为 llmaz 集成 KEDA 实现事件驱动的自动弹性扩展功能。
2. 开发轻量级 KEDA 触发器配置，支持 HTTP 请求和队列负载扩展。
3. 为 llmaz 提供从零到一的 Serverless 实例管理能力。
4. 基于 KEDA 自动化优化 llmaz 资源分配与回收机制。
5. 编写 llmaz Serverless 部署说明文档，输出性能测试报告（从0到1的冷启动时间）。"
实现Nginx配置到Higress配置转换的MCP Server逻辑,基础/Basic,"[[""datas"",""AI""]]",在AI时代，对网关的需求已经远远超越了传统的路由和负载均衡功能，形成了AI网关的形态。AI网关可以为AI应用开发者提供便利，统一不同 LLM 提供商的 API 协议，并提供API编排、安全、稳定性和成本控制等扩展功能。Higress 作为 AI 原生的 API 网关，在 v2.1.0 版本开源了 MCP Server 托管解决方案，基于当前版本的 OPS Mcp Server进行扩展，实现 Ingress Nginx 配置到 Higress 路由配置的自动转换，方便用户快速从 Nginx 迁移至 Higress。Nginx 的配置说明文档：https://nginx.org/en/docs/dirindex.htmlHigress 的文档：https://higress.cn/docs/latest/overview/what-is-higress/,1. 扩展 Higress OPS Mcp Server，实现 Nginx 配置自动转换，方便用户快速从Nginx迁移至Higress
为Cloudpods实现MCP Server,进阶,"[[""dev"",""AIOps""],[""web"",""RESTful API""],[""dev"",""DevOps""],[""os"",""Linux""]]",Cloudpods支持各大公有云同步及创建网络及虚拟机资源，希望可以实现MCP Server支持查询资源信息及创建虚拟机资源，用户可借助Cloudpods MCP Server开箱即用，通过自然语言交互，快速完成复杂运维任务,"1. 实现MCP Server服务2. 支持通过MCP Server实现查询Cloudpods 区域，VPC, 子网，镜像，套餐，存储，虚拟机实例等资源能力
支持通过MCP Server实现虚拟机开关机，重置密码，删除能力3. 可选项4.  产出Cloudpods MCP Server使用样例文档。"
基于框内核架构的Rust教学操作系统,进阶,"[[""os"",""Linux""]]",本项目基于Asterinas提出的框内核架构以及OSTD & OSDK开发套件实现一套新操作系统教学材料，预计总30学时左右，从熟悉的环境--类似普通应用程序的开发开始，以模块化的形式了解操作系统知识。材料配套6次作业与一次大型project。传统教学系统如xv6采用C语言开发，难以体现现代操作系统安全方面的发展；rCore虽使用Rust系统安全语言，但需要初学者在了解启动以及中断等难度较高的代码后，才能接触操作系统的核心，使得入门门槛较高。因此，目前需要一个使用Rust语言，且能上手门槛较低的操作系统教学材料。以下是教学的大纲以及作业安排（迭代中可能会有改动）。需要设计15套教学材料（文档和代码），每套覆盖两个课时；6次作业（包含代码和解析）；以及1次大型的课程项目（包含代码和解析）。,1. 基于Asterinas提出的框内核架构以及OSTD & OSDK开发套件实现一套新操作系统教学材料
为 NebulaGraph 支持 Airbyte,基础/Basic,"[[""datas"",""Database""],[""datas"",""Graph Database""],[""datas"",""MySQL""],[""cloudnative"",""Distributed Storage""]]",Airbyte 是一款领先的数据集成平台，专注于构建和管理 ETL（提取、转换、加载） 或 ELT（提取、加载、转换） 数据管道，帮助用户将来自多种源头（如 API、数据库、文件等）的数据高效迁移到现代数据存储与分析平台，包括 数据仓库、数据湖以及新兴的 数据湖仓等。NebulaGraph 是一款开源的、分布式的、易扩展的原生图数据库，能够承载包含数千亿个点和数万亿条边的超大规模数据集，并且提供毫秒级查询。期望在 NebulaGraph 上增加对 Airbyte 的支持，方便用户可以通过 Airbyte 将各种数据源的数据，导入到 NebulaGraph 中。,1. 增加 Airbyte 的 Writer，支持数据通过 Airbyte 从 Mysql 到 Nebulagraph 的迁移2. 代码能够合入到 Airbyte 仓库，满足相关开发测试规范
基于分布式图计算的自适应Path结构优化,进阶,"[[""datas"",""Graph Database""],[""web"",""GraphQL""]]",在分布式图计算领域，随着图数据规模的快速增长和复杂查询需求的增加（如路径搜索、子图匹配等），如何高效地处理大规模图上的路径匹配问题成为关键挑战。传统的静态Path结构在面对动态图或异构图时往往表现出性能瓶颈，尤其是在分布式环境下，节点间的通信开销和负载不均衡问题进一步加剧了计算成本。因此，设计一种能够根据图特征和查询模式动态调整的自适应Path结构，对于提升分布式图计算系统的性能至关重要。本课题旨在探索并实现一种针对分布式图计算优化的自适应Path结构，通过结合图分割策略、查询模式分析以及动态路径剪枝技术，显著降低路径匹配过程中的计算与通信开销，同时支持高效的分布式执行。3.  构建一个结合实际应用场景的分布式路径匹配演示系统，展示自适应Path结构在性能上的提升效果。本课题聚焦于分布式图计算领域中的路径匹配优化问题，通过设计和实现自适应Path结构，解决传统静态路径结构在性能和扩展性上的不足。项目不仅具有理论研究价值，还能够为实际应用提供高效的解决方案，是分布式图计算领域的前沿研究方向之一。,1.  技术设计文档（包含架构图、算法流程说明、API设计等内容）。2.  自适应Path结构实现源代码（核心模块代码，需包含详细的注释和单元测试）。3.  分布式路径匹配算法实现（至少实现一种优化后的分布式路径匹配算法）。4.  性能Benchmark测试报告（对比传统静态Path结构与自适应Path结构在不同场景下的性能表现，如计算时间、通信开销、内存使用等）。5.  分布式路径匹配Demo（展示自适应Path结构在实际应用中的优势，例如社交网络分析、推荐系统中的路径查询等）。
Apache Shenyu AI Proxy Plugin 能力增强,进阶,"[[""web"",""Spring Boot""],[""datas"",""AI""]]","Apache ShenYu 是一个高性能、开源的API Gateway，其核心优势之一在于其灵活的插件系统。通过开发新的插件，可以方便地扩展Gateway的功能。Apache ShenYu AI Plugin，是 Apache Shenyu 对 AI 模型接口进行代理的插件，此插件使得 ShenYu 能够轻松地与各种公有云AI服务（如OpenAI, DeepSeek等）或私有化部署的AI模型集成。目前插件的内容比较简单直接，没有集成主流的 Spring AI 框架的能力，在与AI交互调用的过程中还可以再做增强，可以补充如下内容：",1. 支持配置AI调用降级， 若高级别模型调用受限，则降级为调用未受限的低级别模型2. 支持记录会话历史， 支持记录会话历史，存储到本地内存或其他中间件（如redis）3. 支持配置代理apiKey，并支持设置apiKey调用限额，在真实apiKey的基础上，支持生成代理key，并支持为每个代理key设置调用限额4. 支持AI模型调用缓存， 支持AI模型调用缓存，根据请求内容的语义缓存AI模型返回的内容，相同的请求直接从缓存返回，减少AI tokens消耗
Implement the MCP for Pulsar Admin Tool,Advanced,"[[""datas"",""AI""],[""datas"",""Kafka""],[""datas"",""Zookeeper""]]","Apache Pulsar is a distributed messaging and streaming platform thatprovides a highly flexible pub-sub model. The pulsar-admin tool isused for managing and monitoring Pulsar clusters. On the other hand,the Model Context Protocol (MCP) is designed to enable seamlessinteraction between software components and large language models.This project aims to integrate pulsar-admin with MCP, allowing usersto interact with Pulsar clusters using natural language commands. Thisintegration will revolutionize cluster management, making it moreaccessible and user-friendly. The project involves implementing theMCP interface for pulsar-admin to interpret and execute everydaylanguage commands.",1. Develop a working MCP implementation for pulsar-admin2. Provide comprehensive documentation for integration and usage3. Provide example use cases or demos demonstrating natural language interactions with pulsar-admin.
Spring Cloud 2024 版本、2025 版本及第三方组件适配升级,基础,"[[""web"",""Spring Cloud""]]",1. 项目背景在 2025 年初，Spring Cloud 官方社区发布了 2024 正式版本、2025 RC 版本，最新版本带来了大量组件更新、能力升级等，包括底层 Spring Boot 也升级到了 3.x 最新版本 Spring Cloud Alibaba 社区当前最新版本是 2023.0.1.0，对应到 Spring Cloud 2023 版本。除了底层 Spring Cloud 抽象之外，Nacos、RocketMQ 等生态组件近期也发布了部分版本升级。2. 学生职责&目标在这个项目中，学生需要同社区开发者一起合作，发布 Spring Cloud Alibaba 2024 版本、2025 RC 版本。要完成的核心工作包括调研并分享 Spring Cloud、Nacos 等的最新版本情况，完成 Spring Cloud Alibaba 适配并完成测试，编写新版本文档。3. 学生要求&技术栈,1. 在这个项目中，学生需要同社区开发者一起合作，发布 Spring Cloud Alibaba 2024 版本、2025 RC 版本。要完成的核心工作包括调研并分享 Spring Cloud、Nacos 等的最新版本情况，完成 Spring Cloud Alibaba 适配并完成测试，编写新版本文档。
bsub -a支持指定具体esub application,基础,"[[""cloudnative"",""Distributed Storage""],[""os"",""CentOS""],[""os"",""GCC""],[""os"",""GDB""],[""os"",""GNU""],[""os"",""Linux""],[""os"",""Ubuntu""],[""safe"",""TCP/IP""],[""codelang"",""Programming Language""]]",是EDA领域非常常用的功能，通常用于通过验证或预解析命令行，来实施特定作业提交策略和命令行语法规则。目前volclava支持了esub，但是不支持bsub -a指定某个或者某几个esub。以下是项目背景esub简介：“esub” 是一个用户自定义编写的可执行文件，对于volclava来说，它不关心用户在esub中实现的逻辑，只是负责提交作业时运行它。以下是一些常使用 “esub” 来完成的事情：1. 验证作业选项。2. 更改由用户指定的作业选项。3. 在提交主机上更改用户环境变量（仅在作业提交时）。4. 拒绝作业（仅在作业提交时）。5. 自动设定作业资源需求。当用户使用 “bsub” 提交作业、使用 “bmod” 修改作业或者brestart重启作业时，在作业被接受之前，volclava会在提交主机上运行 “esub” 可执行文件，以完成相关作业预制操作，例如用户提交作业时使用了诸如 “-R”（用于指定所需资源）或 “-q”（用于指定队列）等选项，“esub” 可以更改这些选项的值，以符合集群资源使用策略。volclava需要为用户的esub可执行文件提供以环境变量形式的如下接口：LSB_SUB_PARM_FILE 文件会包含如下内容：下面是使用这些volclava提供的接口，用于判断和修改作业选项的esub例子：：现在bsub -a 只是为了把格外信息通过环境变量LSB_SUB_ADDITIONAL传给esub脚本。现在我们要利用-a option，指定一个或多个特定于应用程序的esub可执行文件给作业。例如：-a 的值必须与实际的 esub文件的应用程序名称相对应。例如，要使用 bsub -a fluent 命令，esub.fluent 文件必须存在于 volclava_SERVERDIR 目录中。例如，要提交一个调用特定应用程序的 esub可执行文件的作业，这些可执行文件名为 esub.license以及 esub.fluent：如果在 LSF_SERVERDIR 目录中存在名为 esub（文件名中不包含 .应用程序名称）的可执行文件，volclava会首先调用它。接着，会调用lsf.conf 文件中使用 LSB_ESUB_METHOD 参数定义的任何必需的 esub之后，再调用由 -a 参数指定的任何特定于应用程序的 esub 可执行文件（文件名中包含 .应用程序名称）。,"1. lsf.conf添加新参数LSB_ESUB_METHOD，用于指定默认esub list
2. bsub -a/bmod -a/brestart -a指定某个或者某几个esub；
3. 如果多处配置esub，则需按着LSF_SERVERDIR/esub->LSB_ESUB_METHOD->command -a app_list 依次执行。"
基于pprof和skywalking-go进行性能监控,进阶/Advanced,"[[""dev"",""DevOps""],[""os"",""x86""],[""cloudnative"",""Kubernetes""],[""web"",""UI""],[""web"",""UX""]]","在目前skywalking-go的基础上, 利用pprof相关API可以对CPU, 内存, Block, Mutex等内容进行性能监控, 并将结果进行分析在UI中生成火焰图。此功能为分析目标应用（go应用，非skywalking本身）性能。此功能为新功能，需要和导师沟通功能范围，和提交设计和实现方案。","1. 完成SkyWalking go中的性能分析, 可以在UI中展示, 并且完成E2E自动化验证"
面向ARM CCA的Spectre漏洞硬件辅助模糊测试方法,进阶/Advanced,"[[""os"",""ARM""],[""os"",""LLVM""]]",（1）相关背景随着ARM机密计算架构（CCA）的普及，Trust OS的隔离环境成为新型Spectre变种（如Spectre-BHB）的攻击目标。传统模糊测试方法在ARM CCA场景下面临以下挑战：跨域检测盲区：Normal世界与Realm世界隔离机制阻碍了硬件事件的全局监控。低效随机变异：常规syscall序列生成难以触发依赖特定硬件微架构状态的条件竞争。动态窗口捕获难：推测执行漏洞的时间窗口极短（纳秒级），传统工具无法精准捕捉。（2）已有的工作OpenEuler CCA已实现Realm管理扩展（RME）与安全监控框架。Syzkaller社区支持ARM64架构的syscall模糊测试，但缺乏硬件反馈机制。Exorcist项目（Intel平台）通过PEBS事件检测Spectre漏洞，验证了硬件辅助检测的可行性。（3）存在的不足硬件反馈缺失：现有测试工具无法利用ARM PMU事件实时优化syscall变异策略。攻击流碎片化：Spectre变种的PoC依赖人工编写，难以覆盖跨安全域（如Realm→Normal）的复杂场景。误报率高：随机生成的syscall序列中，仅不足5%能有效触发推测执行异常。（4）希望改进的点硬件特征驱动的syscall生成：通过ARM PMU监控BR_MIS_PRED_RETIRED（分支预测错误）与L2D_CACHE_REFILL（缓存未命中）事件，动态调整syscall变异权重。设计“训练-触发-泄露”三阶段攻击模板，将Spectre变种抽象为可参数化的syscall序列模式。跨域协同检测：在Realm世界部署轻量级PMU监控代理，通过SMC调用将硬件事件传递至Normal世界的测试框架。利用ARM FEAT_TRBE（Trace Buffer Extension）实现低开销（<5%）的持续追踪。混合式验证引擎：结合Syzkaller的覆盖引导与符号执行（KLEE），生成边界值测试用例（如超大内存偏移、非法权限组合）。（5）最终项目实现的目标构建ARM CCA场景下的Spectre漏洞检测框架，误报率≤15%，检出效率提升4倍。开发兼容OpenEuler CCA的exorcist-arm组件，支持10+种Spectre变种（含V1/V2/BHB/RSB）。提交自动化测试套件与《ARM CCA推测执行漏洞防御指南》。,"1. 核心代码：
ARM PMU事件反馈引擎（Go实现，集成至OpenEuler CCA监控模块）。
Spectre攻击流模板库（含参数化syscall序列生成器）。
Syzkaller扩展插件syzkaller-hwfeed，支持硬件事件驱动的变异策略。2. 测试验证：
跨安全域（Realm/Normal）PoC测试套件，覆盖5种以上Spectre变种。
性能对比报告（与传统方法在误报率、检出速度等维度的量化对比）。3. 文档输出：
《ARM PMU事件与Spectre漏洞映射表》技术文档。
漏洞检测框架集成指南（提交至OpenEuler CSA仓库Wiki）。"
RustSBI原型系统引导生态完善,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""]]",RustSBI原型系统是使用Rust语言编写的RISC-V架构引导程序和运行环境，能够以机器态的特权级支持常见的操作系统运行。目前RustSBI已经支持与U-Boot引导程序配合启动Linux内核及及常见发行版。RustSBI原型系统引导生态完善项目包括两个方面，可任选一项或同时完成：EDK II引导程序适配：EDK II是常用的UEFI开源实现，它对RISC-V有初步的支持。本项目要求将RustSBI原型系统与EDK II适配，使得RustSBI原型系统能够配合 EDK II在Qemu或真实硬件上启动Linux或RT-Thread等操作系统。Buildroot构建工具适配：Buildroot是一个开源的嵌入式 Linux 系统构建工具，它通过自动化生成交叉编译工具链、内核镜像、根文件系统（rootfs）以及其他必要组件，帮助开发者快速构建轻量级、定制化的嵌入式 Linux系统。本项目要求完善RustSBI原型系统的Buildroot构建支持，结合已有平台的构建工具链，构建一款标准可用的RustSBI原型系统Buildroot构建工具链。已有平台包括不限于:a.算能SG2002芯片b.全志D1芯片c.博流BL808芯片若RustSBI原型系统不完善，为RustSBI原型系统提交的合并请求也计入本项目的贡献中。,1. 完善RustSBI原型系统的EDK II引导程序适配，能在Qemu或真实硬件上启动Linux或RT-Thread等操作系统。2. 构建标准可用的RustSBI原型系统Buildroot构建工具链。
零知识证明/后量子密码算法的研究与实现,进阶/Advanced,"[[""safe"",""AES""],[""safe"",""PKI""],[""safe"",""RSA""]]",*注：从项目1、项目2中选一个方向完成即可零知识证明技术在区块链扩容、可验证计算等领域发挥了重要作用，但存在计算开销大、通用性不足等挑战。本选题聚焦零知识证明协议的高效算法实现以及工程优化，为Web3.0、元宇宙等新兴场景提供核心隐私基础设施。具体来说，本选题内容聚焦以下两方面1、调研 GKR 或其他常用 SNARK 协议，输出调研报告并在隐语中实现2、探索 zkSNARKs 在 LLM 等场景的应用随着量子计算技术的快速发展，向后量子密码体系迁移的任务变得刻不容缓。然而，现有的后量子密码算法存在计算效率低，密钥与签名体积大等问题，难以满足网络通信、区块链、物联网等场景的需求。本课题内容聚焦以下两方面1、调研现有后量子签名算法，分析不同算法的特点与应用场景2、选取典型算法（如Falcon）构建可验证实现原型，并给出算法层或工程层的加速方案,1. 项目1 零知识证明（注：从项目1、项目2中选一个方向完成即可）2. 项目2 后量子密码（注：从项目1、项目2中选一个方向完成即可）
Mooncake PD分离设计和性能优化,基础/Basic,"[[""datas"",""AI""],[""datas"",""GPU""],[""datas"",""GPT""],[""datas"",""PyTorch""]]",实现推理框架（vLLM/SGLang/Ollama）对于Mooncake PD分离框架的支持：1. 设计实现Mooncake Store在vLLM侧的接口。2. 参与社区关于PD Disaggregation的讨论，设计出Mooncake Store集成方案。3. 实现vLLM侧的Mooncake * Store Connector。4. 对RDMA和GPU传输性能进行优化,1. Mooncake 支持一到两种推理框架，SGLang/vLLM/LMDeploy中之一2. 合并若干能够提升性能的PR
在 FIT 中通过 hibernate-validation 来实现 Jakarta Validation,基础,"[[""web"",""Spring Boot""],[""codelang"",""Programming Language""]]",当前 FIT 的扩展中，已经存在了一个支持 javax.validation 的实现，但是随着 JDK 的升级，javax 标准也升级到了 jakarta，因此原本 javax 的校验实现需要升级。而 Jakarta 中的校验实现以 hibernate 最为出名，可以直接集成它的实现，来作为 FIT 中最新的校验实现。但是需要注意的是，在 FIT 中，所有三方依赖，尽可能都是以插件的形式出现的，这样，依赖不会污染用户的插件，也因此，需要将原先的校验扩展改为校验插件，将依赖进行屏蔽。,"1. 一个由 Java 语言实现的 FIT 插件
2. 使用该插件后，在业务的 Java 插件中，可以使用 Jakarta 标准的校验进行参数校验"
优化 nydus 运行时 chunk meta 的加载方式,基础,"[[""datas"",""AI""],[""cloudnative"",""Kubernetes""],[""os"",""FUSE""]]",镜像是容器基础设施中的一个重要部分，目前 OCI 标准镜像的缺陷之一是容器需要等待整个镜像数据下载完成后才能启动，这导致了容器启动时消耗了过多的端到端时间。开源容器镜像加速项目 Nydus 能够使得容器做到秒级冷启动，在镜像构建，分发与运行时，以及性能与安全性上有诸多探索，目前 Nydus 服务了每日百万级的容器创建，也在 AI 模型镜像分发上有着诸多落地场景。本题目是优化 nydus 运行时 chunk meta 的加载方式。,1. nydus 在 EROFS 文件系统基础上对 chunk 分块懒加载支持做了格式扩展，称为 chunk meta，这部分目前是 nydus 运行时按需下载的，我们需要实现为 containerd 下载，以便复用它的重试，压缩下载的能力。并编写单元测试，集成测试，以及用户文档。
卫星场景下 openEuler 系统资源可观测性组件的Rust实现,进阶/Advanced,"[[""os"",""Linux""],[""safe"",""HTTP""]]",本项目旨在openEuler Embedded的基础上，为卫星星务软件提供一款轻量级、资源占用低、适应弱网环境的遥测采集与资源感知组件。（1）相关背景：随着航天器软件复杂度增加，trace、metrics、logs 等可观测性数据对于系统调试、性能分析愈发重要，而传统遥测手段难以满足灵活性与功能要求。（2）已有的工作：OpenTelemetry Collector 是 CNCF 推出的可观测性框架，具备通用性强、协议支持广等优点，广泛应用于云原生场景。（3）存在的不足：原生 Collector 使用 Go 编写，资源开销较大，无法直接部署在资源受限的星载环境。同时，星务应用不具备通过 OTLP 协议发送遥测的能力。（4）希望改进的点：通过使用 Rust 重构 Collector 核心功能，适配 OTLP 协议，并实现弱网环境下的数据缓存、压缩和可靠传输。（5）最终项目实现的目标：构建一个基于 Rust 的轻量化 OpenTelemetry Collector，作为星务服务与星务软件集成，实现星上遥测的标准化、模块化与可观测性闭环。,1. 完善 openeuler embedded中rust的支持2. 基于 Rust 适配 OTLP 协议 v1.5.0 的 OpenTelemetry Collector 轻量化实现3. 使用 Rust 编写的示例应用
基于高性能计算环境实现自适应操作系统性能优化套件,进阶,"[[""os"",""Linux""],[""datas"",""HPC""]]","（1）相关背景随着科学计算、人工智能、气象模拟等领域的快速发展，高性能计算（High Performance Computing, HPC）已成为支撑前沿科研与产业创新的核心基础设施。在高性能计算场景中，软件应用的多样性（如科学仿真、深度学习、大数据分析等）对操作系统提出了差异化需求。例如，部分计算密集型任务依赖高效的并行资源调度，而数据密集型应用则对内存管理和存储I/O性能有更高要求。然而，传统操作系统配置通常基于通用性原则，缺乏针对特定HPC软件的专项优化能力，导致资源利用率不足、性能瓶颈频发。（2）已有的工作OS提供Tune等工具，但需人工配置，无法做到系统开机最优。（3）存在的不足基于高性能计算环境实现自适应操作系统性能优化套件，提供系统开机自适应系统优化配置功能，提供3套以上优化模板，实现系统开机最优方案。（4）希望改进的点引入机器学习模型，通过实时数据分析实现负载场景识别，动态切换预设的sysctl、I/O调度、调度器、线程数等系统级优化参数。（5）最终项目实现的目标完成基于Python和atune-collector采集数据的工业负载场景动态识别模块，并能根据场景匹配应用指定的系统优化参数集，实时优化系统行为以提升应用性能。",1. 开发一套负载场景检测与分类模块2. 开发系统优化参数动态切换模块3. 集成到atune-collector运行流程中4. 提供基本测试用例和验证报告
TinyEditor 支持插入思维导图和流程图,基础,"[[""web"",""Vue.js""]]",随着内容创作需求的多样化，用户希望在 TinyEditor 富文本编辑器中能够方便地插入思维导图和流程图，以便更直观地展示逻辑关系和工作流程。该功能将丰富编辑器的内容呈现形式，提升用户在创作诸如项目计划、知识分享、流程说明等文档时的效率和体验。,1. 实现 TinyEditor 编辑器中插入思维导图的功能，用户可以通过编辑器工具栏的按钮或快捷键等方式，快速插入一个空白的思维导图，并能够对其进行基本的编辑操作，如添加节点、修改内容、调整结构等。2. 提供在 TinyEditor 编辑器中插入流程图的能力，支持用户绘制常见的流程图元素，如开始 / 结束节点、流程步骤、判断条件、流向箭头等，以满足流程描述的需求。3. 针对插入的思维导图和流程图，用户能够在编辑器中进行进一步的编辑和调整，包括修改节点内容、增删节点、改变节点之间的连接关系、调整图表的布局样式等，以达到所需的内容和视觉效果。4. 确保插入的思维导图和流程图能够与编辑器中的其他文本内容自然融合，支持对图表进行排版设置，如调整图表的大小、位置、对齐方式等，使其在文档中合理布局，与周围文本内容协调一致。5. 实现对插入的思维导图和流程图数据的保存和加载功能，当用户保存文档时，图表的相关数据能够被一同保存；在打开已保存的文档时，能够准确地加载并还原图表的显示和内容，确保数据的完整性和一致性。6. 提供包含插入思维导图和流程图功能的 TinyEditor 示例项目，展示该功能在实际应用场景中的使用方法和效果，方便用户参考和学习；同时编写详细的使用文档，介绍如何在 TinyEditor 中插入、编辑和管理思维导图及流程图，包括功能说明、操作步骤、参数配置等内容，帮助用户快速上手使用该功能。7. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。补充相应的文档和自动化测试用例。8. 建议输出TinyEditor插入思维导图和流程图的介绍文章和视频
调研LLVM FLANG对OpenACC 3.3支持情况,基础,"[[""os"",""LLVM""]]",OpenACC是一种基于指令的并行编程模型。与OpenMP类似，开发者可以通过在代码中添加简单的指令便可以借助编译器实现在异构计算平台（如CPU+GPU）上加速应用程序。LLVM FLANG是基于LLVM开发的Fortran前端编译器，经过数年开发已基于完善，对于OpenACC导语也有一定的支持。本选题希望对LLVM FLANG支持OpenACC的现状有一个全面的了解，便于后续项目的开发及应用。,1. LLVM Flang OpenACC支持的原理介绍，包括编译器处理，运行时处理等2. LLVM Flang 针对OpenACC 3.3 所有导语的支持情况及包含该导语的小例子
为NVDA屏幕阅读器（面向视障人士）提供的设备端AI图像描述,进阶/Advanced,"[[""datas"",""Computer Vision(CV)""],[""datas"",""Data Science""],[""datas"",""Deep Learning""],[""datas"",""GPT""],[""datas"",""Machine Learning""],[""datas"",""Natural Language Processing (NLP)""],[""datas"",""PIL""],[""web"",""Desktop Application""]]",NVDA  (NonVisual Desktop Access) 是一款免费、开源的 Microsoft Windows  屏幕阅读器，使视障人士（包括盲人和低视力者）能够使用计算机。其开发由非营利慈善组织 NV Access  协调，它提供了对操作系统和第三方应用程序（包括 Office 和 Web 浏览器）的访问。然而，图形用户界面  (GUI)、网页内容和文档越来越依赖通过图像、图表和其他图形传递的视觉信息，而这些视觉元素常常缺乏充分的替代文本描述。这给视障用户（盲人和低视力用户）带来了显著的可访问性障碍。NVDA 目前可以报告图形元素的存在，并读取作者提供的现有替代文本（alt text）。一些用户依赖外部的、基于云的服务或应用程序来获取图像描述，但这些方法存在局限性。NVDA   内部目前缺乏内置的、现成的功能来为缺少或替代文本不足的图像生成描述。现有的解决方案通常需要有效的互联网连接，这引发了隐私担忧，可能产生费用，并引入延迟。此外，许多  NVDA  用户，特别是在发展中地区的用户，可能互联网访问受限，和/或使用处理能力和内存有限的老旧硬件。目前缺乏一个健壮的、集成的、离线的解决方案。本项目旨在通过将设备端图像描述功能直接集成到  NVDA 中来弥补这一差距。利用高效、小体积的视觉语言模型 (VLM) 和小型语言模型 (SLM)  的最新进展，目标是在不依赖云服务的情况下提供及时且有用的图像描述。一个关键要求是采用模块化架构，以便随着该领域的快速发展，可以相对容易地更新或替换底层的  AI 模型。准确性以及避免模型“幻觉”对于用户信任至关重要。研究、开发并将设备端图像描述功能的原型集成到 NVDA 屏幕阅读器中。这包括选择合适的开源 AI 模型，设计高效的处理流程，在 NVDA 架构内实现集成，确保低资源消耗，优化响应速度，并通过标准的 NVDA 交互模式使该功能易于访问。,"1.   研究与模型选择报告： 一份关于合适的、采用宽松许可的开源设备端视觉语言模型 (VLM) 的文档化分析，对其在目标硬件配置上的性能（准确性、速度、资源占用）进行基准测试。选定1-2个候选模型用于实施。

  2.  模块化集成架构设计： 一份将图像描述功能集成到 NVDA 的设计文档，强调 NVDA 核心与机器学习模型推理组件之间的松耦合，以便于未来的模型更换。

  3.  功能原型实现： 集成到 NVDA 分支中的可工作代码，演示：
    a. 能够从当前聚焦的图形元素捕获相关图像数据。
    b. 使用选定模型进行离线推理。
    c. 将生成的描述通过 NVDA 的语音和盲文输出呈现给用户。

 4.   性能优化与测试： 提供性能分析 (profiling) 和优化工作的证据，以在指定的基准硬件上达到响应速度目标（详细描述 <5秒，理想情况下初始反馈 <1秒）。为已实现的功能提供基础测试套件。

5.    最终项目报告与文档： 一份详细说明项目工作、研究结果、实施细节、遇到的挑战、潜在未来工作以及该功能的基础用户/开发者文档的报告。"
VTable 表中表组件,进阶/Advanced,"[[""web"",""UIKit""]]",开发一个基于 VTable 的表中表组件。系统具备显示选中记录的功能，此功能十分实用且灵活。它支持用户进行多选行操作，用户可以根据自身需求同时选中多个记录行，方便对这些选中的记录进行统一处理，比如批量删除、批量修改等。在数据量较大的情况下，还支持分页显示，会将大量的记录按照设定的每页数量进行分页展示，确保界面清晰，提升用户查看数据的效率。此外，该功能还支持按列排序，用户可以依据某一列的数据内容对记录进行升序或者降序排列，从而更清晰地观察数据的分布和规律，以便做出更准确的判断和决策。3.当用户点击主表的展开按钮时，系统应立即响应并将对应的子表显示出来。子表中的内容较多，为了方便用户查看，采用分页的方式进行展示。用户通过操作分页功能，能够查看更多的记录信息。同时，系统要支持对记录进行多选操作，在用户选中多个记录后，可以对这些选中的记录统一进行批量操作，例如批量删除、批量修改等。4.主表和子表的列宽应具备自适应的能力，能够根据表格中内容的多少和长度自动调整列宽，以保证表格内容完整显示且布局美观。子表的展开位置应在主表对应行的下方，这样的布局符合用户的浏览习惯，方便用户对照主表和子表的内容。分页控件除了常规的上一页、下一页功能外，还需要支持用户手动输入页码，实现跳转到指定页的功能，提高用户查找信息的效率。5.选择使用VTable组件来实现表格的各项功能。在开发过程中，要特别注重系统在不同浏览器（如Chrome、Firefox、Safari等）和不同设备（如电脑、平板、手机等）上的兼容性，确保表格在各种环境下都能正常显示和使用。系统要具备良好的性能表现，尤其是在处理大数据量时，能够快速完成数据的加载和渲染，避免出现长时间的卡顿或等待，为用户提供流畅的使用体验。,1. UI 需求2. 文档
KubeEdge Dashboard前端组件升级优化,基础,"[[""web"",""React""]]",升级优化dashboard前端组件及性能，重点优化ProTable、TableView等公用表单组件。另外可考虑引入mui新加入的Dashboard Layout等组件。,1. 优化ProTable、TableView等表单组件性能2. 优化网络请求，适当加入缓存策略，减少不必要的请求3. 引入MUI新加入的Dashboard Layout等组件（可选）
openGauss 向量数据库集成MemGPT,进阶,"[[""datas"",""Database""],[""datas"",""AI""]]",完成MemGPT与openGauss向量数据库适配，提交适配代码到openGauss社区，并输出案例和详细使用文档。,1. 开发openGauss本地存储模块，支持文档向量化全流程隔离。2. 构建金融/医疗领域私有化案例，输出包含审计机制的安全文档，代码提交社区。
OpenHarmony device 代码生成工具,基础,"[[""os"",""RISC-V""],[""os"",""Linux""]]",在 OpenHarmony 生态中，目前 device 模块已实现 board 与 soc 的解耦设计，这一架构优化虽带来了一定灵活性，但随之也衍生出新的问题 —— 不同 board 与 soc 组合下，存在大量重复性代码。这些冗余代码不仅增加了开发维护成本，还可能导致潜在的兼容性问题与调试难度上升，降低开发效率。为此，OpenHarmony device 代码生成工具致力于通过创新策略实现代码优化：将不同组合中功能通用的代码部分抽离，形成标准化、可复用的代码库；同时，针对各组合间的差异，采用配置文件与 patch（补丁）的形式进行精细化管理。配置文件可便捷调整参数与特性，patch 则用于针对性修复或适配特定场景，从而在保障代码复用性的基础上，灵活应对各类差异化需求 ，有效提升 OpenHarmony 设备开发的整体效能与代码质量。,1. 将现有代码分离出通用和定制两个部分。2. 实现代码生成器的功能，并完成一个新的device的适配。3. 完成相关的设计文档。
基于 Spring AI Alibaba 的本地可观测与调试平台（后端）,基础,"[[""dev"",""LLMOps""]]",1. 项目背景本项目属于 Spring AI Alibaba 社区本地开发调试平台的一部分，平台涵盖前端与后端开发，本项目主要完成后端部分。该平台用于快速跟踪定位Agent运行链路、可视化快速与 Agent 交互等，需要提供sdk埋点、graph埋点、可视化平台后端逻辑、沙箱运行环境与通信协议实现等。2. 学生职责&目标：在这个项目中，学生将和社区导师与开发者一起全面参与平台各个模块的讨论与开发，重点完成基础sdk埋点完善、graph埋点建设、agent沙箱运行环境、平台功能后端逻辑实现等。3. 学生要求&技术栈,1. 在这个项目中，学生将和社区导师与开发者一起全面参与平台各个模块的讨论与开发，重点完成基础sdk埋点完善、graph埋点建设、agent沙箱运行环境、平台功能后端逻辑实现等。
Graph智能体工作流的自动生成与优化,进阶,"[[""datas"",""AI""],[""datas"",""Graph Database""]]",传统的智能体工作流设计，需要大量的人工编排和手动优化工作，不利于智能体能力的快速扩展。随着大模型技术的发展以及推理模型能力的提升，工作流自动生成与优化技术不仅可以降低智能体系统的构建成本，还能降低人工构建的工程约束对智能体推理带来的限制以及负面影响。Chat2Graph作为图数据库上的智能体系统，旨在解决高效用图的问题，当下亟需通过自动工作流技术加速和改进Graph智能体构建，实现图领域上准确的任务拆解、高效的推理执行以及合理的工具调用。,1.  项目设计文档（含架构图、原理图、API文档）。2.  自动工作流训练数据集和测试数据集，提供数据合成解决方案。3.  自动工作流模块源代码（需合并到Chat2Graph主仓库）。4.  性能优化对比实验结果，以及分析报告。5.  自动工作流生成演示Demo。
Emoji Support for Mogan STEM,Basic,"[[""web"",""Qt""],[""web"",""Desktop Application""]]","For now, emoji in Mogan STEM are displayed as.This project is aimed to support emoji in Mogan STEM. And we should  ship the free emoji font with Mogan STEM to make sure that emojis are  rendered correctly and consistently on macOS/Linux and Windows. Mogan  users can also set their preferred emoji font.",1. Support emoji rendering on Linux/macOS/Windows2. Support customization of the emoji font3. Ship the free and open emoji font with Mogan STEM (just like the Noto CJK font)
为 Kata/runtime-rs 实现虚拟机模板（VM Templating）,进阶,"[[""os"",""Virtualization""],[""os"",""Linux""],[""os"",""QEMU""],[""os"",""KVM""]]",模板化是 Kata Containers 提供的一项关键优化特性，旨在通过高效的虚拟机克隆技术加速新容器的创建过程，并显著降低在高密度部署场景下的内存消耗。其核心思想是预先创建一个模板虚拟机，后续创建新的 Kata 容器时，不再需要从头启动完整的 VM，而是通过克隆已有模板 VM 的方式快速生成新的 VM 实例。这些克隆出的 VM 将以只读方式共享模板 VM 的关键启动组件，包括 initramfs、Linux 内核以及 Kata Agent 的内存映像。该机制类似于操作系统层面的进程 fork 操作，但作用范围提升至 VM 层面。通过避免重复加载和初始化相同的启动资源，VM 模板化能够极大地缩短新容器的启动时间，这对于需要频繁创建和销毁容器的场景，如 Serverless，尤为重要。目前该特性已经在Kata Runtime(golang)版本中实现，但是在Runtime-rs上依旧缺失。我们希望在Runtime-rs上增加对该特性的支持。我们希望完成以下任务：在 runtime-rs 中支持通过 VM 模板快速生成新虚拟机，重点完成模板生命周期管理（创建、缓存、销毁）。代码实现（含关键模块注释），设计文档（架构图说明）以及部署文档。相关参考文档如下：,1. 完成 Kata/runtime-rs 虚拟机模板功能以及相应的测试用例，代码合入主线分支；2. 提供完整的设计文档和部署文档（英文表述）；3. 完整的，符合社区开发规范的 PR。
TinyPro 集成页面设计器(考虑基于 TinyEngine 搭建)，可在线快速搭建页面,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",随着数字化转型的加速，企业对于快速开发和部署后台管理系统的需求日益增长。传统的开发模式需要大量的编码工作和专业技术人员的参与，开发周期长、成本高。为了解决这一问题，本任务旨在将基于 TinyEngine 的页面设计器集成到 TinyPro 后台管理系统中，使用户能够通过简单的拖拽操作和配置，快速搭建出符合业务需求的页面，无需编写大量代码，从而显著提高开发效率，降低开发成本，让即使缺乏专业开发背景的人员也能参与到系统开发过程中。,1. 完成TinyEngine低代码设计器与 TinyPro 的无缝集成，提供一个稳定、易用的集成模块，确保用户在 TinyPro 管理系统中能够直接访问和使用页面设计器进行页面搭建。2. 页面设计器中导入全量的TinyVue组件库，并且支持自定义组件和组件库的导入，实现可视化页面编辑，用户能够在所见即所得的编辑环境中对页面进行布局调整、组件配置等操作，实时预览页面效果，方便用户进行页面设计和调整。3. 新建菜单时，可以跳转到设计器页面，设计器中编辑好的页面可以直接导出到项目指定位置，并生成对应的组件路径字段，创建完菜单可以直接绑定对应的页面，进行页面的访问。4. 支持现有的页面模板导入到设计器中进行编辑，如列表页、详情页、表单页等，用户可以根据模板进行快速定制和修改，提高页面搭建的效率和质量。5. 编写详细、清晰的用户操作指南和相关文档，包括页面设计器的功能介绍、操作步骤、组件使用说明、模板应用示例等内容，帮助用户快速上手和掌握页面设计器的使用方法。6. 提供一个或多个完整的示例项目，展示如何在 TinyPro 中使用页面设计器搭建页面，并实现与后端数据的交互，为用户提供更直观的参考和学习案例。7. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。8. 补充相应的文档和自动化测试用例。
PilotGo 适配 RISC-V,基础,"[[""os"",""RISC-V""]]",PilotGo 是 openEuler 社区原生孵化的运维管理平台，采用插件式架构设计，功能模块轻量化组合、独立迭代演进，同时保证核心功能稳定；同时使用插件来增强平台功能、并打通不同运维组件之间的壁垒，实现了全局的状态感知及自动化流程。目前 PilotGo 虽然可以在 RISC-V 架构下编译成功，但无法正常运行。你需要修复 PilotGo 并能确保其在 openEuler RISC-V 上运行，同时产出一份测试报告。,1. 需要能够在 openEuler RISC-V 上成功运行 PilotGo 并产出测试报告，相关代码回合至上游。
OpenHarmony 系统构建一个基于 Lycium 的交叉编译框架，快速编译和验证 C/C++ 第三方库,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""codelang"",""Programming Language""]]",Lycium 是一款协助开发者通过 shell 语言实现 C/C++ 三方库快速交叉编译，并在 OpenHarmony 系统上快速验证的编译框架工具。开发者只需要设置对应 C/C++ 三方库的编译方式以及编译参数，通过 Lycium 就能快速的构建出能在 OpenHarmony 系统运行的二进制文件。目前 Lycium 还不支持 RISC-V 架构，需支持 RISC-V 架构。,1. 能够编译出RISC-V64的二进制库2. 能够成功链接并在RISC-V架构的开发板上运行
Seata-Go 与Seata-Java 版本功能拉齐,进阶/Advanced,"[[""web"",""Apache""],[""codelang"",""Programming Language""]]",Seata-Go 是 Seata 多语言生态中的 Go 语言实现版本，目前最新发布版本已经达到基础功能在生产环境可用状态。随着 Seata 的不断发展，确保 Go 和 Java 实现之间的功能相当，对于在多语言环境中操作的用户来说至关重要。本项目旨在Seata-Go中对齐Java版本已有的功能特性，以确保在多语言生态系统中为用户提供一致的使用体验。,1. 支持与seata-server的 gRPC 通信（优先级P0）2. 支持Seata原生注册中心NamingServer的服务发现和注册（优先级P1）3. 支持Seata-Raft存储模式集成（优先级P1）4. 增加数据库支持（优先级P1）5. seata-go-sample中增加对应功能的使用Demo，可参考seata-sample，并产出一份最佳实践文档（优先级P2）
为HTNN增加token限流能力,基础/Basic,"[[""safe"",""HTTP""],[""datas"",""LLM""],[""datas"",""AI""]]",https://github.com/mosn/htnn 是一款基于 Envoy 和 Go 开发的 AI 网关，当前已具备传统的 QPS 限流与服务降级能力。为了更好地支持 LLM（大语言模型）的推理场景，亟需引入基于 Token 维度的智能限流能力。该功能将允许针对 AI API 进行基于特定键值的 Token 限流配置，而键值的来源可以灵活地从 URL 参数、HTTP 请求头、客户端 IP、消费者名称或者 Cookie 中的 Key 提取。通过细粒度的 Token 限流，能够有效提升下游 LLM 服务及整体业务的稳健性，同时对于被限流的请求可返回更具人性化的响应提示。此外，还支持基于预测的输出 Token 限流能力，专用于控制生成式 AI 模型的输出长度或频率，从而避免因资源过载导致系统不稳定，为整体资源保护与业务运行质量提供保障。,1.Go 插件2. 测试代码3.中英文插件文档
结构感知的量子启发优化算法,基础,"[[""datas"",""AI""]]",任务背景：量子启发算法求解组合优化问题时，可以利用问题结构作算法改进，包括但不限于对称性、分岔点位置等，如何发掘利用这些结构来改进量子启发优化算法是具有应用价值的有趣问题。任务需求：（1）设计工具在合理时间内发掘大规模HUBO问题的全部对称性，并用于改进量子启发算法（2）设计工具在合理时间内计算指定Ising/HUBO模型的分岔点，并用于改进量子启发优化算法,1. 对于~1000节点的Ising/HUBO问题族，1小时内完成全部对称性计算，利用对称性改进量子启发算法，TTS（Time to Solution）相比朴素方法减少1倍以上；2. 对于1中的Ising/HUBO问题，1小时内完成前五个分岔点及分岔图计算，实现可视化功能；3. 提交规范的技术报告，需包含文献调研、算法原理、实验结果等部分；4. 相关评估指标符合要求，代码需要有适当的注释并通过clean code标准5. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。
研究Linux系统典型应用场景的测试方案,基础,"[[""os"",""Linux""]]",Linux系统在企业中有着非常广泛的应用，同时又有一些典型应用场景，比如数据库服务器、存储服务器、缓存服务器等等，针对这些典型的应用场景，操作系统如何进行测试以满足对应场景的需求，是一个挑战。项目的目标就是通过调研梳理一些常见的应用场景，一会针对每个具体的应用场景建立完整的测试方案并开发测试脚本。,1. 调研操作系统在企业中常见的典型应用场景，梳理总结成调研文档，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/scenario_test 目录下。2. 根据上述1中的调研结论，调研对每种应用场景如何进行测试从而可以尽最大可能的保障对应场景的质量，测试方案形成调研文档，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/scenario_test 目录下3. 学习了解openEuler开源社区的mugen测试框架（https://gitee.com/openeuler/mugen ），掌握测试套/测试用例的开发方法以及运行调试方法4. 根据上述2中的调研结论，结合上述3中的知识点，开发场景测试的测试套和测试用例，测试套上传至 https://gitee.com/oepkgs/os-autotest/tree/master/suite2cases/scenario_test 目录下，测试用例上传至 https://gitee.com/oepkgs/os-autotest/tree/master/testcases/scenario_test 目录下（注：os-autotest 是基于mugen框架，旨在建立针对操作系统完整测试方案的测试框架/脚本库）5. 上述4中提交的测试套和测试用例需要在 os-autotest 中执行通过，提交MR时需附执行通过截图
基于RISC-V架构的CRYSTALS-Dilithium能量侧信道攻击研究 ,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""SSL/TLS""]]",侧信道攻击是一种通过分析密码系统在运行过程中泄漏的物理信息（如时间、功耗、电磁辐射等）来获取密钥或其他敏感信息的攻击方法。随着量子计算机的发展，传统公钥密码系统面临被破解的风险，后量子密码学成为研究热点。美国国家标准与技术研究所（NIST）在2016年启动了后量子密码算法征集活动，并于2024年发布了首批标准，其中CRYSTALS-Dilithium表现优异。然而，NIST尚未建立针对基于格的后量子密码侧信道安全性的统一评估框架，实际部署中可能存在未知风险。RISC-V作为一种开源、模块化的指令集架构，为我国自主可控的处理器发展提供了重要支持。本课题旨在结合RISC-V架构，通过侧信道攻击评估基于格的后量子密码算法的安全性，丰富其评估框架。目前，基于格的后量子密码算法在安全性、性能和实现复杂性方面表现优异，但其侧信道安全性尚未得到充分评估。NIST征集提案中明确要求算法具备抗侧信道攻击能力，但缺乏统一的评估标准和方法。现有研究多集中在算法的数学安全性上，对其实施过程中可能泄漏的物理信息关注不足。此外，针对基于格的后量子密码算法的侧信道攻击研究较少，尤其是结合RISC-V架构的硬件实现安全性研究尚未充分探索。RISC-V架构的开放性为侧信道防护提供了灵活的设计空间，但目前针对RISC-V的抗侧信道攻击指令集研究仍处于起步阶段，这为侧信道安全性评估留下了空白。项目最终目标是结合RISC-V32架构，针对CRYSTALS-Dilithium进行侧信道攻击，评估其侧信道安全性。通过开发基于神经网络的攻击方法，以j较高成功率（如80%以上）恢复私钥多项式s1。最终，研究成果将为基于格的后量子密码算法的侧信道安全性评估提供更完善的框架，为RISC-V架构下的后量子密码算法实际部署提供理论支持和技术指导。,"1. 能够针对Dilithium签名过程的泄漏实现以80%以上的成功率恢复私钥多项式s1。
2.编写攻击说明文档。"
将 RISC-V 原生代码生成器 (NCG) 向前移植到 GHC 9.4.8 版本,进阶/Advanced,"[[""codelang"",""Programming Language""],[""os"",""RISC-V""],[""os"",""Linux""]]",GHC (Glasgow Haskell Compiler) 是 Haskell 最流行的编译器实现。NCG （Native Code Generator）为其维护的性能最好，依赖较少且容易维护的代码生成后端。RISC-V 的 NCG 支持已于 2024 年底合并入 GHC 主线，并包含在 9.12.1 版本中。然而，在发行版的维护实践中，处于对旧项目的兼容性考虑往往选择较旧的 GHC 版本进行打包，例如 Arch Linux 与 eweOS 目前均对 GHC 9.4.8 进行打包，导致这些发行版的 RISC-V 移植仅能使用依赖老旧 LLVM 的 GHC 代码生成器。本项目旨在弥合这一差距，将 GHC 9.12.1 中的 RISC-V NCG 后端代码反向移植回 9.4.8 版本，简化这些发行版的维护工作。,1. 在任意 RISC-V 平台 bootstrap 使用 LLVM 后端的 GHC 9.4.8 版本2. 反向移植 RISCV64 NCG 代码至 GHC 9.4 分支，确保 RISCV64 target 能够正确完成编译3. 运行 GHC 测试集，对照失败的测试修复编译器或测试例程4. 使用 shellcheck 等实际的 Haskell 工程进行集成测试，验证编译器工作正常5. （可选）为 eweOS bootstrap 使用 NCG 的 RISC-V 平台 GHC 编译器6. 整理经过测试验证后的代码，要求提交信息清晰准确描述问题，贡献到 https://github.com/eweOS/ghc
Runtime-rs 支持以 Rootless 模式运行 VMM,进阶,"[[""os"",""Virtualization""],[""os"",""x86""],[""os"",""QEMU""],[""os"",""Linux""],[""os"",""KVM""]]",Runtime-rs 即将作为 Kata Containers 4.0 版本的默认运行时。相比于现有的 runtime-go，runtime-rs 采用 Rust 重写，具备更低的资源占用和更快的执行速度，且得到了蚂蚁集团、阿里巴巴、Red Hat、NVIDIA 等多家公司的支持。当前社区的维护重心也在逐步向 runtime-rs 转移。为了确保 runtime-rs 在正式发布前达到可用标准，需要保证其功能与现有的 runtime-go 保持对齐。默认情况下，shim 进程和 VMM（虚拟机管理器）进程均以 root 权限运行。为了满足在安全敏感场景中以更低权限运行用户负载的需求，runtime-rs 需要支持 VMM 进程以 rootless 模式运行。runtime-go 已在 QEMU 和 Cloud Hypervisor 虚拟机中实现了该特性。本项目需将该功能移植到 runtime-rs，完成开发与功能性测试，并接入 CI 测试流程。作为进阶目标，项目还需在 Dragonball（内置 VMM）中实现同样的 rootless 支持。,1. 为 Runtime-rs 实现 QEMU 和 Cloud Hypervisor 虚拟机的 rootless 模式支持。2. 完成功能性测试并接入 CI 测试。3. 完成至少一篇英文版功能性描述文档。4. （进阶，不强制要求）为 Dragonball 实现同样的 rootless 支持。
基于MiniGU的向量存储与索引支持,基础,"[[""datas"",""Graph Database""],[""datas"",""Vector Database""]]",随着大模型时代的到来和RAG应用的普及，向量数据(vector)作为非结构化数据的重要表示形式，在图数据库中的存储与检索需求日益增长。图数据库亦需要实现高效的向量存储方案和专用索引，以支持图结构数据与向量特征的联合查询。MiniGU当前尚未原生支持向量数据类型，缺乏图结构数据的关联分析能力。,1.   技术设计文档（含架构图与API说明）2.   向量存储模块源代码3.  向量索引实现（至少支持1种算法）4.   性能Benchmark测试报告5.   混合查询Demo
Entari 实例管理图形化面板,基础/Basic,"[[""web"",""UI""],[""web"",""Web Application""],[""web"",""Vue.js""]]",ArcletProject 系列下的 Entari 是一个基于 Satori 协议的即时通信开发框架，支持异步并发，内建且可拓展的配置模型，可热重载并回收副作用的插件机制与服务机制，内置强大的命令系统、定时任务系统等。Entari 目前提供了简易的命令行程序来帮助初次使用的用户初始化开发/使用环境，但是缺乏环境搭配、插件搜索、配置编辑等功能，对未有一定开发经验的用户，命令行的使用仍具有一定的困难。此外，其他项目如 koishi、NoneBot 等，均可通过图形化界面的形式为用户提供更便捷的项目开发。因此，我们希望借助 Entari 本身提供的优秀的插件与服务机制 ，提供一个项目管理面板服务，以网页的形式帮助用户开发 Entari 应用。,1. 设计并实现实例管理面板相关功能2. 实现相应 Entari 插件提供界面服务，并提供接口以允许其他插件拓展3. 代码符合相关规范
Casibase容器云平台的功能开发与用户UI界面开发,进阶,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""],[""cloudnative"",""Cloud Native""]]","Casibase是一套开源的基于Docker和Kubernetes的容器云平台。它适合个人或组织用于构建自己的专属容器云环境。Casibase基于Casbin权限管理引擎,实现了细粒度的访问控制策略。用户可以在Casibase上方便地创建、编排、管理容器应用。本项目将重点优化Casibase的应用编排、服务治理、平台可视化等核心功能,提升平台易用性和可管理性,使其成为领先的轻量级容器云平台","1. 优化容器应用编排能力,支持多种编排范式,简化应用部署流程2. 增强服务治理功能,提供服务注册发现、熔断降级、限流等微服务治理能力3. 改进平台可视化,提供更友好直观的WebUI,方便用户操作和管理容器应用4. 解决Casibase主仓库&相关仓库中的issues（数量至少7个）：https://github.com/casibase/casibase/issues"
Karmada 禁止同一资源被多个资源跟随分发,进阶/Advanced,"[[""cloudnative"",""Kubernetes""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。Karmada 支持资源的跟随分发，例如 configmap 资源不需要创建额外的 PropagationPolicy 进行分发，可以直接跟随 deployment 资源进行分发。根据用户的使用反馈，有的用户不会涉及到单个资源被多个资源依赖分布的场景，但也有的用户会使用，比如共享同一个秘籍拉取镜像。在 Karmada 中，如果允许同一个资源被多个资源跟随分发，会给用户带来一定的风险。因此我们需要对这些风险进行分析，来思考是否可以通过某种方式来化解，或者明确禁止用户这样做。Track issue: https://github.com/karmada-io/karmada/issues/6000,1. 技术文档：设计描述与分析2. 功能实现：禁止同一资源被多个资源跟随分发3. 测试覆盖：编写测试用例覆盖新增功能
基于cryptpilot实现in-place磁盘加密,进阶,"[[""os"",""Linux""],[""os"",""ext4""]]",在机密计算场景（如基于TDX等可信执行环境），数据全生命周期加密是核心安全需求。cryptpilot工具已支持系统盘和数据盘加密，但现有方案需依赖额外实例或离线工具完成系统盘加密，存在操作复杂、可信链断层等问题。本赛题中，参赛同学需要设计方案，为cryptpilot增加in-place系统盘加密能力，实现在基于qemu的机密计算虚拟机中直接对当前系统盘分区进行在线加密，解决现有方案在实时性、安全性与操作便捷性方面的不足。,"1. 可运行的代码（或者提交/patch）及测试用例
2. 描述该功能的操作指南文档"
纠删码子系统中心化管理任务流量控制,进阶/Advanced,"[[""cloudnative"",""CubeFS""],[""cloudnative"",""Distributed Storage""]]",CubeFS的纠删码存储子系统（BlobStore），是一个支持在线EC读写、高可靠、高可用、低成本支持EB规模的数据存储子系统。对于海量规模的数据存储集群而言，数据删除、数据修复以及数据迁移是一种常态化的后台任务，每天都在发生。当前各个类型的，，容易出现某种类型任务并发增加导致其他任务执行缓慢，或者多种任务类型叠加导致抢占业务流量影响业务等等。为减轻blobnode读写io压力，在任务调度层感知任务流量，提升后台任务的效率以及保证用户读写的稳定性。当前，对于数据删除、修复以及迁移流量控制，支持独立配置每种任务的并发限制。假设每块盘允许删除的 iops 为 30，磁盘总数为 N，总的用于删除 iops 为 N * 30。考虑 bid（对象） 粒度，EC编码模式为 n+m，现有删除策略下，一次删除在磁盘上主要有3次io（不考虑缓存的情况下），则一次完整删除需要次，一个集群最高删除速度（bid/s）峰值大概在,1. 为分布式文件系统CubeFS提供纠删码引擎提供中心化流量控制 2. 提供完整的代码、测试用例、运营文档、测试文档
基于MindSpore实现多模态外形生成大模型,进阶,"[[""datas"",""AI""]]",外形生成是工业场景中最重要的基础任务之一，也是仿真、设计等的前置工作。本课题需要开发者参考业界CADasLanguage，ShapeLLM，CAD-MLLM等，设计多模态启动外形生成模型，其中至少支持语言、图片和点云三个模态的数据，输出至少一种能被主流CAD软件识别的外形结构,1. 基于MindSpore+NPU，结合AI流体仿真套件MindSpore Flow、大模型套件MindSpore Transformers现有能力，实现支持多模态输入的外形生成模型，生成的外形基本符合输入要求，无明显缺陷
AGI DDS(TravoDDS)支持国密算法,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""PKI""]]","1.背景介绍数据分发服务(Data Distribution Service, DDS)是一种面向实时分布式系统的中间件标准，广泛应用于机器人、工业控制、国防军事、航空航天等重要领域。随着国家信息安全战略的深入实施，在关键信息基础设施中使用自主可控的密码算法已成为必然趋势。2. 现状分析目前，大多数DDS实现（如RTI Connext DDS、OpenDDS等）主要支持国际通用的加密算法：- RSA用于非对称加密- AES用于对称加密- SHA系列用于哈希运算- ECDSA用于数字签名这些算法虽然安全性得到广泛验证，但在国家安全和信息主权方面存在潜在风险：1. 算法源自国外，可能存在后门2. 不符合国家密码管理要求3. 不利于实现密码应用自主可控3. 支持国密算法的必要性1. 国密SM2算法提供与RSA-2048相当的安全强度且运算效率更高，SM4算法较AES具有更好的软硬件实现性能，SM3哈希算法具有优良的抗碰撞性能。2. 《密码法》明确要求在涉及国家安全、国计民生的重要领域使用国产密码算法。3. 《关键信息基础设施安全保护条例》强调关键信息基础设施应当采用自主可控的产品。4. 各行业监管部门对商用密码应用提出具体要求。在机器人、军工装备、工业控制和智能交通等领域，通过扩展DDS安全规范、增加国密算法支持，可显著提升系统安全性，实现数据传输的自主可控。4. 实现目标1.核心算法支持- 实现使用SM2用于身份认证和密钥交换- 实现使用SM3用于消息完整性保护- 实现使用SM4用于数据加密传输2. 标准协议扩展- 扩展DDS安全规范- 增加国密算法标识符- 完善密钥管理机制在当前国际形势和国家安全要求下，DDS支持国密算法既是技术发展的必然趋势，也是确保关键信息基础设施安全的重要保障。通过合理规划和分步实施，可以实现DDS的国密算法改造，为各类重要应用系统提供更安全、可控的数据分发服务。",1. 为DDS组件开发国密加密插件：
Core Library (lolly) Performance Optimization for Mogan STEM,Basic,"[[""os"",""Perf""],[""codelang"",""Programming Language""]]","The lolly library serves as the foundational core of Mogan, powering key functionalities such as data structures, string handling, and algorithm utilities. Over time, we have identified several performance bottlenecks in lolly that severely affect the responsiveness of the editor—especially on lower-end machines or when processing large documents.This project aims to **optimize core data structures and algorithms** in lolly, including but not only:- Replacing or improving the current HashMap implementation; - Optimizing string operations such as concatenation, comparison, and searching;- Improving basic algorithm performance (e.g., sorting);- Refactoring inefficient URL parsing logic caused by its dependency on tree structures.These optimizations are expected to bring **substantial performance improvements** across many parts of Mogan, especially in document loading, UI responsiveness, and internal logic processing. If time permits, we may also explore further refinements in font-related performance or other business-layer hotspots based on profiling.","1. Replace or refactor at least **3 core components** in lolly, with measurable performance improvements.2. Provide **micro-benchmark reports** comparing old and new implementations for HashMap, string operations, and URL parsing.3. Submit at least **3 mergeable pull requests** for each components, each addressing a specific performance-critical module.4. Run **profiling sessions** before/after optimization and visualize results (e.g., with flamegraphs or perf report).5. Implement a **basic performance regression test suite** to track future changes.6. Document all changes and provide developer-friendly explanations to ease future contributions."
在Karmada Dashboard中集成Karmada-MCP-Server,基础,"[[""cloudnative"",""Kubernetes""],[""datas"",""AI""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。自OpenAI推出大模型以来，各个领域都在尝试落地大模型应用。MCP协议是Anthropic公司推出的一个标准化协议，旨在通过标准化的方式将各个垂直领域的能力快速、标准化的接入到现有的工作流中。Karmada 社区也尝试探索大模型落地的方案，比如结合MCP协议开发了Karmada-MCP-Server，在支持MCP协议的客户端中通过自然语言完成多集群管理的工作。但是现有的使用方式用户做诸多配置，相对复杂，同时考虑到MCP是标准协议。 因此我们希望可以在Karmada Dashboard中整合Karmada-MCP-Server，通过ChatUI的形式为用户提供开箱即用的大模型能力，提升集群管理效率。,1. 功能介绍文档：自动化测试设计文档2. 功能实现3. 项目扩展：
升级 Dragonball 的 rust-vmm 依赖到支持 RISC-V 的版本,进阶,"[[""os"",""Virtualization""],[""os"",""RISC-V""],[""os"",""Linux""],[""os"",""KVM""]]",Dragonball 是一个基于 KVM 的轻量级虚拟机管理器（VMM），专为 Kata-Containers Rust Runtime 设计且与之深度集成。当前版本的 Dragonball 所依赖的 rust-vmm 版本不足以支撑 RISC-V 架构的使能工作，需要将来自 rust-vmm 的基础库升级至包含 RISC-V 架构支持的版本。,1. 将 Dragonball 中来自 rust-vmm 的所有依赖升级到支持 RISC-V 架构，且依赖之间自洽的版本。
基于RISC-V架构的抗侧信道攻击指令集设计,进阶,"[[""safe"",""SSL/TLS""],[""safe"",""RSA""],[""safe"",""PKI""]]",随着万物互联时代的到来，现代嵌入式计算设备已深度融入生活的各个方面，物联网安全成为国家安全战略的重要组成部分。功耗侧信道攻击通过分析设备运行时泄露的功耗波动即可还原密钥或获取敏感数据，对信息安全构成严重威胁。布尔掩码作为一种简单且高效的基础侧信道防护方案，通过引入随机数打破敏感数据与功耗之间的关联，但在实际应用中仍面临效率和安全两方面的挑战。RISC-V作为一种开源、模块化的指令集架构，为我国国产处理器发展提供了重要支持，其灵活扩展能力为抗侧信道攻击指令集的设计提供了理想平台。目前，布尔掩码方案在软件实现中存在显著不足。一方面，掩码计算需要大量计算和存储开销，导致性能下降；另一方面，软件实现往往存在噪声不足以及实现缺陷（如过渡态泄露）等问题，这些缺陷可能被攻击者利用，削弱其安全性。尽管指令集扩展技术能够从硬件层面消除或减少这些缺陷，但相关研究在高安全性嵌入式场景中仍屈指可数。现有指令集设计多集中于通用计算优化，针对抗侧信道攻击的专用指令集研究尚处于起步阶段，难以满足高安全性需求。项目具体改进要点包括：从硬件微架构层面消除或大幅降低由架构和微架构原因引发的功耗泄露；在指令执行中引入随机数以及硬件噪声，为掩码方案提供足够的噪声水平；为软件实现提供高效、安全的指令接口。通过硬件与软件协同优化，解决布尔掩码实现中的效率与安全问题。本项目最终目标是开发一套基于RISC-V架构的抗侧信道攻击扩展指令集，显著减少布尔掩码软件实现中的功耗泄露，提升侧信道安全性。通过硬件层面的优化，为掩码方案提供足够的噪声支持，同时为软件实现提供高效、安全的指令接口。最终，本项目将为我国国产RISC-V处理器安全建设提供创新性成果，助力构建高安全性的国产处理器生态体系。,"1. 为布尔掩码软件实现设计一套基于RISC-V架构的抗侧信道攻击指令集；
2.基于热门RISC-V CPU进行扩展指令集实现，验证指令集在抗侧信道攻击上的有效性,最终给出测试结果；
3.编写相关文档，阐明设计原理、指令编码、指令功能等。"
openInula 2.0 Antd 基础组件库,基础,"[[""web"",""Web Application""],[""web"",""Webpack""],[""web"",""UI""],[""web"",""React""]]",openInula 2.0 是一个新兴的前端框架，但目前缺乏一套完整的 UI 组件库支持。本项目旨在基于 Ant Design（Antd）的设计规范，开发一套轻量级的核心组件库，为开发者提供高效、易用的基础组件。相关背景：Antd 是 React 生态中广泛使用的 UI 组件库，但openInula 2.0 作为新框架，需要兼容其特性的组件库。已有工作：Antd 的开源代码和设计规范可作为参考。存在的不足：openInula 2.0 尚未有官方支持的组件库，开发者需要手动适配 Antd 组件。实现目标：提供一套稳定、高效的openInula 2.0 版 Antd 基础组件库，支持常见场景的开发需求，包括：Button (按钮)Icon (图标)Input (输入框)Checkbox (多选框)Radio (单选框)Select (选择器)Switch (开关)Card (卡片)Tabs (标签页)Modal (对话框)Notification (通知提醒框)Spin (加载中),"1.  输出要求的 openInula2.0组件及测试代码，包括：
Button (按钮)、Icon (图标)、Input (输入框)、Checkbox (多选框)、Radio (单选框)、Select (选择器)、Switch (开关)、Card (卡片)、Tabs (标签页)、Modal (对话框)、Notification (通知提醒框)、Spin (加载中)2.  完善的文档，包括架构设计、API说明、使用指南和开发文档"
面向灾害预警的雷达观测极端降水短临预测,进阶,"[[""datas"",""AI""],[""datas"",""Deep Learning""]]",本项目是利用雷达回波图像将物理演变方案与条件学习方法统一到端到端神经网络框架中的非线性短期预报模型。该模型能有效处理极端降水事件，在 2048km×2048km 区域内呈现多尺度模式，预报时效长达 3 小时，且在极端降水预报方面表现出色，此前的方法难以企及。使用 MindSpore 复现 NowCastNet 模型，有望借助其特性，进一步提升模型训练与部署效率，推动气象预报领域的发展，为极端降水预报提供更有力的支持 。,1. 需要参与任务的人员基于 MindSpore 深度学习框架，完成 NowCastNet 模型的复现工作。具体而言，要依据 NowCastNet 模型的原理和架构，使用 MindSpore 的 API 进行代码编写，构建模型的各个组件，包括但不限于网络结构搭建、数据处理流程设计、模型训练与优化等环节。确保复现后的模型能够在给定数据集上达到与原模型相近的性能表现，在极端降水预报等场景中发挥作用，同时要对复现过程进行详细记录和总结。
openGauss向量数据库对接数据来源最佳实践,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",完成Apify 与openGauss向量数据库适配，达成Apify抓取网站数据保存至openGauss、对接大模型完成RAG端到端验证，输出openGauss适配脚本及RAG最佳实践文档。,1.  基于openGauss 容器部署指导文档、Apify部署指导文档，基于docker完成服务部署。编写应用代码，完成Apify对接openGauss功能适配。2. 根据Apify适配流程，对接配置嵌入模型、LLMs，完成基于openGauss的RAG端到端验证，并输出对接文档，对接文档需合入openGauss社区。
Vue组件库ElementPlus转换到openInula,基础,"[[""web"",""React""],[""web"",""Webpack""],[""web"",""Web Application""],[""web"",""UI""],[""web"",""Babel""]]",相关背景：随着openInula的推广，越来越多的业务希望从Vue切换到openInula框架上来。可以通过工具将Vue的代码转换成openInula代码。但是很多业务使用ElementPlus组件库，这就需要也将ElementPlus组件库也转换成openInula框架。已有工作：1、已有Vue到openInula的转换工具。存在的问题：1、没有基于openInula的组件库可以让基于Vue+ElementPlus技术栈的业务平滑切换到openInula。2、当前工具API覆盖不够，需要进一步完善。3、部分API转换前后存在运行时序差异，需要进一步优化。希望改进要点：1、将ElementPlus组件库通过工具转成基于openInula的组件库。2、进一步完善转换工具。,1. 技术栈要求：TypeScript，openInula，Vue，ElementPlus2. 功能要求：基于Vue框架项目转换到openInula后可以平稳运行
LoongCollector 流水线性能和稳定性优化,进阶,"[[""datas"",""Kafka""],[""dev"",""Prometheus""],[""safe"",""TCP/IP""]]",LoongCollector 是一款集卓越性能、超强稳定性和灵活可编程性于一身的数据采集器，专为构建下一代可观测 Pipeline 设计。源自阿里云可观测性团队所开源的 iLogtail 项目，在继承了 iLogtail 强大的日志采集与处理能力的基础上，进行了全面的功能升级与扩展。从原来单一日志场景，逐步扩展为可观测数据采集、本地计算、服务发现的统一体。LoongCollector凭借其灵活的流水线和插件化设计，已在多个开源项目中成为数据流转的核心枢纽。然而，随着用户规模的快速增长，Kafka、OTLP 等主流开源数据源的高吞吐场景下，当前采集性能与稳定性仍存在瓶颈。：通过系统性优化，让 LoongCollector 成为开源生态中最可靠的高性能数据采集工具！你将挑战的核心技术目标：1. 性能突破：用 C++ 重构核心插件目标：针对 Kafka 等高频数据源，开发高性能 C++ 输出插件，取代现有插件的性能短板。技术亮点：掌握C++ 高性能编程，深入理解内存管理、线程池优化等底层技术；通过零拷贝（Zero-copy）和异步处理设计，实现吞吐量的量级提升；与现有 Go 插件对比测试，验证性能飞跃。2. 瓶颈定位：用现代工具与技术精准优化目标：通过性能分析定位瓶颈，结合先进库与架构设计优化系统。技术亮点：使用 perf 工具定位热点函数，结合火焰图（Flame Graph）深度分析；重构代码：通过批处理提升 Go 插件系统的流水线性能，升级 v2 接口；引入等并行计算技术；输出性能对比报告，量化优化效果。3. 稳定性守护：构建全链路监控体系目标：通过插件级自监控，暴露系统问题。技术亮点：通过 Prometheus Exporter 暴露自监控指标（如延迟、错误率、吞吐量）；提升系统容错能力，降低运维复杂度。,1. 实现 C++ 版本的 Kafka 输出模块，性能较目前版本提升至少 30%2. 升级 Go 版本的输入、处理和输出插件接口3. 编写性能分析报告，解决 1-2 个性能瓶颈点4. 为实现的功能模块提供完善的说明文档和使用案例5. 为实现的功能模块添加完善的测试
llvm与gcc兼容性增强 —— 符号类型处理差异,进阶,"[[""os"",""Compiler""]]",llvm和gcc是当下主流的C、C++编译器。应用使用不同编译器编译构建，可能遇到编译或者运行的兼容性问题。为降低客户在从gcc迁移至llvm过程中的人力投入，提升客户体验，需要在llvm编译器中对兼容性进行增强，支持对应场景的处理。不同编译器生成obj文件时，生成的函数/变量符号的类型可能存在差异，最终引发兼容性问题,1. 针对llvm与gcc生成符号属性的行为进行调研，输出调研报告。2. 在llvm中开发功能，根据调研发现的差异进行兼容，在对应功能打开时，保障llvm对符号属性的处理行为与gcc一致。
TinyPro 适配移动端，提升平板和手机端访问的体验,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",TinyPro 是一个基于 TinyVue 打造的前后端分离的后台管理系统，支持在线配置菜单、路由、国际化等，还支持页签模式、多级菜单等丰富的特性。目前 TinyPro 在移动端场景下表现不佳，希望能适配移动端，让平板和手机用户访问 TinyPro 时也能保持良好的用户体验。技术上可以考虑基于 UnoCSS 原子化CSS进行实现。,1. 实现响应式布局，确保在各种移动端设备上，如手机、平板等，后台管理界面能够自适应屏幕大小，提供良好的视觉效果和用户体验，包括但不限于菜单、登录、表格、表单、详情、个人中心、系统管理等模块的合理展示和操作。2. 根据移动端的操作习惯，设计简洁、直观、易用的交互界面和操作方式，如手势操作、触摸反馈、弹窗、下拉面板、表单、表格等，需要符合移动端交互习惯，提升用户在移动端使用后台管理系统的便捷性和舒适度。3. 确保在主流的移动浏览器上能够正常运行，如 Chrome、Safari、Firefox、UC 等，进行充分的浏览器兼容性测试和问题修复，保证用户在不同浏览器环境下都能获得一致的使用体验。4. 确保设备兼容性，对不同品牌、型号的移动端设备进行适配和测试，包括但不限于 iOS、Android 系统的手机和平板，解决因设备差异可能导致的显示问题、操作问题等，确保系统在各种移动端设备上的稳定性和可靠性。5. 确保在各种屏幕大小和分辨率下友好展示，包括但不限于：1024X768、2048X1536、1125X2436、1080X1920、750X1334、640X1136、1536X2560、1440X2560等分辨率6. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。7. 补充相应的文档和自动化测试用例。8. 建议输出移动端适配的介绍文章和视频
集成中文分词到 NVDA 中以增强文本导航和盲文输出,进阶/Advanced,"[[""datas"",""Natural Language Processing (NLP)""],[""datas"",""AI""]]",背景：NVDA 为盲人和视障用户提供基本的文本导航命令（例如按字符、词、行阅读）和盲文输出。然而，书面中文通常在词语之间没有空格，呈现为连续的字符序列。这种语言特性给标准的屏幕阅读器文本处理带来了挑战。现有工作：NVDA   可以逐字符导航中文文本。其“按词阅读”命令目前将每个汉字视为一个单独的词，或者仅依赖标点符号/空格，这对于中文来说既不自然效率也低。盲文输出经常在词中间断行，或者将每个字符单独处理，妨碍了阅读的流畅性。NVDA  内部不存在原生的中文分词功能。当前不足：用户无法使用词级导航高效地查阅中文文本，显著减慢了阅读和编辑任务的速度。选择或删除完整的语义词很困难。由于不佳的断行和缺乏词级阅读单位，盲文阅读体验欠佳。所需改进：本项目旨在将中文分词能力集成到 NVDA 中。这将允许 NVDA 的文本导航命令（特别是“下一个词”/“上一个词”）在中文文本中语义正确的词边界之间移动。它还将使盲文输出系统能够使用这些词边界进行更合理的断行，并可能实现基于词的盲文显示。最终目标：研究、选择并集成一个合适的中文分词库/算法到 NVDA 中。该实现应增强 textInfos 系统（NVDA 的内部文本表示），以识别中文词语单元，从而通过语音实现精确的词级导航，并改进盲文显示器上的格式化/导航。,"1. 研究与库选择报告：记录对可用的开源中文分词库/工具的分析，考虑准确性、性能、内存使用、许可和集成易用性。选定一个候选库/方法。

2. 集成架构设计：一个计划，概述分词如何触发、结果如何在 NVDA 的文本处理框架（textInfos）内存储/缓存，以及导航命令和盲文输出将如何使用此信息。

3. 功能原型实现：集成到 NVDA 分支中的可工作代码，演示：
在中文文本上正确运行“下一个词”和“上一个词”导航命令。
盲文显示器上中文文本断行改进的证据（需要测试设置或模拟）。
所选分词库的集成。

4. 性能分析与优化：分词性能影响的测量以及优化工作（例如缓存）以确保响应性的证据。词语导航的基本测试套件。

5. 最终项目报告与文档：一份涵盖研究、设计、实现细节、性能发现、挑战以及变更的基本开发者文档的报告。"
基于现实设备产品的边缘设备模型设计,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""]]",当前KubeEdge对设备模型的定义比较简单，起到的实质作用并不大，而且其设计在使用时会让使用者产生困扰。在传统IOT中，设备会被设计成：物模型、产品、设备实例，由于历史原因，现在拆成3类对象的成本会很大，而且这么细粒度的抽象意义也不是很大，因此我们将模型定义成现实设备产品的概念（物模型+产品），即用于描述一种设备产品的规格、连接协议、属性获取方式等，这样设备的实例就可以共享这些配置，无非连接的地址对于不同的设备配置不一样。这样的设计，能一定程度的复用配置信息，并且定位更加的清晰。,1. 编写完善的设计方案2. 完成新的CRD设计3. 完成Device下发的改造4. 完成 DMI 的兼容改造
HugeGraph Loader 服务化升级：任务管理、并行处理与存储直通,基础,"[[""cloudnative"",""Distributed Storage""],[""datas"",""Database""],[""datas"",""Data Science""],[""dev"",""DataOps""]]","Loader 是 HugeGraph (Toolchain)中用于从""文本/传统数据库/Spark/Flink"" 等数据源转为的导入组件，目前存在以下的不足:新版 Loader 需要优化提供数据导入功能，以服务化的方式可长期运行(不局限为一次性任务)，实现服务到服务的数据导入:- 服务化：以服务的形式运行在服务端- 任务管理：提供任务管理功能，任务常驻化, 有基本的监控能力，可以实现定时增量导入数据- 并行处理：实现核心链路的尽可能多的并行化, 可使用协程/虚拟线程方式进行优化- 存储直通：数据导入服务可选 bypass-mode 绕过 HugeGraph Server，实现 RPC 直接写分布式图存储 HStore",1. 在当前版本 Loader 代码基础上，添加或修改代码，使其实现新版需求相关功能2. 编写充分的单元测试和集成测试，验证导入功能的正确性和性能 (对比)3. 提供清晰、详细的文档，说明如何使用新版 Loader（中英双语）4. 实现 Toolchain-tools 的代码融合重构 (加分项)
Karmada cluster failover 优化,基础/Basic,"[[""cloudnative"",""Kubernetes""]]",Karmada (Kubernetes Armada) 是一个 Kubernetes 管理系统，它使您能够在多个 Kubernetes 集群和云平台中运行云原生应用程序，而无需更改应用程序。通过使用 Kubernetes 原生 API 并提供高级调度功能，Karmada 实现了真正的开放式、多云 Kubernetes。Cluster Failover 特性旨在显著提升多集群环境下业务的可用性。作为一项关键且功能丰富的特性，我们始终高度重视用户反馈，并持续对其进行迭代优化，致力于为用户打造更卓越的使用体验。本次项目我们计划对 Failover 特性进行了一次大规模的全面升级。在该项目中，我们计划对 Failover 特性的架构进行了深度调整。为集群故障机制添加了明确的约束条件，从而能够统一管控因集群故障引发的资源迁移行为，确保迁移过程更加规范有序。在可配置性方面，我们从系统配置和策略 API 定义等多个维度进行了优化，为用户提供了更广泛的自定义空间，能够满足多样化的业务需求。Track issue: https://github.com/karmada-io/karmada/issues/6317,1. 功能实现：实现任务表中计划于1.15版本实现的功能2. 测试覆盖：编写测试用例覆盖新增功能3. 文档介绍：完成相关文档说明
基于MCP协议整合多源信息实现多模态动态旅游规划系统,基础,"[[""datas"",""AI""]]",基于模型上下文协议（MCP）整合用户偏好、实时交通/天气数据、景点热度、消费成本等多源信息，并结合 SOTA模型（如Qwen3等）实现个性化行程生成、动态路线优化及体验模拟。,"1. 集成来自交通、天气、景点等多个开放API的实时数据，对多源数据及逆行预处理和融合
2.基于MindSpore，采用SOTA的多模态大语言模型，实现对用户偏好和多源信息的理解和处理，提供初步行程建议和路线规划
3.采用策略梯度的强化学习算法（如PPO），实现动态路线优化
4.开发交互式用户界面，展示个性化行程和路线规划结果，提升用户体验"
bsub -pack 性能优化,基础,"[[""codelang"",""Programming Language""],[""cloudnative"",""Distributed Storage""],[""os"",""Linux""],[""os"",""Ubuntu""],[""os"",""GCC""],[""os"",""GNU""],[""os"",""CentOS""],[""safe"",""TCP/IP""]]","bsub -pack的目的是把批量作业一次性提交给服务器，这样可以减少客户端和服务器的网络连接次数，加快作业提交速度，同时简化用户操作。使用方法如下：1. 首先定一个作业文件，文件中添加需要一次性要提交的多个任务，任务选项格式和bsub命令行直接提交格式一样，如下：[admin@host1 ~]$ cat jobs.a-R ""select[mem>200] rusage[mem=100]"" sleep 10-J ""test"" sleep 11sleep 122.在安装好的volclava环境里，提交这个作业文件：bsub -pack jobs.a目前volclava中已经实现了上面的使用方式，在bsub客户端把文件中的作业提交到服务器端的时候，目前是一个作业一个作业提交的，如例子中的作业文件有三个作业，那么客户端会和服务器建立三次网络连接，每建立一次连接发送一个作业数据。我们需要优化作业数据交换方式，使得和服务器建立一次网络连接，一次性把作业文件中的所有作业放在一个数据包中发送给客户端，客户端能一次性解析出多个作业。",1. 要求bsub -pack一次服务器连接提交定义在文件中的所有作业； 服务器端接受请求后，在处理批量作业时，处理完一个作业就及时返回结果，然后接着处理下一个，直到处理完所有作业后再结束连接。
基于关系型数据库的agentUniverse智能体应用元信息持久化与加载,基础/Basic,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""LLM""]]",当前，在 agentUniverse项目中，智能体应用的元信息主要通过配置文件的形式进行存储和管理，常见的格式包括 YAML 和 TOML 等。这种基于文件的配置方式在中小型应用场景中具有部署简单、易于理解和维护的优势，能够有效提升开发者的使用体验和研发效率。然而，随着智能体应用规模的不断扩大以及对高可用性、可扩展性要求的提升，传统的文件型元信息管理模式逐渐暴露出一系列问题，尤其是在大型分布式系统中的适用性明显不足。一方面，配置文件通常以单节点形式存在，当系统需要进行集群化部署时，任何配置的修改都需要通过广播机制同步至所有节点，这不仅增加了运维复杂度，也容易因网络延迟或节点故障导致配置不一致的问题；另一方面，文件系统本身缺乏良好的容错机制，一旦发生节点宕机或磁盘损坏等情况，可能会造成元信息的丢失，严重影响系统的稳定性和数据完整性。为了解决上述问题，本课题提出了一种基于关系型数据库的智能体应用元信息持久化与加载方案。该方案旨在将原本依赖于本地文件的元信息配置迁移到关系型数据库中进行统一管理与访问，从而实现元信息的集中存储、高效查询、事务控制及高可用保障。通过引入数据库技术，不仅可以提高元信息的读写性能和一致性，还能够更好地支持智能体应用在分布式环境下的动态扩展需求。此外，结合 agentUniverse 平台自身的架构特点与业务场景，本课题将进一步探索如何构建一套适用于智能体应用的元信息管理模型，包括但不限于智能体应用元信息的数据结构设计、数据库表结构建模、配置变更的版本控制、多租户支持等内容，最终为其向企业级大规模智能体平台演进提供坚实的技术支撑。,1. 为agentUniverse项目进行数据库表结构设计与建设2. 为智能体应用元信息配置存储与管理提供接口3. 提供必要的单元测试与测试报告4. 撰写设计与功能说明文档
GraphAr 格式数据导入 Kuzu 的扩展工具实现,进阶/Advanced,"[[""datas"",""Database""],[""datas"",""Graph Database""]]",Apache GraphAr (incubating) 是一个标准图存储文件格式框架，底层存储基于 CSV 格式，以及 Apache Parquet 或 Apache ORC 列存文件格式。Kuzu 是一个嵌入式图数据库，旨在实现快速查询和良好的可扩展性，针对大型数据库上的复杂分析工作负载进行了优化，并提供了一套检索功能。Kuzu 原生支持从 CSV、Parquet、NumPy、JSON 等多种格式导入数据。此外，Kuzu 还提供了扩展框架，以更好地与外部系统集成，目前已经实现了对 DuckDB、PostgreSQL、Neo4j 等系统的扩展。本项目需要开发 GraphAr 的扩展，使 Kuzu 能够直接从 GraphAr 格式载入数据，利用 Kuzu 的强大功能方便用户对 GraphAr 存储的图数据进行高效查询和处理。,1. 完成能够从 GraphAr 格式导入数据的 Kuzu 扩展工具。2. 提供完整的文档，详细描述使用该扩展的步骤、功能，并提供示例，确保用户能够顺利上手。3. （加分项）推动该工具成为 Kuzu 的官方扩展。
基于版面解析和大语言模型的文档翻译能力建设,进阶,"[[""datas"",""LLM""],[""datas"",""Computer Vision(CV)""]]",OCR技术正在从单纯的文字识别向文档理解和信息提取方向发展，与大模型的结合成为新趋势。大模型时代下，泛OCR类需求持续，文档理解领域的开源项目影响力增速迅猛。在OCR、文档解析等领域通过技术创新，研发出业界重磅特色方案，基于PaddleX版面解析V3（PP-StructureV3）产线，结合大语言模型，支持对文档图像的多语种翻译工作，并且能够支持PDF转为word/LaTex，恢复正确版面顺序。,"1. 完成产线全流程核心机制的开发，pdf/图像文档能够转变为正确翻译（英文/日文），并恢复正确阅读顺序的word/latex文档。
2. 完成测试评估，文本编辑距离等指标优于其他开源方法2-3个点（其他相关开源项目例如https://github.com/Byaidu/PDFMathTranslate）"
为 Breeze 实现任务栏模块,进阶,"[[""codelang"",""Programming Language""],[""os"",""x86""],[""os"",""LLVM""],[""web"",""UI""]]",#### 1. 项目背景Windows 原生任务栏在功能扩展性、视觉定制化和性能优化方面存在局限，难以满足现代用户对个性化和高效操作的需求。Breeze 社区已通过 Breeze Shell 项目验证了现代化 Shell 组件的可行性，现计划基于现有技术栈重构 Windows 任务栏，提供更流畅、轻量且高度可定制化的替代方案。#### 2. 已有基建与能力- **breeze-ui 基础库**：已实现高性能 UI 渲染框架，支持亚像素抗锯齿、60FPS 动画和低资源占用（静态时接近 0% CPU/GPU 占用）。- **Breeze Shell 技术验证**：现有项目已验证以下能力：- 基于 JavaScript 的扩展 API（支持插件化功能扩展）。- JSON 高度可定制化主题：JSON 配置与 breeze-ui 模块配合，可以非常方便地实现带默认值的同时对大部分界面参数动态修改，实时预览，且不增加太多开发负担- 轻量化二进制（Breeze Shell 仅 2MB，任务栏可复用相同技术栈）。- **Win32 API 集成经验**：已通过 Shell 项目积累了对 Windows 消息循环、窗口管理和二进制操作的成熟封装。#### 3. 当前不足- **原生任务栏的局限性**：- WinUI3 在低配置机器下性能差，导致卡顿- 定制化能力弱（如无法调整图标间距、动态调整区域布局）。- **现有方案的缺陷**：第三方任务栏工具（如 ExplorerPatcher）依赖逆向实现，稳定性差且难以扩展。#### 4. 项目目标实现一个功能完整、性能优于原生任务栏的替代方案，具备以下特性：- **基础功能兼容性**：100% 支持原生任务栏的核心操作（窗口切换、通知中心呼出等）。- **资源占用控制**：运行时内存占用 ≤100MB，静态 CPU 使用率 ≤0.5%。,1. 实现一个功能完整、性能优于原生任务栏的替代方案
优化 Python 绑定，支持复杂场景,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""Data Science""]]",在 Python 生态中，Apache OpenDAL 已成为 AI 数据处理、高性能存储和分布式计算的重要工具。然而，现有的 Python 绑定在复杂环境（如多进程、分布式场景）中的支持仍有不足，同时文档与示例覆盖范围有限，无法完全满足开发者的实际需求。我们希望通过优化 Python 绑定，打造一个功能全面、性能稳定、易于扩展的工具链，让 OpenDAL 成为 AI 数据处理场景下的理想存储解决方案。,1. 模块化拆分与动态加载支持。当前 Opendal Python 绑定将所有功能整合在单一包中，导致安装体积较大且灵活性不足，不适合复杂场景需求。2. 支持自定义层与回调。用户希望能够通过挂载自定义回调函数控制操作生命周期，例如实现自定义日志或指标监控。3. 文档与示例的系统化。提供面向开发者的最佳实践文档，帮助用户快速掌握核心功能。
微信 .NET SDK  ,进阶,"[[""web"","".NET""],[""datas"",""Semantic Kernel""]]",Senparc.Weixin SDK 是目前市场占有率居首位的微信 .NET SDK，并获得微信官方推荐。目前已支持微信全平台大部分常用接口，包括：微信公众号、微信小程序、企业号、微信支付、微信开放平台，等等。Senparc.Weixin SDK 同时也是中国综合排名最高的 C# 开源项目之一：https://github.com/JeffreySu/WeiXinMPSDK,1. 构建基于微信的多智能体服务2. 进一步完善基于国密（SM）的微信支付3. 完善官方接口及文档
 使用floating-ui重构TinyVue的tooltip和popover组件,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",使用Floating UI 重构 TinyVue 的 tooltip 和 popover 组件，可以提升这些组件的灵活性和可维护性。Floating UI 是一个用于创建浮动元素（如 tooltip、popover 等）的库，它提供了强大的功能来处理定位和动画效果。替换 TinyVue 弹出框底层的 popper.js。,1. 使用 Floating UI 替换TinyVue组件库目前使用的 popper.js2. 兼容 tooltip 组件的所有功能和 api 并且跑通所有的测试用例3. 兼容 popover 组件的所有功能和 api 并且跑通所有的测试用例4. 补充对应的使用文档
基于开源通信中间件实现持久化服务,进阶,"[[""datas"",""MySQL""],[""web"",""Qt""],[""os"",""x86""],[""os"",""RISC-V""],[""safe"",""Socket""],[""safe"",""TCP/IP""]]",本项目的数据通信中间件（DDS）在默认情况下，数据仅在发布者存活时保留，发布者离线后数据立即清除，设置本地持久化后，数据在发布者内存中保留，即使发布者离线，已发送的数据仍对本地订阅者可见，但新加入的订阅者无法获取历史数据。如果将数据保存在持久化服务中（数据库），发布者离线后新订阅者仍能获取历史数据。本项目基于开源数据通信中间件，接收并保存数据，开发持久化服务，实现数据的全局保留。,1. 开发数据接收模块，基于开源中间件，接收并存储网络中的所有设置为持久化的数据。2. 开发数据发送模块，发送持久化数据。3. 开发数据存储模块，将数据存储到本地数据库。4. 开发数据加载模块，从数据库中加载持久化数据。5. 搭建服务界面，进行数据展示和管理。
为IvorySQL增加一键式安装脚本,基础,"[[""datas"",""PostgreSQL""]]",(1)相关背景IvorySQL是一个开源的基于PG的兼容Oracle的数据库。支持在多个平台及操作系统下使用。IvorySQL目前通过源码安装的方式为手动执行多条命令安装，缺少一键式安装的方式。(2)已有的工作已有源码安装的教程及命令。(3)存在的不足在不同操作系统下源码安装的过程存在差异，手动执行命令安装过程繁琐且容易出错。(4)希望改进的点通过增加一键式安装脚本使用户可以快速的通过源码安装IvorySQL。(5)最终项目实现的目标提供一个一键式的安装脚本，用户在进行简单配置并执行脚本后，可以通过执行一条命令即可安装启动IvorySQL。,1.脚本开始进行环境监测，检查操作系统类型和版本，以及其他必要条件2. 环境监测通过后，脚本开始从指定位置获取 IvorySQL 的源代码3.获取源码后，脚本自动进行源码编译4. 编译完成后，脚本自动将生成的二进制文件安装到指定的安装目录5. 脚本执行数据库初始化操作6. 脚本启动 IvorySQL 数据库服务，并输出安装成功的提示信息7. 如果安装过程中出现错误，脚本应该输出错误信息并终止安装过程
Apollo 权限系统架构迭代升级	,基础,"[[""web"",""Spring Boot""],[""datas"",""MySQL""]]",Apollo的系统主要可以分为App、Env、Cluster、Namespace四层架构，旨在为真实企业应用提供强大的配置环境隔离能力，所以也需要做到不同用户能够访问、管理的Namespace权限是不同的，做到权限隔离。Apollo早期的权限设计是不够完善的，主要体现在下面几点：<1>仍有部分粒度的权限能力没有实现（参考）。<2>权限校验的实现涉及多次数据库查询，可能成为系统性能瓶颈。<3>OpenApi与Portal的权限实现是两套系统，不便于两侧api归一架构升级。因此需要对Apollo的权限系统进行增强，应该首先做到OpenApi与Portal的归一化，然后再规划更丰富的权限能力，可以参考issue区对权限能力的需求：,1. 实现OpenApi与Portal两端的权限系统归一架构升级，并编写相应测试代码验证2. 优化权限校验实现，并编写相应测试代码验证3. 实现或进一步规划更丰富的权限能力
django支持opengauss,基础,"[[""web"",""Django""]]",使用django5连接openGauss数据库，选择pgsql的方式并不支持。在django里面添加和支持opengauss驱动依赖。,1. .在django项目里面集成opengauss的驱动选项，可以通过原生django就能选择和链接opengauss数据库。2. 在社区博客和资料提交使用说明
为 Kata/runtime-rs 实现对 Seccomp 的支持,进阶,"[[""os"",""Linux""],[""os"",""Virtualization""],[""os"",""KVM""]]",Kata Containers 提升安全性的一种重要手段是通过配置 Linux 内核的 Seccomp（Secure Computing Mode）策略来实现的。本项目旨在增强 Kata/runtime-rs 对 Seccomp 的支持，通过引入并实现对 Seccomp 的支持，进一步提高 Kata Containers 的安全性。当前 Kata agent 和基于 Go 的 Kata runtime 和已经支持 Seccomp，但是基于 rust 的 runtime-rs 还未支持该安全特性。因此，我们计划在 runtime-rs 中引入 Seccomp 支持，以使 Kata Containers 在 rust 生态中能够充分利用 Seccomp 提供的安全特性。我们希望达成以下目标：,1. 完成 runtime-rs 支持 seccomp 的总目标；2. 提供完整的配置说明文档（英文表述）；3. 完整的，符合社区开发规范的 PR。
openHiTLS支持SPAKE2+，实现符合RFC9383,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""PKI""],[""safe"",""SSL/TLS""],[""safe"",""VPN""]]",SPAKE2+ 是一种增强型密码认证密钥交换协议（PAKE，Password-Authenticated Key Exchange），用于在两方之间安全地生成共享密钥，同时避免泄露密码,"1.基于openHiTLS架构与RFC9383协议内容，输出设计文档，包括现有协议实现调研，API 设计与使用说明，模块依赖关系，实现思路，测试策略等；
2.依据开发者文档实现SPAKE2+协议并完成测试，代码合入目标仓库
3.输出测试报告，包括正确性测试，压力测试，性能测试等"
BanyanDB客户端login,基础/Basic,"[[""web"",""UI""],[""dev"",""DevOps""]]",BanyanDB的Java SDK，UI和bydbctl三个客户端实现login功能- https://github.com/apache/skywalking/issues/12865- https://github.com/apache/skywalking/issues/12864,1. BanyanDB各客户端登录统一调后端接口。Java SDK封装REST接口实现登录、Token管理及异常处理；UI客户端利用浏览器内置鉴权，无须修改UI代码，只需调整内嵌HTTP服务即可；而bydbctl命令行工具则支持交互或参数化登录，Token安全存储且支持登出。
为 EulerPublisher 引入容器镜像层依赖关系分析引擎,进阶,"[[""cloudnative"",""Cloud Native""],[""datas"",""AI""]]",EulerPublisher 是一个“一站式”自动构建、测试和分发 openEuler 软件制品的工具。它支持以 openEuler 为底座构建多样化基础和应用容器镜像，并根随 openEuler 的发布计划，构建针对主流公有云的云镜像，同时还支持二进制软件包的处理。当前，容器镜像的构建依赖人工配置层间依赖关系（如 PyTorch 依赖特定 Python 版本），导致构建效率低且易因依赖冲突引发失败。此外，无法根据依赖关系推荐层合并、拆分或顺序调整策略，导致镜像臃肿或构建耗时增加。因此，为了满足复杂场景容器镜像构建需求，我们计划为其集成 AI 驱动的依赖分析引擎，提供自动化依赖分析能力。,1. 设计并实现依赖分析模块2. 训练轻量化依赖关系预测模型3. 设计并实现完整的测试方案4. 提供规范的用户手册和开发者文档
Git仓库RISC-V相关commit扫描工具研发,基础,"[[""dev"",""Git""],[""os"",""RISC-V""]]",软件项目通常统一维护特定于各种指令集架构的代码，各架构特定的代码及其修改都在相同的Git仓库中完成，本项目旨在建立匹配规则，根据规则扫描Git仓库，提取RISC-V架构相关的commit，并对commit数据进行多视角的处理和可视化呈现。,1. 满足以下要求的代码：2. 相关技术文档
基于Soliidty 构建你的第一个高性能 DApp,基础/Basic,"[[""codelang"",""Programming Language""]]",OpenBuild 社区是一个面向 Web3 开发人员的开源社区，为各种技能水平的开发人员提供量身定制的学习和实践平台，帮助大家更好的进入 Web3。而Solidity 是 Web3 新手的最佳编程语言，新人开发者的入门路径:从 5olidity 开始，学习Web3基础知识，例如汽油费、出块时间、验证和区块链技术的一些基础知识。Solidity 是以太坊区块链平台上的智能合约编程语言。通过实践编写 Soiditv 智能合约，你将深入了解区块链技术的工作原理、智能合约的执行过程以及如何在区块链上构建去中心化应用程序(DApps)。智能合约是区块链技术的核心之一，是在区块链上执行的自动化合约、可以自动执行代码并管理数字资产。通过编写自己的智能合约，你将学会如何设计和实现具有特定功能和逻辑的智能合约。Solidity 是一种与众不同的编程语言，具有其自身的语法、数据类型和特性。通过编写实际的智能合约，你将掌握 Solidity 编程语言的基础知识，并提升编程技能。：区块链技术正在迅速发展，区块链开发社区也在不断壮大。通过参与 Solidity 智能合约项目，将有机会与其他开发者交流、学习和分享经验，从而更好地融入这个充满活力的社区。：Monad 网络提供了无与伦比的性能，给EVM带来了巨大的活力，发挥你独特的想象力，寻找一些只能在Monad 网络上构建的有趣/特有的DAPP。,1.  学习Solidity合约开发并部署你的首个智能合约2. Web3开发实践，产出你的Web3应用Demo3.  利用现有的Monad网络的基础设施，构建在Monad上运行的DAPP:https://docs.monad.xyz/tooling-and-infra4. 基于Monad的特性（128KB合约，高出块速度），构建可以发挥Monad特性和最大性能的有趣DAPP
openGauss DataKit支持ER图设计和建模,基础,"[[""datas"",""Database""]]",在openGauss DataKit平台上完成ER图设计和建模功能，用户可以基于其数据特征设计ER图，生成对应的建表、索引、外键语句，在指定的数据库服务端执行完成语句执行。,1. 基于openGauss DataKit完成ER图设计插件开发，使得用户可基于其数据特征设计ER图，生成对应的建表、索引、外键语句，在指定的数据库服务端执行完成语句执行。2. 完整输出项目代码、设计文档和测试报告，代码合入社区。
基于 Spring Cloud Alibaba MCP 服务高效构建通用 AI 智能体,基础,"[[""cloudnative"",""Cloud Native""],[""web"",""Spring Cloud""]]",1. 项目背景2025 年时 AI Agent 爆发的一年，Agent 需要依赖工具辅助完成任务，而 MCP（Model Context Protocol）为智能体与工具交互提供了标准协议。很多企业中有大量使用 Spring Cloud Alibaba 开发的业务系统，通过与 Spring AI Alibaba 社区合作共建的 MCP 解决方案，我们可以将 Spring Cloud 业务系统发布为 MCP 服务。2 学生职责&目标在这个项目中，学生将和社区一起共同探索开发一个通用 AI Agent，重点解决在面对大量 MCP 工具时，如何更有效、智能的过滤筛选 MCP 服务，帮助模型和 Agent 在运行过程中更好的选择 MCP 工具。3. 学生要求&技术栈,1. 在这个项目中，学生将和社区一起共同探索开发一个通用 AI Agent，重点解决在面对大量 MCP 工具时，如何更有效、智能的过滤筛选 MCP 服务，帮助模型和 Agent 在运行过程中更好的选择 MCP 工具。
为 OpenTenBase 实现分布式状态视图,进阶,"[[""datas"",""Database""]]",在 OpenTenBase 中，针对 pg_stat_activity、pg_locks 等单节点状态视图，提供一个分布式的视图，针对同一个 query 把多个节点的视图状态合理地整合为一个，以降低定位成本，快速定位慢语句，判断等待事件，梳理瓶颈点。,"1. 实现功能代码
2. 提供设计文档
3. 提供性能测试数据"
为RISC-V架构迁移辅助插件添加知识库RAG支持,基础,"[[""os"",""RISC-V""],[""codelang"",""Programming Language""]]",RVSmartPorting通过分析各大操作系统发行版（包括但不限于openEuler、Fedora及Ubuntu等）中已适配RISC-V架构的开源软件包，总结形成了一些通用软件在适配RISC-V架构时的难点、痛点及常见解决方案，以自然语言编写的Wiki及软件源代码数据集等形式，形成了面向通用软件开发者的 RISC-V 架构适配多元知识库。参与本项目的同学需要阅读、分析并完善现有知识库的内容和组织形式，为RVSmartPorting社区设计实现的RISC-V架构迁移辅助插件添加知识库RAG的支持。开发者在阅览由架构迁移辅助插件提供的目标代码定位报告时，可通过自然语言形式提出问题或进行搜索，辅助工具可通过RAG技术检索知识库中的相关内容，为开发者提供具体的问题修复方案或建议。在完善知识库的现有内容时，参与本项目的同学需对比分析各种开源软件的历史版本，从中提取适配RISC-V架构时所进行的具体修改内容。将软件包适配RISC-V架构前后的源代码规范整理，形成软件迁移适配RISC-V架构的源代码参考数据集，总结提炼迁移适配RISC-V架构的共性问题和具体解决方案。,1. 在“睿迁RISC-V软件迁移辅助插件”基础上开发实现知识库RAG提问与检索功能2. 在不少于2种编程语言、5个章节的知识库已有内容基础上进行调优，增强相关示例代码，验证RAG提问与检索效果3. 形成不少于50组开源软件迁移适配RISC-V架构的历史版本数据集，需包括适配前后的源代码、对应的diff文件及具体修改内容的描述
改进 XPack 打包插件,基础,"[[""codelang"",""Programming Language""],[""os"",""Debian""],[""os"",""Linux""],[""os"",""Ubuntu""],[""os"",""Clang""],[""os"",""Compiler""]]","Xmake 提供了一个 xmake pack 的打包插件，简称 xpack，可以将构建产物打包生成 msi, deb, rpm 等各个平台的安装包。但是目前它还缺少对 AppImage 和 MacOS 的 dmg 安装包格式支持。另外现有的打包格式也缺少对 Qt 项目构建产物的打包支持，因为构建完 Qt 项目后，还会有一个额外的 qtdeploy 流程去导出所有依赖的动态库和资源配置文件，这些文件都没有被打入安装包中，因此也需要对其做进一步支持。因此，我们需要改进 xpack 插件的实现，使其支持以下特性：","1. 增加对 AppImage 打包格式的支持，支持 Linux, macOS, Windows2. 增加对 macOS dmg 打包格式的支持，支持 macOS3. 增加对 Qt 项目的打包支持"
实现轻量高性能的 Agentic GraphRAG 架构,进阶,"[[""datas"",""AI""],[""datas"",""Data Science""],[""datas"",""Database""]]","目前，我们已经实现了一个基础的 GraphRAG(可支持 Text2GQL+子图查询+自定义图算法执行)，但它依赖于固定的 pipeline/workflow（例如，知识检索和图更新会复用类似的流水线），这导致在变化/复杂场景下灵活性不足, 扩展性也会十分受限。于是我们旨在引入一种基于“动态感知、轻量级调度、并发执行” 为基本原则的智能化（Agentic）架构，将 GraphRAG -转变-> Graph Agent, 核心有以下几个问题：该任务将包含三个核心部分：业内已有大量实现参考方案与代码实现, 详情可见项目备注的参考链接🔗, 有问题可提前交流沟通~","1. 引入高效易用的 workflow 设计, 实现核心的 Graph Agent 模式2. 支持半自动生成图 Schema + Prompts 自动优化3. 优化查询执行 profiler，可以快速的针对某个查询定位性能瓶颈4. 构建高效轻量的记忆管理模块，用于上下文感知的状态跟踪和信息复用"
DragonBoot RISC-V内核引导程序,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""]]",DragonOS 是完全使用 Rust 编写的，二进制兼容 Linux 的操作系统。目前，DragonOS 已实现对 RISC-V 平台的启动支持，能在 QEMU 中进入用户态，并且能结合 u-boot 与 DragonStub ( DragonOS 基于 Linux EFI stub 实现的独立 EFI stub ) ，在 VF2 开发板上引导进入 DragonOS 内核。本选题的目标是，基于 oreboot + RustSBI + DragonOS，开发一个 VF2 固件，使之能够直接利用 DragonOS 内的驱动，在UEFI阶段进入RING3（就像 LinuxBoot 那样）,1. 对现有 DragonOS 在 RISC-V 平台上的启动流程进行修改，允许 DragonOS 直接在 RustSBI + oreboot 环境下启动2. 为 visionfive2 开发板进行必要的驱动适配，使得 DragonOS 能在 visionfive2 开发板上启动并进入用户态3. 基于 RustSBI + oreboot ，结合修改后的 DragonOS 内核，封装一套 ROM 固件，使得在qemu、visionfive2 开发板上能够基于该固件直接进入 DragonOS 用户态。可能需要对 DragonOS 内核进行精简压缩等操作。4. 移植 u-root 进入 DragonOS 内核，允许 DragonOS 以 u-root 作为根文件系统启动，并能使用内置Go编译器正常初始化其内置命令及 bootloader5. （可选进阶）为 DragonOS 实现 kexec，允许在 DragonOS 中使用 kexec 启动 Linux 内核
Apache Linkis MCP 能力支持,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""Hadoop""],[""dev"",""Git""],[""cloudnative"",""HDFS""]]",项目背景：随着人工智能（AI）技术的快速发展，越来越多的企业和组织开始将 AI 应用于数据分析、预测建模、自动化决策等场景。然而，AI 应用的开发和部署面临着诸多挑战，包括数据管理、计算资源调度、任务治理、安全性等。Apache Linkis 作为一个强大的计算中间件，已经为大数据平台提供了高效的计算治理和数据源管理能力。为了进一步提升 Linkis 的功能，使其能够更好地支持 AI 应用，我们计划启动一个项目，通过实现 MCP（Model Context Protocol）Server，将 Linkis 的能力扩展到 AI 领域。本项目主要工作：1.任务和计算治理：将 Linkis 的任务治理和计算治理能力暴露给 AI 模型，使 AI 模型能够动态地提交和管理计算任务。2.数据源集成：通过 MCP Server，使 AI 模型能够直接访问 Linkis 管理的数据源，实现数据的实时查询和操作。3.知识问答： 通过 MCP Server，为用户提供快速、准确的问题解答，减少对专业人员的依赖，提升用户体验和系统推广效率4.官网维护：Linkis 常见问题整理和官网文档优化项目产出要求：1.完成 Linkis MCP Server能力基础框架搭建以便快速开发可用的MCP Server 工具2.完成 Linkis 任务提交、错误码和常见QA问答、关键配置项含义及配置示例问答 MCP Server 工具能力开发工作3.Linkis 常见问题整理和官网文档优化,1.开发工作
Dubbo-Go接入MCP服务,进阶,"[[""datas"",""LLM""],[""cloudnative"",""Cloud Native""]]",1. 项目概述在当前大模型时代，许多厂商已经提供了MCP Server功能。为了使Dubbo-Go在大模型时代保持技术领先并提供创新解决方案，我们提议为Dubbo-Go框架增加MCP Server能力。这将帮助开发者更容易地将Dubbo-Go服务作为AI能力暴露出来，同时促进Dubbo-Go生态系统与大模型服务的无缝集成2. 技术领域3. 编程语言4. 开源协议5. 项目简述目标：实现Dubbo-Go与MCP协议的无缝集成，使Dubbo-Go服务可注册为MCP Server的原子工具，或通过MCP Client调用外部工具，推动微服务与AI驱动的任务协作生态融合。核心功能：6. 期望完成时间 & 支持架构7. 里程碑：8. 导师支持,"1. 代码交付：MCP协议适配模块；Dubbo-Go与MCP Server/Client集成示例
2. 文档：开发文档；测试报告
3. 辅助材料：Demo演示视频；开源之夏结项报告"
制作和提交 C/C++ 包到官方包仓库,基础,"[[""codelang"",""Programming Language""],[""dev"",""Git""],[""dev"",""CI""],[""os"",""ARM""],[""os"",""Fedora""],[""os"",""GCC""],[""os"",""Linux""],[""os"",""LLVM""],[""os"",""Ubuntu""]]",Xmake 的一大特性就是内置了对 C/C++ 依赖包的管理和快速集成，并且提供了一个官方的 C/C++ 包管理仓库，目前已经收录了接近 1700 多个包，但相比庞大的 C/C++ 生态，还远远不够。因此，为了进一步完善 C/C++ 的包依赖生态，希望通过此项目，帮助 Xmake 社区，制作和提交入库更多的 C/C++ 库进来，让更多的项目从中受益。本项目需要完成以下这些包，将它们成功提交入 https://github.com/xmake-io/xmake-repo 包管理仓库。- cmake- [xor_singleheader](https://github.com/FastFilter/xor_singleheader)- [libsolv](https://github.com/openSUSE/libsolv)- [libnfc](https://github.com/nfc-tools/libnfc)- [flashlight](https://github.com/flashlight/flashlight)- [telegram-bot-api](https://github.com/tdlib/telegram-bot-api)- [openvpn3](https://github.com/OpenVPN/openvpn3)- meson- [systemd](https://www.freedesktop.org/wiki/Software/systemd)- [libxcrypt](https://github.com/besser82/libxcrypt)- [libselinux](https://github.com/SELinuxProject/selinux)- autotools- [libxls](https://github.com/libxls/libxls)- [openssh](https://www.openssh.com/portable.html)- make- [hashcat](https://github.com/hashcat/hashcat),1. 完成和入库以下 C/C++ 包，至少保证一个主流系统平台可用
为Risingwave增强时间序列相关功能,进阶,"[[""datas"",""Flink""],[""datas"",""PostgreSQL""],[""datas"",""Relational Database""],[""datas"",""Database""]]",https://github.com/risingwavelabs/risingwave/issues/19343RisingWave 是一款基于 Apache 2.0 协议开源的分布式流数据库，旨在简化实时流数据处理和管理。它采用存算分离架构，支持高效的复杂查询、动态扩缩容和快速故障恢复，帮助用户轻松搭建稳定且高效的流计算应用。不同于传统主要关注存储和查询历史数据的时间序列数据库，RisingWave 专注于实时处理数据流，支持亚秒级延迟的分析和复杂变换，如多路连接、聚合和窗口函数。GitHub 上的相关问题列表中，涵盖了其时间序列功能的部分开发计划，以进一步增强其时间序列处理能力,1. 完成上述github issue中的功能
openKylin RISC-V版本Python环境管理平台的开发与搭建,进阶/Advanced,"[[""os"",""Linux""],[""os"",""RISC-V""]]",Python虚拟环境是搭建AI开发环境的重要组成部分，当前主流的方案采用Conda、mamba、venv等方式管理，在openKylin RISC-V系统中，搭建AI开发环境，由于缺少好用的python虚拟环境管理工具，面临python版本管理困难，RISC-V架构python包难以安装，缺少有效依赖等问题，因此亟需开发一款专为 RISC-V 平台设计的高效、稳定的 Python 虚拟环境管理器，以更好地支持其部署与运行需求。解决openKylin操作系统在RISC-V架构下的python生态、AI开发环境问题。,1.实现RISC-V 架构下的python环境管理器2. 搭建RISC-V架构下的python 软件源仓库管理平台3. 搭建RISC-V架构下的 Python 软件包构建平台
Apache SeaTunnel支持metalake开发,进阶/Advanced,"[[""cloudnative"",""Flink""],[""cloudnative"",""HDFS""],[""cloudnative"",""Kafka""],[""datas"",""Data Science""]]",目前，Apache SeaTunnel的任务配置都将数据源的用户名密码写死在任务脚本中，这样会导致数据源信息泄漏以及当数据源配置信息发生变更所有的任务都需要手动修改一遍，所以需要有一个集中的地方可以存储数据源信息通过数据源id来映射。本题的目的是可以支持主流的数据目录Apache Gravitino并可以方便扩展支持其他三方数据目录（需要留接口方便实现）。参考：,"1. 完成metalake配置信息适配
描述: 可以将metalake配置信息配置在seatunnel-env中，任务启动后加载到任务配置脚本的env中。2. 完成source和sink的数据源配置信息改造
描述: 读取env中是否开启metalake标识，source/sink增加sourceId标识作为去metalake查询的唯一id，获取数据源信息替换source/sink配置项中的占位符。3. 插件的方式支持metalake支持并支持apache gravitino集成
metalake接口定义，支持根据唯一id查询获取数据源配置信息功能，并支持apache gravitino数据源信息转seatunnel数据源配置项占位符"
Kmesh eBPF程序的UT补充,进阶/Advanced,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""],[""os"",""Linux""]]",Kmesh 是一种基于 eBPF 和可编程内核的高性能、低开销服务网格数据平面。因为编写eBPF prog的时候，想要验证其功能就需要编译之后进行黑盒测试。但这样效率低下且功能的看护程度取决的测试人员的测试能力。因此我们参考cilium，引入了eBPF prog的测试框架。现阶段测试框架已经搭建完成，需要大家完善eBPF Prog的测试用例,1. 成功运行的Kmesh的ebpf sendMsg prog的UT测试代码2. 成功运行的Kmesh的eBPF cgroup prog的UT测试代码3. 附加：在github action中集成eBPF Prog UT的运行，并输出覆盖率。4. sendMsg和Cgroup的测试文档
HugeGraph 支持向量索引存储与检索,进阶,"[[""datas"",""Database""],[""datas"",""Vector Database""],[""cloudnative"",""Distributed Storage""],[""datas"",""Graph Database""]]","随着 LLM/AI 快速发展，向量存储检索已经成为构建 LLM RAG/Agent 应用架构中的重要一环，进而催生了Milvus 等向量库的火爆，KV存储中 KVRocks/OB/ES/Neo4j 等 NoSQL 数据库也跟进支持向量检索，降低业务应用中的选型复杂度。HugeGrpah 已经在社区业务中广泛应用，为了更好的整合支持业务使用向量场景，降低业务上手/使用门槛，决定引入向量存储检索和查询的能力。拓展此能力意义在于支撑 LLM 应用，拓宽原有场景使用方式。(也可以尝试用 Graph Embedding 来代替默认的 Text-Embedding, 准确性可能更高)1. 可以先实现单机版下的向量索引存储 + 查询 (基础)2. 实现 HStore 分布式后端 (Raft) 下的索引 + 查询 (能力强的同学也可以直接基于分布式向量存储查询实现)可根据向量 embedding 的结果, 找到子图 VertexID 或 Property，更好的是可以结合原生的图结构, 复用 Graph EmbeddingPS:- 向量索引可优先集成成熟的 Java 开源库进行开发 (例如 Apache Lucene, 也可参考 Elastic Search 实现分布式向量索引方式)- 如果有比较合适的 C++/Rust 可方便集成的库也可以选用 (参考 OB/KVRocks 等)",1. 在单机/分布式存储上实现向量数据类型并支持其持久化2. 在 HugeServer 实现向量相关的 DDL/DML API，基础的创建向量库 + CRUD 即可3. 简洁清晰的性能对比和使用文档 (例如 Faiss)
为 Excelize 添加创建股价系列图表支持,进阶/Advanced,"[[""codelang"",""Programming Language""]]",Excelize提供广泛的图表功能，支持56种不同类型的Excel图表和组合图，以满足广泛的数据可视化需求。无论用户是要创建简单的条形图、复杂的多系列折线图还是高级散点图，Excelize都能满足用户的需求。该项目旨在为Excelize添加股票图表支持，包括4种箱体和蜡烛图类型股票图表：“最高价-最低价-收盘价”、“开盘价-最高价-最低价-收盘价”、“成交量-最高价-最低价-收盘价”、“成交量-开盘价-最高价-最低价-收盘价”图表。,1. 为 AddChart 和 AddChartSheet 函数添加支持创建四种股票图表2. 在 drawing.go 和 chart.go 源代码文件中进行实现3. 具有完备的文档和单元测试，在 drawing_test.go 和 chart_test.go 源代码文件中编写单元测试，增量行测试覆盖度达到 100%4. 高质量的代码实现，具有良好的性能表现
扩展GPT-VIs协议，支持Agent工作任务视窗，实时展示Agent执行的代码、文档等信息,进阶,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""LLM""]]",背景：随着MCP作为Agent的工具协议出现，Agent的能力边界得到了很大的拓展，但是当Agent使用不同工具的时候如何将信息实时像用户进行可视化展示，对齐Agent和人的信息差异是基于AI落地和构建产品，获取用户信任的关键环节。预期目标：所以希望在DBGPT的Agent下完成任务视窗模式类似Manus的工作窗口，使用GPTVIs组件的方式构建动态任务视窗。 项目分两部分：1.后端，使用python构建Agent工作过程的数据流，并将不同任务结果转换成VIS协议数据，通过流式接口推向前端2.前端，使用NextJS开放各种任务视窗可视化控件，展示Agent工作过程的任务展示，比如文件、图表、网页、表格、视频流等等,1.  项目设计文档（含架构图、原理图、实现细节等））2. Agent输出源代码、前端可视化VIS组件源代码3. Agent开发使用文档（提供完整的使用教程文档）4. 构建基于DBGPT的标准验证场景Agent和可视化模版
基于KubeEdge-Ianvs的大模型联邦微调算法,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""cloudnative"",""Kubernetes""]]",随着大语言模型（LLM）在医疗、金融、政务等多个隐私敏感行业的广泛应用，利用本地数据对LLM进行微调以满足领域定制化需求成为趋势。传统的联邦学习方法在面对LLM的超大参数量与计算成本时显得力不从心。目前KubeEdge-Ianvs及KubeEdge-Sedna已支持协同推理和协同训练方式，但并未支持大模型联邦微调。为此，本项目拟在KubeEdge-Ianvs框架下构建一个联邦学习范式流程以及支持参数高效微调的大模型联邦微调算法。未来可能利用KubeEdge-Sedna的边缘节点调度、资源管理能力，实现低通信、低计算、高适配性的大模型联邦学习流程。,1. 参考KubeEdge-Sedna的联邦学习算法库，在KubeEdge-Ianvs中实现一个联邦学习的新流程范式2. 基于KubeEdge-Ianvs的新联邦学习范式，实现一个大模型联邦微调算法，作为算法基线3. 基于KubeEdge-Ianvs的新联邦学习范式，提供标准化测试套件，包括数据集、测试指标和测试环境脚本4. （可选）对范式中提供大模型联邦微调算法基线，针对边缘客户端本地训练进行优化
VChart 扩展图表：K线图,基础/Basic,"[[""web"",""npm""]]",为 VChart 这一图表库添加全新的图表类型，具体为可用于金融领域展示股票、期货等价格走势的 K 线图。,1. 调研标注K线图的功能、交互、数据格式，形成K线图需求文档
改善 Fcitx5 与 Deepin Desktop Environment 的集成,基础/Basic,"[[""os"",""Linux""],[""os"",""Window Manager""],[""os"",""DBus""]]",Deepin Desktop Environment (DDE) 是一个美观且用户友好的桌面环境，是 Linux 发行版 Deepin 的默认桌面环境，也广泛存在于其他各大桌面环境中。本项目旨在为 Deepin Desktop Environment 改善 Fcitx5 的集成。一个可能的方向是：允许输入法框架（如 Fcitx 5）将其用户界面（例如预编辑文本、候选词列表、状态图标等）直接嵌入到应用程序或桌面环境的界面中，而不是使用传统的独立悬浮窗口，使 Deepin 用户能够无缝使用 Fcitx5 并享受与其他成熟桌面环境环境一致的输入法面板体验。项目将包括实现相关的接口适配、与 DDE 的集成、用户界面优化以及相关文档的编写，确保项目的可持续性和可维护性。可以参考的内容有Gnome: https://github.com/wengxt/gnome-shell-extension-kimpanelSway: https://github.com/swaywm/sway/pull/7226通过本项目，Deepin 的用户将能够在 DDE 中获得更一致、更高效的多语言输入体验，同时促进 Deepin 生态系统的协作与兼容性。,1. 调研目前各类桌面环境对 Fcitx5 的支持情况和实现方式，分析目前 DDE 存在的改进空间，提出切实的改进方案，并整理形成相关报告。2. 根据上一条中的调研报告，为 DDE 的桌面组件增加功能，或编写新的 DDE 插件，实现例如 Fcitx5 在DDE 上的原生候选词弹出窗口，或其他重要的功能改进。3. 编写完善的技术文档，记录相关的上游标准或事实标准，以及本项目最终采用的实现方式。
开发Space 间距组件,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",在UI设计中，间距（Space）组件是一个非常基础但又极其重要的元素。它主要用于控制界面元素之间的空白区域，帮助提升整体布局的清晰度和美观性。通过合理使用间距，可以有效地组织页面内容，使用户更容易理解和操作。在实际应用中，合理的间距设置不仅能够增强视觉效果，还能改善用户体验，使得信息层次更加分明，操作流程更为直观。例如，在一个列表界面中，适当的间距可以帮助用户快速区分不同的项目；在一个复杂的表单中，恰当的间距则能减少用户的认知负担，提高填写效率。,1. 实现垂直间距：用于调整两个相邻元素在垂直方向上的距离。2. 实现水平间距：用于调整两个相邻元素在水平方向上的距离。3. 实现统一间距：适用于需要保持一致间距的情况，比如列表项之间的间隔。4. 实现自定义间距：允许开发者根据具体需求设置特定大小的间距。5. 实现对齐方式：可以从尾部对齐、从中间对齐、空间围绕；实现反向排列内部元素6. 详细补充对应的文档并添加全量的自动化测试用例7. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。8. 建议输出Space 间距组件的介绍文章和视频
基于oneDNN的RVV优化,进阶,"[[""datas"",""AI""],[""datas"",""PyTorch""],[""os"",""RISC-V""],[""os"",""Linux""]]",项目描述：目前oneDNN库已支持在riscv架构上的编译，但众多算子还未有优化实现，因此使用RVV向量扩展指令优化oneDNN底层算子库，包括卷积、矩阵乘、池化等操作，本项目最终实现在riscv平台上的向量加速。产出标准：1. 评估目前OneDNN库 RVV优化效果，包含但不限于自动向量化对比标量、已优化的Pooling效果等。2. 进一步优化Pooling，包含但不限于优化现有RVV实现、增加Average Pooling实现、增加更多数据类型支持等。3. 进一步利用RVV优化OneDNN库，包含但不限于matmul、convolution、gemm等技术要求：熟悉计算机系统原理，熟悉向量编程，熟悉C++编程,1.利用RVV优化OneDNN库，包含但不限于matmul、convolution、gemm等2. 进一步优化Pooling，包含但不限于优化现有RVV实现、增加更多数据类型支持等3. 评估目前OneDNN库 RVV优化效果4. 编写算子优化说明文档，输出功能与性能验证报告；
Linux系统安全保障方案及测试工具,基础,"[[""os"",""Linux""]]",目前针对Linux操作系统的安全保障没有一套完整的解决方案，普遍存在仅使用各种安全扫描工具扫描而没有完整的安全保障方案问题，本项目通过调研面向企业级应用的操作系统的安全指标并选型合适的安全测试工具，形成一套针对企业级应用的操作系统的安全保障/测试方案，并基于openEuler社区mugen测试框架开发对应的测试脚本，项目的目标是建立针对企业级应用的操作系统的安全保障方案。,1. 调研操作系统在企业应用中在系统安全方面被关注的核心方向，形成调研文档，要求调研结果能相对比较真实的反映各项安全指标在企业应用中的关注程度，不得直接借助AI生成文档应付，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/security_test 目录下。2. 根据上述1中的调研结论，调研用于测试系统安全的测试工具，形成调研文档，对于多个安全测试工具，需要进行对比并做选型，给出选型原因，调研文档上传存放于 https://gitee.com/oepkgs/os-autotest/tree/master/doc/security_test 目录下3. 学习了解openEuler开源社区的mugen测试框架（https://gitee.com/openeuler/mugen ），掌握测试套/测试用例的开发方法以及运行调试方法4. 根据上述2中的调研结论，结合上述3中的知识点，开发安全测试的测试套和测试用例，测试套上传至 https://gitee.com/oepkgs/os-autotest/tree/master/suite2cases/security_test 目录下，测试用例上传至 https://gitee.com/oepkgs/os-autotest/tree/master/testcases/security_test 目录下（注：os-autotest 是基于mugen框架，旨在建立针对操作系统完整测试方案的测试框架/脚本库）5. 上述4中提交的测试套和测试用例需要在 os-autotest 中执行通过，提交MR时需附执行通过截图
BanyanDB通过OAP/UI实现自监控,基础/Basic,"[[""dev"",""DevOps""]]",SkyWalking OAP 通过Otel-Collector 抓取 BanyanDB暴露的基础监控指标，通过MAL进行分析，并通过SkyWalking UI进行展现。此功能为新功能，需要和导师沟通功能范围，和提交设计和实现方案。,1. 	完成BanyanDB监控指标的抓取，进行分析并在SkyWalking UI中展示，并且完成E2E自动化验证和SkyWalking Showcase 部署
Project for OSPP 2025: MuPDF integration for Mogan STEM,Basic,"[[""web"",""Qt""]]","mgubi implemented a MuPDF renderer for GNU TeXmacs, this project is to  integrate mgubi’s code into Mogan STEM and improve the renderer  implementation. The current renderer is implemented in Qt, the renderer  in MuPDF will free the renderer of Mogan STEM from Qt, and later, it is  possible for us to get rid of Qt and implement a small TMU/TM reader via  WASM in web browsers.",1. Integrate the MuPDF renderer impl by mgubi and add a xmake option to enable or disable it2. Improve the MuPDF renderer impl3. Make the MuPDF renderer work on WASM in web browsers
Cloudpods 虚拟机支持 kickstart 自动化安装 ISO 镜像,进阶,"[[""os"",""QEMU""],[""os"",""Linux""]]",Cloudpods 目前支持创建虚机并且挂载 ISO 镜像，但不支持虚机启动时通过 kickstart 自动化安装 ISO 镜像。需要开发支持创建虚机流程中注入 kickstart 脚本到 cloudpods 元数据中，启动虚机时添加 kickstart 自动化安装 ISO 镜像相关 QEMU 参数，并且兼容主流的操作系统。,"1. 虚拟机启动能够触发 kickstart 自动化安装 ISO 镜像。2. 通过 Cloudpods API/CLI 注入或者更新 Kickstart 配置。3. 兼容主流 Linux 发行版（CentOS/RHEL, Fedora, Ubuntu 等）。4. 代码以 PR 形式提交到 https://github.com/yunionio/cloudpods 仓库。5. 产出项目开发使用文档。"
HintlessPIR 算法的研究与实现,进阶,"[[""safe"",""AES""],[""safe"",""RSA""]]",目前 PIR 领域的研究方式出现了一个新的方向，即基于 LWE 加上预计算的方式来完成 PIR 协议的构造。这类协议以 SimplePIR、DoublePIR、FrodoPIR 为代表工作。他们有一个共同的特点是需要一个离线阶段，在该阶段服务端会计算出一个数据库相关的信息，称为 Hint，并发送给客户端；客户端需要保存该 Hint，当处于在线阶段后，客户端的查询需要结合该 Hint 才能够完成。然而，带 Hint 的 PIR 协议为客户端引入了更多的存储和状态维护的开销，为了进一步解决和优化这个问题，在此基础上，又出现了一类 HintlessPIR 的协议。这类协议的主要目的就是去除 Hint，同时尽量保有带 Hint 的 PIR 协议的优势。。,1. 在 https://github.com/secretflow/psi 中实现一个 HintlessPIR 的 SOTA 协议2. 需要为该实现提供完备的测试以及 Benchmark，详细分析该协议每一个阶段的计算和通信开销3. 为该协议的实现编写对应的说明文档
添加BiSheng JDK 8 RISC-V port的JIT支持,进阶,"[[""os"",""Compiler""]]",（1）相关背景目前BiSheng JDK 8在RISC-V上使用的是不含汇编的Zero VM，启用JIT可以提升约几十倍的性能（2）已有的工作目前BiSheng JDK 11已有RISC-V的支持，可以此为基础进行backport[1]，也可参考OpenJDK 8 ARM64的移植patch（3）存在的不足BiSheng JDK 8 RISC-V port的JIT目前还没有开源的实现（4）希望改进的点在实现解释器的基础上，增加JIT的支持（5）最终项目实现的目标为BiSheng JDK 8 RISC-V port提供JIT支持，完成C2的移植，C1移植为可选项。,1. BiSheng JDK 8 RISC-V port解释器完整移植2. BiSheng JDK 8 RISC-V port JIT C2完整移植3. BiSheng JDK 8 RISC-V port JIT C1完整移植（可选）
Support time series data structure and commands like Redis,Advanced,"[[""datas"",""Database""],[""cloudnative"",""Redis""]]","RedisTimeSeries is a redis module used to operate and query time series data, giving redis basic time series database capabilities.As Apache Kvrocks is characterized by being compatible with the Redis protocol and commands, we also hope to provide temporal data processing capabilities that are compatible with RedisTimeSeries.This task is to implement the time series data structure and its commands on Kvrocks.Note: Since Kvrocks is an on-disk database based on RocksDB, the implementation will be quite different from Redis.References:",1. Add indexing and encoding algorithm of time series data in Kvrocks2. Support the major part of commands of RedisTimeSeries in Kvrocks3. Add C++ and golang test cases for these new changes
RISC-V生态下的增量式程序静态分析框架建设,进阶,"[[""os"",""RISC-V""],[""codelang"",""Programming Language""]]","静态分析技术作为软件质量保障的重要手段，已广泛应用于开发环境以早期发现潜在缺陷。然而，传统静态分析工具在RISC-V生态中面临双重挑战：一方面，工具自身执行耗时影响开发效率；另一方面，现有RISC-V开发平台固有的性能瓶颈进一步制约了分析工具的实用化进程。为了提高静态分析工具在RISC-V开发平台上的可用性，RVSmartPorting社区计划设计实现一套可集成在C/C++项目开发流程中的增量分析框架IncAnalyzer，支持对C/C++项目配置、构建、分析的全流程管控，支持基于变更的文件级/函数级增量信息提取。为了完善IncAnalyzer分析框架，一方面，需要适配更多的构建系统（如CMake，GNU Make等），从构建过程中捕获后续分析需要用到的编译数据库（Compilation Database）；另一方面，需要调研常见的C/C++静态分析工具（如Clang Static Analyzer, CppCheck, ClangTidy等），确认其能否迁移到RISC-V开发平台下使用，并根据工具的分析流程，尝试将这些静态分析工具集成到IncAnalyzer中，利用IncAnalyzer提供的增量信息实现文件级或函数级增量分析，最终达成对RISC-V平台开发过程中的软件的高效静态分析。",1. 完成至少一种新的构建系统的适配，支持构建配置的输入和编译数据库的生成2. 调研至少三个静态分析工具的基础上，完成至少两个静态分析工具的文件级增量分析适配，至少一个静态分析工具的函数级增量分析适配
为 StarRocks 添加 llm() 用户自定义函数以实现 LLM 交互 ,基础/Basic,"[[""datas"",""AI""],[""datas"",""Database""]]",本项目旨在为 StarRocks 数据仓库系统添加一个新的内置用户自定义函数(UDF)，使用户能够直接在 SQL 查询中与大型语言模型(LLM)进行交互。这将使数据分析师和工程师能够在不离开数据库环境的情况下执行情感分析、文本摘要、数据分类和实体提取等任务，从而显著简化 AI 驱动的数据处理流程。该函数将支持与提供 OpenAI 兼容 API 的服务（如 OpenAI、Azure OpenAI）以及 Ollama 端点进行交互，并通过灵活的配置参数允许用户自定义 LLM 交互的各个方面。,"1. 实现核心 llm() UDF 功能，支持：
- 与 OpenAI 兼容的端点（如 OpenAI、Azure OpenAI）集成
- 与 Ollama 端点集成
- 灵活的配置选项（服务类型、模型、参数等）
- 适当的错误处理和超时机制

2. 完整的单元测试和集成测试
3. 详细的用户文档，包括：
- 函数用法说明
- 配置参数详解
- 多种使用场景的示例（情感分析、文本摘要、数据提取等）
- 故障排除指南
4. 代码符合 StarRocks 项目的编码规范和质量标准"
基于ai的开源运营辅助模块设计与实现,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""],[""web"",""React""]]",目前在开源项目的管理与运营中，虽然已有不少工具辅助，但对于项目内各类复杂信息的智能分析与处理仍显不足，传统的分析方式多依赖人工经验，难以快速、准确地挖掘出有价值的信息，也无法充分适应开源项目快速变化的特性。本项目旨在集成大语言模型的先进能力，打造一款智能化的开源项目辅助工具。利用大语言模型的能力，探索大语言模型在开源运营辅助插中的应用场景，例如项目问答、代码解释、自动分析等，实现对开源项目的智能洞察与自动化分析。本项目的目标是开发一个功能强大、灵活可配、智能高效的开源项目辅助系统原型，并在多个典型开源项目中验证其在提升项目管理效率、挖掘潜在问题与机遇方面的实用性和准确性。,1.集成大语言模型的能力，探索AI在开源领域的应用场景2. 开发与大语言模型的交互展示界面3. 实现全新的ai能力支持，包括但不限于项目问答、代码解释、自动分析4. 编写模块使用说明文档与开发文档
openGauss对接AI编排工具Kotaemon实现智能小助手,进阶,"[[""datas"",""Database""],[""datas"",""AI""]]",完成Kotaemon开源RAG UI 与openGauss 向量数据库的适配，将默认向量空间设置为openGauss，通过配置嵌入模型、LLMs等完成可视化RAG端到端验证，输出openGauss适配脚本及RAG流程效果文档。,1. 基于openGauss 容器部署指导文档、Kotaemon开源RAG UI 部署指导文档，基于docker完成服务部署。编写应用代码，完成Kotaemon对接openGauss功能适配，代码提交至openGauss社区。2. 根据openGauss适配流程，对接配置嵌入模型、LLMs，完成基于openGauss的RAG端到端验证，并输出对接文档，对接文档需合入openGauss社区。
 RocketMQ 路由反向更新机制,进阶,"[[""cloudnative"",""Kafka""],[""cloudnative"",""Cloud Native""],[""cloudnative"",""RabbitMQ""],[""cloudnative"",""Amazon SQS""]]",RocketMQ 消息路由由NameServer进行管理，而客户端或Proxy感知路由变化都是采用定时更新的策略（客户端默认30s更新一次，Proxy默认20s更新一次），这种策略具有滞后性，比如Broker上下线，主备Broker进行切换等场景下，客户端或Proxy需要一段时间才能感知路由更新，可能会造成一段时间不必要的消息发送、接受失败等情况。不管是客户端还是Proxy，都保持了长连接，路由反向更新的条件客观存在，因此本方案需要你设计和实现一个路由反向更新的方案，当NameServer路由更新后，能及时通知客户端和Proxy路由感知变化。,1. 路由反向更新模块2. RocketMQ 客户端路由管理模块3. RocketMQ Proxy 路由缓存管理模块4. 兼容性及稳定性整合适配5. 从 0 到 1 完整的设计、研发、测试、上线
MaxKey官方文档优化和系统手册编写,基础,"[[""safe"",""OAuth""],[""safe"",""OpenIDConnect""],[""safe"",""LDAP""],[""safe"",""JWT""],[""safe"",""SAML""]]",Dromara单点登录认证系统是，谐音为马克思的钥匙，寓意它能够像一把万能钥匙(最大钥匙)一样，解锁复杂的企业安全需求，提供简洁而高效的解决方案。产品支持OAuth 2.x/OpenID Connect、SAML 2.0、JWT、CAS、SCIM等标准协议，提供的用户身份管理(IDM)、身份认证(AM)、单点登录(SSO)、RBAC权限管理和资源管理等。MaxKey注重企业级场景下的性能、安全和易用性，广泛应用于医疗、金融、政府和制造等行业。MaxKey，开源、安全、合规、自主可控。,1. 官方文档优化2. 编写系统手册3. 文档整体视觉效果优化
ONNX Runtime 在 RISC-V 架构 OpenHarmony 系统上的移植与性能优化,基础,"[[""os"",""RISC-V""],[""datas"",""AI""],[""os"",""Linux""]]",ONNX Runtime 是微软开源的高性能深度学习推理引擎，广泛用于跨平台部署 AI 模型。随着 RISC-V 架构的发展，AI 推理在该架构上的落地已成为推动生态的重要方向。OpenHarmony 作为面向多设备场景的操作系统平台，其对 AI 能力的支持也日益重要。本项目旨在完成 ONNX Runtime 在 RISC-V 架构 OpenHarmony 系统上的适配移植，并支持运行 2-3 种主流类型的 AI 模型（如图像分类、目标检测、LLM）。在此基础上，探索基于 RISC-V 向量扩展（RVV）进行算子级优化，提升推理速度，推动 RISC-V 在智能终端设备中的实际应用。,1. 成功在 RISC-V + OpenHarmony 平台运行 ONNX Runtime，支持图像分类、目标检测等类型的模型推理。2. 提交完整的适配过程文档和问题分析报告。3. 基于 RVV 的性能优化尝试，提供优化前后的对比分析。
基于openvela系统的UI应用开发,基础/Basic,"[[""web"",""UI""]]",openvela 操作系统专为 AIoT 领域量身定制，以轻量化、标准兼容、安全性和高度可扩展性为核心特点。openvela 以其卓越的技术优势，已成为众多物联网设备和 AI 硬件的技术首选，涵盖了智能手表、运动手环、智能音箱、耳机、智能家居设备以及机器人等多个领域。我们希望借此机会让大家能够认识了解使用openvela系统，共建开源开放的AIoT操作系统生态。此次项目的任务是基于openvela框架的图形界面应用程序开发，类型不限（如播放器、工具类应用、小游戏等），要求体现完整的交互逻辑和可视化设计。,"1. 开发基于 openvela 框架的图形界面应用程序，类型不限（如播放器、工具类应用、小游戏等），要求
体现完整的交互逻辑和可视化设计。"
openHiTLS支持TOTP协议，实现符合RFC6238标准,基础,"[[""safe"",""SSL/TLS""],[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""PKI""]]",TOTP（Time-based One-Time Password）是一种基于时间生成的动态密码算法，该算法结合了共享密钥和当前时间，生成一个在短时间窗口内有效的一次性密码。其主要功能包括：TOTP生成与校验，密钥生成，密钥协商，安全存储等。其标准依据RFC 6238所规范内容,"1.基于openHiTLS架构与RFC 6238协议内容，输出设计文档，包括现有协议实现调研，API 设计与使用说明，模块依赖关系，实现思路，测试策略等；
2.依据开发者文档实现TOTP协议并完成测试，代码合入目标仓库
3.输出测试报告，包括正确性测试，压力测试，性能测试等"
Pikiwidb kvcache,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""Database""]]",在大语言模型领域，随着模型参数量呈指数级增长以及上下文窗口持续扩展，算力需求急剧攀升。与此同时，推理过程中不可或缺的 KVCache 技术所引发的显存资源消耗问题日益凸显，已成为阻碍模型性能提升的关键瓶颈。KVCache 技术通过缓存历史 Token 的 Key/Value 向量矩阵，有效规避了重复计算，大幅提升推理效率。然而，随着生成文本长度的增加，KVCache 占用的显存呈线性增长趋势，严重制约了长文本生成能力与批量推理性能，成为当前大模型应用的核心痛点。Pikiwidb KVCache致力于突破这一技术瓶颈，通过构建显存 - 内存 - 存储三级分布式缓存系统，实现 KVCache 的动态分层存储。该方案打破传统 “纯显存驻留” 模式，创新性地采用分级缓存架构，不仅显著提升了提升计算效率，更有效拓展了模型的上下文处理能力。最终通过Pikiwidb KVCache适配主流推理框架，为大语言模型的高效运行与性能优化提供坚实的技术支撑。本项目的主要工作：,1. 设计项目方案，并定期产出相关文档。2. 测试和验证，使用单元测试、集成测试、混沌测试、压力测试等方式测试该方案的稳定性与可行性。3. 基于pikiwidb，构建显存 - 内存 - 存储三级分布式kvcache分布式缓存系统。4. 实现的kvcache分布式缓存系统，能适配主流的推理框架。
Nonebot插件管理页面统一集成入口框架,进阶/Advanced,"[[""web"",""Web Application""],[""web"",""UI""],[""web"",""Vue.js""],[""web"",""React""]]",随着Nonebot-Bison项目功能的不断完善，现有Web管理页面的功能已经无法满足插件用户和管理者的配置管理需求，加之Web管理页面所使用的相关前端代码久未更新，框架老旧，重构一个对用户和管理者更加便利的Nonebot-Bison 订阅管理、配置管理、Cookies管理的全新Web管理页面迫在眉睫。同时我们注意到，解决 authn 和 authz 是一个共性的需求，有相当一部分Nonebot插件均会为用户或者插件管理者提供诸如账号管理，配置管理之类的Web管理页面，这些页面会分散在各个插件之中，页面的访问方式各不相同，在用户使用上存在诸多不便，我们希望有一个框架来解决这个问题，为此我们设想在Nonebot-Bison的Web管理页面的基础上，构建一个统一的插件Web页面统一接入框架，只需要在项目中调整相关打包配置，在尽可能少，甚至不需要修改项目Web代码的情况下，实现对Nonebot插件Web页面的统一入口集成，module-federated项目的存在，让该设想成为可能。综上所述，本项目希望调研并实现一种跨Nonebot插件、跨Web框架（Vue/React/...）的Web页面入口集成方案。该方案需要保证在代码低侵入性甚至非侵入性的基础上，兼容尽可能多种里的前端框架，提供插件页面所需功能与接口，保证插件页面接入之后的可用性与正常功能，实现多插件统一入口，并以Nonebot-Bison Web 新管理页面验证所实现的接入方案。,1. 多页面集成方案调研2. 基于现有方案，或使用或改造或编写Nonebot插件Web页面统一入口集成方案
研究 eBPF 技术在机器学习驱动的系统观测与自适应优化中的应用潜力,进阶,"[[""os"",""Clang""],[""os"",""Debian""],[""os"",""GNU""],[""os"",""Linux""],[""os"",""Perf""],[""os"",""Ubuntu""],[""os"",""x86""]]",eBPF 技术提供了前所未有的内核级别细粒度、低开销的数据观测和事件处理能力。与此同时，机器学习（ML）在模式识别、异常检测和优化决策方面展现出强大威力。将这两种技术结合，有望在系统性能分析、安全监控、资源管理等领域实现更智能、更自适应的解决方案。然而，如何在受限的 eBPF 环境与计算密集的 ML 算法之间建立高效、有效的协同机制，仍然是一个开放的研究领域。本项目旨在。研究将聚焦于以下一个或多个方向：1.eBPF 驱动的 ML 数据流优化:研究如何设计 eBPF 程序，以高效地从内核中采集、预处理（如过滤、聚合、初步特征提取）并传输高质量的数据流，专门用于进行训练或推理。探索在 eBPF 中进行何种程度的预处理是可行且有益的。2.ML 指导的 eBPF 行为自适应:研究如何利用所学习到的知识（如识别出的模式、异常阈值、最优参数配置），生成配置或规则，并将其（例如通过 eBPF Maps），以指导 eBPF 程序的行为。例如，根据 ML 识别的流量模式动态调整 eBPF 防火墙规则，或根据 ML 预测的负载调整 eBPF 资源监控的采样率。3.面向 eBPF 环境的轻量级智能算法探索:研究哪些（可能不严格等同于传统 ML 模型，但有类似目标）能够在 eBPF 的限制条件下（如无浮点、有界计算）实现，用于执行简单的实时分类、异常评分或状态判断任务。,1. 一份研究报告，深入探讨所选 eBPF 与 ML 结合方向的技术细节、实现方法、潜在应用和挑战2. 一个或多个原型系统的源代码，包含 eBPF 程序、用户空间 ML/交互组件、以及相关的配置和脚本3. 演示案例，展示所研究结合方式在特定场景下的工作流程和效果4. 对 eBPF 在支持机器学习任务方面的能力边界和优化方向的分析
Milvus支持 timestamptz 数据类型,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""Vector Database""]]",背景：timestamptz（全称 timestamp with time zone）是 PostgreSQL 中用于存储日期和时间的数据类型，同时包含时区信息。其底层以 UTC 格式存储时间值，但插入或查询时会根据客户端或会话的时区设置自动转换为本地时间。例如，输入 2023-10-01 12:00:00+08（东八区时间）会转换为 UTC 时间存储，查询时再按客户端时区（如 UTC-5）显示为对应本地时间。适用于全球化系统（如电商、协作平台），确保用户在不同时区看到统一且正确的时间。时间计算方面，自动处理夏令时和时区偏移，适合航班调度、跨国会议等需精准时间对齐的场景。日志记录方面，在分布式系统中统一存储 UTC 时间，便于跨区域日志分析。项目要求：milvus可以存储 timestamptz数据。进行增删改查。,"1）用户可以通过pymilvus客户端在建表时指定数据类型为Timestamptz；
2）用户可以使用pymilvus 插入和取回 timestamptz 类型的数据，可以在请求中指定时区，输入格式形如 '2025-05-01 23:259:59+08'
3）用户可以通过alterdatabase, altercollection等指定database和collection级别的时区
4）用户可以在取回数据时，指定extract(field ,timestamp field) 函数，只取回Year, Month, Day, Hour， DOW （day of week)等；
5）用户基于timstamptz列进行标量过滤（比较算子，相等，不等，大于，小于，大于等于，小于等于），在比较年算子中，可以同时和interval 进行运算， 比如 timestamptz + inerval < timestamptz const value;其中 Interval 的输入格式为（P1Y2M3DT4H5M6S 格式）；
6) 针对 timestamptz列构建索引加速相应查询
7）提交代码并合并进 milvus主分支"
多Agent协同的内核漏洞自动化复现框架,进阶/Advanced,"[[""os"",""Linux""],[""datas"",""LLM""],[""datas"",""AI""],[""codelang"",""Programming Language""]]","（1）相关背景随着内核漏洞复杂度的提升（如CVE-2021-43267的多阶段竞争条件漏洞），传统漏洞复现方法面临三大挑战：跨阶段漏洞建模难：漏洞触发需精准控制内存操作、并发调度、硬件状态等多维度条件。人工经验依赖性强：OpenEuler安全专家需耗费数周分析漏洞模式并设计PoC，尤其针对新版本kernel上线场景。工具链割裂：现有工具（LLM/Syzkaller/PoC生成器）缺乏协同，导致信息流断裂。（2）已有的工作Syzkaller支持覆盖率引导的模糊测试，但无法关联漏洞语义。GPT-4o/Deepseek-R1具备代码生成能力，但未针对内核漏洞优化。学术界提出基于符号执行的漏洞复现方法（如KLEE），但效率低下。（3）存在的不足单点工具局限性：LLM生成、模糊测试、PoC验证等环节孤立运行，缺乏反馈闭环。动态环境感知弱：无法根据Syzkaller运行时状态（如覆盖率/崩溃点）动态调整生成策略。多模态数据处理缺失：文本型CVE描述、代码补丁、硬件事件日志未实现联合分析。（4）希望改进的点构建多Agent协同框架，包含以下核心Agent：CVE Analysis Agent：解析CVE文本（如NVD描述），提取漏洞特征（漏洞类型/触发条件/影响组件）。输入：CVE-2021-43267描述 → 输出：""TIPC协议未校验msg_section大小导致堆溢出""。Syscall Conversion Agent：构建CVE中kernel的历史漏洞报告（CVE+补丁diff）与Syzkaller语法文件与成功PoC案例的数据库利用RAG技术，支持自然语言到syscall模板的转换（如""制造堆溢出""→copy_from_user+kmalloc组合）。Sequence Generation Agent：根据漏洞特征生成候选syscall序列， 用于syzkaller检测特定CVE漏洞。Fuzzing Orchestration Agent：动态调度Syzkaller实例，支持并行测试多组候选序列。实时监控KASAN/KCSAN报告，捕获use-after-free、data race等异常。PoC Synthesis Agent：将触发崩溃的syscall序列转换为可验证的C代码PoC。（5）最终项目实现的目标实现5个功能Agent的协同工作流，复现10+历史漏洞（含CVE-2021-43267）。对比社区解决方案，漏洞复现效率提升8倍（平均耗时从72h降至9h）。提交多Agent框架至OpenEuler社区，支持API扩展（新增Agent接入）。","1. 核心Agent：5个标准化Agent模块（Docker容器化部署）。2.  测试验证：包含5种漏洞类型的测试集（堆溢出/竞争条件/整数溢出等）。3. 文档输出：
《多Agent协同协议设计规范》。
《Agent扩展开发指南》。"
Superset 集成 VisActor,基础/Basic,"[[""datas"",""Power BI""]]",基于 Superset (https://github.com/apache/superset)项目，进行VisActor 可视化组件集成，创建VisActor BI 场景的应用案例。替换Superset 项目原图表和表格为 VChart 和 VTable,1. 功能需求2. 文档和案例
Volcano 大规模场景性能瓶颈分析与持续优化,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""],[""dev"",""Grafana""],[""dev"",""Prometheus""],[""os"",""Linux""]]",性能一直是 Volcano 社区高度关注并持续优化的关键领域。随着用户使用场景的日益丰富、集群规模的不断扩大以及 Volcano 功能的逐步增强，对 Volcano 在大规模场景下的性能提出了越来越高的要求。尽管 Volcano 在早期已经进行了一系列性能优化工作，但为了更好地应对未来的挑战，进一步提升其在大规模场景下的性能至关重要。本项目旨在深入分析 Volcano 在大规模场景下的性能瓶颈，并制定和实施持续的优化策略。具体而言，将借助现有的开源工具，例如 Kubernetes 模拟器 KWOK 以及调度器性能压测工具等，对 Volcano 在处理大规模批量下发 Deployment 和 Volcano Job 等典型场景下的性能表现进行细致的分析。通过性能指标采集与分析、性能瓶颈识别、阶段耗时分析、开源工具应用、优化方案制定与实施、性能回归测试以及持续性能监控与告警等环节，全面提升 Volcano 在大规模场景下的性能，为用户提供更稳定、更高效的任务调度服务。,1. 详细的性能分析报告： 包含在大规模场景下 Volcano 各个关键指标（如 Pod 创建时延、调度时延、API Server 交互时延、CPU/内存使用率等）的基准测试数据和瓶颈分析结果。2. 大规模场景性能压测工具和环境： 能够用于模拟大规模批量任务下发和调度的测试工具和可复用的测试环境配置（例如基于 KWOK）。3. 针对性性能优化方案： 针对识别出的性能瓶颈，提出具体的优化方案和实施计划。4. 优化的 Volcano 代码实现： 实施至少一项或多项性能优化方案，并将其合入 Volcano 社区的代码仓库。5. 性能回归测试报告： 提供优化前后性能对比的详细报告，验证优化效果。6. 性能监控和告警方案： 设计并实现一套可行的 Volcano 性能监控和告警方案。7. 项目总结报告和最佳实践： 总结本次性能优化项目的经验和最佳实践，为后续的性能优化工作提供参考。
为MOE实现Overlapped_forward_backward func,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""GPU""]]",基于DualPipe 的 MOE model 高效流水并行优化DualPipe 是 DeepSeek 开源的一个流水并行算法。这个流水并行算法可以用于MOE大模型的分布式训练，将前向和后向计算与通信阶段的重叠，从而提升训练效率。现在还没有一个开源的MOE模型 DualPipe训练实现。实现 MOE 模型 DualPipe优化 的关键：1. 是要针对MOE模型，定义一个包含 overlapped_forward_backward func 的 PipelineStage；2. 一个优化的 overlapped_forward_backward 实现，让计算和通信尽量的重叠，可以参考 DeepSeek 的 profiling： https://github.com/deepseek-ai/profile-data/blob/main/assets/train.jpg目标是可以跑通一个使用 DualPipe 的MOE 模型，并且能达到较高的通信和计算重叠率。,"1. 是要针对MOE模型，定义一个包含 overlapped_forward_backward func 的 PipelineStage；
 2. 一个优化的 overlapped_forward_backward 实现，让计算和通信尽量的重叠"
基于 RISC-V 架构的 oeAware 框架移植,进阶/Advanced,"[[""os"",""RISC-V""]]",（1）相关背景：RISC-V 架构凭借其开源、灵活等特性，在新兴计算领域得到广泛应用，而 oeAware 作为 openEuler 上低负载采集感知调优框架，亟需适配 RISC-V 以拓展应用场景。（2）已有的工作：oeAware 已在其他架构上实现低负载采集、感知和调优功能，拥有完善的插件体系和 SDK 接口 。（3）存在的不足：当前 oeAware 不支持 RISC-V 架构，限制了其在 RISC-V 生态中的应用。（4）希望改进的点：完成 oeAware 在 RISC-V 架构下的代码适配、依赖库移植及功能验证。（5）最终项目实现的目标：实现 oeAware 在 RISC-V 架构上的稳定运行，支持各类采集、感知和调优插件功能。,1. 完成 oeAware 在 RISC-V 架构下的代码修改与适配2. 实现各插件在 RISC-V 上的功能验证3. 提交完整移植报告及测试用例
基于openvela系统的快应用开发,基础/Basic,"[[""web"",""Apache""]]",openvela 操作系统专为 AIoT 领域量身定制，以轻量化、标准兼容、安全性和高度可扩展性为核心特点。openvela 以其卓越的技术优势，已成为众多物联网设备和 AI 硬件的技术首选，涵盖了智能手表、运动手环、智能音箱、耳机、智能家居设备以及机器人等多个领域。我们希望借此机会让大家能够认识了解使用openvela系统，共建开源开放的AIoT操作系统生态。此次项目的任务是基于openvela操作系统开发一款可上下滑动（如下图所示）查看七日内天气（不需要真实数据，假数据mock即可）的应用。,1. 基于openvela系统做一款类似上图小米手环所示，可以上下滑动查看七日内天气（不需要真实数据，假数据mock即可），天气图标可通过图标网获取。
将QBE引入openEuler,基础,"[[""os"",""Linux""]]",QBE（Query By Example - Backend Compiler）是一个专门为编译器开发者设计的后端编译框架，旨在提供强大的架构特定代码生成支持.本选题目标为将qbe引入openEuler.,1. 在openEuler Gitee软件仓库中创建qbe软件仓库，并提交对应spec及tarball文件2. 可以在openEuler安装环境使用，覆盖aarch64、x86_64架构
openInula DevTool开发,进阶,"[[""web"",""Babel""],[""web"",""React""],[""web"",""UI""],[""web"",""Webpack""],[""web"",""Web Application""],[""datas"",""AI""]]",相关背景：随着前端框架的复杂性和多样性增加，开发者亟需高效的调试工具支持多渲染器场景下的开发体验。当前openInula js已经支持兼容react的API1.0和基于响应式的API2.0的两个版本API。但现有Devtool仅针对 API1.0 实现了基础调试功能，且代码耦合度高、可维护性差，无法快速适配 响应式API2.0 的调试需求。已有工作：1、当前 DevTool 版本已完成 API1.0 的基础调试功能，包括组件树查看，组件状态的修改存在的问题：1、现有代码逻辑与 API1.0 高度耦合，缺乏抽象层，难以复用至 API2.02、稳定性和易用性问题 目前DevTool存在一些功能上的bug，界面美观度需要提升希望改进要点：1、代码结构解耦通过模块化设计分离核心调试逻辑与渲染器适配层，定义通用接口。抽象通信协议和数据格式，确保API1.0和API2.0可实现插拔式适配2、性能与稳定性优化，解决功能bug，优化界面美观度,1. 技术栈要求：TypeScript，React，openInula API2.02. 功能要求
Casdoor协议相关功能支持,基础,"[[""safe"",""OAuth""],[""safe"",""OpenIDConnect""]]",Casdoor 是一个基于 OAuth 2.0、OIDC、SAML 和 CAS 的 UI-first 身份和访问管理(IAM)/单点登录(SSO)平台。目前，Casdoor 已经基本实现了这些协议的单点登录功能。本项目旨在优化和完善 Casdoor 的协议相关功能支持，例如实现 OIDC、SAML 的单点登出功能，支持更多第三方应用登录（如企业微信 Wecom），从而进一步提高 Casdoor 的易用性和可用性。,"1. 优化和完善Casdoor的OAuth 2.0、OIDC、SAML、CAS等协议相关的单点登录和单点登出功能,以提高用户体验。2. 扩展Casdoor支持更多第三方应用登录,方便用户使用。3. 完善Casdoor中至少4个功能模块、协议模块等。4. 解决Casdoor主仓库&相关仓库中的issues：https://github.com/casdoor/casdoor/issues，数量方面，至少解决6个issue"
基于MindSpore实现DeepSeek v3安全推理算法,进阶,"[[""datas"",""AI""]]","基于模型和数据混淆的安全推理是解决云上推理用户数据泄露的有效方法，并且在传统的LLM模型（如Bert, GPT, llama等）上进行了验证。本项目拟针对deepseek v3模型架构，基于MindSpore框架设计并实现混淆算法，保证deepseek推理时用户数据安全。",1. 基于MindSpore完成deepseek v3模型的混淆算法设计和实现，打通安全推理全流程，最后输出技术报告
RocketMQ 主备副本利用系统内置Topic完成元数据增量同步,进阶,"[[""cloudnative"",""Kafka""],[""cloudnative"",""RabbitMQ""]]",当前 RocketMQ 主备元数据同步依赖定时 RPC 完成（详见SlaveSynchronize 类），这种同步方式存在以下缺点本题目希望你能设计和实现一个新的方案，利用内置系统topic完成元数据同步，要求•  具备快照能力，当元数据落后很多的时候，可以通过传快照进行数据快速跟进,1. 内置系统Topic元数据同步模块2. 快照及恢复模块3. 与高可用能力的整合适配，并保证兼容性4. 从 0 到 1 完整的设计、研发、测试、上线
基于flow-canvas画布实现低代码设计AI Agent功能,基础,"[[""web"",""UIKit""],[""web"",""Vue.js""]]",Farris Vue 是基于Vue 3开发的低代码UI组件库，其中flow-canvas组件已经具备拖拽编排画布元素的基本能力，尚有优化线条布局，自动连线，扩展布局元素等特性等待社区开发着参与贡献。,1. 迭代更新flow-canvas组件2. 基于flow-canvas和Farris Vue项目提供的Designer开发套件实现AI Agent Designer3. 通过PR提交代码，通过代码审查完成完整项目
数据快速入库,进阶/Advanced,"[[""datas"",""Database""],[""cloudnative"",""Redis""],[""cloudnative"",""HDFS""],[""cloudnative"",""Hadoop""]]",当前业务场景中，存在大量由离线计算产生的数据，比如通过map/reduce计算产生。但是要想他们发挥作用，必须导入到在线存储系统，比如pikiwidb。因此业务写了非常复杂的代码，费了很大力气把大量数据定期导入Pika，这个过程费时费力，还不能保证稳定性。所以我们计划借助 RocksDB 提供的 ingest 功能，实现数据的高效快速入库，将整个流程进行自动化改造，支持业务自动导入数据以及查看分析已导入数据。这将显著提升数据处理效率，降低人工操作成本，并确保数据导入过程的稳定性与可靠性。本项目的主要工作：,1.实现生产指定sst格式文件并传输到指定位置的功能。2. 实现sst文件注入功能：rocksdb实现ingest接口，将sst文件注入pikiwidb。3.  将上述两个核心功能自动化。4. 设计项目方案，并定期产出相关文档。5. 测试和验证，使用单元测试、集成测试、混沌测试、压力测试等方式测试该方案的稳定性与可行性。
NowInOpenHarmony,基础,"[[""codelang"",""Programming Language""]]",目前OpenHarmony开源项目已成规模，生态日益繁荣，但与OpenHarmony相关的资讯平台多为网站且比较零散，另外OpenHarmony应用比较缺乏，应用生态是未来发展重点。结合上述两个现状，本选题目标为开发一款运行在OpenHarmony系统上的聚合OpenHarmony相关资讯的应用。,1.使用ArkTS开发运行于OpenHarmony的资讯应用（内容包括OpenHarmony社区新闻、开发者论坛热门话题、版本发布信息等）；2.资讯内容来源建议： 1）使用Web开发框架开发服务器聚合OpenHarmony资讯网站，为应用提供接口，2）应用直接通过OpenHarmony社区网站获取资讯并展示。
在XS-gem5上实现RISC-V的sv48分页机制,进阶,"[[""chip"",""Chip Design/Verification""]]",XS-gem5是与香山昆明湖架构对齐的gem5 模拟器，支撑香山的架构探索及性能评估等工作。sv48分页机制是riscv的一种虚实地址转换标准，本选题目标为在xs-gem5上实现sv48分页机制。,1. 在 XS-GEM5 上实现 Sv48 地址翻译机制
基于vllm-mindspore实现eagle投机算法,基础,"[[""datas"",""AI""]]",vllm-mindspore是让vLLM在MindSpore 框架上运行的组件。vLLM-MindSpore将MindSpore高效算子、模型、算法在vLLM中使能起来，拥抱生态；eagle系列算法是推测性采样方法，提升LLM的推理速度。vLLM社区最新版本支持eagle3功能。vllm-mindspore支持eagle算法可进一步提升推理性能，拓展生态。,1. 基于vllm-mindspore实现最新eagle算法对标功能;2.  基于qwen2.5模型，提供自验报告，精度和性能对标vLLM开源社区；3. 代码贡献到vllm-mindspore仓；
设计器支持TS,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",,1. 实现低码设计器系统功能对TypeScript的支持，包括出码、Schema、状态变量、输入代码等；完善协议层面对TS的支持。2. 确保TypeScript代码的类型安全性和可维护性，出码代码能够正常预览与编译；TS作为可选功能，不打开TS时不影响当前功能正常。3. 提供详细的设计文档与使用文档，提供必要的提示，确保用户能够轻松使用该功能。4. 代码逻辑清晰，模块划分合理，可维护性强，符合项目开发规范。
MatChat模板小程序支持,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",根据用户使用习惯的不同，用户可能希望通过在微信小程序中使用matechat来进行与模型的对话，目前matechat仅支持了pc端。本项目要求提供一套基于pc端一站式解决方案模板自动生成微信小程序模板的方案，在pc端一站式解决方案的模板迭代后，通过脚本或插件的方式，自动更新小程序的模板，不再需要人工维护多份模板。,"1、编写一个脚本或插件，用于将pc端的一站式解决方案模板自动生成小程序模板
2、脚本或插件，尽量使用简单"
G3开源代理覆盖率提升,基础,"[[""safe"",""DNS""],[""safe"",""HTTP""],[""safe"",""libcurl""],[""safe"",""SSL/TLS""],[""safe"",""TCP/IP""],[""safe"",""tcpdump""],[""safe"",""Wireshark""]]",是字节跳动内部为正向代理等业务场景设计的新一代代理安全网关项目，基于Rust语言开发，性能好、稳定性高，在字节跳动全球IDC均有部署，日常流量在Tbps级别。功能上，支持正向代理、反向代理、TLS卸载/劫持、国密卸载/劫持、流量审计、动态加速等，开源版本目前有用户反馈的主要涉及业务为AI安全审计、游戏加速、正向代理、反向代理等场景。目前G3开源代理已经使用CI流程进行自动化测试，使用进行覆盖率上报，当前测试覆盖率在55%左右。整体测试覆盖率提升至65%左右，其中lib目录单元测试覆盖率提升至70%,1. 整体测试覆盖率提升至65%左右，其中lib目录单元测试覆盖率提升至70%。2. 对单元测试的PR提交需要分crate提交，可少量多次提交PR，单次PR不超过1000行改动。3. 提交PR前需先在自己仓库跑通CI流程并取得codecov数据。
openGauss 向量数据库集成PrivateGPT,进阶,"[[""datas"",""Database""],[""datas"",""AI""]]",完成PrivateGPT与openGauss的私有化部署集成，实现敏感数据本地化存储管理，输出安全增强方案及实施文档。,1. 开发openGauss本地存储模块，支持文档向量化全流程隔离。2. 构建金融/医疗领域私有化案例，输出包含审计机制的安全文档，代码提交社区。
milvus-storage自适应encoder & compressor,基础/Basic,"[[""datas"",""Database""],[""datas"",""AI""],[""datas"",""Vector Database""]]",背景：Milvus Storage 是一个基于 Apache Arrow Parquet 的高性能存储引擎，它通过将数据列分组打包的方式来优化读写性能。这个项目支持分别控制读写内存、减少存储文件数量，并支持部分数据读取。它兼容多种主流云存储服务（如 AWS S3、Google Cloud Storage、阿里云 OSS、腾讯云 COS）Milvus Storage 是一个基于 Apache Arrow Parquet 的高性能存储引擎，它通过将数据列分组打包的方式来优化读写性能。这个项目支持分别控制读写内存、减少存储文件数量，并支持部分数据读取。并兼容多种主流云存储服务（如 AWS S3、Google Cloud Storage、阿里云 OSS、腾讯云 COS）。需求为根据数据统计或写入schema对于每个field选择合适的encoding/compression算法，并在读取时根据对应的算法进行decode/decompress，以优化存储成本与性能。,"1. 基于数据特征（如分布、范围、重复度等）自动选择最优的编码和压缩算法，为每个字段配置最适合的存储策略。
2. 不同压缩策略结果性能对比
3. 提交代码并合入主分支"
基于 RISC-V RVV 向量扩展的 Apache HBase 实时查询性能优化,进阶,"[[""datas"",""Hbase""],[""os"",""Linux""],[""os"",""RISC-V""]]",(1)背景RISC-V 架构凭借其开源特性与向量扩展（RVV）能力，为大数据存储系统的底层优化提供了新方向。Apache HBase 作为高吞吐量的分布式 NoSQL 数据库，其核心操作（如数据压缩、布隆过滤、Scan 查询）存在计算密集型任务，尚未充分利用 RISC-V RVV 的硬件加速潜力。(2)已有工作HBase 支持通过 JNI 调用本地库优化关键路径（如压缩算法）。RISC-V 社区已完善 RVV 1.0 工具链（GCC/Clang）与硬件生态（如 SOPHON SG2042）。(3)不足HBase 在 RISC-V 平台缺乏 RVV 指令级优化，导致压缩/查询性能低于 x86/ARM。现有优化多针对传统SIMD 指令集（如 AVX/NEON），未覆盖 RISC-V 生态。(4)改进目标为HBase 设计 RVV 向量化模块，覆盖压缩（Snappy/LZO）、布隆过滤等关键路径。优化JNI 层与本地库的 RVV 指令集成，降低 CPU 负载并提升吞吐量。构建RISC-V 平台自动化测试框架，验证性能提升效果。(5)最终目标性能提升：在RISC-V 硬件（如 SOPHON SG2042）上，目标场景（实时 Scan 查询）性能提升 25%+。生态贡献：向Apache HBase 社区提交 RVV 优化代码，推动 RISC-V 大数据存储生态发展。,1. 实现 2-3 个 RVV 优化的 HBase 核心模块（如压缩、布隆过滤）2. 提供 RISC-V 平台性能测试报告（对比优化前后指标）3. 提交 Apache HBase 社区 PR，包含代码与文档4. 编写 RVV 优化指南
VIDEX 适配 MariaDB ,进阶/Advanced,"[[""datas"",""Database""],[""datas"",""MySQL""],[""datas"",""Data Science""]]",,1. VIDEX-Plugin: 完成 VIDEX plugin 对 MariaDB 的适配开发，提供可编译通过的插件源码及编译脚本，确保在 MariaDB 11+ 版本中正常安装与卸载；2. VIDEX-全流程: 给出 MariaDB 和 MySQL 对于 VIDEX-Statistic-Server 和 VIDEX-Build-Env（构建流程） 的适配，让 VIDEX 全流程适配 MariaDB3.  查询计划对比工具：开发工具，能够基于 trace 和 EXPLAIN，高效对比查询计划差异根因。并以 TPC-H 10 条以上的查询完成验证报告，证明适配后效果不低于 MySQL 原生支持水平；4. 安装文档、镜像资源与适配差异文档
开发一款插件，用于在 ONLYOFFICE 编辑器中实现中文文本的简体与繁体转换,基础/Basic,"[[""web"",""Web Application""],[""web"",""Desktop Application""]]",本项目旨在为 ONLYOFFICE 编辑器开发一款插件，支持中文文本的简体与繁体转换。插件基于开源 OpenCC 库构建，并应该包含自动拼音注释等可选功能。该功能对跨境协作、翻译工作流程和语言教育具有重要价值，能够帮助用户根据区域偏好或学习需求灵活调整内容。,"1. 适用于 ONLYOFFICE 文档、电子表格、演示文稿和表单编辑器的插件
2. 允许用户在简体和繁体字符集之间转换中文文本
3. 提供可选功能：为文本添加拼音注释"
实现图计算系统 Vermeer 任务优先级调度器,进阶,"[[""datas"",""HDFS""],[""datas"",""Graph Database""],[""codelang"",""Programming Language""]]",Vermeer 是一个 Go 编写的自研 HugeGraph 高性能分布式图计算框架(内存优先)。在图计算平台上，承载用户例行的图计算任务。但目前 vermeer 的任务调度器只支持单个任务的发起和顺序的调度，而在真实的使用场景下，用户的使用方式是多样的，现有任务的发起方式需要用户自己包装逻辑。并且任务的大小和执行速度，在顺序调度的情况下会经常出现资源利用率较低的问题。并且在这其中包含了任务依赖关系，状态检查等问题。因此 vermeer 需要进一步完善任务调度器，以此实现更好的易用性。本课题旨在设计并实现一种针对分布式图计算平台的优先级调度策略，通过结合任务资源占用大小、任务优先级等实现优先级调度策略，提高多用户多任务情况下的资源利用率。实现多种任务发起新特性，提升用户易用性。,1. 优先级调度器实现源码2. 技术设计文档（包含架构图、流程说明、API 设计等内容）3. 测试和报告相关
基于Agent实现独立环境、代码执行等能力,进阶,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""LLM""]]",背景：AI Agent 逐步成为使用 AI 解决真实环境中各类问题的有力工具，然而真实环境的任务隔离性和安全性是企业落地中必然要考虑的问题。 DB-GPT Agent 目前不支持统一、可扩展的安全沙箱环境。预期目标： 为 DB-GPT Agent 实现一个安全的沙箱执行环境（支持 Agent、工具的运行和多语言代码的执行）。 分三个部分：1. 基于 DB-GPT Agent + Docker 容器实现安全的代码执行环境，支持 Python、Shell、Node.js 等代码的执行，改造 DB-GPT 现有的代码执行智能体。2. 支持有状态的沙箱环境，多次代码执行可以在相同的环境中，并且上次环境的变更能影响下次的执行（例如第一次执行安装 pypi 依赖，第二次执行安装后的依赖能正常使用）3. 插件化的安全沙箱环境实现，设计统一的沙箱环境接口，支持 Docker、Podman、本地进程（基Cgroup/Namespace/WebAssembly等）等沙箱环境的实现。,1. 项目设计文档（含架构图、原理图、实现细节等）2. 实现安全沙箱环境的核心模块（统一沙箱环境接口，Docker 实现和本地进程的实现）3. 提供完整的使用教程文档说明4. 基于沙箱环境，开发一个支持 Python 等代码执行的 Agent 案例
Volcano 原生异构资源管理：集成昇腾 NPU 调度插件,进阶/Advanced,"[[""datas"",""AI""],[""dev"",""Git""],[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""]]",Volcano 作为首个云原生批量计算平台，旨在提供对包括 GPU、NPU、x86、ARM 等异构资源的统一管理和调度能力。目前，针对昇腾 NPU 资源的调度支持以独立插件的形式在昇腾社区维护，这导致用户在使用 Volcano 调度 NPU 时需要依赖外部组件，增加了复杂性和维护成本。本项目旨在将昇腾社区维护的 NPU 调度逻辑作为 Volcano 社区的原生插件进行集成和统一管理。通过将现有的独立插件迁移到 Volcano 社区并进行重构，使其完全融入 Volcano 的架构体系，用户将能够更方便地在 Volcano 框架内直接使用 NPU 调度能力，无需额外依赖和维护第三方组件。,1. 集成后的昇腾 NPU 调度插件: 提供成功迁移并集成到 Volcano 社区代码仓库中的昇腾 NPU 调度插件代码。该插件应符合 Volcano 的插件规范和架构设计。2. 重构后的 NPU 调度逻辑: 提供经过重构的昇腾 NPU 调度逻辑，能够与 Volcano 的核心调度框架、资源模型、扩展机制等无缝协作。3. 增强的异构资源调度扩展性: 通过本次集成，提升 Volcano 原生对异构资源调度的扩展能力，为未来支持更多类型的加速卡或其他异构资源奠定基础。4. 全面的测试报告: 提供单元测试、集成测试和端到端测试报告，证明集成的昇腾 NPU 调度插件在 Volcano 框架内的正确性、性能和稳定性。5. 完善的用户文档: 提供清晰的用户文档，指导用户如何在 Volcano 中配置和使用原生的昇腾 NPU 调度功能。6. 完善的开发者文档: 提供开发者文档，方便社区开发者理解集成的 NPU 调度插件的代码结构、扩展方式以及如何贡献新的异构资源支持。7. 社区集成与发布: 将重构后的昇腾 NPU 调度插件成功合入 Volcano 社区的主干分支。
基于classic-flang支持C Strings in Character Constants,基础,"[[""os"",""classic-flang""]]",Fortran语言由于其接近数学公式自然描述的语言特征，时至今日仍然是用于HPC场景的主流编程语言。但由于Fortran语言规范相对较宽容，代码中较易出现标准外行为，不同编译器可能对此存在编译或者运行的兼容性问题。针对HPC实际应用场景中出现的C Strings in Character Constants场景，classic-flang、gfortran、ifort三款主流Fortran编译器的行为都存在不同；经分析，ifort的行为相对更具合理性，因此本选题目标为完成classic-flang对C Strings in Character Constants场景的支持，支持程度与ifort对齐。,1. 完成基于classic-flang的代码开发，支持C Strings in Character Constants行为与ifort对齐
openGauss向量数据库迁移Milvus的迁移测试,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",基于openGauss 迁移Milvus指导文档，使用docker部署openGauss向量数据库与Milvus，通过python SDK完成向量表的构建、向量数据插入与检索，并通过迁移脚本完成Milvus数据迁移至openGauss。测试的数据类型应包含标量、向量、稀疏向量等，应至少包含常用DQL、索引构建等语法。输出测试报告。,1. 基于openGauss 容器部署指导文档、Milvus容器部署指导文档完成向量数据库的部署，编写应用代码，使用Python脚本实现Milvus向量表的构建、向量数据插入与检索。参考Milvus迁移openGauss工具，完成数据迁移至openGauss。测试的数据类型应包含标量、向量、稀疏向量等，应至少包含常用DQL、索引构建等语法。输出测试报告。2. 输出测试设计文档，测试设计文档需合入openGauss社区。3. 输出测试报告，测试报告文档需合入openGauss社区。
为 HTNN 增加 AI 内容安全插件,基础,"[[""safe"",""HTTP""],[""datas"",""LLM""]]",是一款基于 Envoy & Go 开发的 AI 网关。我们希望为这个网关增加一个 AI 内容安全插件。AI 内容安全插件是一种基于人工智能（AI）技术的工具，用于实时检测、过滤和管理数字化平台上的违规或有害内容。它通过机器学习等技术，自动识别敏感、违法或低俗内容，帮助企业或平台高效维护内容安全，降低法律风险，提升用户体验。这个插件只需要满足基本要求，即解析出请求内容（如 OpenAI chat 接口中的 prompt），调用第三方平台进行安全检测即可。,"1. 一个 Go 写的插件，能够通过配置指定第三方平台对 AI 内容（输入的 prompt、生成的内容）进行安全检测
2. 该功能的测试代码：即要有单元测试、也要有集成测试
3. 中英文插件文档，类似于 https://github.com/mosn/htnn/blob/main/site/content/zh-hans/docs/reference/plugins/ext_auth.md"
基于 RISC-V 硬件的 IpCam 固件,进阶/Advanced,"[[""os"",""Linux""],[""os"",""RISC-V""],[""web"",""Web Application""]]",适配 RISC-V 硬件，基于 Live777 完成适配 IPCam 固件。Live777 已经完成了在 RISC-V 设备上运行的验证工作。使用 React 和 Tailwind CSS，Live777 是使用 React 和 Tailwind CSS 已经有部分组件可以复用在这里，观看实时图像（使用 WHEP ，已经实了和播放器部分代码）使用无数据库实现，配置系统的存储：WebUI中心视频源分流架构，使用 Live777,1. 基本功能2. 实时部分3. 服务部分4. 录制&回放5. 部署方案
Apache HertzBeat 自动化任务 MCP Server,基础/Basic,"[[""dev"",""AIOps""],[""datas"",""AI""]]",Apache HertzBeat 是一个开源的实时监控系统，专注于提供高效、灵活的监控解决方案。它支持多种数据源的监控，广泛应用于云原生环境下的运维场景。目前我们都是在平台上看监控数据或者告警数据，但是不能针对告警数据或者采集数据，做成下一步比如自动恢复，自动修复等操作。现在有了AI的相关能力，可以借助AI实现监控告警自动化。AI根据告警信息，监控信息等，自己生成和决定对端异常服务的处理修复脚本或者修复任务，然后调用部署在对端服务器上面的mcp server执行。本项目的核心目标是实现一个mcp server，server可以提供自动化相关功能，供模型进行调用。此server是一个独立应用，部署到对端服务器上面，用rust编写，拥有如下特性。1. 脚本执行能力，通过此server执行自己的任意脚本2. 任务执行能力，可以预制不同类型的任务，AI直接发现并执行这些任务3. 日志审计，将AI调用执行的操作记录日志4. 安全拦截，支持配置黑名单或者白名单命令,1. Mcp Server module2. 脚本执行能力3. 任务执行能力4. 日志审计5. 安全拦截
基于 Dubbo-go-Pixiu 构建 MCP/A2A 协议的 AI 网关及混合治理能力集成,进阶/Advanced,"[[""safe"",""HTTP""],[""datas"",""LLM""]]",随着 AI 技术的快速发展，以及 Agent 技术的兴起，应用间的互联互通需求日益增长。传统的 API 网关在面对新型协议（如 MCP、A2A）和复杂的应用场景时，在协议兼容性、安全认证、动态能力协商和混合治理等方面存在不足。尤其是在 AI Agent 场景下，不同 Agent 采用不同通信协议，需要网关具备灵活的协议适配和转换能力。本项目旨在基于 Apache Dubbo-go-Pixiu 现有框架，构建一个支持 MCP/A2A 协议的 AI 网关，增强其在 Agent 互联互通和混合治理方面的能力，使其成为一个面向未来的、灵活可扩展的协议网关。目前，Dubbo-go-Pixiu 已有初步的 AI 协议（HTTP/SSE）支持和 Token 计算的基础工作。本项目将在此基础上，进一步完善这些核心能力，实现一个面向未来、支持混合治理的 AI 网关。,1. 实现对 MCP 和 A2A 协议的完整支持2. 实现可用的基于 OAuth 2.1 和 API Key 的统一认证授权机制3. 实现基于 MCP 协议的动态能力协商功能4.将现有 AI 治理能力扩展到 MCP 和 A2A 协议的上下文中5. 为新增功能编写相应的单元测试、集成测试和文档
改进 Open Build System 的 pacman 支持,基础/Basic,"[[""os"",""Linux""]]",Open Build Service (OBS) 是一个通用的源码构建和分发系统，eweOS 使用 OBS 作为其包构建系统。OBS 支持多种包格式，包括 eweOS 使用的 pacman 包格式（通过 PKGBUILD 文件定义）。OBS 当前包含一个用于解析 PKGBUILD 文件的模块，该模块主要使用 Perl 语言和正则表达式实现。我们发现当前的 PKGBUILD 解析器实现比较脆弱，尤其是在处理复杂的 Bash 特性例如数组展开、参数展开以及条件逻辑时。这导致它与标准的 PKGBUILD 打包约定兼容性不佳。本项目旨在重构或显著改进 OBS 中的 pacman 打包流程，使得基于 pacman 的发行版 （如 eweOS）的包维护者能够更顺畅地在 OBS 中构建软件包，减少因解析器限制导致的问题。有以下两种解决方案可供参考：1. 改进 PKGBUILD 解析器，使其能够更准确地解析 PKGBUILD 文件中使用的常见 Bash 语法结构，提升 OBS 对 PKGBUILD 格式的兼容性。2. 改进 OBS 的构建流程，使其能够在提供 .SRCINFO 的情况下直接解析其内容。作为可选项，为 OBS 的 tar_scm service 添加生成 .SRCINFO 的支持，以便在拉取源码时自动生成该文件。,1. 如果选择改进 PKGBUILD 解析器2. 如果选择改进 OBS 的构建流程
基于低代价采样的单列 NDV 和直方图估计 [算法],进阶/Advanced,"[[""datas"",""Database""],[""datas"",""Data Science""],[""datas"",""AI""],[""datas"",""MySQL""],[""datas"",""Relational Database""]]",,1. 算法设计文档：含采样策略流程图、NDV/直方图模型公式推导、复杂度分析；2. 代码实现：基于Python实现采样与估计逻辑，禁止使用全表扫描接口，需通过主键抽样验证；3. 人工数据集验证：构造3种非平凡分布数据集，测试基于全表扫描和基于采样算法的效率和精度4. 【进阶、可选】：在TPC-H / JOB 上验证，提交测试报告，或进一步形成论文。
面向RISC-V架构适配的Java程序崩溃报告过滤与定位,基础,"[[""codelang"",""Programming Language""],[""os"",""RISC-V""],[""datas"",""LLM""]]",Java程序在适配RISC-V架构的过程中产生的崩溃信息，通常采用静态分析工具进行错误定位。由于分析精度，静态分析工具在过程中会产生一定量的误报，影响开发者的修复效率。RVSmartPorting社区观察到，以CrashTracker为代表的开源工具及相关工作提供了一系列Java程序在适配RISC-V架构时产生的崩溃相关错误报告。参与本项目的同学需要基于AST静态分析技术和基于大模型的过滤技术，收集崩溃报告中包括但不限于错误方法、错误方法原因、异常崩溃约束等，通过启发式算法确定是否为与RISC-V架构本身有关的异常；然后通过这些静态收集的上下文信息，进一步进行根因分析和误报过滤。目前，本项目已经完成整体代码框架的设计以及初步的代码实现，参与项目的同学需要根据当前版本的代码进一步完善错误报告过滤与分析技术。,1. 在RISC-V架构下实现对崩溃相关Java代码的AST提取分析，支持根据崩溃栈收集对应代码片段；对于崩溃栈方法签名不完整的，实现启发式补全2. 通过收集到的代码和候选信息上下文，利用大语言模型，实现对库代码的崩溃约束提取3. 通过提取到的崩溃约束和相关的崩溃栈代码信息，实现对错误定位报告的误报过滤模块
基于提示词工程的能力，提升基础模型节点 Function Calling 的准确率,基础,"[[""datas"",""AI""]]",目前平台提供的基础模型节点支持 function calling，但在选择某些模型的时候准确率较低，会出现参数格式不规范等问题，所以需要通过优化 function calling 提示词、规范参数后处理等方式提高 function calling 准确率，本项目目标为通过提示词工程等方式提高模型节点function calling 的准确率。,"1. 通过 App-Platform 构建一条复杂的应用流程，可以运行成功。
2. 通过替换其中的模型节点背后的模型配置，对于应用中的模型 Function Calling 能力，都能连续调用成功。"
实现oracle force view功能,进阶,"[[""datas"",""Database""]]",实现 oracle force view 功能，创建视图时，支持指定 force 选项创建视图，其基本功能为即使视图定义错误也可以创建成功。在查询该视图时，重新验证视图定义，如果合理则可以查询，否则报错。例如，基础场景为：即使 t1 表不存在，v1 也可以创建成功，但 v1 视图查询时会报错，创建 t1 表之后，可以成功查询 v1 视图，并输出其内容。除了基础场景之外，还应考虑 force 选项和其他创建视图的选项结合时应该如何处理，例如，将 replace 和 force结合时，需要考虑视图在正常状态和非正常状态如何转换，同时考虑到该视图的依赖关系处理。,1. 在创建视图时支持 force 选项，其主要功能包括：2. 完善的设计文档和测试用例编写3. 提供功能测试数据
openInula 2.0 VSCode 插件,基础,"[[""web"",""React""],[""web"",""Webpack""],[""web"",""Web Application""]]",为openInula 2.0框架开发一个VSCode插件，能够在开发过程中为开发者提供组件信息、标识状态、派生值、响应关系等实时反馈，增强开发体验，帮助开发者更高效地开发、调试和维护应用。已有工作：1、openInula 2.0框架已提供丰富的API和功能，开发者可以利用这些信息来构建插件。2、VSCode插件已在前端开发中得到广泛应用，有较成熟的开发框架和插件生态。存在的不足：1、现有的openInula 2.0开发工具尚未集成到IDE中，开发者需要通过集成openInula 2.0 编译器到插件中目标：1、基于openInula 2.0框架开发一个VSCode插件，提供组件信息、状态标识、派生值等功能。2、插件能够实时显示组件状态的变化，提升开发者的开发效率。,1. 技术栈要求：TypeScript，Node.js，VSCode插件开发，openInula 2.0框架。2. 功能要求：
file stats 透传 skip index，更丰富的 skip index,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""Vector Database""]]",背景：Milvus当前支持简单的标量数据Skip Index，保存了一些数据的统计信息，允许在过滤查找的时候快速跳过大块数据而无需遍历所有行。其实现有两个主要的问题：Skip Index总是在数据加载的时候动态构建，会消耗一定的查询节点的计算资源；当前Skip Index仅包含minmax信息。需求：,"1. 基于数据特征（如基数、重复度、范围）等或基于用户配置（从SDK端动态配置或配置文件处静态配置），选择合适的Skip Index类型，并进行索引构建和持久化
2. 不同查询场景下不同类型的SkipIndex类型性能对比
3. 提交代码并合并到主分支"
从 kubeedge-ianvs 迁移联合推理大模型 example 至 kubeedge-sedna,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""],[""cloudnative"",""Docker""],[""cloudnative"",""Kubernetes""]]",Sedna 是一个通用的云边协同 AI 平台，能够便捷地在云端和边缘部署、管理各类 AI 模型。当前，Sedna 已支持多种 AI 协同范式，包括联合推理、联邦学习、增量学习和终生学习，并在多个行业场景中实现了落地应用。我们已针对传统判别式模型，提供了丰富的协同范式案例，帮助用户快速搭建符合自身需求的应用。随着案例数量的增加，用户对模型性能评估的需求也日益增长。为此，我们推出了 kubeedge-ianvs 基准测试平台，为模型在部署到 Sedna 之前提供标准化的测试流程，确保其性能满足生产环境要求。近年来，大语言模型（LLM）在云边协同场景下的应用逐渐增多，ianvs 项目中已孵化出多个优秀的云边协同大语言模型案例。然而，Sedna 平台目前尚未提供相关的大语言模型应用案例，导致有此类需求的用户缺乏参考和借鉴。因此，本项目旨在将 kubeedge-ianvs 中优秀的联合推理大语言模型案例迁移至 Sedna 平台，丰富 Sedna 的应用案例库，为开发云边协同大语言模型的用户提供实践参考。同时，在迁移过程中，我们将梳理和总结案例迁移中遇到的问题，为后续实现案例自动化迁移和 Sedna 框架的持续优化提供依据和建议。,1. 基于 [cloud-edge-collaborative-inference-for-llm ](https://github.com/kubeedge/ianvs/tree/main/examples/cloud-edge-collaborative-inference-for-llm)案例迁移至 sedna2. 提供 Dockerfile 文件并推送相关镜像至官方 sedna 案例库3. 提供详细的案例部署文档和视频 demo4. 以文档形式提供案例迁移的具体步骤以及部署过程遇到的迁移难点和痛点（提供issue）
面向公司组织结构的数据权限控制组件,基础,"[[""web"",""Spring Boot""]]",随着公司规模的扩张和业务复杂度的提升，现有系统缺乏对组织结构敏感数据的精细化权限管控。目前，部门间协作与数据保密需求并存，但传统角色分配模型（如仅区分“管理员”和“普通用户”）已无法满足多层级组织架构下的安全管理要求。部门负责人需要全局掌握团队数据以支持决策，而普通员工仅需访问个人相关数据，现有粗粒度权限体系存在数据泄露风险和管理效率瓶颈。当前系统已基于RBAC（角色访问控制）模型实现了基础权限划分：构建一个，实现：,1. 开发MyBatis拦截器实现部门级数据自动过滤功能2. 完成RBAC权限模型数据库表结构设计文档3. 实现动态权限策略配置界面与缓存机制4. 集成安全上下文自动注入用户部门信息功能5. 提供拦截器单元测试与集成测试报告6. 编写部署配置说明与策略配置模板7. 生成压力测试报告验证吞吐量≥500TPS8. 交付用户手册含权限配置操作指南
为EventMesh实现MCP 服务,基础,"[[""datas"",""AI""],[""dev"",""AIOps""]]",目前 MCP 协议越来越流行，EventMesh 需要在Server端支持 MCP 协议，把mcp协议通信功能暴露出来，方便各种AI工具集成。最终实现的效果是：,1. 实现MCP Server服务2. 支持通过EventMesh MCP Server实现向MQ插件收发消息的能力
提供OpenYurt边缘节点组件yurthub的自动化部署运维能力,基础,"[[""cloudnative"",""Kubernetes""]]",本项目旨在优化OpenYurt边缘计算平台中的核心组件yurthub的部署方案。yurthub作为边缘节点的关键组件，负责处理边缘节点与控制面之间的通信代理。目前，yurthub采用static pod的方式部署，这种方式导致了与kubelet之间的循环依赖问题：yurthub需要kubelet来维持运行，而kubelet又依赖yurthub与控制面通信。这种依赖关系可能引发组件不稳定和运维困难等问题。我们希望通过这个项目，将yurthub改造为可选的addon组件，实现更灵活的可插拔式部署。你将有机会参与设计全新的部署方案，解决现有的循环依赖问题，并确保系统组件的稳定性和可靠性。这个项目不仅包括核心功能的开发，还需要考虑现有集群的平滑迁移方案，以及完善的文档和测试用例编写。如果你对云原生技术特别是边缘计算感兴趣，具备Go语言开发能力，并且希望深入了解Kubernetes生态系统，这个项目将是一个很好的机会。你将有机会接触到真实的工程挑战，并为广泛使用的开源项目做出贡献。项目完成后，你将掌握容器编排、边缘计算等领域的核心技能，这对你未来的职业发展将带来很大帮助。,1. 设计并实现yurthub新的部署方案，支持作为addon组件的部署和管理功能；2. 实现已有static pod形态向新部署方案的平滑迁移能力；3. 提供完整的系统测试用例，验证新部署方案的可靠性；4. 编写详细的设计文档、部署指南和最佳实践指南。
基于低码的意图生成代码平台,进阶,"[[""web"",""Babel""],[""web"",""React""],[""web"",""UI""],[""web"",""Web Application""],[""web"",""Webpack""],[""datas"",""AI""]]",本项目旨在构建一个智能化的低代码开发平台，通过集成DeepSeek大语言模型，实现从自然语言需求到可视化界面的自动化生成。1、构建一个基于openInula框架的低码平台(可基于lowcode-engine和antd)2、接入DeepSeek大模型，实现基于大模型自动生成界面能力（要求：LLM -> schema -> 界面）,1. 完整的低代码平台基础功能，包括组件拖拽、属性配置、页面预览等2. 基于Deepseek的自然语言处理模块，输入：”数据“+”用户意图“，输出：结构化Schema3. Schema到界面的渲染引擎，支持常见的表单、列表、详情页等业务场景4. 至少5个典型业务场景的端到端示例，展示从需求到界面的完整流程，成功率80%以上5. 完善的文档，包括架构设计、API说明、使用指南和开发文档
Apache ShenYu代理插件细粒度服务配置,基础,"[[""web"",""Spring Boot""],[""web"",""npm""],[""web"",""React""],[""web"",""RESTful API""]]",本课题旨在增强 Apache Shenyu 网关的功能，使其能够支持在 Selector 级别配置 Plugin 的行为。目前 Shenyu 的 Plugin 配置主要是全局级别，缺乏更细粒度的 Selector 级别控制。实现此功能将提供更灵活的流量管理能力，满足更复杂的业务场景需求,1. 完成admin模块Selector 级别的 Plugin 配置支持2. 完成数据同步支持selector级别的配置数据同步到bootstrap3. 完成selector级别的plugin配置生效，selector配置优先级大于全局plugin配置4. 确保旧版本的 Shenyu 数据（无 Selector 级 Plugin 配置）能正常加载，不影响现有业务5. 完成功能的文档、单元测试
SOFARPC 超时控制支持 Deadline 机制,基础,"[[""web"",""Spring Cloud""]]",SOFARPC 超时控制本身支持 timeout 机制，可以为每个 RPC 调用指定 timeout 时间。为每个链路单独设置超时时间，可以确保整个链路能够正确调用的同时，也能避免无限等待响应结果导致资源占用。但是这样也存在一些不必要的资源浪费，比如有些场景下，尤其是链路较长的情况下，最上游调用超时时，下游未执行的调用其实可不用执行，并且整个链路都可以结束执行。为了解决这一类问题，期望在 SOFARPC 上支持 deadline 机制。通过在整个调用链路中透传 deadline 值，deadline 到期后，调用链路中其他尚未执行的任务将不会执行。同时每一次调用实际可用的超时时间，需要根据当前透传的 deadline 去设置，从而统一整个链路的超时。,"1. SOFARPC 超时控制支持 Deadline 机制 PR
2. SOFARPC 超时控制支持 Deadline 机制使用文档"
dora openloong 软件集成,进阶,"[[""os"",""Ubuntu""],[""os"",""x86""],[""codelang"",""Programming Language""],[""datas"",""LLM""],[""datas"",""OpenCV""]]",在具身智能领域，开源人形机器人项目 Openloong 具有重要的研究与应用价值。当前该项目使用 ROS 作为中间件，但 ROS 存在诸多问题。其架构设计在大规模、复杂的具身智能系统中面临挑战，数据传输性能有局限，AI能力也存在困难。而 Dora-rs 机器人中间件在AI 框架支持，运行速度、软件质量以及安全可信等方面优势突出，能契合机器人对下一代软件平台的严苛要求。因此，有必要将 dora-rs 机器人框架移植到 Openloong 项目中，以解决现有问题。本项目改进 Openloong 项目的架构设计，解决 ROS 架构在复杂具身智能系统中的通信拓扑复杂、AI 能力弱等问题，提高系统的可扩展性。提升数据传输性能，降低通信延迟，确保在处理大量实时数据时系统的实时性，满足机器人实时避障、快速响应交互指令等场景的需求。优化计算资源管理，在资源受限的嵌入式设备上充分利用硬件资源，提高系统性能，减少对机器人续航能力和运行效率的影响。提供便捷的AI 预集成框架，增加对机器人AI能力的支持。,1. 感知和运动单元移植
为 bouffalo-hal 完善外设、运行时和生态支持,进阶,"[[""os"",""RISC-V""]]",Bouffalo-hal 是一个为博流系列芯片（如BL602/BL702/BL808等）提供 Rust 语言硬件抽象层（HAL）的支持库，为开发者提供了安全、高效且易于使用的博流芯片硬件接口，推动了 Rust 在博流芯片生态中的发展。Bouffalo-hal 包含三个部分，分别是为外设提供硬件抽象层的 bouffalo-hal 模块、裸机运行环境支持的 bouffalo-rt 模块、以及辅助烧录的镜像融合工具 blri 模块。目前在 bouffalo-hal 方面已经实现了对常用基础外设的驱动支持，而对于部分外设支持尚不完善；在 bouffalo-rt 方面 #[entry] 宏功能已基本完善，但仅对 BL808 芯片的支持经过了充分测试，而 BL616 等其他芯片的支持还需完善。尽管 Bouffalo-hal 已经为 Rust 在博流芯片的开发奠定了基础，但外设支持仍有待补充。本项目的核心目标是扩展 Bouffalo-hal 的外设驱动覆盖范围和多核支持，进一步完善支持库功能，能够支持更广泛的应用场景。具体包括：补充外设支持。选择并实现 1 到 2 款当前尚未支持的外设（详见备注）；补充外设支持示例。在对应括号内外设完成的基础上，编写示例程序 LCD (SPI/DBI)、Camera sensor (CSI)、Touch (I2C) 其中之一；裸机运行环境支持包改进。完善除 BL808 外其他芯片的设备列表，实现 interrupt 宏中 BL808 的 mcu 和 lp 核中断支持，目前只有 d0 核支持较为完整；扩展辅助烧录工具 blri。实现使用 blri run 烧录完成后构建串口控制台等功能，使得烧录后可直接于串口控制台中与开发板进行通信。,1. 实现1-2款项目中博流系列芯片的外设驱动支持并补充相关示例程序2. 设计裸机运行环境并为此增加中断功能3. 扩展烧录工具，完成串口控制台等更多功能支持
基于MindSpore实现典型工业场景下基于非结构化离散的三维流场仿真,进阶,"[[""datas"",""AI""]]",实际工业场景中的流场求解通常在高雷诺数(E6量级)且包含复杂的外形。这导致传统基于结构化离散的卷积神经网络(如UNet等)、神经算子(如FNO)和融合方法(如VisionTransformer)无法适配。因此，有必要结合图神经网络相关方法发展基于非结构化离散的高雷诺数AI流场仿真模型。当前，业界已有一些探索，如GINO、FVGN等，在数据需求、适配场景等方面各有优劣。开发者需结合现有方案优势，基于MindSpore及其AI流体套件开发基于非结构化离散的工业场景AI流体仿真模型。要求稳态求解核心气动指标误差小于5%，且相关GNN模型可处理网格数量>E5，初步达到工业应用标准。,1. 基于MindSpore+NPU，结合AI流体仿真套件MindSpore Flow现有能力，实现非结构化离散下的AI流场仿真模型。在汽车/能源/航空航天公开数据集或自建数据集下，压力场/速度场预测L1损失达到e-2量级。
文档质量优化的数据集生成工具,进阶,"[[""datas"",""AI""]]",,1.研究数据集开发的方法并开发一个工具，从gitee.com/openeuler/docs的PR中提取数据集2. 按照规定的格式生成一个不少于1000条的数据集
openInula 2.0 交互式教程,基础,"[[""web"",""React""],[""web"",""Webpack""],[""web"",""Web Application""],[""web"",""UI""]]",相关背景：随着前端框架的不断发展，传统的文档由于缺乏实践性，难以帮助开发者快速入门。当前主流的前端框架社区，如React、Vue、Svelte均提供了官方或社区的“交互式教程”。该项目的目标是为openInula API 2.0开发一套交互式教程，帮助开发者更快上手API 2.0的关键能力与特性。已有工作：1、已完成对 API 2.0 能力与特性的梳理，提供《项目概览》与《API 文档》2、已开发交互式编辑器组件，支持在页面上编写简单组件并实时渲染，并基于该组件在官网提供 playground项目目标：1、根据现有文档内容，策划交互式教程纲要，覆盖API 2.0核心能力与特性，提供解说文本与示例代码2、基于交互式编辑器组件，开发交互式教程界面，挂载到官网,1.  技术栈要求：TypeScript，Node.js，openInula 2.0框架。2.  功能要求：
基于 KubeEdge 的主题化设备数据发布/订阅框架,进阶,"[[""cloudnative"",""Kubernetes""]]","在工业物联网场景中，设备数据的实时发布与灵活订阅是支撑AI分析（如预测性维护、工艺优化）和精细化运维（如故障告警响应、能效监控）的关键基础。通过主题化数据分发和动态路由策略，可精准区分高优先级事件（如设备异常）与低优先级属性数据（如能耗统计），避免混合传输导致的解析负担和响应延迟。统一的发布/订阅机制能简化多协议设备接入、提升边缘-云协同效率，为智能化应用提供低时延、高可靠的数据供给，同时满足动态扩容场景下的灵活扩展需求。为此，本项目旨在设计并实现一套基于 KubeEdge 的统一主题化设备数据发布/订阅系统，通过定义层级化主题模型（如 sensor/temperature, camera/objectDetected等）），实现动态订阅机制与边缘-云协同路由策略，支持应用按主题灵活订阅数据、事件数据（高优先级实时推送）与属性数据（低优先级批量传输）的分类处理，最终与 KubeEdge 的 DeviceTwin等原生组件集成，提升工业物联网场景中数据分发的实时性、灵活性与可扩展性。",1. 完整的技术设计方案（包含架构图、消息流、容错/重连策略）2. 动态注册与订阅发布机制实现3. 不同数据的优先级机制4. 编写完整的技术文档，包含方案背景、方法说明、部署建议与测试参考，支持后续拓展与集成。
为 Cloud-Hypervisor RISC-V 引入 ACPI 支持,进阶,"[[""os"",""Virtualization""],[""os"",""Emulation""],[""os"",""Linux""]]",Cloud Hypervisor是一个用Rust实现的开源VMM。为了区别于之前工作的大量模拟，Cloud Hypervisor专注于云工作负载，使用最少的硬件模拟，只模拟了几个虚拟设备。为了实现虚拟机的功能，Cloud Hypervisor线程在内部使用一系列API来相互通信。 现阶段的 RISC-V 架构支持已达第一阶段（可以在 RISC-V 环境下 direct-boot Linux），但是仍然缺乏 ACPI 的支持。,1. 如果依赖缺乏RISC-V支持，需要为依赖引入对应的支持2. 为Cloud-Hypervisor 引入 RISC-V ACPI 支持
消息驱动型任务调度模块开发,进阶,"[[""web"",""Spring Boot""],[""web"",""RESTful API""],[""datas"",""Kafka""],[""datas"",""MySQL""]]",项目背景：在实时数据处理场景中，如何高效、准确地响应数据流中的事件成为了一个关键挑战。通过消息队列接收事件，并基于这些事件自动触发相应的流水线任务执行，可以极大地提高数据处理的实时性和灵活性。为了增强πFlow平台在实时数据处理方面的能力，本项目旨在开发一个消息驱动型任务调度模块，该模块能够根据接收到的消息自动触发相关任务的调度与执行，满足用户对实时数据处理的需求。项目内容：一、消息协议接入与解析●多协议支持：研究并实现对接主流消息队列协议的支持，如Kafka、RabbitMQ等，确保不同来源的消息能够被正确解析和使用。●消息过滤规则配置：允许用户自定义消息过滤规则，通过对消息内容的筛选，决定哪些消息将触发后续的任务调度。●消息解析与转换：将原始消息转化为适合任务调度使用的格式，以便于后续流程的处理。二、消息驱动型任务调度●任务上下文注入：设计合理的架构，使得每条消息都可以作为任务执行的上下文信息，指导任务的执行路径。三、消息触发调度列表管理●任务管理界面：提供直观易用的用户界面，用于展示所有已注册的消息触发调度任务的状态（运行中、暂停、已完成等）。●任务生命周期管理：支持从任务的创建、配置到启动、暂停直至删除的完整生命周期管理，方便用户随时调整任务状态以适应业务需求的变化。●日志与监控：设计详细的日志记录，帮助用户追踪任务执行情况及排查潜在问题。四、文档编写与发布●设计模块原型以便与前端沟通。●编写技术实现方案，包括模块架构设计思路、主要功能划分、数据库设计方案以及接口定义等。●编写详细的使用手册，涵盖参数说明、典型应用场景示例等。●构建测试案例库，提供一系列覆盖不同使用场景的测试用例，验证模块的稳定性和可靠性。：本项目要求采用Java语言编写（结合Spring Boot）。,"1.接入至少一种主流消息队列（如Kafka或RabbitMQ），支持图形化界面配置消息过滤规则及消息格式转换至标准内部结构（JSON/Java Bean）；
2.基于Spring Boot构建任务调度框架，使每条消息作为上下文触发相应流水线任务；
3.实现任务全生命周期管理（创建、启动、停止、删除），并提供可视化页面展示任务状态（运行中、已完成、失败）；4.集成详细日志记录，涵盖任务触发时间、条件和执行耗时等信息。
5.文档产出有技术设计文档（含架构图、数据库ER图、接口规范）、用户使用手册（操作说明与示例场景）。
6.UI方面提供不少于2页的UI原型设计稿，覆盖任务总览与规则配置页面。
7.工程代码需完整、符合Java编码规范且易于维护扩展。"
基于KubeEdge-Ianvs云边协同推理的大模型隐私保护算法,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""datas"",""PyTorch""],[""datas"",""TensorFlow""],[""cloudnative"",""Kubernetes""]]",随着大型语言模型（LLM）在各行业的广泛应用，用户隐私保护成为关键挑战。传统云端LLM部署要求用户将敏感提示上传至远程服务器，造成严重隐私风险。本项目旨在基于KubeEdge-Ianvs的云边协同推理框架，开发一个大模型隐私保护算法，在边缘侧对敏感提示进行不可逆变换处理，确保即使使用最先进的嵌入重构攻击也无法恢复原始数据。,"1. 基于KubeEdge-Ianvs中云边协同推理范式，实现一种端到端的大模型隐私保护算法样例作为基线，以支持边缘侧提示处理与云端模型推理分离2. 基于KubeEdge-Ianvs中云边协同推理范式，提供标准化测试套件,量化其隐私保护强度，包括数据集、测试指标和测试环境脚本3. 基于KubeEdge-Ianvs中云边协同推理范式和隐私保护算法基线，开发不可逆提示变换算法，如差分隐私、神经元掩蔽和嵌入空间投影"
TinyCharts 横向进度图开发,基础,"[[""web"",""UI""]]",TinyCharts是一个前端Web图表库，其中横向进度图是一个用来表达各个指标值、指标占比、指标排名的图表。希望完成TinyCharts横向进度图开发，要求使用canvas绘制，支持响应式。,1. 完成所要求的图片内的图表开发2. 每行包含标题文本、标题排名、数值文本、百分比文本、进度条图形3. 图表最上方包含名称、金额、贡献度三个文本，这些文本内容都可以通过API控制4. 进度条颜色可以用户自定义，每行可以显示不同的颜色5. 当数据条数过多时，图表纵向出现滚动条6. 鼠标悬浮到进度条上时，出现悬浮提示框，提示框的内容可以让用户自定义7. 要求2中的标题文本，过长时出现...省略，同时鼠标悬浮时出现tips
Flink-openGemini-Connector实现,进阶,"[[""datas"",""Database""],[""datas"",""Flink""]]",是专为Apache Flink与openGemini时序数据库设计的高性能数据集成插件，旨在打通流式计算与海量时序数据存储的链路，助力用户实现实时数据“端到端低延迟处理+高效持久化”的一体化架构。该Connector深度适配Fink DataStream API与Table API，支持将流式计算结果（如窗口聚合指标、异常检测事件、设备状态快照等）快速写入openGemini，同时提供负载均衡以及失败重试机制，确保在高吞吐、分布式场景下的数据完整性与稳定性。通过内置的异步批量提交、缓冲池等技术，写入性能满足海量数据的实时写入需求。该Connector适用于实时监控告警、工业物联网（IIoT）、时序数据分析等场景的数据接入，帮助企业在Flink流处理引擎中直接释放openGemini的时序分析潜力，无需额外开发数据接入工具，显著降低运维复杂度与资源开销。核心能力：项目架构图数据经Flink计算后，通过本项目开发的Connector，将数据写入到openGemini时序数据库,1. 完成项目的设计、开发、测试并提供架构和使用以及插件二次开发的文档2. 单核满足80MB/s及以上的数据写入性能要求3. 在openGemini社区中开源
基于MindSpore的4D毫米波雷达-图像双视角融合的3D检测模型复现,进阶,"[[""datas"",""AI""],[""datas"",""Deep Learning""]]",自动驾驶感知系统需要兼顾性能、鲁棒性和成本，而现有的摄像头和激光雷达方案在恶劣天气或复杂场景下仍存在不足，4D毫米波雷达与摄像头融合可提升复杂天气下的3D检测鲁棒性。DPFT提出双视角投影（前视+鸟瞰）和跨模态注意力机制，，在K-Radar数据集上实现了SOTA性能。目前该方案仅支持PyTorch框架，将其迁移至MindSpore将推动国产自动驾驶技术的发展，并为多模态感知提供新的解决方案。,1. 将DPFT模型从PyTorch迁移至MindSpore，并在K-Radar数据集上验证性能2. 基于MindSpore套件做框架特性开发，并实现应用案例
RISC-V架构加速多标量乘法MSM,进阶,"[[""safe"",""SSL/TLS""],[""safe"",""RSA""],[""safe"",""PKI""],[""safe"",""AES""]]",多标量乘法（MSM）是椭圆曲线密码学（ECC）和零知识证明（ZKP）中的核心计算任务，广泛应用于区块链、隐私计算和密码学协议中。由于MSM计算涉及大量的点乘和加法操作，其计算复杂度高，成为证明生成阶段的主要性能瓶颈。目前，MSM的加速研究主要集中在GPU和FPGA上，而在RISC-V处理器上的优化研究较少。随着RISC-V架构在通用计算领域的普及，优化其在MSM计算 中的性能具有重要意义。现有CPU方案主要依赖软件优化，例如采用Pippenger或Strauss方法来减少计算复杂度，但未充分利用硬件特性。GPU方案通过并行计算能力加速MSM，但功耗较高，适用于大规模任务。FPGA方案通过专用硬件实现高效计算，但开发复杂度高，通用性较低。当前RISC-V处理器已有部分指令扩展用于加速密码学计算，但在MSM计算优化方面仍然不足，计算效率较低。传统CPU计算MSM主要依赖通用整数或浮点指令，未充分利用SIMD和流水线优化。本项目计划通过指令集优化、微架构改进和软件优化等方式提升RISC-V处理器在标量乘法与椭圆曲线点乘运算中的性能。具体包括：扩展RISC-V指令集，优化标量乘法和点加运算的执行效率；改进处理器微架构中的算术逻辑单元，增强大整数运算能力；优化基础数乘算法，提升计算效率。同时，将充分利用SIMD指令和流水线技术，充分发挥硬件并行计算潜力。本项目旨在开发一套针对标量乘法和椭圆曲线点乘运算优化的RISC-V指令集扩展，设计并实现硬件加速方案，并在RISC-V处理器上进行性能测试与对比分析，相较于纯软件方案，预期在典型椭圆曲线上的点乘运算速度提升100倍。通过软硬件协同优化，显著提升RISC-V处理器在基础密码学运算中的性能，为区块链、隐私计算等应用场景提供高效、低功耗的计算支持。,"1. 设计RISC-V指令扩展，优化MSM点乘与加法运算；                                  
2.相较于纯软件方案，预期在典型椭圆曲线上的点乘运算速度提升100倍；    
3.编写性能测试脚本，对比优化前后计算速度；  
4.输出硬件设计文档，说明指令扩展与优化方案"
基于 LangGraph 实现的 KubeSphere 社区问答 AI 助手,进阶,"[[""datas"",""AI""],[""cloudnative"",""Kubernetes""],[""datas"",""Vector Database""]]",基于 LangGraph 和 Milvus 向量数据库开发一个智能问答系统，整合 KubeSphere 社区的知识库、文档和常见问题，构建 Agentic RAG 工作流，为用户提供准确、实时的技术支持和解答，提升社区用户体验和技术支持效率。随着 KubeSphere 社区的快速发展，用户对技术支持和问题解答的需求日益增长。传统的文档检索和人工解答方式已无法满足高效率、高质量的服务需求。利用大语言模型和向量数据库技术，构建一个基于 Agentic RAG 的智能问答系统，可以极大提升社区支持效率，让用户能够快速获取准确的技术信息，同时减轻社区维护者的负担。,1. 开发基于 LangGraph 的 Agentic RAG 工作流核心2. 实现与 KubeSphere 控制台集成的 Web 前端界面3. 编写完整的项目文档和使用说明书
源码转换DSL能力,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",本赛题旨在实现将Vue/React代码转换为低代码DSL的能力，及支持出码后修改源码的逆向转换，提高低码扩展性与灵活性，方便更好的导入导出项目。,1. 实现从Vue/React代码到低代码DSL的转换功能。2. 支持出码后修改源码的逆向转换功能。3. 提供详细的文档和示例代码，确保用户能够轻松使用该功能。4. 代码逻辑清晰，模块划分合理，可维护性强，符合项目开发规范。
eulermaker构建优化,进阶,"[[""cloudnative"",""Docker""]]","eulermaker目前在本地构建时脚手架启动流程复杂,遇到多个包编译时管理困难.因为目前构建环境都是在容器下执行,由于docker的接口易用性,可以在docker的api上进行功能拓展,方便初始化编译环境以及构建异常时环境探针的配置,对于拓展性方便,更容易与ide交互,以及web端调用.","1. 实现对docker接口调用的封装,实现一致的调用RPC接口:"
MaxKey WebAuthn登录认证开发和双因素认证优化,进阶,"[[""web"",""Angular""],[""safe"",""OAuth""],[""safe"",""OpenIDConnect""],[""safe"",""SAML""],[""web"",""Spring Boot""]]",Dromara单点登录认证系统是，谐音为马克思的钥匙，寓意它能够像一把万能钥匙(最大钥匙)一样，解锁复杂的企业安全需求，提供简洁而高效的解决方案。产品支持OAuth 2.x/OpenID Connect、SAML 2.0、JWT、CAS、SCIM等标准协议，提供的用户身份管理(IDM)、身份认证(AM)、单点登录(SSO)、RBAC权限管理和资源管理等。MaxKey注重企业级场景下的性能、安全和易用性，广泛应用于医疗、金融、政府和制造等行业。MaxKey，开源、安全、合规、自主可控。‌WebAuthn（Web Authentication）是一种基于FIDO2规范的API，用于在浏览器和平台上实现强大的无密码身份验证‌。它利用公钥密码学，将私钥安全存储在用户设备上，公钥则用于服务器验证用户身份。WebAuthn的核心技术是CTAP（FIDO2的客户端到验证器协议），允许外部身份验证器与浏览器协同工作‌1、基本原理WebAuthn使用公钥和私钥的成对生成技术。公钥可以公开，而私钥必须保密。公钥用于加密数据，只有对应的私钥才能解密；反之亦然，这种非对称加密技术确保了数据的安全性‌。在WebAuthn中，用户的身份认证是通过公钥凭证进行的，服务器不存储任何密码，从而大大提高了安全性‌2、应用场景和优势WebAuthn适用于各种web应用和网站，提供极简的登录流程和极高的安全性。相比传统的密码认证方式，WebAuthn不需要密码，用户只需通过PIN码、指纹、面部识别或USB密钥等方式进行身份验证。这不仅简化了登录流程，还提升了用户体验‌。此外，由于服务器不存储密码，大大减少了数据泄露的风险‌3、兼容性和未来发展目前，主要浏览器如Chrome、Firefox和Edge都支持WebAuthn。未来，随着更多设备和应用的支持，WebAuthn有望成为主流的身份验证方式，进一步推动无密码登录的发展‌双重认证（英语：Two-factor authentication，缩写为2FA），又译为双重验证、双因素认证、二元认证，又称两步骤验证（2-Step Verification，又译两步验证），是一种认证方法。,1. 1. 开发WebAuthn登录认证功能2. 双因素认证优化
HIPLOT (ORG) 生物医学数据分析功能大版本更新,进阶,"[[""codelang"",""Programming Language""],[""web"",""Web Application""],[""datas"",""Data Science""],[""datas"",""Scientific Computing""]]",自 2019 年 10 月以来，Openbiox 生物信息学社区和 HIPLOT 协作小组已实现数百个与生物医学数据可视化分析挖掘相关的开源网页插件，并通过 HIPLOT（ORG）（https://hiplot.org）等在线网站提供一键式免费可视化分析服务。相关在线网站涵盖了常见的生物医学数据可视化分析需求，已被数十万名科学研究人员应用于各类生物医学等科研数据可视化分析工作，谷歌学术引用超千次。本项目旨在显著增加 HIPLOT (ORG) 生物医学数据可视化平台数据可视化分析功能，以解决近年来新增的用户需求和痛点，例如多表格、多层次数据的整合展示、新型统计方法/深度学习模型和大型组学公共数据集的一键式可视化挖掘。项目参与学生将主要基于 HIPLOT (ORG) 原生插件框架和 R 语言完成面向标准化表格数据的可视化分析插件开发和测试，并深度参与后续 HIPLOT (ORG) 系列科学论文的撰写和修改工作。,1. 新增单一表格数据的基础统计分析功能插件至少 10 个；2. 新增多表格数据可视化整合分析功能插件至少 10 个，例如基因组+转录组；3. 新增多层次数据展示功能插件至少 10 个，例如整体+个体；4. 新增新型数据统计和可视化方法至少 10 个，可在单一工具统一支持多个方法；5. 新增深度学习模型相关工具插件至少 10 个，可利用 Nvida RTX 5090D 单卡高效完成任务优先；6. 新增至少 3 个公共数据集的基础挖掘功能（参数统计、关联分析和预后分析）。7. 构建和维护社区自定义基因集（HiSIG），用于支持癌症、衰老以及其他重大慢性疾病研究。
MateChat模板移动端(Android、IOS、鸿蒙)支持,基础,"[[""web"",""UI""],[""web"",""Vue.js""],[""web"",""AndroidX""]]",根据用户使用习惯的不同，用户可能希望通过在App中使用matechat来进行与模型的对话，目前matechat仅支持了pc端。本项目要求提供一套基于pc端一站式解决方案模板自动生成App端H5模板的方案，在pc端一站式解决方案的模板迭代后，通过脚本或插件的方式，自动更新App端H5的模板，不再需要人工维护多份模板。,"1、编写一个脚本或插件，用于将pc端的一站式解决方案模板自动生成App端H5模板
2、脚本或插件，尽量使用简单"
openGauss 向量数据库 AI 评估框架对接最佳实践输出,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",完成 Arize Phoenix、DeepEval、FiftyOne 对接 openGauss 最佳实践教程输出,1. 基于 openGauss 部署指导文档，完成openGauss Docker 部署2. 参考 Milvus weaviate 等文档，完成  Arize Phoenix、DeepEval、FiftyOne、对接 openGauss 最佳实践教程输出3. 将文档提交至 openGauss 社区
NoneBot HTML 图片渲染插件,进阶,"[[""web"",""Qt""],[""web"",""UI""],[""datas"",""PIL""],[""dev"",""Selenium""]]",文字与图片一直是聊天机器人的两大主流交互方式，而图片的渲染一直是用户开发应用的一大痛点。常见的方式包括 PIL 图片编辑、浏览器渲染 HTML 截图等。PIL 图片编辑依赖人工构建图片布局，容易出现自适应问题，且提升图片特效、美观程度需要极大的开发成本。浏览器渲染方案通过 HTML 与 CSS 能够轻松完成美观自适应能力强的布局，但其部署门槛较高，难以支撑较大规模调用量。而其他轻量化渲染引擎通常不具有完整 HTML/CSS 现代化标准实现，且未提供 Python Binding 直接使用。本项目希望调研并实现一种高效、便捷的图片渲染方案。该方案需要在保障跨平台一致性、最大程度保证 HTML 与 CSS 现代化标准的前提下，低成本（资源消耗与吞吐量）将 HTML 渲染为对应图片。,1. 调研 HTML/CSS 渲染引擎2. 基于渲染引擎实现 HTML 图片渲染插件
openHiTLS密码库RISC-V架构下基于RVV实现对AES、SM4对称密码算法的加速与优化,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""SSL/TLS""],[""safe"",""TCP/IP""]]",作为现代信息安全的基石，对称密码算法AES和SM4等对称密码算法在全球化应用和国家安全关键领域发挥着不可替代的作用。AES凭借其多轮非线性变换结构和标准化优势，广泛应用于物联网终端、云数据加密和高吞吐量网络通信；而SM4作为我国密码体系的核心算法，在金融支付、政务数据保护和5G车联网等关键场景中具有强制部署要求，其32轮复合迭代设计在安全性上与AES形成等效保障。然而，二者在实现上面临相似的性能挑战，当前主流的硬件加速方案（如x86 AES-NI指令集或ASIC定制电路）难以适配RISC-V开放架构的生态需求。在当前RISC-V生态中，尽管其开放指令集架构为定制化扩展提供了基础，但针对openHiTLS中对称密码算法加速方案仍存在空白。以x86架构的AES-NI指令集为例，其通过专用指令直接内化S-Box查表、轮密钥混合等核心操作，将AES加解密吞吐量提升数倍，充分验证了指令集-算法协同设计的必要性。然而，RISC-V社区尚未形成类似AES-NI的标准化加密指令扩展，现有实现多依赖软件模拟基础运算，导致计算密度低、访存延迟高，尤其在openHiTLS场景下，算法与硬件模块的实时交互需求进一步暴露了软硬协同优化能力的不足。本项目拟突破这一瓶颈，相较于传统软件实现中频繁的查表中断与标量计算瓶颈，该方案利用RVV的超宽向量寄存器与SIMD特性，将两类算法的关键瓶颈操作重构为向量化并行原语。此外，结合openHiTLS平台对算法关键路径的动态追踪与微架构建模，可进一步优化向量寄存器分配策略与内存访问模式，减少数据搬运冗余。相较于传统CPU中依赖分支预测和缓存预取的软件优化方案，该设计无需引入专用密码指令集，而是复用V扩展指令集中的通用向量计算单元，在保持RISC-V指令集生态兼容性的前提下，提高AES、SM4的加速效能和优化水平，为国产芯片在高安全场景中的规模化落地提供核心算力基座。,"1. 为 AES/SM4 设计 RISC-V RVV 向量化加速模块，优化 S-Box、轮密钥混合；                                     
 2.为 openHiTLS 集成向量化加密接口（C/Python 调用）；                                       
3.编写含 RVV 指令优化细节技术文档与性能报告"
面向代码任务的DeepSeek大语言模型的本地部署和性能优化,基础,"[[""datas"",""LLM""]]",在将代码从gcc/g++迁移到基于LLVM/Clang的毕昇编译器时，往往会遇到由于编译器兼容性问题所引发的代码兼容性的编译错误，这些错误的定位与修复需要投入大量时间。目前，智能迁移助手（BiSheng AI）利用大语言模型（LLM）来辅助分析和修复这些编译错误，但该工具目前依赖于云端的大模型进行推理。为了提高用户代码的安全性和隐私保护，采用本地部署的大语言模型成为更理想的选择。然而，本地机器的硬件性能通常较为有限，尤其是在仅有CPU的情况下，如何实现高效且快速的推理成为一大挑战。并且不同用户的本地硬件不同，本地部署需要根据硬件条件进行调整。本项目的目标是实现智能迁移助手的基座LLM（大语言模型）在多核CPU环境下的本地部署的通用化，并在推理速度、模型精度与模型参数大小之间找到最佳平衡。具体来说，项目将集中于建立一个通用的大模型接入层，使切换不同平台的大模型代价最小，减少切换时底层代码修改。另外，学生需要评估并选择适合在学生自己本地CPU上运行的最大DeepSeek模型，并利用量化、裁剪、代码模型优化等技术手段，提升推理速度和效率，从而最大化本地模型的性能。通过该项目，学生将面临在硬件资源有限的情况下，如何优化复杂AI模型在多核CPU上的执行，平衡模型性能与资源消耗。学生不仅会深入了解模型优化的技术方法，还会实践在不同硬件环境中部署大规模语言模型的挑战。,"1. 完成智能迁移助手中LLM的本地化部署（CPU），使接入API对本地和云端的大模型通用，保证本地平台模型（如通过llama.cpp，ollama，vllm 等）和云端平台模型都能够最小代价接入，减少切换平台时的代码修改。最后将代码合入openeuler仓库。
模型接入格式要求：实现openAI API （最好使用request库），支持post和stream两种模式，输出格式为JSON，最好可以跨语言调用。2. 在本地化部署过程中，（以学生自己的笔记本或台式机的CPU为例）考虑到在CPU核数和CPU内存硬件资源限制下，找到一个合适参数大小的deepseek模型并尝试进行优化，在精度损失较小的前提下提高推理速度。提交一份报告比较优化前后的模型性能。"
支持Rust构建RT-Thread安全组件,进阶,"[[""os"",""RISC-V""],[""os"",""RTOS""]]",随着Rust语言在系统级开发中的广泛应用，本项目要求参赛者为RT-Thread嵌入式实时操作系统扩展Rust语言支持能力：可以在RT-Thread内核中使用Rust语言开发系统组件（例如文件系统，协议栈，或扩展软件包等），以及在RT-Thread/Smart系统上加载并运行使用rust语言编写的内核模块，从而探索Rust在嵌入式场景中实现内存安全与高性能并重的实践路径，为OS课程教学和工业应用提供新型开发范式。,1. 在rt-thread/components下加入rust组件(目录)，实现Rust相关的支撑接口；2. 完善rt-thread/components/libc/posix/libdl加载内核模块的支持；3. 需保证Rust组件与C语言内核的ABI兼容性；4. 在QEMU/riscv64，K230/riscv64平台上完成实现和验证；5. 需包含说明文档，使用文档及性能相关文档；
完善DAPLINK使用python脚本控制脱机下载的能力,基础,"[[""os"",""ARM""],[""os"",""RISC-V""]]",当前开源的DAPLINK项目不支持Python脚本，只有在线调试和U盘拖拽下载的能力，且一种固件只能针对一种型号的单片机。MicroLink基于DAPLINK增加了PikaPython脚本的支持，实现了通过python脚本控制daplink进行任意单片机脱机下载的能力。然而MicroLink对PikaPython的支持还比较初步，还缺乏灵活的python API支持，以及自动生成python脚本的工具。当前还需继续完善的功能：1、添加更多内置的python脚本，用来给用户提供更多的API来自行控制读写数据的流程2、添加通过python脚本来控制硬件GPIO的能力3、编写一个简单的UI界面，可以通过输入参数自动生成对应的python脚本,"1. 可以通过按键输入自动执行python脚本执行下载流程
2. 通过UI界面自动生成python脚本
3. 通过终端输入python脚本读取FLASH或者RAM数据"
可部署于机器人终端的基于yolo的小样本学习工具包,基础,"[[""datas"",""CNN""],[""datas"",""OpenCV""],[""datas"",""Deep Learning""],[""os"",""ARM""],[""os"",""Linux""]]",1.1相关背景随着机器人技术的快速发展，其在复杂环境中的自主导航与目标识别能力愈发重要。YOLO（You Only Look Once）系列算法因其高效的目标检测性能，成为机器人视觉系统中的关键技术之一。然而，在实际应用中，机器人终端往往面临数据量有限、计算资源受限等问题，这使得传统的深度学习模型难以直接部署。因此，开发一款可部署于机器人终端的基于YOLO 的小样本学习工具包显得尤为必要。该工具包旨在通过优化YOLO模型结构和训练策略，使其能够在少量样本的情况下快速学习并准确识别目标，同时降低对计算资源的需求，可部署在小型设备上，从而提升机器人在复杂环境中的适应性和灵活性。1.2项目描述1.2.1 已有工作随着机器人技术在复杂环境中的广泛应用，其视觉系统的目标检测能力愈发重要。然而，机器人终端在部署深度学习模型时，常面临数据量有限和计算资源不足的挑战。为此，开发“可部署于机器人终端的基于YOLO的小样本学习工具包”显得尤为关键。该工具包结合YOLO系列算法的高效检测能力，通过优化模型结构和训练策略，使其能在少量样本的情况下快速学习并准确识别目标。此外，该工具包还支持在资源受限的机器人终端上高效运行，为机器人视觉系统提供了更灵活、高效的解决方案。1.2.2 存在不足基于 YOLO 的小样本学习在部署过程中面临诸多挑战。首先，YOLO 系列算法虽然在实时性方面表现出色，但其计算需求较高，尤其是 YOLOv4 等版本，对低功耗设备的部署存在明显限制。例如，高计算需求使得在资源受限的边缘设备上难以直接运行，需要通过模型压缩等技术进行优化。其次，小样本学习场景下，YOLO 模型的泛化能力受限。由于训练数据量有限，模型在面对新类别或复杂场景时容易出现性能下降。此外，YOLO在小目标检测方面存在天然缺陷，早期版本如YOLOv1 和 YOLOv2因网格限制导致小目标检测精度不足，尽管后续版本通过改进特征融合等技术有所提升，但在复杂背景下的小目标检测仍面临挑战。1.2.3 希望改进方向1.增强小目标检测能力：在小样本学习场景中，小目标检测是一个关键问题。可以引入注意力机制（如CBAM）或Transformer模块来增强模型对小目标的检测能力。例如，YOLOv5结合Swin Transformer的层次化设计，可以有效提升小目标检测的性能。2.模型轻量化与优化：为了适应机器人终端有限的计算资源，需要对YOLO模型进行轻量化处理。可以通过模型剪枝、量化以及采用更高效的网络架构（如MobileNet或GhostNet）来减少模型的参数量和计算复杂度。例如，使用GhostNet作为YOLO的骨干网络，可以显著减少参数量并提高推理速度。3.将计算密集型任务部署到Jetson Nano上，作为推理引擎，确保实时性。同时实现在Nano上进行小样本yolo学习功能，在Nano上完成“标记-训练-推理”全流程打通。1.2.4 最终项目实现目标1.高效的实时目标检测确保工具包在Jetson Nano上能够高效运行，实现实时目标检测功能。通过优化模型结构和计算资源管理，使检测速度满足实时性要求，能够快速识别和处理图像中的目标对象，适用于机器人终端等资源受限的边缘设备场景。2.低功耗与轻量化部署实现低功耗运行，充分利用Jetson Nano的硬件特性，通过模型压缩和优化技术（如权重量化、减少计算量等），降低模型对硬件资源的依赖，确保在有限的计算资源下仍能高效运行，延长设备的续航时间，提升工具包在实际应用中的可行性和经济性。3.适应小样本学习场景保持工具包对小样本数据的良好学习能力，通过迁移学习、数据增强等策略，确保模型在少量标注数据的情况下仍能快速收敛并达到较高的检测精度，适应机器人终端在复杂多变环境中的实际应用需求，提升系统的灵活性和适应性。,1. 完成labelMe工具在Nano中的搭建。2. 完成fewshot-yolo在Nano中的推理部署。3. 完成fewshot-yolo在Nano中的训练执行。4. 完成fewshot-yolo的量化优化操作，在精度损失小于5%的情况下减少30%的模型尺寸。
基于c语言实现MapperFramework,进阶/Advanced,"[[""codelang"",""Programming Language""],[""cloudnative"",""Kubernetes""]]",KubeEdge的Mapper-Framework提供了全新的Mapper自动生成框架，集成了DMI设备管理面与数据面能力。目前KubeEdge多语言Mapper-Framework已实现了golang和java版，然而在IoT领域，边缘端侧设备驱动大多是基于C语言编写的，因此在本课题中，我们希望能够给予C语言实现Mapper-Framework，为用户提供基于C语言的设备驱动Mapper，提升用户开发效率。,1. 输出设计方案2. 开发基于C语言的Mapper-Framework
基于KubeEdge-Ianvs的多LLM云边路由范式：面向具身智能应用,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""datas"",""PyTorch""],[""cloudnative"",""Kubernetes""]]",当前，大模型研究面临算力垄断、训练成本高企和技术路径单一等挑战，“路由LLM（Routing LLM）”范式为突破这些瓶颈提供了新思路。该范式通过智能调度和协同多个开源（及闭源）小模型，以“组合创新”替代传统“规模竞赛”，具备异构兼容、多目标优化和灵活部署等多重优势。例如，它能够兼容GPT-4、Llama等多类模型，实现性能、成本和风险的动态权衡，并可按需快速定制针对如代码生成、医疗问答等场景的解决方案，而无需从头训练大模型。KubeEdge-Ianvs目前已支持云边协同推理，可视为“多LLM云边路由”的一种雏形，未来在云+边多模型的智能协同必将成为LLM性能优化的重要趋势。本项目将基于KubeEdge-Ianvs，进一步拓展和实现多LLM云边路由能力，打造支持多模型注册、调度、分发与动态路由的开源平台，为云边智能推理和产业实际应用提供创新高效的技术路径。,1. 在KubeEdge-Ianvs中实现多LLM云边路由范式2. 在KubeEdge-Ianvs中实现一个多LLM云边路由的example3. （可选）实现更高效的针对多LLM云边路由的router算法
Kuasar机密容器：基于x86 SEV 实现,进阶,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Cloud Native""],[""os"",""Linux""],[""os"",""x86""],[""os"",""QEMU""],[""os"",""KVM""]]",随着社会隐私意识增强，保护数据安全的政策推出，各大企业对数据安全的重视程度增加，数据保护相关技术不断发展，云原生场景下的隐私计算需求快速增加。在系统架构领域，ARM推出了TrustZone硬件级安全技术，未来还将落地机密计算架构（CCA），而AMD推出了SEV硬件级隔离技术。在云原生领域，kata-containers社区已支持机密容器能力，以解决安全容器无法全面保证数据安全性、隐私性和安全性，以及云原生场景下用户对云服务提供商的信任问题。Kuasar社区也需要构建机密容器相关能力，以满足Kuasar用户对数据安全的需求。目前openEuler社区正在支持ARM架构下的Kuasar机密容器，为了覆盖X86场景，Kuasar还需支持基于SEV的机密容器，并且为了看护功能持续演进，需要补充相关资料和e2e。,"1. Kuasar支持x86机密容器能力。
2.机密容器模块代码补充单元测试用例。
3.机密容器开发e2e测试用例。
4.为Kuasar使用机密容器编写使用说明等资料。"
基于secGear的高效数据库存储设计与实现。,进阶/Advanced,"[[""os"",""Linux""],[""codelang"",""Programming Language""]]",（1）相关背景：随着云计算技术的迅速普及，对于云服务器来说，实现高效安全的数据库服务越来越重要。对于用户来说，在云服务器上托管敏感数据可能会导致严重的隐私泄露隐患，因为使用云服务就意味着用户必须要信任云服务器环境上的所有软件，包括操作系统、监视器等特权软件，也要信任云服务提供商以及相关工作人员，但这些部分现实中往往是不可信任的。机密计算则作为近年来可信计算领域的一项新兴技术应运而生，它为用户提供了一种硬件隔离沙箱环境，能够保护内部数据的安全。（2）已有的工作：现有的基于机密计算的数据库存储方案如SecureKV、EnclaveDB等等，设计的存储架构在优化性能与安全做了比较好的平衡。（3）存在的不足：虽然这些工作在很大程度上提高了在云计算环境当中使用机密计算进行数据库存储的效率，但相比于非机密计算环境下的效率还是低很多，有更高的延迟以及更低的吞吐量。（4）希望改进的点：这些缺点主要来源于SGX 中的一些限制，因为安全内存EPC的大小被限制在128MB，在面对大量数据处理的环境中会引起频繁的页面交换，严重影响系统的响应速度和吞吐量。（5）最终项目实现的目标：secGear是华为自主研发的机密计算框架，通过将计算隔离到基于硬件的受信任执行环境以保护运行态数据，并且将不同处理器架构的机密计算方案的差异在软件层面抹平。因此在现有工作的基础上设计一种基于secGear的高效数据库存储方案，在enclave内存有限的情况下通过TEE技术的结合，既保护数据，又能利用其他的方案减少这种限制对于系统性能的影响。,1. 设计并实现一种基于secGear的高效数据库存储方案，对所实现的存储方案进行安全性分析及性能评估2. 将实现的方案与现有工作（如：EnclaveDB）进行实验对比并分析，要求减轻EPC在面对大量数据处理的环境中频繁的页面交换，从而提高系统的响应速度和吞吐量，最终提升在50%以上3. 提交功能代码和测试代码
基于Frama-C的openHiTLS国密算法（SM3/SM4）形式化验证与安全增强,进阶,"[[""safe"",""AES""],[""safe"",""RSA""],[""safe"",""SSL/TLS""]]",课题背景1、SM3/SM4作为国家商用密码标准，在金融、政务等场景广泛应用，但算法实现中的逻辑漏洞（如整数溢出、边界条件处理不当）可能引发严重安全风险2、Frama-C是支持C代码形式化验证的开源工具，可通过ACSL（ANSI/ISO C Specification Language）规范描述算法数学逻辑，结合WP插件生成证明义务并调用SMT求解器（如Alt-Ergo、Z3）进行验证。课题目标1、使用Frama-C对openHiTLS中、SM3（哈希计算）、SM4（加解密）的核心函数进行形式化建模，验证其与国密标准（GM/T 0003-2012等）的一致性。2、发现并修复代码中潜在逻辑错误（如内存越界、未处理异常分支）。,1. 使用openHiTLS对接Frama-C工具，进行SM3、SM4对应数学模型建模，完成SM3、SM4算法接口的内存安全验证
修复 nydus 运行时 shared mode 下的 inode cache 问题,进阶,"[[""datas"",""AI""],[""cloudnative"",""Kubernetes""],[""os"",""FUSE""]]",镜像是容器基础设施中的一个重要部分，目前 OCI 标准镜像的缺陷之一是容器需要等待整个镜像数据下载完成后才能启动，这导致了容器启动时消耗了过多的端到端时间。开源容器镜像加速项目 Nydus 能够使得容器做到秒级冷启动，在镜像构建，分发与运行时，以及性能与安全性上有诸多探索，目前 Nydus 服务了每日百万级的容器创建，也在 AI 模型镜像分发上有着诸多落地场景。本题目是修复 nydus 运行时 shared mode 下的 inode cache 问题。,1. nydus 在多个文件系统子挂载点情况下，当用户 umount 子挂载点后，没有正常 invalid fuse 的 entry 和 inode cache，需要调查并进行修复，该问题需要对文件系统及 fuse lib 有一些了解，并编写单元测试，集成测试，以及用户文档。
为Linux Kernel扩充更多基于RISC-V V扩展和K扩展的SHA-3算法加速实现,基础/Basic,"[[""os"",""RISC-V""],[""os"",""Linux""],[""safe"",""Cryptography""]]","当前Linux内核中近ARM64架构对SHA-3(FIPS 202)算法进行了基于密码算法指令集扩展的SHA3实现。相比于ARM64架构的ARM CE,RISC-V架构的K扩展对SHA-3算法的支持并不完善，但是可以借助V扩展实现一个次一级效果的SHA-3加速器。SHA-3标准：https://www.nist.gov/news-events/news/2015/08/nist-releases-sha-3-cryptographic-hash-standard",1. 实现一个Linux内核模块，提供基于RISC-V V扩展和K扩展进行SHA-3算法运算的能力。
openInula 2.0 编译器 Rust化,进阶,"[[""web"",""Babel""],[""web"",""React""],[""web"",""Webpack""],[""web"",""Web Application""],[""os"",""Compiler""]]",随着Rust语言在性能和安全性方面的优势，越来越多的项目开始迁移到Rust技术栈。该项目的目标是将openInula 2.0框架中的编译器部分迁移到Rust，利用Rust的高性能和内存安全特性提升编译器的效率和稳定性。同时，可以借助Rust生态中的工具和库，如rolldown、oxc等，进一步优化编译过程。已有工作：1、openInula 2.0框架目前使用的编译器部分主要基于现有babel的技术栈，使用TS编写。2、Rust语言在性能、并发处理等方面表现出色，已经有一些成功的项目将编译器部分迁移到了Rust。存在的不足：1、现有的编译器部分性能较低，且在处理复杂任务时容易出现瓶颈。目标：1、将openInula 2.0框架的编译器部分（jsx解析模块）迁移到Rust技术栈，提升性能和稳定性。2、利用Rust的优势实现高效的编译过程，并支持跨平台使用。,1. 技术栈要求：Rust，rolldown、oxc等相关工具，openInula 2.0框架。2.功能要求
基于时间序列预测方法的降雨预测,进阶,"[[""datas"",""AI""]]",ModelRain是基于Informer时序预测模型并利用已有的气象数据以及水汽数据进行1-3小时天气预报的一款降雨预报模型。使用 MindSpore 复现 ModelRain模型，有望借助其特性，进一步提升模型训练与部署效率，推动气象预报领域的发展，为降水预报提供更有力的支持 。,1. 需要参与任务的人员基于 MindSpore 深度学习框架，完成 ModelRain模型的复现工作。具体而言，要依据 ModelRain 模型的原理和架构，使用 MindSpore 的 API 进行代码编写，构建模型的各个组件，包括但不限于网络结构搭建、数据处理流程设计、模型训练与优化等环节。确保复现后的模型能够在给定数据集上达到与原模型相近的性能表现，在降水预报等场景中发挥作用，同时要对复现过程进行详细记录和总结。
为Arthas 实现 MCP 服务,进阶,"[[""datas"",""AI""],[""dev"",""AIOps""]]",目前 MCP 协议越来越流行，Arthas 需要在Server端支持 MCP 协议，把诊断功能暴露出来，方便各种AI工具集成。最终实现的效果是：,1. 使用 netty 或者 JDK 自身的 http 库实现 mcp server2. 支持最新的 https://modelcontextprotocol.io/specification/2025-03-26 协议规范3. 需要实现 Streamable HTTP，支持 Mcp-Session-Id 重连4. 需要使用第三方客户端实现集成测试
低代码物料快速导入能力,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",本赛题旨在增强TinyEngine的低代码物料导入能力，使用户能够快速将外部组件库/组件导入到TinyEngine中，根据文档或者源码快速自动生成物料配置文件。建议结合AI技术，实现自动化的物料导入流程。,1. 实现一个物料系统，包含完整前后端，能够正常的启动与部署。2. 物料系统实现低代码物料的快速生成功能，支持从不同源导入物料（如文档代码库、文档URL、文件、输入的信息）生成最终的物料文件，并支持预览物料文件在TinyEngine效果。3. 支持物料的可视化或者自然语言(结合AI)二次调整优化。4. 支持物料相关的必要的合并分割、物料管理等能力。5. 界面引导清晰，交互友好，无明显问题；提供必要的设计与使用文档；代码逻辑清晰，模块划分合理，可维护性强，符合项目开发规范。
RISC-V IOMMU HPM & Nested支持 ,进阶,"[[""os"",""Linux""],[""os"",""RISC-V""],[""os"",""QEMU""],[""os"",""Virtualization""]]",本项目旨在为EulixOS/OLK-6.6移植RISC-V IOMMU 硬件性能监控（hardware performance monitor）和嵌套 IOMMU 支持。同时，还引入了更多操作，这些操作是嵌套IOMMU 所需的，例如和。该项目基于的RISC-V IOMMU 规范已经通过批准，并可在 GitHub/riscv-non-isa [1] 获取。在高层次上，RISC-V IOMMU 规范定义了以下内容：1.数据结构：：将设备与地址空间关联，并保存用于地址转换的每设备参数。：基于设备提供的进程标识号（process identification numbers）关联不同的虚拟地址空间。：用于将MSI（Message Signaled Interrupts）定向到 IMSIC（Incoming Message Signaled Interrupt Controller）中的客户中断文件。2.内存中的队列接口：：用于向IOMMU 发送命令。：用于报告故障和事件。：用于报告从PCIe 设备接收的“页面请求”消息。。3.内存映射编程接口：强制和可选的寄存器布局及描述。设备初始化和功能发现。[1],"1. 基于EulixOS/OpenEuler-OLK6.6移植适配：
- RISC-V IOMMU硬件性能监控。  
- 嵌套IOMMU支持。2. RISC-V IOMMU核心功能测试验证：
- 制定RISC-V IOMMU HPM/Nested测试方案。
- 梳理筛选iommu-selftests的功能点，适配RISC-V架构。
- 基于iommu-selftests测试套件，验证并完善RISC-V IOMMU特性。3. 探索支持其它RISC-V IOMMU内核特性：
- 对比ARM/X86架构，分析其它架构与RISC-V IOMMU支持的硬件差异。 
- 对比ARM/X86 IOMMU内核实现，完善RISC-V IOMMU内核支持。"
基于RustSBI文档的FAQ问答库设计与实现,进阶,"[[""datas"",""AI""],[""datas"",""LLM""],[""os"",""RISC-V""]]",在智能对话系统中，FAQ指的是高频的常见的问题，缓存为一个基础的问答库，这样就不用每次都通过模型生成相应的答案，因为模型生成答案一个问题是存在不确定性，不一定生成的答案就是正确的，另外一点是模型生成答案的速度通常较慢，较为消耗资源，因此通过FAQ库可以一定程度缓解上述问题。构建FAQ库首先是需要生成Question和Answer数据对，随着大模型技术的发展，数据生成变得越来越简单，因此可以通过结合大模型技术生成Question和对应的Answer。然而生成高质量的数据并不是一件简单的事情，因此最重要的是需要考虑如何生成更高质量的Question和Answer。在生成了相应的数据后，通过Faiss等向量检索库，完成语义检索问答功能。,1. 完成Q-A对生成代码，包括完整的prompt、大模型调用等2. 对生成的数据进行精炼迭代，产出高质量Q-A数据不少于300条3. 搭建语义检索向量库，具备语义检索问答功能4. 提供代码使用说明
为 TDengine 完善逻辑备份和恢复功能,进阶,"[[""datas"",""Database""],[""datas"",""Structured Database""],[""datas"",""MySQL""]]",TDengine 是一款专为物联网、工业互联网等场景设计并优化的大数据平台，其核心模块是高性能、集群开源、云原生、极简的时序数据库。它能安全高效地将大量设备每天产生的高达 TB 甚至 PB 级的数据进行汇聚、存储、分析和分发，并提供 AI 智能体对数据进行预测与异常检测，提供实时的商业洞察。目前，TDengine Enterprise 已支持基于 TMQ（Time-Series Message Queue）的增量备份和恢复解决方案，但该方案存在：初始备份性能差、耗时长的问题。本项目的目标是，基于数据库查询/存储引擎调用/数据文件扫描等方式，对指定时间范围的时序数据进行备份，备份文件能够支持高效的数据恢复。解决方案能够实现以下目标：,1. 代码提交到 TDengine 仓库，通过 Review 并成功合并到主分支；2. TDengine 逻辑备份和恢复的技术文档，包括：User Manual、Functional Specification、Test Specification。
利用AGIROS实现机器狗导航和控制,进阶,"[[""datas"",""AI""]]",：机器狗和人形机器人普遍采用ubuntu操作系统，并且与国外ROS可实现对接。而国内开源机器人操作系统AGIROS缺乏优秀的实践，本项目将基于AGIROS实现四足机器人的导航控制，验证国产系统的建图和路径规划等能力。：已经编译了部分AGIROS包，以及对教学类puppy小狗的分析。：未对接宇树机器狗提供特定的sdk，未实现手势控制，建图导航等能力均未在AGIROS系统上验证。：控制系统完全迁移到AGIROS系统，需要迁移激光雷达，深度相机/普通相机等驱动，并开发控制节点，实现建图导航和手势控制两个场景的工作流，对接宇树机器狗提sdk，控制机器狗完成特定动作。：机器狗能够被AGIROS系统控制，对环境进行二维建图，标定位置后，能避障并抵达目的地。人在相机位置手势（剪刀，石头，布）控制机器狗做不同动作。,1.新建OS系统，调雷达驱动，相机驱动，宇树机器狗sdk调试，建图调试，导航调试，标定调试，图像采集和手势识别，开发业务流，调试定位精度，解决AGIROS软件包问题等。2. 激光雷达，深度相机/相机，树莓派单板，机器狗等硬件，需要整合电池包和单板，网线等，放到机器狗身上，牢固美观。3.风险控制：通过优先级控制风险，项目目标优先级为：建图导航（高），手势识别（中），跟随（低），根据最终结果做出评价。4. 总结整个开发过程，整理成文档。
在BMQ调度算法中实现无锁的抢占队列，全局运行队列和优先级级别全局运行队列锁,进阶,"[[""os"",""Linux""]]",在ELF BMQ(Enqueue Lock-Free BMQ)设计中，需要实现全局运行队列，为了最大化优化全局运行队列性能，需要实现每个CPU的无锁的抢占队列，和优先级级别的全局运行队列锁。本选题目标为在BMQ算法中实现以上功能，并修订由此引起的设计改动。,1. 在开发分支上完成本选题目标2. 开发分支上的内核编译的BMQ调度算法可以通过虚拟机和真实机器测试
基于AI大模型提升社区翻译效率,基础,"[[""cloudnative"",""Cloud Native""],[""datas"",""AI""],[""cloudnative"",""Docker""]]",为加速openEuler国际化进程，本项目旨在构建智能翻译辅助系统，通过AI大模型技术优化社区文档本地化流程。系统将深度分析Gitee平台的PR差异文件（diff），利用大模型能力实现：智能变更解析：结合代码上下文生成精准翻译建议；增量式摘要生成：对文档修改内容生成结构化变更摘要（包括修改类型、影响范围等）。术语库动态维护：自动提取领域专业术语并构建持续演进的翻译记忆库翻译人员可通过摘要界面快速获取上下文关联的翻译建议，相比传统人工对比方式，预期提升翻译效率。系统将深度集成到社区CI/CD流程。,1. 基于大模型实现文档智能变更解析，为翻译人员提供参考，提升效率：实现变更影响范围预测（准确率>85%）；总结改动内容（包括修改类型、影响范围等）2. 基于大模型实现翻译pr的语法正确性校验3. 工程化测试体系：单元测试覆盖率≥60%4. 将上述能力集成到社区文档CI/CD流程，实现自动化。5. 全生命周期文档6. API参考文档
Apache Dolphinscheduler 新增 gRPC 任务插件,基础/Basic,"[[""cloudnative"",""Docker""],[""web"",""Vue.js""]]",Apache Dolphinscheduler 是一个分布式的工作流调度系统，支持多种任务类型，并且提供了高扩展的插件机制。该项目旨在为 Dolphinscheduler 添加对 gRPC 任务的支持，使用户能够通过 gRPC 协议调用远程服务并获取执行结果。该插件将允许用户在工作流中定义 gRPC 任务，并提供必要的配置选项，如服务地址、方法名称、请求参数等。通过这个插件，用户可以更方便地集成和调用基于 gRPC 的微服务，提高工作流的灵活性和可扩展性。要求可配置性高，使用方便，与Apache Dolphinscheduler插件体系保持一致。,1. 主要需求2. 非功能性需求
扩展OpenManus 可视化生成能力,基础/Basic,"[[""datas"",""AI""],[""datas"",""LLM""]]",基于OpenManus（https://github.com/mannaandpoem/OpenManus）已有的可视化能力。目前已经集成了VMInd 到 OpenManus 做数据分析，处理和可视化生成，在此基础上做特定场景的能力增强和标注能力。成果会被合入OpenManus ，相当如同时在VMInd 和 OpenManus 贡献了代码。,1. 完成3个特定场景的生成优化2. 完善智能标注能力3.  梳理完整的功能需求、设计、Demo文档
为 Cloudpods 服务编译打包 RISC-V 镜像,进阶,"[[""cloudnative"",""Docker""],[""os"",""RISC-V""],[""os"",""Linux""]]",Cloudpods 是一个使用 Go 编写，能够以容器化方式运行在 K8s、K3s 和 docker compose 上的私有云+多云管理平台。目前已经支持在 x86_64 和 aarch64 架构的系统上运行，现在需要在 RISC-V 架构的系统上运行。为了实现 RISC-V 的支持，需要把各个服务组件使用 docker buildx 编译成支持 X86_64/AARCH64/RISC-V 的多架构镜像。,"1. 将 https://github.com/yunionio/cloudpods 的服务使用 golang 编译成 RISC-V 架构的二进制，再使用 docker buildx 打包成能在 RISC-V 架构系统上运行的容器镜像
2. 代码已 PR 形式提交到 https://github.com/yunionio/cloudpods 仓库"
完善星绽内核的 RISC-V 64 支持,进阶/Advanced,"[[""os"",""RISC-V""],[""os"",""Linux""]]",星绽（Asterinas）是基于 Rust 开发的 Linux 兼容内核，目前主要支持 x86 虚拟机和可信执行环境。对于 RISC-V 当前已实现编译和 QEMU 启动能力。虽然现有 PR#1695 已初步完成异常处理、中断控制器等基础功能，但仍缺乏用户态程序支持，且尚未适配物理开发板。,1. 需突破以下物理硬件特有挑战：实现 SD 卡/UART 启动流程、开发板特定时钟初始化、硬件外设总线驱动适配、物理中断控制器集成。最终目标是在至少一款 RISC-V 物理开发板上完成内核冷启动、串口交互、外设驱动验证及基础用户态程序执行。
AI-Powered API Testing Agent for atest,Basic,"[[""datas"",""AI""],[""datas"",""Database""],[""web"",""Vue.js""]]","is an open-source API development and testing tool. It supports Restful API, gRPC for now. It allows users to make a HTTP request, and verify it in a simple way or advanced way. It's not easy for everyone to remember all kinds of useful usages. Considering AI now have the great power to understand the user requirements and take the actions. The AI agent should have the following features:","1. Users could input their requests on the web page, and they can receive the result2. Agent should be able to support three types of databases at least3. Agent should be an extension of atest4. Agent should be published as a docker image5. Agent should support a local deployment AI and online service"
企业级分布式 MCP 服务部署与调用方案与实现,基础,"[[""datas"",""AI""],[""cloudnative"",""Cloud Native""]]",1. 项目背景如何将普通的 Spring Cloud Alibaba 应用发布为 MCP 服务是当前很多企业关注的重点。首先，框架要支持将 Spring Cloud Alibaba 应用发部位 MCP 服务并实现 MCP 地址、工具等信息的注册；其次，由于 Spring Cloud Alibaba 应用存在分布式多节点部署的特点，框架需要支持智能体快速接入MCP服务并实现流量在多节点间的均衡分布。2. 学生职责&目标在这个项目中，学生将和社区一起共同探索如何将 Spring Cloud Alibaba 服务发布为标准 MCP 服务，包括 MCP 服务的开发、分布式部署方案与实现，MCP 服务的动态发现、负载均衡调用等。3. 学生要求&技术栈,1. 在这个项目中，学生将和社区一起共同探索如何将 Spring Cloud Alibaba 服务发布为标准 MCP 服务，包括 MCP 服务的开发、分布式部署方案与实现，MCP 服务的动态发现、负载均衡调用等。
生物医学可视化开源图鉴项目拓展,进阶,"[[""codelang"",""Programming Language""],[""datas"",""Data Science""],[""datas"",""Scientific Computing""]]",可视化图形作为连接数据与知识的桥梁，是探寻自然客观规律、挖掘和解释科学发现的重要媒介。在当今数据驱动的生物医学研究时代，利用数据可视化相关的编程语言、图形化交互平台或其他人工智能技术完成各类数据挖掘任务已成为生物医学领域研究人员的核心技能之一。目前，指令式数据分析软件包、图形界面软件以及云平台已逐渐成为提升科学研究效率的重要基础设施。如何进一步提高生物医学数据分析相关研究的重复性是科学社区面临的重要挑战之一。另外一方面，对于众多生物医学研究的初学者而言，编程语言、绘图工具的学习曲线陡峭，特别是在将编程代码应用于实际科学研究场景时往往四处碰壁，大量有用有益的指南手册、编程语言函数或示例散落在互联网各处，仍未被充分整合利用、验证和推广。为此，我们发起，为学习、利用和讨论数据可视化、促进可视化数据分析相关软件开发提供一体化的平台和协作社区，希望构建国内/国际别树一帜的生物信息学基础设施。,1. 按照 Bizard 项目文档要求，使用 Quarto 文档（https://quarto.org/）完成 50-100 个 Hiplot 插件的开源可视化教程撰写【Hiplot (org)图表整理https://kdocs.cn/l/cvqDqGQBQL25 】；2. 进行 Bizard 项目网站的优化（https://openbiox.github.io/Bizard/），增强教程文档的展示效果和易用性；3. 整理/构建10-20个生物医学领域常用的/精简数据集，方便可视化探索和教程撰写。
基于MindSpore实现RL+启发式混合算法,基础,"[[""datas"",""AI""]]",任务需求：使⽤MindSpore框架复现 (2021) Combining Reinforcement Learning with Lin-Kernighan-Helsgaun Algorithm for the Traveling Salesman Problem 中提出的⽅法。,1. 基础功能完整：2. 代码结构清晰：3.  相关评估指标符合要求，代码需要有适当的注释并通过clean code标准。4. 最终项目代码需要通过审核并合入MindSpore Quantum代码仓。
基于MCP + Agent实现表格对话、多表格场景应用,基础,"[[""datas"",""AI""],[""datas"",""Database""],[""datas"",""LLM""]]",背景： 在企业数据分析和日常办公场景中，表格（如Excel、CSV等）是核心的数据载体，但用户与表格的交互仍依赖手动操作或简单的Copilot辅助。随着MCP和Agent技术的发展，如何通过自然语言实现表格的自动化查询、跨表关联分析及动态对话交互，成为提升数据生产力的关键需求。预期目标：1. 智能表格对话：基于MCP协议构建表格专属Agent，支持用户通过自然语言对话完成数据查询、筛选、计算、可视化等操作，无需手动编写公式或代码。2. 多表格协同分析：支持跨表格的关联查询、数据融合及一致性校验，解决企业多数据源场景下的分析难题。3. 智能数据获取与动态增强：支持自动化采集外部数据（如API、爬虫）、动态补充关联字段，并通过MCP协议协调多Agent任务流，实现从数据获取到分析的全流程自动化。,1. 项目设计文档（含架构图、原理图、实现细节等）2. 实现表格Agent核心模块（含MCP适配层、多表格操作引擎、智能数据获取模块）3. 提供完整的使用教程文档说明4. 输出一套垂直实用场景
为 Higress 实现基于多个 MCP Server 的 AI Agent，实现对 Higress 的管控/运维诊断,进阶/Advanced,"[[""datas"",""AI""]]",Higress 是一款云原生 API 网关，核心基于 Istio 和 Envoy，支持通过 Wasm 插件和 Golang HTTP Filter 等方式进行扩展，目前已提供数十个开箱即用的插件。MCP（Model Context Protocol，模型上下文协议）是由 Anthropic 推出的一种开放标准，旨在统一 LLM 与外部数据源和工具之间的通信协议。该项目的目标是实现一个 Higress AI Agent 工具，以及多个 MCP Server 能力，使 LLM 能通过调用相应的 MCP 工具，智能地辅助 Higress 的配置运维与诊断分析，帮助进行问题排查与定位，例如查询 Higress 日志和配置，或使用 Istio debug 接口查看配置，Higress 相关的 Kubenetes 资源管理，以及创建 MCP API/Agent API 等。Higress 的 MCP 相关能力可以参考：https://higress.cn/ai/mcp-quick-start,1. 实现 Higress Ops MCP Server，提供配置运维和诊断分析能力2. 实现 Higress API MCP Server，实现 LLM API/MCP API/Agent API/DB API的全生命周期管理3. 实现 Higress Agent，可以组合多个 MCP Server能力，实现对 Higress 统一的智能化管理
Fury Golang序列化类型前后兼容支持,进阶/Advanced,"[[""codelang"",""Programming Language""]]",（1）背景： Fury是一个高性能的序列化库，支持跨语言的二进制协议。目前基于Go语言的应用逐渐增加。Go语言以其高性能和并发特性而被广泛使用，同时也面临着需要与不同版本和类型结构兼容的序列化挑战。针对Go语言的序列化，保证类型的前后兼容性对于长期项目演化和多版本支持至关重要。（2）已有的工作： 目前Fury已经在Java/Python/NodeJS等语言中实现了高效的序列化和反序列化，但在Go中相关工作仍处于早期阶段，只支持在对象类型Schema严格一致时进行序列化和反序列化。随着项目的扩展和复杂性增长，序列化方案需要更加完整且高效，以支持版本演进。（3）存在的不足： 现有的Fury Go序列化机制尚未充分支持结构类型的前后兼容性。在类型更新时，缺乏适配机制来处理新增字段或移除字段，以保证序列化数据的稳定性和一致性。同时，元数据的高效共享机制还未形成最佳实践。（4）希望改进的点： 希望通过实现一种基于元数据共享的类型兼容机制，使得Fury Go序列化能够支持类型的动态更新，并且保证前后版本之间的兼容。通过高效的元数据共享方式，实现对新增、修改、移除字段的智能序列化处理，以减少版本变动带来的开发负担和运行风险。（5）最终项目实现的目标： 最终目标是为Fury Go实现一个能够支持类型前后兼容的序列化框架。该框架将利用Fury二进制序列化协议的元数据共享机制，实现上可以参考Fury Java/NodeJS等语言的实现，最终自动适应类型结构的变化，确保不同版本之间的数据能够被正确序列化和反序列化，提升Fury在Go生态中的应用广度和深度。,1. 实现元数据编码和解析模块，编译时获取类型元数据，并按照Fury元数据协议进行编码2. 实现元数据共享模块，多个相同类型对象只序列化一次类型元数据3. 编译时解析元数据，生成针对类型不一致场景的反序列化器
开发 AIbrix 高级命令行界面（CLI）工具,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""datas"",""AI""],[""datas"",""LLM""]]",本项目的目标是开发一款面向用户的高级 AIbrix 命令行界面（CLI）工具，用于帮助不熟悉 Kubernetes 的用户更高效地管理 AIbrix 工作负载。该 CLI 工具将提供直观的操作方式，与 AIbrix 所使用的自定义资源定义（CRD）进行交互，从而简化工作负载的部署、管理和扩展过程。目前，AIbrix 的工作负载管理依赖 Kubernetes，用户需具备一定的 Kubernetes 概念和操作经验。这对许多希望利用 AIbrix 生成式人工智能（GenAI）推理能力的用户，尤其是缺乏基础设施管理经验的入门用户来说，构成了显著的学习障碍。为降低这一门槛，我们计划构建一个用户友好的 CLI 工具，目标如下：通过该 CLI 工具，AIbrix 将为用户提供更高的可用性与生产力，进一步营造一个包容性强、易于上手的 AI 开发与部署环境。,1. 提供一个统一的client入口 支持对人工智能推理任务的一键部署 按需扩展 实时监控 性能诊断等等
完善 Web3Insights 的 GitHub 数据处理与优化（基于 gharchive）,进阶/Advanced,"[[""datas"",""Database""],[""datas"",""Data Science""],[""datas"",""Structured Database""],[""codelang"",""Programming Language""],[""datas"",""Graph Database""]]",Web3Insights 是一个用于评估 Web3 生态系统、社区和项目库的开源指标系统。完善和优化 Web3Insights 项目中 GitHub 相关数据的整理工作。清洗 gharchive 数据集。识别并过滤掉恶意刷星行为。识别并过滤掉无意义或垃圾（spam）提交。3. 将清洗后的数据进行结构化处理，以便在项目中有效利用。,1. 一个经过清洗、去重、标记（例如，标记恶意行为）的 GitHub 数据集2. 产出的数据需结构化，格式清晰（例如，定义好的文件模式或数据库表结构）3.数据格式和结构需满足 Web3Insights 项目后续分析和使用的需求4. 提供清晰的数据处理流程文档或代码注释
基于xenomai的Rustpilot飞控优化,进阶/Advanced,"[[""os"",""Linux""],[""os"",""RTOS""]]",（1）相关背景Xenomai是双内核架构，可以在同一个板卡上可以运行硬实时和非实时的任务。而随着无人机发展复杂度的上升，RTOS-based的主控难以承载复杂的业务需求，Linux-based的主控具备开发简单，迭代迅速，架构简单的特点，所以这个题目期望在xenomai上支持RustPilot飞控。RustPilot 是一款采用 Rust 语言开发、运行于 Linux 系统的开源飞控软件。项目以简洁性与可维护性为核心，基于模块化设计与仿真驱动开发，为开发者、无人机爱好者及研究人员提供灵活可靠的飞控解决方案，同时降低小型无人机的开发门槛，为低空经济发展降低门槛。（2）已有的工作目前Xenomai已经支持了开源飞控PX4，对接了各部分传感器，成功驱动无人机飞行（3）存在的不足但是PX4不是Linux原生的飞控，架构设计上存在不少和Linux不一致的地方（4）希望改进的点本项目期望基于Xenomai完善Linux原生飞控RustPilot，进行架构方面的优化，并基于Xenomai优化飞控框架的功能和性能（5）最终项目实现的目标在Xenomai上成功移植RustPilot，补全所需要的组件，并进行整体性能的调优,1. 补全Xenomai所需要的驱动2. 完善RustPilot的对应Xenomai的用户态组件3. （进阶）在实机上优化Xenomai驱动RustPilot的性能与可靠性，设备由社区提供
基于RISC-V的高性能多模态AI业务解决方案研发与优化,进阶,"[[""datas"",""PyTorch""],[""os"",""Linux""],[""os"",""RISC-V""]]",当前电信业务（如视频检索、科创大模型）面临多模态数据处理效率低、异构硬件适配性差、国产化生态不成熟等问题。RISC-V架构因其开放性和定制化优势，结合Triton编译器及多模态大模型技术，可为电信AI场景提供高性能、低成本的解决方案。RISC-V芯片SG2044已支持NPU/TPU异构加速。开源框架VideoRAG、LangChain已实现视频检索与知识库问答功能。Milvus向量数据库支持亿级向量检索。Triton编译器与RISC-V硬件的算子适配尚未完成，导致AI框架（如PyTorch）性能未达最优。视频检索场景中，跨模态模型（DeepSeek-VL/Qwen2-VL）的推理速度与精度需进一步提升。RAG框架在RISC-V环境的动态检索策略优化不足，影响多轮对话响应效率。​：实现Triton算子库与RISC-V SG2044芯片的深度适配，优化PyTorch/TensorFlow框架性能。​：提升视频检索场景中跨模态模型（文本/图像/语音）的实时推理能力。​：优化LangChain框架在RISC-V环境的动态检索策略，支持多轮对话的智能推理。​：构建基于RISC-V的电信AI全栈方案（视频检索+科创大模型），验证性能对标NVIDIA GPU生态。,1. 动态RAG引擎：基于LangChain实现多轮对话的动态检索策略，支持上下文关联与冗余过滤。2. 完成RISC-V上关于向量数据库Milvus的安装适配；3. ​性能验证报告：对比RISC-V与NVIDIA GPU在视频检索与科创大模型的性能差异。4. 开源部署套件：提供RISC-V环境的一键部署脚本、适配文档及性能调优指南。
Apache HertzBeat 支持 RISC-V 架构和 Native Build 原生二进制包,基础/Basic,"[[""os"",""RISC-V""]]",Apache HertzBeat 是一个开源的实时监控系统，专注于提供高效、灵活的监控解决方案。目前系统无法在 RISC-V 架构下运行，且启动时需要依赖JRE环境。本需求旨在支持系统在 RISC-V 架构下部署运行，和通过 GraalVM Native Image 技术将项目编译为原生可执行文件。实现以下目标：RISC-V是目前较流行的一种计算机CPU架构，但目前Apache HertzBeat尚未提供RISC-V版本，本需求需要实现RISC-V64下的运行和性能测试和Docker镜像。,1. RISC-V64运行2. GraalVM native build
TinyEngine低代码引擎支持多人协作能力,进阶,"[[""web"",""UI""],[""web"",""Vue.js""]]",本赛题旨在实现TinyEngine的多人协作功能，允许多个用户同时编辑同一个页面，实时同步更改，提高团队协作效率。,1. 实现多人协作功能，支持多个用户同时编辑同一个页面，实时同步更改。2. 提供版本控制和冲突解决机制，确保数据的一致性和完整性。3. 支持消息通知和协作工具，提高团队协作效率。4. 提供详细的文档和示例代码，确保用户能够轻松使用该功能。5. 代码逻辑清晰，模块划分合理，可维护性强，符合项目开发规范。
基于MoonBit的Qt绑定探索与实现,进阶/Advanced,"[[""web"",""Desktop Application""],[""codelang"",""Programming Language""],[""web"",""UI""],[""web"",""Qt""]]",‌：随着MoonBit语言生态的逐步完善，其跨语言能力与系统编程潜力亟待探索。本项目旨在通过MoonBit与Qt框架的深度集成，探索MoonBit在GUI开发领域的可行性，并为未来构建跨平台、高性能的MoonBit应用奠定基础。‌‌,1. 通过MoonBit现有的Python桥接能力，初步探索MoonBit调用Qt GUI组件的可行性，开发一个简单的MoonBit界面程序示例。2. 尝试基于C ABI或其他方式直接实现MoonBit到Qt的原生绑定。3. 优化开发体验，设计一套初步的接口规范，便于未来扩展更多Qt组件。4. 尝试在鸿蒙系统（OpenHarmony）上运行示例程序，探索兼容性问题并记录。
deepin-upgrade-tool 优化,基础/Basic,"[[""web"",""PyQt""]]",目前 deepin-upgrade-tool 实现了基本的软件更新提醒、软件更新功能。但是存在如下问题：1. 软件界面是固定大小的，无法根据像素自动调整，也不能手动拉伸，2. 软件在存在多版本软件包时，可升级列表显示重复。,1. 软件界面根据像素自动调整适宜的大小。2. 界面支持可以手动拉伸、缩小。3. 优化存在多版本软件包时，更新工具处理逻辑。
参考 NestJS 后端接口规范，提供 Java SpringBoot 或 Python Django 版本后端,基础,"[[""web"",""UI""],[""web"",""Vue.js""]]",随着 TinyPro 后台管理系统的广泛应用，为满足不同技术栈团队的需求，计划基于 TinyPro 现有的 NestJS 后端接口规范，分别提供 Java SpringBoot 和 Python Django 版本的后端实现。通过这一举措，使熟悉 Java 或 Python 的开发团队能够更便捷地使用 TinyPro 模板进行开发，降低技术门槛，提升开发效率。,1. 完成基于 Java SpringBoot 或 Python Django 的后端项目搭建，项目结构清晰合理，按照 TinyPro NestJS 后端接口规范，实现相应的 RESTful API 接口，，包括用户管理、菜单配置、权限管理等模块的接口，确保接口功能完整、响应数据格式与原规范一致，且能与 TinyPro 的前端部分能够无缝对接。2. 完成Java SpringBoot 或 Python Django 的后端与MySQL、Redis数据库的对接。3. 编写详细的 SpringBoot或Python Django 版后端使用文档，包括项目部署、接口调用示例、配置说明等内容，方便开发人员快速上手使用。4. 提供一个使用 SpringBoot 或Python Django版后端与 TinyPro 前端结合的示例项目，展示从项目启动到页面展示、数据交互的完整流程，涵盖常见的后台管理功能，如用户登录、菜单显示、数据列表查询等，方便用户直观了解和学习。5. 提供清晰的项目部署方案，包括在常见服务器环境（如 Linux 系统）下的部署步骤、所需依赖环境的安装配置方法、容器化部署（如 Docker）的支持等，方便用户将项目部署到生产环境，实现快速上线和稳定运行。6. 确保代码符合项目规范，有完整的TypeScript类型声明，UI美观体验良好。7. 补充相应的文档和自动化测试用例。8. 建议输出 Java SpringBoot 或 Python Django 版本后端的介绍文章和视频
Tab Completion for Mogan STEM,Advanced,"[[""web"",""Qt""]]","For now, tabbed alternatives are displayed in the status bar of Mogan STEM.In this project, one need to help add new tab completion for various different senarios and implement the tab completion widget.","1. implement the tab completion widget2. support tab completion for hybrid command (activated by press \)3. support tab completion visually for tab cycling (for example, d tab will produce δ, d d tab will produce \mathd, but it is not visually available)4. support tab completion in math mode (it means tab completion widget should support displaying math formula)"
Apache ShenYu服务状态可视化管理,进阶,"[[""web"",""npm""],[""web"",""React""],[""web"",""RESTful API""],[""web"",""Spring Boot""]]",1.项目背景目前Apache ShenYu Admin同时管理Client上报服务与Apache ShenYu网关，但目前ShenYu Admin对这一系列服务的管理较为缺失，特别是可视化管理方面。2.当前状态目前服务状态可视化方面，ShenYu已提交部分关于网关的PR，但下游服务的管理目前较为缺失，且需要完备的前端可视化管理界面来保证服务管理的可用性3.最终目标实现Apache ShenYu Admin对于下游服务的可视化管理，包括但不限于服务下线、服务上线、服务监控等,1. 以图文方式设计服务状态管理细节并以文档形式呈现2. 设计服务状态管理的前端页面，并针对已有方案进行优化3. 在shenyu主仓库提交PR用来管理下游服务状态等信息
基于 LLM 的开源软件评估指标、模型生成及评估报告生成,进阶/Advanced,"[[""datas"",""LLM""]]","在开源软件生态蓬勃发展的当下，精准且全面地评估开源软件的质量、影响力以及可持续性变得至关重要。随着大语言模型（LLM）技术的迅猛进步，其强大的自然语言处理能力、知识理解与生成能力为开源软件评估带来了新的契机与方法。本课题旨在探索如何借助 LLM 构建更为完善的开源软件评估体系，涵盖评估指标的确定、评估模型的生成以及高质量评估报告的自动生成，以助力开发者、企业及开源社区更深入地理解开源软件的价值与生态健康状况。通过引入 prompt engineering 和多种具备特定功能的 agents，尤其是让各 agent 基于思维链（Chain of Thought, CoT）模式相互协作，进一步提升 LLM 在本项目各个关键环节的应用效能与智能交互水平。整体方案设计中的 Agent 构建​（一）任务规划 Agent​功能：综合项目目标、资源和时间，用 CoT 模式制定任务执行计划，拆解项目为子任务并分配资源。​协作：与各 Agent 沟通，下达任务要求，收集反馈，动态调整计划。​（二）数据获取 Agent​功能：从 Compass API 获取数据，用 LLM 和 prompt engineering 构造 API 调用提示，智能体间依 CoT 模式协同，确保数据采集高效完整。​协作：接收任务规划 Agent 指令，遇问题尝试自解或请求协调，整理数据后传递给后续环节的 Agent。​（三）模型设计 Agent​功能：依据评估指标，借助 prompt engineering 引导 LLM 生成模型架构建议，分析架构优劣，反馈实际限制辅助 LLM 调整策略。​协作：从任务规划和数据获取 Agent 处获取信息，与 LLM 协作设计架构，与指标计算 Agent 沟通确保模型输出适配。​（四）指标计算 Agent​功能：用 Compass API 数据统计指标相关性，反馈 LLM 优化评估指标，指标优化智能体和数据分析智能体依 CoT 模式配合验证指标。​协作：接收任务和数据，与模型设计 Agent 协作，将计算结果给报告生成 Agent，反馈相关性结果给 LLM。​（五）报告生成 Agent​功能：将评估结果输入 LLM 生成报告文本，引入审核智能体依 CoT 模式检查报告，用可视化库生成图表并让 LLM 嵌入描述。​协作：从多 Agent 获取信息，与 LLM 和可视化智能体协作生成报告，依据反馈优化流程。​（六）报告解读 Agent​功能：依任务规划 Agent 设定，用自然语言处理技术和 LLM 解读报告，满足不同用户需求，提取关键信息呈现给用户。​协作：接收报告，有疑问时与多 Agent 沟通，收集用户反馈促进报告质量提升，反馈问题给任务规划 Agent 优化流程。",1. 评估指标体系：构建经 LLM 优化的指标体系，明确指标定义、计算方法和权重，体现各智能体基于 CoT 模式对指标确定和优化的作用。2. 评估模型：开发高效准确的评估模型，基于 Compass API 数据训练验证，说明智能体协作提升模型性能的过程和效果。3. 自动化报告系统：实现 Web 自动化报告生成系统，用户输入信息即可生成报告，阐述智能体在报告生成和交互方面的应用成果。4. 技术文档与案例报告：撰写技术文档，分析典型案例，展示方法工具的应用效果，量化智能体协作带来的效益提升。
OpenHarmony 系统实现语音唤起功能,进阶,"[[""os"",""RISC-V""],[""datas"",""AI""],[""os"",""Linux""]]",实现一个语音唤起程序，在操作系统挂起时监听到特定语音内容（如：“你好，如意”）后唤起 OpenHarmony 操作系统。常规系统唤醒的方法一般是电源按键或者触摸屏，现希望新增基于轻量级 AI 模型的的唤醒方式。操作者可以通过特定语音或者手势唤醒操作系统（例如亮屏或者解锁）。同时该方案需要保证本地化和轻量化，在不连接互联网的情况下可以正常使用且系统负担较小。,1. 代码、可执行文件、技术文档。2. 语音识别模型能力达到可实用水平，能够响应不同音色的对应内容，并有效避免杂音导致的误响应。3. 程序具备全量离线部署（非联网状态下可用）、低资源占用、低功耗，高实时性的特征。4. 交付一个整体解决方案，可以是系统服务、应用及其组合。
跨平台 WebAuthn 密钥管理器,进阶,"[[""web"",""Flutter""]]",随着无密码认证（passwordless authentication）技术的发展，WebAuthn 标准逐渐成为主流身份认证方式。开源项目 https://github.com/nfcim/fido2 提供了基础的 FIDO2/WebAuthn 协议支持，但目前该项目仅支持数据解析与简单密钥管理，而缺少下列功能：本项目目标为完善 nfcim/fido2 项目，补充 FIDO2 注册和验证流程，并进一步开发一个支持 Android、iOS、Windows、macOS 和 Linux 的跨平台 WebAuthn 密钥管理程序。通过该管理器，用户可以直观地：,"1. 基于 nfcim/fido2 仓库，补充注册和验证流程的完整功能；
1.1. 进行合理的 API 设计和模块划分；
1.2. 基于测试驱动开发，要求高代码覆盖率；
2. 使用 Flutter 框架开发一个跨平台 WebAuthn 密钥管理器；
2.1. 管理器支持列出、注册、验证、删除 WebAuthn 密钥；2.2 部分性能关键组件，或复杂密码学运算，可能需要使用其他语言（如 Rust）；
3. 撰写完整的用户文档和开发文档；
4. 贡献代码回 PR 到原 fido2 项目或自建分支，维护清晰的提交记录。"
openeuler/epkg-factory epkg一键开发环境搭建,进阶,"[[""cloudnative"",""Cloud Native""],[""os"",""x86""]]",相关背景EPKG软件包是openEuler社区正在研发的新型软件包，具有自包含、支持多版本等特点，epkg-factory是为epkg生产而定制的加包工程，以支持rpm、deb等上游生态包转换到openEuler系统上能够安装使用。已有工作目前已经转换了一部分openEuler和ubuntu24.04 的一部分repo源，但存在不足，当前转换过程自动化程度不高，需要人为介入，未分析EPKG软件包的元数据进行依赖关系进行转换和测试；当前EPKG包管理器开发者功能验证时，需要加包工程的配合，急需本地可以自验证的EPKG开发环境，提高EPKG包管理器的开发效率。,1. epkg 软件包反向依赖和正向依赖分析工具2. epkg包管理器开发环境一键安装工具3. 设计并实现完整的测试验证方案4. 提供规范的用户手册和开发者文档
实现Automotive Grade Linux在openEuler Embedded上的初步适配,进阶,"[[""datas"",""Embedded Database""],[""os"",""Linux""]]",（1）项目背景：智能驾驶以及更进一步的具身智能是当前最火热的应用的前沿，无论智能驾驶也好具身智能也好都需要强大的基础软件平台支撑，当前国内面向智能驾驶的开放基础软件平台目前比较少，我们计划基于openEuler Embedded构建面向软件定义汽车的开放基础软件平台，本项目是该计划中的一部分（2）已有工作：（3）存在的不足:（4）希望改进的点：a. 完善智能驾驶所需的基础组件，例如vsomeipb. 在a的基础之上，实现AGL在openEuler Embedded上的适配（5）最终项目实现的目标：基于openEuler Embedded构建面向智能汽车的基础软件平台,1. 在openeuler embedded上实现如下中间件的集成，支持qemu arm64和一个硬件平台，实现2个节点以上的通信2. 完成前述工作后，实现AGL基础功能在openEuler Embedded上的适配，能运行一个仪表盘应用3. 全部工作大概产生10+个pr，20+commit
为深度学习库测试生成工具完善RISC-V支持,进阶,"[[""os"",""RISC-V""],[""datas"",""AI""],[""datas"",""Deep Learning""]]",在RISC-V架构的迁移适配工作中，为了对迁移到RISC-V架构之上的深度学习库代码质量进行评估，希望将深度学习库代码的测试生成工具GenPyte移植到RISC-V架构上。然而，GenPyte当前版本在RISC-V架构上执行效率较低，并导致GenPyte在RISC-V架构上进行测试时测试覆盖率较低。本项目通过分析GenPyte现有的难点和痛点，提高GenPyte在RISC-V架构上的测试效率，从而完善GenPyte对RISC-V架构的支持。一方面，需进一步实现并完善GenPyte对深度学习库API的输入空间自动构建，基于项目中已有的测试用例，分析每个参数的类型和合法空间，并自动构建输入空间。另一方面，针对深度学习库代码在RISC-V架构下的测试效率问题，对测试过程中的问题进行优化，提高测试效率，达到更高的测试覆盖率。通过本项目的实施，预期将提高RISC-V架构下的深度学习库测试用例生成效率和有效性，为进一步丰富完善RISC-V软件生态提供有效支撑。,1. 实现GenPyte在RISC-V架构下对深度学习库的自动化输入空间构建，并对不少于两个深度学习库实现适配，输入空间应包含API的完整参数列表以及每个参数的类型信息和合法输入值的集合2. 提高GenPyte原型工具自动测试生成效率，对不少于两个深度学习库实现自动化测试用例生成，在被测项目中的代码覆盖率应不低于60%
基于RPM打包的Audacity音频编辑器移植与优化,基础/Basic,"[[""os"",""Linux""]]","Audacity作为全球领先的开源跨平台音频编辑工具，目前在openEuler发行版中尚未提供官方支持的标准化软件包。本项目将系统性解决Audacity在欧拉生态中的集成挑战，重构符合Linux Standard Base规范的SPEC打包脚本，并针对欧拉内核特性优化实时音频处理性能。通过建立自动化构建流程和兼容性测试矩阵，确保软件包在aarch64/x86_64架构下的稳定交付,最终目标是为openEuler社区提交可直接通过DNF/YUM部署的生产级Audacity软件包，填补欧拉生态在专业音频编辑领域的工具链空白。",1. 完成Audacity.spec标准化RPM打包文件2. 提交完整代码及文档：包括基于社区提交仓库、测试报告等
基于RISC-V架构的Ssctr内核虚拟化支持,进阶,"[[""os"",""Linux""],[""os"",""RISC-V""],[""os"",""CentOS""],[""os"",""QEMU""]]",本项目旨在为RISC-V架构添加并完善控制传输记录（Control Transfer Records）扩展的虚拟化支持。CTR扩展类似于x86中的架构长分支记录（Arch LBR）和ARM中的分支记录缓冲区扩展（BRBE）。该扩展目前处于稳定状态，但尚未冻结，最新版本可在此处找到[0]。CTR扩展提供了一种在寄存器可访问的内部核心存储中记录有限分支历史的方法。CTR允许使用过滤位掩码选择性地记录分支。在计数器溢出时，CTR停止记录，内核在溢出处理程序中采样记录的分支。CTR还支持RASEMU模式。在RASEMU模式下，每次函数调用时都会记录一次调用，每次返回时都会从缓冲区中移除一个条目。CTR扩展依赖于其他几个扩展：1）S[m|s]csrind：间接CSR扩展，它定义了额外的（[M|S|VS]IREG2-[M|S|VS]IREG6）寄存器，以解决RISC-V CSR地址空间的大小限制问题。CTR通过sscsrind扩展访问ctrsource、ctrtarget和ctrdata CSR。2）Smstateen：mstateen位[54]控制S模式对CTR扩展的访问。3）Sscofpmf：计数器溢出和特权模式过滤。以下是设置并在Linux上运行基本perf演示以使用CTR扩展的指导文档。[0]: https://github.com/riscv/riscv-control-transfer-records/release[1]: https://github.com/riscv/riscv-indirect-csr-access[2]: https://github.com/riscvarchive/riscv-count-overflow/tree/main[3]:https://github.com/rajnesh-kanwal/linux/wiki/Running-CTR-basic-demo-on-QEMU-RISC%E2%80%90V-Virt-machine,1、调研分析Ssctr硬件特性、内核裸机支持情况以及riscv-pmu虚拟化框架，输出分析文档2、为RISC-V Ssctr扩展添加虚拟化支持3、为kvm-riscv/selftests添加Ssctr功能测试
基于KubeEdge-Ianvs的政务智能体基准测试,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""cloudnative"",""Kubernetes""]]",随着云边协同大模型技术的快速发展，其在政务场景中的应用潜力日益凸显。政务服务的智能化升级涉及政府内部协同、公众服务及企业服务三大核心场景，亟需通过大模型技术提升效率与服务质量。然而，政务场景具有高度的专业性、规范性和安全性要求，现有的大模型评测体系缺乏针对政务垂直领域的标准化评估方法，导致技术落地面临准确性、合规性及场景适配性等挑战。因此，本项目旨在基于KubeEdge-Ianvs分布式协同框架，构建面向政务场景的智能体评测Pipeline与Benchmark，为政务智能化提供可量化、可复用的能力评估工具，推动大模型技术在政务服务、政府办公、城市治理等典型场景中的安全高效应用。,1. 引入政务领域数据集，按三大类标准化任务分类并重新整理现有数据集：政务服务（政府办事、热线坐席、营商惠企等）、政府办公（政务知识问答、公文信息提取、公文生成等）、城市治理（城市数据分析、事件感知、事件分拨、事件分析等）2. 在KubeEdge-Ianvs中选择至少一种上述场景提供标准化测试套件，包括数据集、测试环境、测试指标，以标准化统一数据格式梳理数据集3. 在KubeEdge-Ianvs中基于标准化测试套件实现政务智能体基线算法
vkernel RISC-V支持,进阶,"[[""os"",""RISC-V""]]",目前openEuler 2503引入vkernel概念作为2503特性增强容器隔离能力，同时针对其功能、性能和兼容性进行LTP、UnixBench、容器运行时对比、容器生态兼容、相关应用性能共计5项测试，未发现问题，整体质量良好。但是目前该特性并没有riscv64的支持，希望能够基于当前的工作，添加riscv64支持，同时通过其对应功能的LTP、UnixBench、容器运行时对比、容器生态兼容、相关应用性能共计5项测试。,1. 基于当前的工作，添加Vkernel的riscv64支持，同时通过其对应功能的LTP、UnixBench、容器运行时对比、容器生态兼容、相关应用性能共计5项测试，并将最终代码提交到 openEuler/kernel 仓库中。
并行面向多 SDK 版本的 RISC-V 架构 Java 软件包构建方案设计与验证,进阶,"[[""os"",""RISC-V""]]",在保持依赖兼容性的基础上设计一套可行方案，在 Java 相关软件包构建时面向各个选定的 JDK 版本构建多份，以满足 RISC-V 等多样性算力的独特需求,1. 在保持依赖兼容性的基础上设计一套方案，在 Java 相关软件包构建时面向各个选定的 JDK 版本构建多份，在 RISC-V 架构构建基础设施上验证可行
为opentelemetry-go-auto-instrumentation提供ollama框架的大模型可观测能力,进阶,"[[""os"",""Perf""]]",在https://github.com/alibaba/opentelemetry-go-auto-instrumentation项目中，通过插件的方式提供对https://github.com/ollama/ollama 框架的大模型可观测能力，并支持OpenTelemetry GenAI的规范。,1. 在https://github.com/alibaba/opentelemetry-go-auto-instrumentation项目中，通过插件的方式提供对https://github.com/ollama/ollama 框架的大模型可观测能力，并支持OpenTelemetry GenAI的规范。相关代码合入主干分支。
DragonOS 桥接网络支持,进阶,"[[""os"",""Linux""],[""cloudnative"",""Kubernetes""],[""os"",""x86""],[""safe"",""TCP/IP""]]",随着云原生与边缘设备本地化部署的需求增长，单机虚拟网络能力成为支撑容器、轻量级虚拟机等隔离环境的核心基础。作为 Rust 自研的操作系统内核，DragonOS 需补齐网络虚拟化能力，以支持单机内多容器/虚拟机的网络隔离与互通，实现与 Linux 内核类似的本地虚拟网络的功能（Bridge、veth、Network Namespace）。当前 DragonOS 已具备基础的传输层协议（TCP/UDP）和Netlink 的部分支持，但还缺乏 route 子系统、Net Namespace 、NAT 等特性的支持。本项目旨在为 DragonOS 实现完整的单机虚拟网络支持，重点解决容器/虚拟机在同一主机内的网络隔离、互通与动态管理问题。,1. 虚拟网络设备驱动开发2. 网络隔离与命名空间支持3. 协助补充 NAT 功能（SNAT/DNAT）4. 协助路由子系统功能完善5. 测试与验证6. 技术文档
Integrating a software framefork for machine learning in Embox RTOS,Advanced,"[[""datas"",""TensorFlow""],[""dev"",""Git""],[""os"",""GCC""],[""os"",""GDB""],[""os"",""GNU""],[""os"",""Linux""],[""os"",""QEMU""]]","The project goals on integrating Neural Network (NN) inference engine like TensorFlow (Tensorflow Lite Micro) in Embox RTOS.This allows to use Embox for embedded Machine Lernign (ML) more efferctively.For testing you can use standard model examples like: micro speech,or.Also it will be better if the results run  on a embedded platform for example on RISC-V arch or STM32 platform",1. Port TensorFlow on Embox RTOS2. Check the TensorFlow on Embox with some standard model examples3. Port on RISC-V arch or some other embedded platforms4.  Check the TensorFlow on the embedded platform
基于SpinalHDL的DDR3 PHY设计及其在Xilinx UltraScale FPGA上的实现,进阶/Advanced,"[[""chip"",""Chip Design/Verification""]]",SpinalHDL是一种基于Scala的硬件描述语言，其包含丰富的硬件逻辑库以加速高性能数字电路设计。然而，当前SpinalHDL的DDR控制器库在支持特定FPGA硬件架构（如Xilinx UltraScale系列）与内存模块（DDR3 SDRAM）的深度适配时存在不足，同时缺乏对内存接口训练流程的完整控制机制。本课题将围绕以下目标展开：1. 设计可综合的DDR3 PHY物理层模块，遵循Xilinx UltraScale系列FPGA的硬件约束；2. 实现DDR训练功能（如DLL校准、时序补偿），在PHY中支持DFI训练接口，并改造现有的DDR控制器支持训练功能；3. 建立完整的验证框架，确保在FPGA硬件与仿真环境中的一致性表现。,1. 实现支持Xilinx UltraScale FPGA的DDR3 PHY模块。2. 实现PHY模块中的训练功能支持（基于DFI接口）。3. 修改DDR3 DFI控制器逻辑支持训练功能。4. 搭建环境验证DDR3访问完整流程。5. 功能均能通过DDR3 SDRAM仿真模型测试
为“香山”高性能处理器软件仿真环境实现UART串口和ELF加载的增强,基础/Basic,"[[""chip"",""Chip Design/Verification""]]",在开发“香山”开源处理器的过程中，我们主要依靠 Difftest 软件仿真框架进行功能调试，同时使用 NEMU 指令集模拟器作为参考实现。我们注意到 Difftest 和 NEMU 在一些特性上存在缺失，与开发环境中的其他组件不能对齐，带来了一些麻烦：本项目旨在解决上述问题。本项目要求在已有的“香山”仿真环境、NEMU 上实现（完善）UART 16550 串口外设，并通过伪终端等方式支持输入功能；要求在 NEMU 上支持 ELF 工作负载加载功能，功能逻辑与“香山”软件仿真框架保持一致。,1. 在“香山”软件仿真平台上实现 UART 16550 串口的模拟；2. 整理改进 NEMU 上 UART 16550 串口外设的遗存代码，确保其工作正常；3. 在“香山”软件仿真平台和 NEMU 上，基于 Linux 伪终端机制，实现串口输入和输出4. 将“香山”软件仿真平台上的 ELF 加载功能移植到 NEMU5. 为新功能补充文档
Triton-CPU tile操作生成AArch64 SVE/SME,进阶,"[[""os"",""Compiler""],[""datas"",""HPC""]]",在现代高性能计算（HPC）和机器学习（ML）应用中，矩阵运算（如加、减、乘、转置等）是核心操作。目前在Triton-CPU中，已经基于ARM NEON和X86 AVX512实现了固定长度向量的矩阵操作。而SVE/SME指令集支持可变长度向量，能够大幅提升数据并行吞吐，如果能够基于SVE/SME实现矩阵操作，可以优化运算逻辑并显著提升计算性能。因此本选题目标是基于SVE/SME指令集，在Triton-CPU中实现高效的tile加、减、乘、转置操作。,1. 在Triton-CPU上完成tile加、减、乘、转置的SVE/SME实现
Arch Linux for Loong64 软件包构建信息管理平台,进阶/Advanced,"[[""os"",""Linux""],[""os"",""GNU""]]",本项目旨在为（Arch Linux 龙架构移植版）一个更加强大的，通过集成监控、通知与（半）自动化控制，优化软件包构建流程的管理效率。平台将整合打包任务的关键信息，提供智能化的失败任务分类与处理、动态黑名单管理，并实现多编译机调度与构建后检查。通过透明化的问题追踪和自动化操作，降低维护复杂性，助力团队高效跟进 Arch Linux 官方更新，推动龙架构生态的可持续发展。本社区，但是可维护性与集成度较低。项目申请者可以现有代码进行开发，也可以进行重构。本平台将显著降低 LoongArch64 架构下软件包维护的复杂性，助力团队实现及时跟进 Arch Linux 官方更新，并为未来推动 Arch Linux Ports 支持龙架构奠定技术基础。同时，本平台也将通过透明化的问题追踪与自动化流程，吸引更多开发者参与社区贡献，培养开源生态人才。,0. 可整合复用现有代码，或自行重新实现，在这一综合平台中集成以下功能：1. 构建任务管理与呈现2. 构建失败任务智能分类与自动化处理3. 打包黑名单动态维护与展示4. 任务完成后的自动化检查与仓库管理5. 多编译机调度与状态监控6. 鉴权机制（可选）
Kmesh website自动化能力建设和文档优化,基础,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Kubernetes""]]",Kmesh website在完成重构之后，新增了归档旧文档的功能。且kmeshctl文档会随着kmesh主库对kmeshctl组件的修改而修改。因此希望能够添加两个自动化工具：1、自动同步主库的kmeshctl描述文档到website库中。2、能够在版本发布的时候，通过打tag的方式，触发自动化工具，进行旧文档的收编，与文档中关于版本号的修改，实现新文档的发布初次之外，也希望能够进行中文文档的优化工作。英文文档有github action进行看护，但中文文档欠缺这方面的github action。如果能够开发一个github action进行错别字检查和语法检查最好，如果不能的话，也希望对中文文档进行检查。,1. kmeshctl自动同步工具2. 文档自动归档与发布工具3. 附加：中文文档的检查与看护工具的开发
Volcano 子项目 CI/CD 流程、Helm 发布与自动化测试体系建设,基础/Basic,"[[""dev"",""CD""],[""dev"",""CI""],[""dev"",""DevOps""],[""cloudnative"",""Kubernetes""],[""os"",""Linux""]]",随着 Volcano 社区的不断发展，涌现出越来越多的新子项目，例如 descheduler、volcano-global、dashboard 等。然而，这些新创建的子项目目前普遍缺乏完善的 CI/CD（持续集成/持续交付）流水线 workflow、自动化 Helm 发布包构建流程以及充分的自动化测试覆盖（包括单元测试 UT 和端到端测试 E2E）。基础设施的缺失会影响项目的开发效率、代码质量、发布流程的标准化以及最终产品的稳定性。本项目旨在为 Volcano 社区中尚未具备完整 CI/CD、Helm 发布和自动化测试体系的新子项目进行全面的基础设施建设。目标是建立一套标准化的流程和工具链，使得新子项目能够快速地实现自动化构建、测试、打包和发布，并具备足够的自动化测试覆盖以保障代码质量。,1. CI/CD 流水线： 为每个目标子项目（例如 descheduler、volcano-global、dashboard 等）设计并实现一套完整的 CI/CD 流水线 workflow，通常包括代码提交触发、每日构建、代码质量检查、单元测试执行、集成测试执行、镜像构建与推送等环节。2. 自动化 Helm 发布包： 为每个目标子项目创建和维护 Helm Chart，并实现自动化构建 Helm 发布包的流程。3. 自动化单元测试覆盖： 为每个目标子项目引入或完善单元测试框架，并提供足够的单元测试用例。4. 自动化端到端测试覆盖： 为每个目标子项目搭建或完善端到端测试环境，并提供相应的 E2E 测试用例。5. 流程文档： 编写清晰的文档，描述每个子项目的 CI/CD 流水线、测试策略、Helm 发布流程以及如何进行维护和扩展。6. 可复用模板与最佳实践： 总结出一套可复用的 CI/CD 流水线模板、测试框架集成方案和 Helm Chart 最佳实践。
OI Wiki Markdown 转换 LaTeX 导出印刷用途 PDF 项目,进阶,"[[""datas"",""AI""],[""datas"",""Machine Learning""],[""datas"",""Data Science""],[""dev"",""CI""],[""dev"",""CD""],[""dev"",""Git""],[""dev"",""MLOps""]]",纸质版的 OI Wiki 对于一些没有互联网访问的使用情况（例如赛时参考和不在机房的 OI 选手）有着重要的价值。本项目旨在，基于现有的 markdown 转 LaTeX 的 PDF 导出实现，针对印刷用途（如图片、链接等富文本特性）进行一些针对性的优化来提升 accessibility，同时减少页数和方便索引。在此之上，针对灰度打印做进一步优化，从而在保持更强可用性的同时降低打印成本。,1. 针对印刷用途进行特定优化，从而减少页面数量，可参考 https://github.com/OI-wiki/OI-Wiki-export/issues/93 列出的内容改进 clang-format 规则、图片尺寸计算和避免不必要的行距。2. 使得导出内容更加定制化，满足使用者不同阶段的需求。可参考 https://github.com/OI-wiki/OI-Wiki-export/issues/24 的讨论计算内链闭包从而使得导出的页面范围选择更为灵活，以及只导出 C++/Python 语言的代码块。3. 改进当前的内链和外链索引和标记方式以方便更便捷和快速的索引，例如加入内链文本对应的页码等。4. 针对灰度印刷进行优化，参考 https://github.com/OI-wiki/OI-wiki/issues/4346 中的讨论以及往届的灰度化算法，在灰度化图片时用从正文中提取的颜色文字以及对应的色标作为图例附于图片附近，从而使灰度化算法更加实用1. 针对印刷用途进行特定优化，从而减少页面数量，可参考 https://github.com/OI-wiki/OI-Wiki-export/issues/93 列出的内容改进 clang-format 规则、图片尺寸计算和避免不必要的行距。
为 MQTTX 实现高级视图器功能,基础/Basic,"[[""web"",""Vue.js""],[""web"",""UX""],[""web"",""npm""],[""web"",""Electron""],[""datas"",""AI""],[""web"",""Desktop Application""],[""web"",""Sass""],[""web"",""UI""],[""web"",""Webpack""],[""web"",""Yarn""]]",,1. 开发可拖拽、可配置的仪表盘视图画布界面。2. 为仪表盘视图集成核心图表可视化功能 (至少含折线图、仪表盘、大数字)。3. 提供仪表盘组件的数据源（Topic）绑定与可视化配置能力。4. 实现仪表盘配置的导入与导出功能。5. 开发支持交互式浏览的 JSON Payload 树状视图。6. 开发用于对比消息 Payload 差异的并排视图。7. 为新视图添加必要的时间范围选择功能。8. 编写新视图模块的功能说明和基本使用文档，(可选，但推荐) 为关键功能模块编写单元测试或集成测试。
Performance trace optimization in the multimedia framework,Advanced,"[[""os"",""Perf""],[""datas"",""AI""]]","BabitMF(https://github.com/BabitMF/bmf) is a multimedia framework which is widely used in media processing and AI related scenarios, there is a previous trace machenism for performance measurement already exists, but it will impact the latency (~10% more time cost occured) of whole pipeline once BMF_TRACE is enabled. This is a problem that needs to be solved urgently.","1. To root cause of the latency impacted by TRACE2. To optimize the trace machenism to be lightweight, make the time cost bring by trace under 3%"
为 OpenDigger 实现完整的 MCP 服务,基础/Basic,"[[""datas"",""Data Science""]]","- 👥: [@birdflyi](https://github.com/birdflyi)- 💪: [DeepSeek](https://deepseek.com/), [TypeScript](https://www.typescriptlang.org/), [MCP](https://modelcontextprotocol.io/), [Node.js](https://nodejs.org/en/)- ⌛: 250 小时- 📈: 基础- 📎: https://github.com/X-lab2017/open-digger/issues/1698- 💬: OpenDigger 主要为开源项目提供数据指标，而在大模型兴起后，如何使用这些指标文件为用户生成具有洞察力的数据报告一直是 OpenDigger 重要的一个目标。为此 OpenDigger 发布了大量开源项目的数据指标，在大模型出现后利用大模型生成数据报告成为一种新的手段，而 MCP 的出现则为大模型实时调用 OpenDigger 接口获取数据提供了新的可能。- 🎯: OpenDigger 目前已经开发了第一版的 MCP 服务，可在本地部署并访问一些简单的数据指标。本任务希望开发者可以为 OpenDigger 提供完整的 MCP 支持，包括完整的数据指标访问能力，以及支持 SSE 模式，并最终将 MCP 服务发布到各主流 MCP 服务市场和平台中。",1. 完整的 MCP 支持
Adding Standard Device Tree  support for Embox RTOS,Advanced,"[[""os"",""QEMU""],[""os"",""RISC-V""],[""os"",""Linux""],[""os"",""GNU""],[""os"",""GDB""],[""os"",""GCC""],[""os"",""Complier""],[""dev"",""Git""]]","In embedded system development, an operating system needs  to understand the structure and resources of the underlying hardware.  Traditionally, this information is hardcoded in the OS source code,  which leads to poor flexibility and maintainability, as the kernel must  be recompiled each time the hardware or peripheral configuration  changes.Embox is a modular embedded operating system that currently uses an internally defined, statically coded device tree mechanism.This project aims to enhance Embox’s flexibility and  hardware adaptability by introducing support for a standard, external  Device Tree mechanism (DTS/DTB).",1.  Describe hardware using standard DTS files and compile them into DTB using DTC (Device Tree Compiler);2. Provide binding documentation for devices defined in the DTS files;3. Load standalone DTB files at system startup;4. Port or implement new APIs to allow the kernel to parse and access device information.5.  Test on real hardware.
基于 Hugo 的 Volcano 官网重构与功能定制开发,基础/Basic,"[[""web"",""Hugo""],[""cloudnative"",""Kubernetes""]]",Volcano 社区的官方网站 () 是用户了解、使用和参与 Volcano 项目的关键入口。当前网站基于 Hugo 静态站点生成器构建，但在用户界面、用户体验和功能性方面仍有提升空间。本项目旨在对 Volcano 官网进行前端功能的深度开发与用户界面和用户体验的全面升级，重点在于增强文档的搜索和导航能力，优化现有的文档版本管理机制，构建全新的用户展示平台（Adopter Group 页面），并进行整体的用户界面和交互体验优化。此外，本项目还将涵盖对核心组件和功能的文档进行细致的更新和完善，确保文档的准确性和实用性。本课题的目标是增强 Volcano 官网的功能性与用户体验。,"1. 增强文档搜索功能： 研究现有 Volcano 网站的搜索方案，分析其不足，探索并实现更高级的搜索功能（如模糊搜索、关键词高亮、结果排序优化、多语言搜索支持等），提交包含代码修改和配置文件的 Pull Request。2. 优化文档结构和导航： 分析当前 Volcano 网站的文档结构和导航方式的用户体验，基于用户反馈和最佳实践提出改进方案，并修改 Hugo 网站的导航菜单、侧边栏结构及页面链接，提交包含网站结构和模板修改的 Pull Request。3. 优化现有文档版本管理和切换功能： 分析当前功能的用户体验和实现方式，提出至少两项改进方案（例如更清晰的版本展示、更便捷的版本切换、版本差异对比、与代码仓库 Release Tag 同步等），并实现至少一项优化，提交包含代码修改和配置文件的 Pull Request。4. Home 页面新增 Adopter Group 页面并丰富内容： 设计并实现 Volcano 官方网站 Home 页面的 ""Adopter Group"" 页面，收集并展示用户和采用者信息，提交包含新增页面文件、样式修改以及内容管理方案的 Pull Request。5. 贡献核心组件文档： 深入学习 Volcano 的核心组件（Scheduler、Controller、Admission）的功能、配置和使用方式，编写详细且易于理解的文档内容，并按照网站规范进行格式优化，提交符合网站规范的 Markdown 文档。6. 贡献核心功能文档更新与示例： 深入学习 Volcano 的核心功能，更新其文档内容，使其与最新的代码和实践一致，并编写或更新相关代码示例，提交更新后的 Markdown 文档和代码示例。"
为 RobstMQ 实现安全&云原生部署功能,基础/Basic,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Docker""],[""datas"",""Kafka""],[""safe"",""MQTT""]]",本项目需要为 RobustMQ 完善安全、云原生部署两个部分的工作，以及需要完善对应的测试用例：安全部分：指需要完善 RobustMQ MQTT 的安全控制部分，比如认证、鉴权、SSL、JWT、Auth2.0 等。这部分工作是 Rust 内核的开发工作。会涉及到分布式系统的安全控制的知识点。云原生部署：指需要完善 RobustMQ 的云原生部署。比如 Dockerfile 的完善、kubernetes operator的开发等。这块主要是 K8s 和 Docker 相关的知识点。测试用例完善： 需要完善对应的测试用例。这个项目会让你学到：分布式系统的访问控制相关的内容。比如认证、鉴权、SSL、Auth2.0 等等分布式系统 Rust 内核的开发，基于 Rust 的技术栈。K8s 、Docker 相关的知识点学会如何参与开源系统的测试用例编写,1. 完善 RobustMQ MQTT 的安全控制部分2. 完善 RobustMQ 的云原生部署3.  需要完善对应的测试用例
基于高性能RISC-V处理器核“香山”的微架构UT验证——IFUtop模块,进阶,"[[""os"",""RISC-V""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。IFU（Instruction Fetch Unit）即取指单元，负责接收 FTQ 的取指和预取请求并从ICache获取指令码并切分、预译码、扩展等，最终将正确的指令和指令信息以及错误结果写入ibuffer和写回FTQ。本项目需要验证完整的IFU top模块。我们将通过测试完整度（覆盖率等）进行分级，在验证过程中，您将需要按自选的功能点自行划分测试点进行测试，功能点详细描述请参考。本项目是对IFUtop模块的验证，所有的任务都将通过分配。请fork上述之后完成验证代码和文档的编写，成果齐备后，请发起PR以提交。,1. 验证环境+API：验证环境和API是代码成果，是针对待验证对象（DUT）的数据职责（引脚）和行为职责（逻辑）的封装，需要提供特定的可复用的接口、 测试套件、测试覆盖率等的定义。2. 测试用例：测试用例是代码成果，定义了用于测试的输入组合，以及预期的输出组合。3. 验证报告：验证报告是文字成果，包括对环境、测试点和测试用例的介绍，复现代码所需的环境和指令，以及对测试覆盖率等衡量指标的报告。
基于高性能RISC-V处理器核“香山”的微架构UT验证——FTQ 与分支预测单元交互,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""],[""dev"",""pytest""]]",芯片设计工作中的一大挑战是芯片验证。“万众一芯”项目是为探索开源硬件众包验证可能性、降低芯片验证成本、吸引软件工程师参与到硬件工作而发起的，面向全球的芯片设计开源众包验证项目。本项目基于开源高性能RISC-V处理器核“香山”的最新架构昆明湖，通过参与，您将深入了解到高性能处理器设计，有机会进入贡献排行榜、获得实习Offer、RISC-V中国峰会差旅补贴，为开源芯片的发展贡献力量。FTQ是取指目标队列，在处理器前端设计中承担着重要作用，负责前端分支预测单元BPU和取指令单元IFU之间的交互，以及前端与后端之间交互。本项目涉及了FTQ基本存储结构，和FTQ与分支预测单元BPU交互的内容。,1. 验证环境+API：验证环境和API是代码成果，是针对待验证对象（DUT）的数据职责（引脚）和行为职责（逻辑）的封装，需要提供特定的可复用的接口、 测试套件、测试覆盖率等的定义。2. 测试用例：测试用例是代码成果，定义了用于测试的输入组合，以及预期的输出组合。3. 验证报告：验证报告是文字成果，包括对环境、测试点和测试用例的介绍，复现代码所需的环境和指令，以及对测试覆盖率等衡量指标的报告。
基于 Dragonfly 优化 LLMaz 的镜像与模型分发机制实现,基础/Basic,"[[""datas"",""LLM""],[""dev"",""LLMOps""],[""dev"",""MLOps""],[""cloudnative"",""Kubernetes""],[""cloudnative"",""Cloud Native""]]",（1）相关背景：llmaz 是一个基于 Kubernetes 的轻量推理平台，专注于大语言模型的高效部署与推理（是一个开源的 P2P 文件分发与镜像加速系统，适合云原生环境，可提升模型和镜像的分发效率。llmaz 已集成 Manta 作为轻量级模型缓存系统，但对镜像和模型分发的支持仍需优化。（2）已有的工作：llmaz 支持多种模型提供商（如 HuggingFace）和推理后端（如 vLLM），并通过 Manta 提供模型缓存与分发功能。Manta 利用 P2P 技术实现模型分片缓存和预热，但主要针对模型分发，未覆盖容器镜像加速，且功能仍在重构中。（3）存在的不足：llmaz 当前缺乏对容器镜像的高效分发支持，模型分发依赖 Manta，但 Manta 的功能尚不完善，缺乏对镜像的统一管理和加速能力。Dragonfly 的 P2P 分发能力尚未集成，导致镜像和模型加载速度较慢，影响部署效率。（4）希望改进的点：通过集成 Dragonfly，优化 llmaz 的镜像和模型分发效率，支持统一的 P2P 缓存与加速机制。参考 Manta 的轻量设计，确保 Dragonfly 集成保持低资源占用，同时提升分发速度和稳定性。（5）最终项目实现的目标：基于 Dragonfly 实现 llmaz 的镜像和模型高效分发功能，完善 P2P 缓存与加速支持，参考 Manta 构建轻量通用解决方案，提升部署效率并降低资源成本,"1. 为 llmaz 集成 Dragonfly 实现镜像和模型 P2P 分发功能。
2. 开发轻量级 Dragonfly 配置，支持高效缓存与加速。
3. 为 llmaz 提供统一的镜像和模型分发管理接口。
4. 基于 Dragonfly 优化 llmaz 部署速度并生成性能报告。
5. 编写 Dragonfly 集成说明文档，输出部署测试报告。"
Implement heuristic reducer which can shrink complex queries for Risingwave's differential testing,Advanced,"[[""datas"",""Relational Database""],[""datas"",""Database""]]","RisingWave includes acalled, which randomly generates both stream and batch queries. It seeds base tables with random data and runs the generated queries to detect any panics or unexpected errors—indicating a potential bug.We’ve extended Sqlsmith to supportbetween our batch and stream engines. This involves comparing their outputs for the same queries; any discrepancies suggest a logic bug in one of the engines.A key challenge we face isfailing queries. While we currently shrink at thelevel, the queries themselves are often complex (e.g., multi-way joins with numerous selected columns). To reduce debugging time, we need more advancedcapabilities.As a starting point, we plan to adopt a heuristic-based approach, as outlined in.","1. implement the heuristic reducer as described in [**sqlsmith: SQL reducer**](https://github.com/risingwavelabs/risingwave/issues/7504). 

2. increase test coverage to uncover more bugs—this allows us to evaluate how effective the reducer is at shrinking failing queries. Start by measuring the [current coverage of our Sqlsmith tests](https://github.com/risingwavelabs/risingwave/issues/7825). Then, according to the test coverage report, we can expand our test scope. Some examples are: inc"
在 GreptimeDB 中实现基于查询粒度的资源追踪与配额控制机制,进阶/Advanced,"[[""datas"",""Database""],[""cloudnative"",""Cloud Native""]]",GreptimeDB 当前已支持逻辑租户隔离，但尚未提供针对租户的资源使用监控与限制机制，尤其在查询执行层面。该项目旨在开发一套查询级别的资源追踪系统，用于监控每条查询的 CPU 和内存使用情况，并在其超过预设配额时终止查询执行。在执行阶段，查询会被优化为不同的执行计划，资源使用指标可以附加到这些计划上，从而让 GreptimeDB 实时感知资源消耗。,1. 实现一套查询级别的资源追踪系统，可以追踪查询的资源消耗2. 可以限制单个查询能使用的内存和 CPU 时间，可以提前终止超过限制的查询3. （可选）可实现全局的资源限制，即限制所有查询最多可使用的资源
基于 Apache Iceberg 的 GreptimeDB 备份功能增强,基础/Basic,"[[""datas"",""Database""],[""cloudnative"",""Cloud Native""]]",GreptimeDB 是一款时序数据库，目前使用自研格式进行备份，这在一定程度上限制了其与企业级数据湖平台的兼容性。本项目将开发一套新的备份机制，使得 GreptimeDB 的数据可导出为 Apache Iceberg 格式（一个为大规模分析数据设计的开放表格格式）。该集成将有助于实现与 Apache Spark、ClickHouse 等大数据平台的数据互通与管理能力增强。,1. 项目将支持将 GreptimeDB 中的时序数据导出为符合 Apache Iceberg 规范的表格格式，完整涵盖数据与元数据的映射关系2. 编写测试用例，确保导出的 Iceberg 数据能够被 Apache Spark、ClickHouse 等主流大数据平台正确识别与读取，验证格式的兼容性与数据的一致性。3. 撰写详细的用户文档，说明如何启用 Iceberg 备份功能、导出数据，以及如何在下游平台中加载使用导出的数据，文档需配合配置说明与命令示例，帮助用户快速上手。
GreptimeDB 通用 UDF 执行框架设计与实现,进阶/Advanced,"[[""datas"",""Database""],[""cloudnative"",""Cloud Native""]]",用户自定义函数（UDF）是数据库系统提供可扩展能力的重要机制。本项目旨在为 GreptimeDB 实现一套 UDF 执行框架，涵盖 UDF 的定义、管理与执行。UDF 的后端可基于 Python 或 WASM，增强其生态适配性。该任务需要开发者具备 Rust 编程能力、数据库执行引擎的基本知识、SQL 编程经验以及相关系统知识。,1. GreptimeDB 支持创建、修改、删除以及在 SQL 执行时调用用户提交的 UDF，并为 UDF 执行提供基本的运行时安全与隔离能力2. 完善的设计并完成使用文档的撰写
基于Aliyun Peerpod的Confidential AI,进阶,"[[""datas"",""AI""],[""os"",""x86""],[""os"",""Virtualization""]]",在过往几年间，算力、算法和大数据这三大发展AI技术所需的基础能力已经初步具备，因此如今AI技术正在快速迭代与发展。但与此同时，AI数据安全问题层出不穷。本项目针对模型数据保护，要求同学使用Confidential AI模型数据保护方案，结合兼容K8S生态的PeerPod（CAA）开源项目，实现在阿里云上部署Confidential AI+PeerPod方案。其中，Confidential AI是阿里云推出的用来保护模型推理服务中模型数据安全的解决方案，PeerPod方案是开源社区利用机密计算基础设施保护容器负载的技术方案。本方案要求参与同学在对两大技术方案和架构理解的基础上，实现方案融合。参考：- PeerPod（CAA）：https://github.com/confidential-containers/cloud-api-adaptor- CAI开源方案：https://github.com/inclavare-containers/Confidential-AI,1. 项目文档2. 代码和镜像
Confidential AI软件供应链参考值全周期自动化管理,进阶,"[[""datas"",""AI""],[""dev"",""CI""],[""os"",""Linux""]]",在机密计算（Confidential Computing）与人工智能融合的技术场景中，软件供应链安全面临双重挑战：一方面，传统CI/CD流程缺乏对预编译二进制包可重复构建能力的自动化验证机制，导致构建过程存在潜在安全风险；另一方面，可信执行环境（TEE）内运行的程序与供应链源头数据之间缺乏动态校验链路，无法保障运行时策略执行的可靠性与一致性。为此，本项目聚焦构建从软件开发到部署运行的端到端可信闭环，通过自动化技术实现软件参考值的全生命周期管理。项目核心任务涵盖构建阶段与运行时验证两大环节：在构建阶段，基于GitHub Actions集成自动化流水线，实现预编译二进制包及其密码学参考值（包含哈希指纹、元数据证明）的同步发布，并嵌入可重复构建验证流程，生成完整的构建证据链，确保每次构建结果均可被独立复现与审计；在运行时阶段，基于参考值供给服务（RVPS）向策略托管方（Trustee）提供权威参考值基准，同时扩展参考值采集器（AttestationAgent）实时采集运行时组件哈希值，通过策略托管方（Trustee）实现实测数据与策略库的自动化校验，最终形成从软件构建到策略执行的无缝信任传递链路。项目需实现以下核心功能：1、基于Github Action自动化完成预编译包的参考值生成与可重复构建验证；2、构建阶段与运行时环境的参考值动态同步机制；3、TEE环境内运行时组件哈希值的实时采集；4、基于Trustee策略引擎的自动化合规判定与执行反馈。本方案通过“构建-验证”双闭环架构设计，将软件供应链安全保障延伸至运行时环境，结合工业级技术标准（如in-toto规范）与轻量化工程实现，为机密AI场景提供可落地的全生命周期参考值管理范式。,1. 基于Github Action自动化完成预编译包的参考值生成与可重复构建验证；2. 构建阶段与运行时环境的参考值动态同步机制；3. TEE环境内运行时组件哈希值的实时采集；4. 基于Trustee策略引擎的自动化合规判定与执行反馈。
MCP Server 资源安全扫描功能设计与实现,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""PostgreSQL""],[""cloudnative"",""Docker""],[""dev"",""Git""],[""datas"",""LLM""]]",随着 Anthropic 推出的 MCP（Multi-Call Protocol）逐渐成为 AI Agent 连接外部工具的事实标准，越来越多开发者在 AI 应用中采用 MCP Server 来托管模型可调用的工具服务。MCP 的灵活性为 AI Agent 注入了极大的能力，但其安全问题尚未获得足够重视。目前，MCP 工具描述在实际运行中直接被加载进大模型上下文，而模型自身缺乏判断指令安全性的能力。一旦工具描述中包含恶意指令，模型就可能被引导执行攻击者设计的操作，从而危及 Agent 本身的安全边界。当前主流 MCP 服务和 Agent 平台中，MCP Server 资源的审核机制较为薄弱：,1.实现 MCP Server 资源安全扫描功能2.实现资源变更自动触发扫描机制
Nacos Mcp Router推荐的性能和效果优化,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""]]",## 背景[MCP(Model Content Protocol)](https://modelcontextprotocol.io/introduction)是一个开放协议，它统一规范了应用程序向大语言模型（LLMs）输入上下文的方式。随着社区对MCP协议的认可，越来越多的应用软件和服务提供商都开始提供MCP支持，以方便大语言模型（LLMs）访问并获取数据进行AI领域的应用探索。但大量的MCP提供方也导致了MCP Server的泛滥，例如在`mcp.so`网站中就发布着超过一万以上的MCP服务，用户在实际使用时根本无法完全过滤和筛选；即使用户花费大量时间，过滤出需要的MCP服务后，本地所安装和配置的MCP服务列表工作量依然很大，而且会在与大语言模型（LLMs）回话中占用大量的Token。Nacos 3.0 作为MCP Registry的定位，配合[Nacos Mcp Router](https://github.com/nacos-group/nacos-mcp-router)来解决这个问题：通过将存量API转化为MCP Server及从各类市场导入MCP 服务的方式管理MCP Server，同时在Nacos Mcp Router中利用向量数据库等技术对MCP Server进行筛选和过滤，准确且最小化地传递MCP Server给大语言模型（LLMs），减少用户维护本地MCP Server的麻烦，同时降低Token的使用量。但是Nacos Mcp Router中引入的向量数据库没有对使用方式和性能进行优化，导致向量索引的建立不够合理，消耗巨大的内存（数个G），同时过滤和筛选的效果也不是那么优秀，因此Nacos社区希望在“开源之夏2025”期间，对Nacos Mcp Router中使用向量数据库进行性能优化和用法改善，最终实现在保证过滤和筛选的效果不变或更优的情况下，消耗的内存仅数百M甚至数十M。## 目标对Nacos Mcp Router中使用向量数据库进行性能优化和用法改善，最终实现在保证过滤和筛选的效果不变或更优的情况下，消耗的内存从`数GB`降低至`数百MB`甚至`数十MB`。,1. 在保证过滤和筛选的效果不变的情况下，通过参数调优及用法优化，实现消耗的内存从`数GB`降低至`数百MB`甚至`数十MB`。2. 在降低内存消耗的基础上，通过参数调优及用法优化，实现过滤和筛选的准确率提升。
Starry-next：兼容Linux ABI且基于Rust的组件化monolithic架构操作系统内核,基础/Basic,"[[""os"",""QEMU""],[""os"",""RTOS""],[""os"",""Linux""],[""os"",""RISC-V""]]",随着AI、物联网、AIoT等领域的快速发展，根据某个特定场景，对操作系统进行改造和定制的工作一直是人们关注的热 点。通过分析不同的场景，开发者调整内核的架构设计，选择性的强化或者忽略 某些部分的功能，从而更好地发挥对应场景下的特点。但当前的操作系统内核难以适应这种多样化的需求。组件化monolithic架构操作系统内核Starry-next由清华大学陈渝老师操作系统实验室团队郑友捷同学等主持开发，它使用Rust语言编写，基于多种Arceos内核组件，旨在通过组件化的设计思想，提供一个灵活、可定制且兼容Linux ABI的宏内核，满足不同应用乃至不同场景的需求。项目开源代码可以在Github上（ https://github.com/oscomp/starry-next ）获取。Starry-next作为组件化操作系统，有着灵活的可定制性功能，利用Rust的条件编译机制，完成对Starry-next的不同模块的功能定制，即通过开发者传入的feature信息，将它传递给模块层和元件层的不同模块中，从而实现对整体内核的条件编译，达到灵活定制内核镜像的要求。Starry-Next 整体框架采用了模块化的设计思想，框架主体部分大致可分为src、core和api三个模块，其中src模块主要为应用程序的入口进行封装并对系统调用的分发进行处理；core模块实现了系统的核心功能，包括任务管理、内存管理、文件系统等，并向下依赖基座代码ArceOS中提供的底层支持，各个模块之间通过接口进行交互，保证了系统的可扩展性和可维护性。api模块则封装了系统调用的实现，为用户空间程序提供了与内核交互的接口，在其中又依照系统调用的功能与相互的依赖关系将其划分为任务、内存、文件与网络四个组件，分别处理对应的相关系统调用实现。主要模块的功能罗列如下：• 用户应用加载：负责将用户应用程序加载到用户地址空间，并设置入口点和栈指针。• 系统调用接口：负责注册系统调用处理程序，分发处理用户程序发起的系统调用，如sys_exit、sys_mmap、sys_brk 等。• 内存管理：处理内存相关系统调用，调用core中内存相关处理函数实现用户地址空间的创建、映射、解除映射和权限管理，以及用户堆和栈的分配等。• 任务管理：处理任务相关系统调用，调用core中任务相关处理函数实现用户任务的创建、调度和管理，包括任务的命名空间、时间统计和子任务管理。• 文件系统：处理文件相关系统调用，调用core中文件相关处理函数实现文件的的读取、写入和权限管理，以及文件系统的挂载和卸载等。• 网络模块：处理网络相关系统调用。• 用户程序入口点：负责读取应用程序，调用run_user_app函数运行用户应用程序，并记录每个用户任务的退出码。在架构设计上，Starry-Next 框架注重组件的独立性与解耦和性，使得每个组件可以独立开发、测试和升级，而尽量减少对其他组件正常开发与运行的影响，这种设计方式大大提高了框架的灵活性与可扩展性，也使得开发者能以相对独立的方式对组件化宏内核操作系统进行协同式组件开发。当前Starry-next由几十个相对独立的内核级Crates组成，为面向AI、物联网、AIoT等领域的新一代操作系统的开发提出了新的思路和实现方法。为支持同学们高效地学习Rust编程、组件化操作系统内核等知识，掌握基于Rust开发操作系统内核的能力，我们提供了对应的开源操作系统训练营（ https://opencamp.cn/os2edu/camp/2025spring https://githubc.om/learningos ），帮助大家学习和提升能力。,1. Starry-next Tutorial Book扩展改进完善2. Starry-next基础实验实例扩展改进完善3. Starry-next 在github/gitlab/gitee/gitlink等上CI/CD支持4. 撰写组成Starry-next的内核功能Crates的分析文档5. 改进完善组成Starry-next的内核功能Crates的功能/性能/安全性6. 移植组成Starry-next的内核功能Crates到x86/arm/riscv/loongarch的开发板上7. 改进Starry-next与组件化unkernel ArceOS内核的接口设计与实现8. 改进Starry-next与组件化HAL的接口设计与实现
AxVisor：基于Rust的组件化hypervisor,基础/Basic,"[[""os"",""RTOS""],[""os"",""Linux""],[""os"",""Virtualization""],[""os"",""KVM""]]",随着AI、物联网、AIoT、机器人、智能无人系统等领域的快速发展，根据某个特定场景，对多种操作系统进行改造和定制，并能并发运行的工作一直是人们关注的热点。通过分析不同的场景，开发者调整内核的架构设计，选择性的强化或者忽略 某些部分的功能，从而更好地发挥对应场景下的特点。但当前的操作系统内核难以适应这种多样化的需求，通过虚拟化软件技术，如Hypervisor或VMM等，可在单一硬件平台上支持多种操作系统内核和应用运行，极大提高了相关应用的灵活部署。基于Rust的组件化hypervisor：AxVisor由清华大学陈渝老师操作系统实验室团队胡柯洋同学等主持开发，它使用Rust语言编写，基于多种Arceos内核组件，旨在通过组件化的设计思想，提供一个灵活、可定制的Hypervisor，满足不同应用乃至不同场景的需求。项目开源代码可以在Github上（ https://github.com/arceos-hypervisor/axvisor ）获取。AxVisor作为组件化Hypervisor，有着灵活的可定制性功能，利用Rust的条件编译机制，完成对AxVisor的不同模块的功能定制，即通过开发者传入的feature信息，将它传递给模块层和元件层的不同模块中，从而实现对整体内核的条件编译，达到灵活定制内核镜像的要求。AxVisor在功能需求方面，主要包括处理器虚拟化、内存虚拟化和 I/O 虚拟化等。在性能需求方面，主要包括实时性、精确度、鲁棒性。在安全需求方面，主要包括防故障设计、错误检测与恢复、安全验证、软硬协同隔离等，以支持系统虚拟化软件架构中各个软件模块的安全可靠开发。AxVisor整体框架采用了模块化的设计思想，框架主体部分大致可分为axvm、axcpu、axaddrspace、axdevice等模块。AxVisor通过底层硬件抽象层（axhal）直接与硬件交互，管理虚拟机的生命周期和资源分配。各个模块（如 axvm、axconfig、axalloc 等）协同工作，提供全面的虚拟化支持和管理功能。虚拟机（如 Linux 和 Linux-RT）在AxVisor上运行，为上层应用提供稳定、安全的运行环境。应用程序在虚拟机内运行，通过虚拟机提供的接口和服务访问底层资源。AxVisor确保不同虚拟机和应用之间的隔离与安全，同时支持高效的跨域调用，实现虚拟机之间的协作和资源共享。在架构设计上，AxVisor 框架注重组件的独立性与解耦和性，使得每个组件可以独立开发、测试和升级，而尽量减少对其他组件正常开发与运行的影响，这种设计方式大大提高了框架的灵活性与可扩展性，也使得开发者能以相对独立的方式对组件化宏内核操作系统进行协同式组件开发。当前AxVisor 由几十个相对独立的内核级Crates组成，为面向AI、物联网、AIoT等领域的新一代操作系统的开发提出了新的思路和实现方法。为支持同学们高效地学习Rust编程、组件化操作系统内核等知识，掌握基于Rust开发操作系统内核的能力，我们提供了对应的开源操作系统训练营（ https://opencamp.cn/os2edu/camp/2025spring https://githubc.om/learningos ），帮助大家学习和提升能力。,1. AxVisor Tutorial Book扩展改进完善2. AxVisor基础实验实例扩展改进完善3. AxVisor 在github/gitlab/gitee/gitlink等上CI/CD支持4. 撰写组成AxVisor的内核功能Crates的分析文档5. 改进完善组成AxVisor的内核功能Crates的功能/性能/安全性6. 移植组成AxVisor的内核功能Crates到x86/arm/riscv/loongarch的开发板上7. 改进AxVisor与组件化unikernel ArceOS内核的接口设计与实现8. 改进AxVisor与组件化HAL的接口设计与实现
适配A-Tune到RISC-V架构并对混合式负载进行调优,进阶,"[[""os"",""RISC-V""]]",（1）相关背景A-Tune是一款基于AI开发的系统性能优化引擎，它利用人工智能技术，对业务场景建立精准的系统画像，感知并推理出业务特征，进而做出智能决策，匹配并推荐最佳的系统参数配置组合，使业务处于最佳运行状态。（2）已有的工作A-Tune可以在RISC-V平台安装运行，但是功能不可用。（3）存在的不足A-Tune在RISC-V平台功能无法正常使用，且没有相应调优案例。（4）希望改进的点A-Tune在RISC-V平台正常使用，并针对各种业务场景进行调优。（5）最终项目实现的目标在RISC-V平台编译、构建、安装A-Tune，并针对各种业务场景进行调优，最终实现对混合式负载（例如数据库负载和Web服务负载）进行调优。形成文档。,1. 在RISC-V平台编译、构建、安装A-Tune，针对包括混合式负载在内的各种业务场景进行调优，形成文档。
为 EulerPublisher 引入 Jenkins 作为工作流执行引擎,进阶,"[[""cloudnative"",""Cloud Native""],[""cloudnative"",""Docker""],[""dev"",""Jenkins""],[""dev"",""Git""]]",EulerPublisher 是一个“一站式”自动构建、测试和分发 openEuler 软件制品的工具。它支持以 openEuler 为底座构建多样化基础和应用容器镜像，并根随 openEuler 的发布计划，构建针对主流公有云的云镜像，同时还支持二进制软件包的处理。目前 EulerPublisher 使用 Github Actions 作为工作流执行引擎，极大地提升 openEuler 软件制品构建分发效率。然而，Github Actions 在执行器配置方面存在一定的限制。因此，为了满足复杂软件制品构建工作流对执行器配置的高需求，我们计划为其引入 Jenkins 作为工作流执行引擎。,1. 设计并实现容器镜像构建与分发功能2. 设计并实现云镜像构建与分发功能3. 设计并实现任务调度功能4. 设计并实现完整的压力测试方案5. 提供规范的用户手册和开发者文档
网络数控面统一编程IDE插件,进阶,"[[""codelang"",""Programming Language""]]",网络编程中，数据面与控制面通常采用不同的语言开发，如数据面常用P4等DSL高效地表达转发逻辑，而控制面通常用python、c等通用语言表达复杂的控制逻辑。研究表明38.8%的网络编程bug由控制器的错误配置导致，部分就可以归咎于数据面、控制面开发语言不一致。本课题希望基于VSCode，提供数据面、控制面统一的IDE插件，降低错误配置的可能性，提高开发者网络编程效率。,1. IDE插件能够提取P4语言实现的数据面程序的关键可编程组件的信息（Table/Key/Action等），在控制面python程序中进行高亮显示、自动补全、语法检查等功能。
实现状态窗口功能,进阶,"[[""cloudnative"",""Flink""],[""datas"",""Non-relational Database""]]",eKuiper 作为一款轻量级的边缘流式处理引擎，使用类 SQL 语言对数据流进行实时分析。其强大的窗口功能是流处理的核心，目前主要支持基于时间的窗口（如滚动、跳跃、会话窗口）。然而，在很多物联网和实时监控场景中，用户更关心的是根据来聚合或分析连续的事件段，而不是简单地按固定时间或固定数量切分。例如，用户可能需要分析：设备连续处于“高温”状态持续了多久？或者，计算系统处于“正常运行”状态期间的某个指标的平均值？当前的窗口机制难以直接、优雅地表达这类基于“状态持续性”的分析需求。本项目旨在为 eKuiper 引入一种全新的窗口类型——。状态窗口的核心思想是：根据用户定义的，将该表达式结果连续相同的事件划分到同一个窗口中。一旦流入的新事件使得状态表达式的结果发生了变化，当前的状态窗口就会关闭（并可能触发计算），同时开启一个新的状态窗口。例如，用户可以编写类似的查询，引擎会自动将连续为的事件划入一个窗口，将连续为的事件划入另一个窗口，并在状态切换时进行计算。这将极大地增强 eKuiper 处理状态相关流式数据的能力。,1. 核心状态窗口逻辑2. SQL 语法集成3. 测试用例4. 文档和规则示例
Audio Controls Feature for vhost-device-sound,Advanced,"[[""os"",""Virtualization""],[""os"",""Emulation""],[""os"",""Linux""]]","The virtio-sound device emulation has been evolving to provide better virtualization support for audio functionalities.The goal of this project is to extend the capabilities of the virtio-sound device within the[vhost-device-sound]()crate by adding audio control features such as volume adjustment, muting/unmuting, and mode switching.Recent[patches]()have introduced support for audiocontrols in the Linux headers used by QEMU, and the[VirtIO sound 1.3 specification]()has now incorporated these audio controls feature.This project will focus on implementing these new features in the Rust-based vhost-device-sound crate. This new feature enhancement willallow a user of the guest OS to dynamically control audio settings, improving the flexibility and usability of virtualized audio devices.The audio controls support should be implemented following the[VirtIO sound 1.3 specification]().",1. Extended Audio Control Features in vhost-device-sound2. Integration with QEMU3. Automated Testing4. Documentation and Upstreaming
为 Cloudpods ocboot 实现 RISC-V K3s 部署,进阶,"[[""os"",""Linux""],[""os"",""RISC-V""],[""cloudnative"",""Kubernetes""],[""os"",""Ansible""],[""os"",""Virtualization""]]",Ocboot 是一个部署 K3s 和 cloudpods 服务的工具，cloudpods 服务运行在 K3s 容器管理平台之上。目前已经支持在 x86_64 和 arm64 的 OpenEuler 24.03 上部署 K3s ，现在需要在 RISC-V 的机器上部署 K3s。Ocboot 部署工具使用 python3 和 ansible 来实现部署流程，可在框架层面集成 RISC-V 架构操作系统的部署。该项目的难点在于：需要测试 RISC-V 编译的 k3s 组件，可能涉及一些需要自己编译的组件，比如 calico 相关的 cni 插件。,"1. 将 K3s 使用 Cloudpods ocboot 部署工具部署到 OpenEuler 24.03 RISC-V 的机器上
2. 要求能够多节点部署，组成 K3s 集群
3. 支持卸载和重装
4. 代码已 PR 形式提交到 https://github.com/yunionio/ocboot 仓库"
SnailJob-灵活、可靠、高效的分布式任务调度与重试平台,基础,"[[""codelang"",""Programming Language""],[""os"",""x86""],[""os"",""CentOS""],[""cloudnative"",""Docker""],[""web"",""Vue.js""],[""web"",""Spring Boot""],[""web"",""RESTful API""],[""web"",""Nginx""]]",SnailJob 是一个灵活、可靠且高效的分布式任务重试和任务调度平台。其核心采用分区模式实现，具备高度可伸缩性和容错性的分布式系统。拥有完善的权限管理、强大的告警监控功能和友好的界面交互。,1. 支持分布式重试的能力2. 支持分布式任务调度能力3. 支持动态任务编排能力4. 支持高可用、易扩展能力
插件数据存储逻辑优化,进阶,"[[""codelang"",""Programming Language""],[""datas"",""Relational Database""],[""safe"",""HTTP""],[""web"",""UI""]]",目前，AstrBot 插件系统在数据存储方面缺乏一致的架构。部分插件使用 SharedPreference 存储机制和 JSON 格式进行数据持久化。这种多样化的存储方式导致了存储逻辑的不统一，既影响了数据的安全性，也增加了插件间的兼容性问题。此外，缺乏标准化的接口使得插件的数据存储和访问方式各异，给系统的维护和扩展带来挑战。本项目旨在重构当前存储方案，引入更安全且高效的数据存储机制，并设计一个统一的插件数据接口模型，规范插件的数据存储与访问，提升系统的安全性、可扩展性和可维护性，为未来插件的开发与管理提供坚实基础。,"1. 设计并实现统一且高效的插件数据存储接口模型，规范插件的数据存储；
2. 重构当前 SharedPreference 的存储逻辑，采用更安全的存储方式；
3. 补充相关技术文档。"
PIEditor,进阶,"[[""os"",""RISC-V""],[""codelang"",""Programming Language""]]",基于arkts的鸿蒙原生富文本编辑器，采用delta数据模型，丝滑转换md和html格式文档，可通过扩展机制实现自己定义数据格式,"1. 基于PIEditor的插件基类实现工具栏插件
2、基于PIEditor的插件基类实现菜单插件
3、基于PIEditor的数据模型实现指定的数据格式导出插件（比如md、html）
4、根据实现的插件编写使用说明文档"
基于Rust的机器博弈引擎性能优化与RISC-V适配,进阶/Advanced,"[[""datas"",""AI""],[""os"",""RISC-V""]]",：：：：：开发高性能Rust机器博弈引擎，支持五子棋/六子棋双赛项，适配openEuler+RISC-V生态,1. Rust引擎代码合入minzuchess SIG主仓2. 单机性能：搜索速度≥10倍Python版，内存占用≤1/53. 技术文档《Rust在RISC-V环境的优化实践指南》4. 可选：集群加速原型（3节点延迟≤100ms）
openGauss 向量数据库集成Kotaemon,基础,"[[""datas"",""Database""],[""datas"",""AI""]]",实现Kotaemon框架与openGauss的深度集成，构建基于向量数据库的LLM应用模板，输出适配器代码及企业级应用案例。,1. 开发openGauss数据连接插件，支持检索增强型应用构建。2. 制作客户服务知识库等企业案例，输出包含权限控制的实施文档，代码合入社区。
基于外挂 FDT 硬件描述信息的 RISC-V Linux SBC 通用 UEFI 启动方案,进阶,"[[""os"",""RISC-V""],[""os"",""Linux""]]",（1）相关背景为同时支持 openEuler RISC-V 的 ISO 安装镜像在基于 UEFI+ACPI 的 RISC-V 高性能服务器平台，以及当下更普遍的嵌入式板卡、SBC 等设备上运作，需要构建一条基于 UEFI+FDT 的通用启动链路。而目前该 ISO 安装镜像仅能在 QEMU 进行重复验证，对实体硬件平台的支持存在较大缺口。（2）已有的工作- RVCK (RISC-V Common Kernel)计划：通过回合上游 RISC-V 演进补丁，与来自厂商的平台支持代码，在操作系统内核层面确保统一镜像的可行性- U-Boot BootSTD：提供了通用的启动流程实现，支持必要的 EFI Boot-time Service- Grub2：上游已支持 devicetree 命令，启动时加载外挂 fdt，并且也支持了基础的 fdtdump 功能- EDK2：部分厂商提供了基于 EDK2 的 UEFI+FDT 的 demo- 已在多个 SoC 平台上通过 U-Boot UEFI+FDT 手动成功启动至系统（3）存在的不足- 厂商提供的 EDK2 demo 受制于功能实现的差异以及不佳的维护状态，以及下游进行维护的可能性，无法作为主体方案推行- U-Boot UEFI + FDT + Grub2 方案目前无法在启动时动态决策并加载外挂 FDT ，导致易用性不佳（4）希望改进的点- Grub2：实现必要的 fdtdump 功能、必要的 fdt fixup 能力、以及 fdtdir 支持- U-Boot：探索一种合理的方法，传递硬件信息给 Grub2（5）最终项目实现的目标- 在支持 U-Boot BootSTD 的板卡上运行的 openEuler RISC-V 系统中安装改进后的 Grub2，能够无缝切换至 UEFI+FDT 的启动流程- 对 ISO 安装镜像包含的 Grub2 进行升级，使其能够在多个嵌入式板卡上正常工作,1. 完成 Grub2 新增功能的开发、测试；提供个人仓分支并应用上述改动；提供补丁并合入欧拉仓库2. 发起 Grub2 上游提交
Apache Linkis 管理台重构,基础/Basic,"[[""web"",""Vue.js""],[""web"",""npm""],[""web"",""RESTful API""],[""web"",""Webpack""]]",项目背景：Linkis管理台项目存在文件结构不清晰、功能组件维护不合理、交互界面待优化等问题，因此考虑进行重构。本项目主要工作：1.熟悉现有Linkis管理台源码和功能2.根据约定的项目文件结构和代码规范，编写新的Linkis管理台代码3.对负责的组件和页面进行自测，确保无明显问题和重大bug4.完善负责的组件、页面的使用文档和注意事项项目产出要求：代码功能上1.组件和页面能正确完成对应功能2.编写代码符合Eslint规范3.代码逻辑清晰，有合理的注释说明4.正确抽离工具函数和组件，代码有着较高的可靠性、拓展性和复用性5.组件和页面有合理的使用文档和逻辑设计文档项目技术要求：技术栈1.熟悉html、css、javascript、typescript2.vue3，less3.webpack/vite4.了解微前端相关知识,1. 开发工作
为 Apache Kvrocks Operator 支持 Cluster 模式管理功能,进阶/Advanced,"[[""cloudnative"",""Kubernetes""],[""cloudnative"",""Redis""]]",Apache Kvrocks Operator 提供在 Kubernetes 上管理 Kvrocks 实例的  Operator。该组件基于框架构建，当前支持主从模式部署方案。虽然现有版本已实现主从模式部署，但在易用性方面仍有较大提升空间，包括实例的横向扩缩容、集群模式支持等功能扩展。项目核心目标包含：,1. 在主从架构下整合 Redis Sentinel 实现节点动态增删能力2. 实现集群模式节点的自动化创建，并通过 kvrocks-controller 组件实施节点管理
Hippo4j Server 模式轻量化集群部署实现,进阶,"[[""safe"",""Netty""]]",项目背景Hippo4j 是一款基于 Java 开发的轻量级动态线程池管理框架，专注于解决传统线程池配置僵化、监控缺失等痛点，通过对接配置中心（如 Nacos、Apollo 等），Hippo4j 支持线程池参数的实时动态调整，包括核心线程数、最大线程数、队列容量等，无需重启应用即可适配业务流量变化，显著提升系统弹性与稳定性。框架提供多维监控指标（活跃度、拒绝率、任务耗时等），并集成报警通知功能，帮助开发者快速定位资源瓶颈。其兼容性强，无缝支持 Spring Boot、Dubbo、RocketMQ 等主流框架的线程池托管，同时提供开箱即用的控制台，实现线程池配置可视化管理。作为开源项目，Hippo4j 设计简洁、扩展性强，适用于微服务架构下的高并发场景，助力企业构建高效、可控的异步任务处理体系。项目目标：实现 Hippo4j Server 端的多节点集群部署，集群中的 Server 实例应自动互相发现、同步配置，并能容忍部分节点故障而保持服务可用。：设计统一的注册中心适配接口，支持通过配置动态加载注册中心实现模块；提供至少 Nacos 和 ZooKeeper 两种注册发现的适配器。：在无外部注册中心的场景下，提供默认的对等广播（）集群模式，无需额外中间件。节点可通过广播/组播或类似 Gossip 协议的方式发现彼此、同步状态，并进行故障剔除。：保证集群中所有节点的线程池配置保持一致。当某个节点启动或配置变更时，能够向其它节点广播更新。集群节点需具备服务发现、配置同步、健康检测和故障剔除等基本能力。：提供注册中心抽象接口及 Nacos、ZooKeeper、对等广播 三种实现；实现 Server 启动后自动加入集群并同步配置；在默认广播模式下能够实现一个无需第三方组件的可用集群；编写完整的测试用例、部署示例和使用文档。主要挑战：抽象出统一的注册中心接口需要覆盖不同平台的差异，如 Nacos 的命名空间、Zookeeper 的节点目录结构等，确保接口足够通用且易扩展。SPI 加载机制需要妥善处理实现包的引用和生命周期。：Nacos 和 ZooKeeper 在客户端逻辑上有很大不同，实现细节复杂（如会话管理、Watcher 机制、ACL 配置等）。需要深入理解两者的 API 和一致性模型，确保在注册、心跳和数据订阅方面与统一接口保持一致。：集群分布时数据同步顺序复杂，必须解决并发更新和网络分区问题。如在无中心场景下，若多个节点同时调整线程池配置，需要考虑版本控制或冲突合并策略。：分布式集群功能难以模拟，需要设计充足的测试用例来验证节点加入/退出、网络波动、配置同步等场景。性能和稳定性测试也是挑战，需要保证广播或同步机制在多节点（如三至五台）时仍然可用。,1. 完整可运行的 Hippo4j Server 集群方案代码，支持多注册中心集群以及默认无第三方中间件对等广播模式2. 提供 Docker Compose 模板 或 Kubernetes 示例配置，支持一键启动多节点 Server 集群3. 官方文档新增《集群部署指南》章节，详细说明两种部署方式：java -jar 和 Docker4. 提供 CLI 命令行工具或 HTTP API，支持查询当前集群角色状态及节点列表，验证集群有效性。模拟节点宕机，确保客户端请求无中断
Apache ShardingSphere：Proxy Native 支持 RISC-V 架构（进阶）,进阶,"[[""os"",""RISC-V""]]",Apache ShardingSphere 是一款分布式数据库生态系统。目前，ShardingSphere Proxy 已支持编译为 Native Image，以此提升启动速度和降低资源消耗。并且，GraalVM 主要支持 x86 和 ARM 架构，并在 2023 年已支持 RISC-V 架构，详见：https://medium.com/graalvm/graalvm-native-image-meets-risc-v-899be38eddd9。相关技能,"1. Proxy Native 支持在 RISC-V 架构上运行；
2. 增加相应的 E2E 集成测试；"
狮偶编程文字代码支持,进阶/Advanced,"[[""codelang"",""Programming Language""]]",狮偶图形化编程语言，是一款基于的完全自主研发的图形化编程语言，主要面向业务场景。现在需要向技术方向拓展，需要有一套与图形化内容完全匹配的文字版本。文字版本需要可以转成JSON格式的狮偶的抽象语法树，期望可以达到文字和图形版本可以互相等价转换。,1. 在IDE中增加文字代码编辑器2. 编写测试样例3. 高质量的代码实现，具有良好的性能表现
狮偶IDE无障碍开发,进阶/Advanced,"[[""codelang"",""Programming Language""],[""web"",""Vue.js""]]",狮偶图形化编程语言，是一款基于Blockly的完全自主研发的图形化编程语言，主要面向业务场景。为了支持无障碍开发，需要对现在狮偶IDE进行无障碍化改造。要求理解无障碍需求、无障碍软件设计。屏幕阅读器（Screen Reader）是一种辅助技术软件，用于将屏幕上的文本、控件和界面元素转换为语音或盲文输出，帮助视障用户操作计算机和移动设备。在开发环境中（如IDE），屏幕阅读器需要深度适配，以确保开发者能够高效编写、调试和管理代码。,1. 界面元素无障碍​​2.调试与错误处理​​3. 提供无障碍文档​​提供屏幕阅读器专用的IDE使用指南
用于 NVDA 屏幕阅读器的设备端 OCR 引擎,进阶/Advanced,"[[""datas"",""AI""],[""web"",""Desktop Application""],[""datas"",""Computer Vision(CV)""],[""datas"",""Data Science""],[""datas"",""Deep Learning""],[""datas"",""GPT""],[""datas"",""Machine Learning""],[""datas"",""Natural Language Processing (NLP)""]]","背景：NVDA  (NonVisual Desktop Access) 是一款免费、开源的 Microsoft Windows  屏幕阅读器，使盲人和视力障碍者能够使用计算机。它由非营利组织 NV Access  开发，提供了对操作系统和应用程序的关键访问权限。然而，用户经常遇到嵌入在图像中的文本、不可访问的应用程序界面（例如，自定义绘制的控件、以图像形式呈现的扫描文档）或未通过标准辅助功能  API 公开其文本内容的应用程序。这使得此类内容完全无法访问。现有工作：NVDA  在读取标准文本控件以及通过辅助功能 API (UIA, IAccessible2 等) 公开的内容方面表现出色。一些用户使用独立的 OCR  应用程序或基于云的 OCR 服务（有时通过 NVDA 插件集成）来读取不可访问的文本。NVDA 也集成了基本的 Windows OCR  功能；然而，其在某些语言环境下（例如中文）的识别准确率可能较低，并且需要较新的 Windows 版本。当前不足：NVDA  核心中缺乏内置的、准确且易于使用的设备端 OCR  功能。现有解决方案通常需要安装第三方插件，可能依赖于活动的互联网连接（引发隐私担忧、产生潜在成本、引入延迟，并在离线场景下失败），或者依赖前述的准确率较低（尤其对某些语言）的  Windows OCR 集成。因此，许多包含关键文本的图形元素或应用程序窗口仍然无法读取。需要改进之处：本项目旨在将一个高性能、准确的设备端  OCR 引擎直接集成到 NVDA 中。通过利用高效、现代的开源 OCR 模型（例如来自 RapidOCR 或 PaddleOCR  的模型），目标是为用户提供一种快速可靠的方式来识别和读取屏幕上任何位置、聚焦对象或特定窗口内的文本，而无需依赖云服务或不稳定的外部依赖项。一个关键要求是采用模块化架构，允许更新或替换底层的  OCR 模型/引擎。文本识别的准确性和基本布局（阅读顺序）的保留至关重要。最终目标：研究、开发和集成一个设备端  OCR 功能的功能原型到 NVDA 屏幕阅读器中。这包括选择合适的开源 OCR 模型/库，设计高效的处理流程（图像捕获 -> OCR  -> 文本呈现），在 NVDA 架构内实现集成，确保低资源消耗（CPU、RAM），优化响应速度，并使该功能可通过直观的 NVDA  命令访问（例如，识别当前导航器对象中的文本，执行屏幕 OCR）。","1. 研究与模型/库选择报告：一份文档化的分析报告，评估合适的、许可宽松的开源设备端 OCR 库（例如 RapidOCR, PaddleOCR-json 或其他 ONNX 模型），对其在目标硬件配置文件上的性能进行基准测试（在样本 UI 元素/文本图像上的准确性、速度、资源使用、语言支持）。选择一个候选库/模型用于实现。

2. 模块化集成架构设计：一份文档化的设计方案，用于将 OCR 功能集成到 NVDA 中，强调 NVDA 核心与 OCR 推理组件之间的松耦合，以便未来的更新或替换。定义用于触发 OCR 和接收结果的 API。

3. 功能原型实现：集成到 NVDA 分支中的可用代码，演示：能够捕获相关图像数据（例如，从当前导航器对象）。使用选定的 OCR 模型/库进行离线推理。向用户呈现识别出的文本（通过 NVDA 的语音和盲文输出）。

4. 性能优化与测试：提供分析和优化工作的证据，以在定义的基线硬件上满足响应性目标。为实现的 OCR 功能提供针对样本图像/UI 元素的基本测试套件。

5. 最终项目报告与文档：一份详细说明项目工作、发现、所选库/模型、实现细节、面临的挑战、潜在未来工作（例如，语言选择、区域选择改进）以及该功能的基本用户/开发者文档的报告。"
Casdoor单点登录系统管理平面、权限相关功能支持,进阶,"[[""safe"",""OAuth""],[""safe"",""OpenIDConnect""]]","Casdoor是一套基于OAuth 2.0 / OIDC协议的统一身份认证（单点登录）系统。其支持多种第三方登录方式，如QQ、微信、Google, GitHub等。Casdoor具有Web管理界面，可以用来管理用户、角色、权限（基于Casbin）。本项目将关注Casdoor的管理控制平面、多组织和权限相关功能，提高其可扩展性和灵活性，满足不同组织和业务场景的需求。",1. 完善Casdoor的管理控制平面功能，实现灵活的配置管理2. 优化、美化Web界面3. 完善Casdoor中至少2个功能模块、协议模块等4. 解决Casdoor主仓库&相关仓库中的issues：https://github.com/casdoor/casdoor/issues，数量方面，至少解决8个issue
支持RISC-V架构的Casdoor单点登录系统,进阶,"[[""os"",""RISC-V""],[""safe"",""OAuth""],[""safe"",""OpenIDConnect""]]","Casdoor是一套基于OAuth 2.0 / OIDC协议的统一身份认证（单点登录）系统。其支持多种第三方登录方式，如QQ、微信、Google, GitHub等。Casdoor具有Web管理界面，可以用来管理用户、角色、权限（基于Casbin）。本项目将致力于将Casdoor适配到RISC-V架构，优化其在RISC-V下的性能表现，以满足物联网、嵌入式等RISC-V应用场景下的认证鉴权需求。主要目标包括：1. RISC-V架构支持：使Casdoor后端服务可以在RISC-V64架构下编译运行。提供RISC-V64的Docker镜像。2. 跨平台前端适配：优化前端，提高在RISC-V等资源受限平台的运行效率，降低内存占用。3. 管理平台和权限功能增强：完善Casdoor的管理控制平面、多组织和权限相关功能，提高其可扩展性和灵活性，满足不同组织和业务场景的需求。优化美化Web管理界面，实现灵活的配置管理。4. 性能优化与测试：在RISC-V开发板或者QEMU模拟器上，对Casdoor进行性能测试，找出性能瓶颈并优化。通过上述努力，让Casdoor成为一个对RISC-V友好的开源统一身份认证解决方案，更好地服务于RISC-V生态。",1. 实现Casdoor在RISC-V64架构下的运行，并提供二进制包和Docker镜像2. 优化Casdoor前端，提高其在资源受限环境下的性能表现3. 完善Casdoor的管理控制平面功能，实现灵活的配置管理4. 优化、美化Casdoor的Web管理界面5. 在RISC-V开发板或QEMU环境下，对Casdoor进行性能测试6. 解决Casdoor主仓库&相关仓库中的issues：https://github.com/casdoor/casdoor/issues
Casibase的AI知识库功能开发与用户体验优化,进阶,"[[""datas"",""AI""],[""datas"",""Database""]]",Casibase是一套开源的AI云操作系统，适合个人或者组织作为自己的专属内部AI知识库来使用。它基于Casbin的强大权限管理引擎，实现了精细的访问控制策略。用户可以在Casibase上创建、编辑、分享和管理知识库。本项目将关注Casibase的知识组织、AI工具和协作功能的优化，提升用户体验和团队协同效率，使其成为领先的知识库系统。,1. 优化知识库文档的组织结构和分类方式，提高检索效率2. 改进搜索算法和推荐机制，提升搜索结果的准确性和相关性3. 集成更多AI模型接口（至少2个AI模型），丰富知识处理和应用场景4. 优化前端界面，提供更友好、直观的用户交互体验5. 解决Casibase主仓库&相关仓库中的issues（数量至少7个）：https://github.com/casibase/casibase/issues
Casdoor与其他开源软件相关对接支持,基础,"[[""safe"",""OAuth""],[""safe"",""OpenIDConnect""]]","Casdoor是一套基于基于OAuth 2.0 / OIDC协议的统一身份认证（单点登录）系统。其支持多种第三方登录方式，如QQ、微信、Google, GitHub等。目前，有大量的其他开源软件存在着使用 OAuth2.0/OIDC 或 SSO 的需求。因此，本项目的任务是开发 Casdoor 相关的插件，SDK等形式，同时对 Casdoor 系统本身进行开发，增加新的功能，从而为其他开源软件提供更加便捷的 OAuth 2.0/OIDC 和单点登录的方案。",1. 开发插件、SDK等，支持更多的开源软件集成 Casdoor2. 开发 Casdoor 主仓库，为系统开发更多的功能，以满足其他开源软件的需求3. 对现有的插件和SDK仓库进行维护，并提供插件使用文档和插件索引文档，方便用户快速查看和使用插件4. 解决Casdoor主仓库&相关仓库中的issues：https://github.com/casdoor/casdoor/issues，数量方面，至少解决8个issue
基于agentUniverse多智能体框架的后台管理模块建设,进阶/Advanced,"[[""datas"",""AI""],[""datas"",""LLM""],[""dev"",""LLMOps""]]",agentUniverse项目为开发者轻松构建具备专业Knowhow的智能应用提供一系列关键能力，包括多智能体协同调度机制、单一智能体核心组件（LLM/工具插件/知识库/记忆模块等）、服务化注册体系以及应用级可观测性框架。为进一步提升项目用户的效能与体验，本项目将重点为用户提供可视化管控、智能化诊断、全链路可关键为一体的后台管理模块。该模块主要包含以下重点功能：1）智能体、组件、服务可视化展示功能该功能将提供统一的资源管理可视化能力，清晰的展示当前应用中所建设的智能体详情、组件详情（LLM/工具/知识库/记忆等）、智能体服务详情。2）智能体调用链路追踪与优化功能开发者可通过时序图、拓扑图等多种可视化形式，实时观测智能体交互流程，精准定位性能瓶颈。模块可进一步提供智能调优建议模块，基于链路分析结果自动生成优化方案。3）智能体应用监控与分析构建多维度监控指标体系，涵盖LLM调用频次、token消耗量、组件调用成功率、服务响应时间等关键KPI。通过实现历史观测数据与趋势预测，系统可提供异常检测分析、预警提示等能力。,1. 为agentUniverse多智能体框架的后台管理模块研发必要的管理页面与模块接口2. 提供必要的单元测试与测试报告3. 撰写设计与功能说明文档
基于 KubeSphere 实现 CodeSpace 功能,进阶,"[[""web"",""React""],[""web"",""npm""]]",项目目标基于 vscode-server 实现 Github CodeSpace 类似的 Online Web IDE 能力，为 KubeSphere 私有云环境提供服务增强；项目背景Github CodeSpace 是个非常有创新性的能力，它同时支持 DevContainer 协议，自动完成开发环境的部署，这对于团队新人非常友好，节省了环境准备的痛苦经历，把更多注意力集中在代码开发中。但是在私有云环境中，轻量级的 CodeSpace 在企业内部，特别是对于一些轻量级项目来说，非常实用方便；我们将通过此项目为 KubeSphere 提供 CodeSpace 支持；项目详情开发内容自定义 CRD 描述整个项目的配置仿照 DevContainer 自定义项目中配置文件配置开发 Operator 监控 CRD 配置，基于项目项目配置创建 DEV POD通过共享存储存储和保存项目源码技术实现使用 python 语言开发 Kubernetes Operator自定义 CRD 配置及 合理的默认值开发 Kubesphere 插件，实现简单前端界面支持项目至少为 python，java， nodejs 项目,"1. 使用 kopf 框架开发 Kubernetes Operator
1.1 编程语言: Python；开发框架: kopf
1.2 自定义 CRD 实现项目配置及适当的默认值
1.3 实现 Operator 核心逻辑并验证

2. 实现与 KubeSphere 控制台集成的 Web 前端界面
2.1：前端技术: JavaScript、React (与 KubeSphere 前端集成)
2.2：基于 Luban 框架实现与 KubeSphere 控制台集成

3. 文档支持
3.1 编写完整的项目文档和使用说明书
3.2 编写测试项目及测试步骤"
EventMesh operator完善与k8s组件集成,进阶,"[[""cloudnative"",""Kubernetes""]]",基于现有EventMesh operator完善它的功能，完成EventMesh runtime、connector、storage等组件的k8s部署与启动的功能，同时可以支持对接eventmesh dashboard后台进行管理，对已部署的EventMesh服务组件生命周期进行管理与维护。,1. 能够使用operator完成 eventmesh runtime、eventmesh connector、eventmesh storage等组件的k8s部署与编排2. 能够配合dashboard admin后端完成eventmesh各个组件集群的生命周期的管理
电力设备巡检大模型应用开发,进阶,"[[""datas"",""AI""],[""datas"",""Deep Learning""]]",基于昇思MindSpore对电力设备巡检图片进行缺陷检测，根据检测结果通过大模型给出运维建议。,1. 在Mindspore框架下训练缺陷检测检测、多模态模型对电力设备缺陷进行检测；2. 检测模型在Ascend硬件上进行部署；3. 设计大模型对检测结果进行运维分析。
Scanner support for the Printer Application framework PAPPL - Finalizing the API and integrating the components,Advanced,"[[""safe"",""TCP/IP""],[""os"",""Linux""]]","is a C-based framework used to implement Printer Applications, emulations of driverless IPP printers. Printer Application replace classic printer drivers in all-IPP environments where classic drivers are not supported any more (CUPS 3.x, Windows with WSL). They also allow sandboxed, OS-distribution-independent packaging of printer drivers, as they communicate only via network protocols and do not need to be located at a pre-defined place in the file system.While PAPPL currently focuses on printers, there is growing motivation to extend its capabilities to Scanner Applications, particularly for combined applications to support multi-function printers and also for sandboxed packaging of scanner drivers.The work done in Google Summer of Codeandlaid the foundation for scanning support in PAPPL. This includes:Despite this progress, the scanner support remains incomplete and not yet integrated into theupstream PAPPL repository.This project addresses the following gaps:This project will result in a reusable, tested, and documented API, allowing developers anddistributions to package Scanner Applications just like Printer Applications with PAPPL.","1. Implement and upstream scanner APIs as described in PAPPL issues #130, #131, #133, and #1342. Integrate previous years’ eSCL modules, dummy driver, and SANE retrofit into new APIs3. Develop and test a Scanner Application that supports both dummy and SANE backends4. Provide comprehensive unit tests and developer documentation"
为 SimpleKernel 添加 ACPI 支持,进阶,"[[""os"",""x86""],[""os"",""PIC""],[""os"",""QEMU""],[""os"",""GNU""]]",在 SimpleKernel 中集成 ACPI（Advanced Configuration and Power Interface）支持，并利用 ACPICA（ACPI Component Architecture）开源库实现硬件抽象、电源管理与设备枚举功能。,"1. 支持 ACPI 设备枚举。可加载并解析 RSDP/XSDT/FADT/MADT 等核心 ACPI 表。输出硬件信息（CPU、内存、中断控制器）
2. 支持 ACPI 电源操作（关机、重启、睡眠）
3. 在内核中集成 ACPICA。编译并集成 ACPICA 库到内核。实现 AML 解释器，支持 DSDT/SSDT 解析与设备控制"
迭代升级低代码建模语言UBML2.0融合生成式AI实现代码与模型双向转换,进阶,"[[""datas"",""AI""],[""codelang"",""Programming Language""]]",UBML（统一业务建模语言）是一种元级化低代码领域建模语言，具备语言无关、可扩展、全栈刻画应用能力，分六层低代码建模创建完整应用，当前深入用于低代码开发企业经营管理类应用。在UBML与生成式人工智能融合的过程中，我们计划升级UBML版本至2.0，实现“模型即代码，代码及模型”，增加代码转换为低代码模型，以便在与生成式AI融合过程中，实现由AI生成代码创建低代码模型。,1. 参与讨论制定UBML 2.0低代码模型标准，编写标准草案，提交PR通过评审合并至主分支。2. 参与“模型即代码，代码即模型”设计研讨，通过PR输出设计方案。3. 参与实现UBML 2.0代码模型双向转换模块编码，通过PR提交代码，通过代码审查合并至主分支。4. 完整完成项目任务。
提升版本发布体验,基础/Basic,"[[""dev"",""CI""],[""dev"",""CD""],[""dev"",""DevOps""]]","为 Opendal 项目提供更好的发布准备体验。目标是实现一个类似的流程，自动生成所有子项目的版本升级计划（release plan），并允许发布经理（Release Manager, RM）在计划文件中手动编辑和确认各个包的版本号。最终，RM 可通过命令一键执行整个发布计划，而无需逐个手动操作。",1. 实现 just release plan 命令，自动生成所有子项目的默认版本升级计划（如全部 bump patch 版本），并保存为 dist/release_plan.txt，同时输出到控制台。2. 支持 RM 编辑 release_plan.txt，讨论并确认最终发布计划。3. 实现 just release run 命令，自动根据 release_plan.txt 执行版本升级、提交变更并生成发布列表。4. 相关文档和使用说明。
面向Gemmini加速器的性能测试套件开发,进阶/Advanced,"[[""os"",""Compiler""],[""os"",""RISC-V""]]",面向 Gemmini 加速器的测试套件要求覆盖各类计算负载，软件栈被测对象包括：,1. 面向Gemmini加速器的性能测试套件2. 面向Gemmini加速器的性能测试套件使用文档
面向“香山”高性能处理器Spike参考模型的向量指令Agnostic写1策略的实现,基础,"[[""chip"",""Chip Design/Verification""]]",在开发“香山”开源处理器的过程中，我们主要依靠 Difftest 软件仿真框架进行功能调试，并使用NEMU和Spike作为参考模型和香山进行对比。但是，由于RISC-V指令集具有较大的实现自由度，Spike作为RISC-V的一种实现，其一些行为和“香山”没有对齐，从而会在比对时出现假阳性问题。一个较大的差异在于向量指令的Agnostic策略。对于含有Agnostic元素的向量指令，“香山”选择实现写1策略，而Spike选择保留原值策略。本项目旨在解决这一问题，为Spike指令集模拟器提供Agnostic写1的支持，从而实现和“香山”的对齐。,1. 在 OpenXiangShan/riscv-isa-sim 仓库主线上实现向量指令 Agnostic 元素写1策略2. 作为参考模型时，可以和 NEMU 以及 “香山” 通过 DiffTest
基于RISC-V 的RAID调研/测试及优化,进阶,"[[""os"",""Linux""],[""os"",""RISC-V""],[""os"",""QEMU""]]","1)目前已经基于RISC-V完成了raid6 PQ校验的Linux kernel加速（https://lore.kernel.org/lkml/20250305083707.74218-1-zhangchunyan@iscas.ac.cn/）此patch中包括了4种不同展开程度的算法实现，需要进行多平台测试。本项目目标为确定哪些级的展开实现是需要的。2)调研常见等级raid使用场景，有哪些是可应用于RISC-V数据中心场景（比如raid2，3, 4, 5, 10技术）;3)在所有适合用于RISC-V数据中心场景的raid技术中，有哪些是在RISC-V架构下具有优化空间的（比如raid2，3, 4, 5, 10技术在数据中加入的错误修正码，是如何计算得到的，基于RISC-V架构是否有加速空间）4)通过上面调研，如果发现有优化空间，基于RISC-V架构实现优化（比如：基于RISC-V向量扩展指令改写计算过程，对比通用指令有加速，即可证明有优化）。",1. 基于RISC-V硬件平台完成raid6 PQ校验测试，输出测试报告;2. 调研RAID哪些等级的技术适用于RISC-V数据中心场景，输出调研报告;3. 调研适用于RISC-V数据中心场景的raid技术中，有哪些部分可基于RISC-V扩展指令进行优化;4. 完成基于RISC-V的raid技术性能优化代码，形成补丁，并提交开源社区。
