1. 自监督学习:

模型会学习海量无标注数据，比如全网文本、书籍、文章等。
训练目标是让模型学会预测、补全信息，比如根据上下文猜下一个词，从而掌握语言规律、常识、知识关联等基础能力。
这个阶段不需要人工标注答案，模型自主从数据中挖掘规律，就像人大量读书积累知识的过程。
1. 监督式学习:

人工会给模型提供标注数据，即 “输入问题 + 标准回答” 的成对样本。
模型学习根据特定输入输出符合预期的结果，比如输入 “介绍人工智能”，就输出规范、准确的介绍内容。
这个阶段相当于有老师指导，纠正模型的输出偏差，让模型学会遵循人类的基本指令和输出规范。
1. 人类反馈强化学习:

先让模型输出多个答案，由人类对这些答案打分，标注出优劣。
基于人类的打分数据，训练一个 “奖励模型”，再用这个奖励模型指导原模型调整参数。
模型会不断优化，优先输出符合人类偏好的结果，比如更贴合需求、语气更自然、逻辑更清晰的内容。