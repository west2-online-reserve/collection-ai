# 生成式人工智能

## 1.自监督学习（Pre-training）

自监督学习就是机器自己可以通过爬虫爬取网页上的大量数据进行学习。这样就得到了一个基础模型，这个模型已经有了大量的数据，能够进行简单的文字接龙。但由于缺少监督，模型进行文字接龙的准确率很低，这时就需要监督学习了。

## 2.监督式学习（Supervised Fine-tuning）

监督式学习即让语言模型接受人类教师的指导。这个阶段，人类给大模型提供一个个问答对，然后，将这些问题与答案整理成适合语言模型训练的“文字接龙”格式，机器通过这些正确的问答来学习。

## 3.人类反馈强化学习（RLHF）

在这个阶段，人类对模型输入问题并收到多个回答，然后模型会询问：新答案和旧答案更好？当人类作出评价时，语言模型就得到了反馈。但是人类直接判断一个答案好不好很困难，因为语言的质量往往是相对的。所以需要奖励模型用来模拟人类。奖励模型先收集人类的偏好数据，再训练模型对每个答案打分，分数高的即为更可能被人类认可的答案。