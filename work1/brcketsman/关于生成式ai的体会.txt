大语言模型大体训练流程

第一阶段-自我学习:先主要利用爬虫通过网络学习语法结构和世界知识,以正确生成下一个词元(记得过滤一些有害或无意义的信息).但这不但有着一些道德和法律上的问题,效果也不够

第二阶段-指令微调:先要准备教材,让人类教师通过指令微调让机器学会正确回应(记得标注讲话角色提高准确率).可以利用适配器来进行微调.因为能提供的数据有限,没法直接进行人类教学,所以才先有第一阶段的预训练,以提供更复杂的规则.
    预训练后有两条路:
    第一条是专注于一个任务.通过大量相近的数据来让其自我学习,在某一些任务上体现的非常强大
    第二条是使模型一次学会多种能力.通过收集所有可能的任务数据,甚至未出现过的数据,让其能专注较多的任务
(穿插:可以通过逆向工程获取ai的训练数据,尽管质量不高)

第三阶段-人类反馈强化学习(与用户互动):让用户在与模型互动中可以收集数据(例:如果用户不满意,让其重新生成,可以询问用户哪个回答更好).通过了解哪个反馈更有效果,优化输出结果的质量.相比第二阶段,第三阶段只要选择哪个回答更好,减少了人类的负担.同时可以利用奖励模型虚拟人类,可以让ai拜托人类自我强化学习,但也可能导致语句过于有指向性.未来有期望期望可能能让AI训练AI.但强化学习仍然面对着"标准不同"这一根本问题
