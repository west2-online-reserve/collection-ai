# leegenai-tutorial

## 一、什么是生成式 AI？

我理解的生成式 AI（GAI）是：**让机器能够产生复杂、有结构的内容**。它不像传统分类问题那样从有限选项里挑一个，而是要从近乎无限的可能性里生成结果。

为了做到这一点，现代模型（如 ChatGPT）把“生成”拆解成**逐字预测**的过程，也就是“文字接龙”。每一步都只是从词表里挑一个词，但累积起来就能写出完整的句子或文章。

同时，GAI 的技术基础几乎都来自深度学习（DL）与 Transformer 架构。它们通过大量参数和训练，让模型学会语言模式与世界知识。

## 二、GAI 有哪些特点？

过去的 AI 更像工具；现在的生成式 AI 更像一个“通才”，功能是开放的，关键在于你给它什么指令。

在使用模型时，我发现几件事特别重要：

- **它愿意帮你才会犯错**：幻觉不是故意的，而是因为它试着满足你的要求。
- **提示词很关键**：像“step by step”、“你要非常谨慎”等“咒语”，往往会改变它的表现。
- **模型会随着时代演进，对提示词的依赖不同**：旧模型需要思维链（CoT）帮助，新模型很多逻辑本来就能推。
- **给它更多资讯与范例（ICL）很有效**：尤其是在你想让模型做某种特定风格或格式的任务时。

## 三、如何让模型生成更好的内容？

我常用的方法可以分成几类：

1. **拆解任务**
   不要一次让模型做太多事情。先写大纲，再写段落，再总结。模型对“步骤化任务”特别敏感。

2. **让模型检查自己**
   让它写完后再“检查一下是否有误”，很多时候准确度会提高。像 GPT-4 就有类似自我反省能力。

3. **利用随机性**
   同一问题让模型回答多次，再取最多的答案。

4. **结合策略：Tree of Thought（ToT）**
   拆解任务、多次生成、自我检查，组合起来能大幅提升复杂问题的表现。

5. **让模型使用工具**
   当它做不到的事（例如复杂计算、查资料）就让它调用工具（搜索、写代码、查数据库）。这就是 RAG 与函数调用的核心思想。

## 四、推理长度：越长越好吗？

我原本以为推理越长越好（甚至尝试过用神秘提示词去给 gpt-5-auto 开 2000 的 juice），但**并不是**。

对同一问题多次提问后再比较：

* 最长推理 vs 最短推理：**正确率差不多**。
* 很多冗长推理其实是“废话”，不是有意义的推断。

因此现在的方向是：

* 限制推理长度（如 Chain of Draft）
* 用 RL 奖励“短而正确的推理”
* 鼓励模型学会“心算”，不用都写出来

## 五、什么是“推理模型”？

像 DeepSeek-R1 之类的“推理模型”，本质上是：

- 在回答前会进行一段较长的内部思考（think block）
- 过程中会探索、验证、规划
- 追求在**测试阶段增加更多算力**来换取更强表现

构建推理模型，可以用：

* **CoT 训练**（模仿思考过程）
* **多次采样 + 验证器**（Best-of-N）
* **过程验证**（检查中间步骤）
* **模仿学习 + 数据飞轮**（让模型自己产推理数据）
* **强化学习（RL）**（只看最终答案）

这些方法都围绕着“让模型更会想”，而不是“更会写”。

## 六、AI 智能体（Agent）：模型开始“行动”

AI Agent 的概念对我影响很大。它不只是回答，而是：

1. 接受目标
2. 观察环境
3. 决定动作
4. 执行动作
5. 回到第 2 步循环

使用 LLM 做 Agent 的强大之处在于：

-（ 动作不限于有限集合，任何文字都能成为行动指令。
- 不用训练奖励函数（不像传统 RL）。
- 它能看懂环境回传的错误与反馈。